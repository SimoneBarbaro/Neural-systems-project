,doc_id,result_id,text
0,232756,0,"Observation learning induces rapid auditory discrimination: \n During a pre-training phase, experimenters (EXP) were accustomed to air-puffs that followed one of two auditory stimuli of different duration. Then a training phase followed, during which we exposed EXP to the full training set of 10 auditory stimuli (Fig.�2a left panel and Supplementary methods). Gradually, EXP learned to escape from the perch more often in puffed trials; their escape probabilities (cumulated from trial onset to trial end) became larger on puffed trials than on unpuffed trials (Fig.�2b left and right). We quantified the birds� ability to discriminate stimulus class by the difference in (cumulative) escape probabilities (dPesc) between puffed and unpuffed trials (Fig.�2b, c, d, e). EXP attained a statistical performance criterion (based on the perching behavior in the most recent 800 trials,�see Methods and Supplementary Figure�1d) after 4700 [800, 10500] trials (median [range], n?=?10 birds). This criterion defined the end of the training phase, at which time EXP displayed a dPesc of 0.35 [0.27, 0.46] (median [range], dPesc averaged over the last 3 blocks of training, including the criterion block). After the training phase (or observation phase for observers), the experimenter was replaced by the observer (OBS) and a naive bird was placed in the observer�s cage. Then we began testing the OBS using the same pre-training and training paradigms it was previously allowed to observe. We refer to the training of observers as testing, Fig.�2a right panel. \n  At the beginning of the testing phase (first 3 testing blocks), OBS displayed a significantly higher discrimination performance than EXP at the beginning of their training phase (dPesc in first 300 trials: EXP (n?=?10) 0.2 [0 0.32], OBS (n?=?9) 0.4 [0.16 0.64]; EXP � OBS, median difference?=??0.22, p?=?0.013, test statistic?=?15; two-sided Wilcoxon rank sum test; 95% CI?=?[-Inf ?0.1]), Fig.�2d. Surprisingly, OBS� initial performance was no worse than that of EXP who had reached the learning criterion (average initial dPesc?=?0.40 in n?=?9 OBS vs average final dPesc?=?0.36 in n?=?10 EXP). OBS reached the performance criterion nearly instantaneously, in only 900 [800, 5600] trials (median [range], n?=?9 birds), less than a third of the trials required by EXP (two-sided Wilcoxon rank sum test with alternative hypothesis: EXP ? OBS, median difference?=?3100, p?=?0.015 (not exact), test statistic?=?75; 95% CI not computed because of ties), Fig.�2f. After reaching the criterion, OBS showed a significantly higher discrimination performance than EXP (dPesc at criterion in OBS?=?0.46 [0.29, 0.65]; EXP � OBS, median difference=??0.17, p?=?0.005, test statistic?=?12; two-sided Wilcoxon rank sum test; 95% CI?=?[?0.2 ?0.031]), Fig.�2e."
1,232756,1," Observers generalize poorly compared to experimenters \n  To compare generalization in experimenters and observers, first, we allowed generalization observers (GENOBS) to watch generalization experimenters (GENEXP) learn to discriminate the stimuli in the training set, after which we tested both groups of birds on the generalization set of stimuli, Fig.�3a. Contrary to our findings on the training set, GENOBS initially showed significantly poorer discrimination on the generalization set (average dPesc over the first 3 blocks (median [range]) in GENEXP: 0.41 [0.34, 0.6] and in GENOBS: 0.2 [?0.02, 0.54]; GENEXP � GENOBS, median difference?=?0.24, p?=?0.019, test statistic?=?67, two-sided Wilcoxon rank sum test, 95% CI?=?[0.016, 0.36]), Fig.�3b, c. GENOBS also took more time than GENEXP to reach criterion (3600 [800, 13300] trials in n?=?9 GENOBS versus 800 [800, 2200] trials in n?=?9 GENEXP; GENEXP�GENOBS median difference�?=??2800, p?=?0.006 (not exact), test statistic?=?10, two-sided Wilcoxon rank sum test; 95% CI not computed because of ties), Fig.�3d. \n  GENOBS needed more trials to reach the learning criterion than did OBS (GENOBS�OBS, median difference?=?2100 trials, p?=?0.044, test statistic?=?63.5, two-sided Wilcoxon rank sum test), demonstrating that observers reacted to small differences between stimuli from the training and generalization sets. Thus, overall, observers seemed to associate the perch-escape behaviors by experimenters much more exclusively with the presented auditory stimuli than did the experimenters themselves, who associated the air puffs inclusively with the stimuli (to include similar stimuli from the generalization set). \n  We inspected the escape behaviors of observers and experimenters. We found that after reaching the learning criterion, EXP and OBS displayed similar perch escape strategies. That is, they tended to abruptly increase their perch escape rates just before air-puff onsets (Supplementary Figure�2a, b), suggesting that birds responded by learning to escape the air puffs rather than by learning to stay when no puff was imminent."
2,232756,2," Observers do not learn through passive perceptual processes \n  We set out to characterize the requirements for observation learning. To test whether observers learned from experimenters� actions in response to the air-puffs, we allowed experimenter and observer pairs to experience several thousand (mean?�?standard deviation?=?7.5?�?3.6*103) stimulus playbacks including the sound of air-puffs, but not the tactile sensation of the puffs. We realized this perceptual paradigm by directing the air outlet away from the experimenters, Fig.�4a. Consequently, experimenters never experienced the air-puff as a force against their body. We refer to observers in such pairs as perceptual learners (PLs), because they could potentially learn from the pairing of stimuli with air-puff sounds. \n  Experimenters in this perceptual paradigm never produced dPesc values different from 0 (average dPesc after 5000 training trials in 3 experimenters: [?0.065, ?0.002, 0.007], p?=?0.81, p?=?0.25, p?=?0.64, respectively; z-test of individual proportions), hence they did not show the discriminative behavior that we suspected would drive learning in observers. When we tested PLs (n?=?7 birds) with air-puffs directed at them, they needed significantly more trials to reach criterion than OBS (4200 [1800, 20,300] trials in PLs versus 900 [800, 5600] in OBS; OBS � PL median difference?=??2400; two-sided Wilcoxon rank sum test of alternative hypothesis PL ? OBS, p?=?0.016 (not exact), test statistic?=?8.5; 95% CI not computed because of ties), Fig.�4e. PLs were slower than OBS even after removing an outlier bird (trials to criterion?=?20300) in the PL group (median difference?=???2389,�p?=?0.032 (not exact), test statistic = 8.5, 95% C.I not computed). PL performance at criterion was comparable to OBS performance (0.33 [0.064, 0.63] in PL versus 0.46 [0.29, 0.65] in OBS; OBS- PL; median difference?=?0.16, p?=?0.142, test statistic?=?46, two-sided Wilcoxon rank sum test, 95% CI?=?[?0.077 0.338]) and was not statistically different from performance in EXP (EXP � PL; median difference?=?0.06, p?=?0.41, test statistic?=?26, 95% C.I?=?[?0.2 0.2], two-sided Wilcoxon rank sum test). The absence of rapid learning in PLs suggests that learning in OBS required an experimenter engaged in the task and responding to air puffs."
3,232756,3," Observers do not learn from naive experimenters \n  We expected observation learning to be most effective when information is provided by an expert. To probe for sensitivity to experimenter performance, we tested a group of Valence Learners (VLs, n?=?5) that observed naïve experimenters who did not reach the performance criterion within (on average) 5600 [4360, 11436] trials. These naïve experimenters were hit by air puffs on average 539 times out of 1000 puffed trials, and escaped in unpuffed trials on average on 400/1000 trials. In addition, to give VLs direct experience of the reinforcer (its valence), 3/5 of these VL birds were initially exposed to air puffs (approximately 500 strong 1-s air puffs, see Methods). When tested, VLs were much slower than OBS to reach the learning criterion (trials to criterion in VL [n?=?5], median [range]: 6700 [6200, 12,100] versus OBS [n?=?9]:900 [800, 5600]; OBS�VL median difference?=??5500, two-sided Wilcoxon rank sum test of alternative hypothesis VL ? OBS, p?=?0.006 (not exact), test statistic?=?0, 95% CI not computed), Fig.�4e. The performance of VLs at criterion was lower than the performance of OBS (dPesc for VL [n?=?5]: 0.26 [0.13, 0.45] versus for OBS [n?=?9]:0.46 [0.29, 0.65], median difference =?0.21, p?=?0.007, test statistic?=?42, two-sided Wilcoxon rank sum test, 95% CI?=?[0.034 0.355]), and there was a trend of lower performance in VL compared to EXP (VL�EXP, median difference?=??0.11, p?=?0.07, test statistic?=?10, 95% C.I?=?[?0.21 0.05], two-sided Wilcoxon rank sum test). The poor testing results in VLs suggest that OBS did not learn by predicting the reward value experienced by EXP�and by converting this prediction into an optimal action during testing. Instead, VL behavior suggests that OBS focus on experimenters� discriminative actions, which must necessarily contain the information required for observation learning. In combination, PLs and VLs emphasize the importance of experimenters� discriminative actions for observation learning."
4,232756,4," Vocal exchanges are not required for observation learning \n  Given the importance of experimenter actions, we speculated that rapid learning in OBS could depend on vocal exchanges between EXP and OBS through calls occurring during and following stimulus presentation, Fig.�4c. Indeed, on the last day of the training phase, when EXP had reached the learning criterion, we found a difference in calling behavior between puffed and unpuffed trials. In six EXP-OBS pairs (on one day each), we inspected calling rates (defined as the probability of observing at least one call) during the stimulus period (from stimulus onset to stimulus offset) and during the delay period (defined from stimulus offset to air-puff onset), Fig.�4d. In puffed trials, the calling rate was lower in the delay period than in the stimulus period: stim call probability 0.44 [0.14, 0.88] vs delay call probability 0.27 [0.07, 0.45], median difference (Delay � Stim) ?0.15, p?=?3.8*10?6, test statistic?=?0, two-sided Wilcoxon sign rank test, n?=?6 EXP-OBS pairs. In unpuffed trials, there was merely a trend of reduced calling during the delay period: stim call probability 0.35 [0.08, 0.65] vs delay call probability 0.36 [0.16, 0.91], median difference 0.08 (Delay � Stim), p?=?0.052, test statistic?=?327, two-sided Wilcoxon sign rank test, n?=?6 EXP-OBS pair. In combination, the reduction in calling rate was much more pronounced during puffed trials: difference in median call probabilities for puffed (Delay � Stim) � unpuffed (Delay � Stim)?=??0.23, p?=?10?6, test statistic?=?592, two-sided Wilcoxon rank sum test, n?=?6 EXP-OBS pairs). Hence, the significant reduction in calling rates during puffed trials could signal the imminent arrival of an air puff. \n  To test whether observers used calls as a learning cue, we housed experimenters and observers (n?=?5 pairs) in separate soundproof boxes and gave them visual access to each other by virtue of two adjacent windows. Moreover, to trigger social interest, we allowed birds to vocally interact with each other using a custom digital communication system composed of two microphones and loudspeakers and an echo cancellation filter (Supplementary methods). We suppressed vocal exchanges during stimulus presentation by interrupting the communication system from stimulus onset to air-puff offset. We termed the observers in this paradigm no-trial-communication learners (-TCOM). Despite elimination of vocal interactions during the discrimination task, we found that -TCOM acquired stimulus-discriminative information in amounts comparable to OBS (trials to criterion: -TCOM (n?=?5): 800 [800, 4900]; OBS (n?=?9): 900 [800, 5600]; OBS � TCOM�median difference ?=?0.00001, p?=?0.77, test statistic?=?25, two-sided Wilcoxon rank sum test, 95% CI?=?[?1200 2300]), Fig.�4e. Hence, it follows that OBS did not require immediate vocal interactions. They could learn from visual displays only or from vocal exchanges following trials."
5,232756,5," Regularized logistic regression differentiates OBS from EXP \n  Observer behavior was reminiscent of a machine learning system that overfits the training data and generalizes poorly because it contains too many parameters and is trained on too few examples. In this sense, observers seemed to lack regularization, which is an umbrella term for all kinds of processes that prevent overfitting by introducing additional information, for example to use as few nonzero parameters as possible during fitting. Essentially, regularization methods improve generalization performance by dynamically regulating the use of parameters and of training data16,17. \n  In the context of our findings, these insights from statistical learning theory suggest that direct experience of the reinforcing learning cue is associated with regularization whereas observation is not. We tested the hypothesis that regularization could set the divide between experimenter and observer behaviors, by training a simple artificial neuron with a logistic activation function to discriminate between the two stimulus sets, Fig.�5a. The neuron received input from a group of at least 22 input neurons tuned to diverse sound features such as amplitude, pitch, duration, and Wiener Entropy, collectively defining the feature set used in Sound Analysis Pro (SAP), a popular birdsong analysis software18 (Supplementary Figure�4 and Supplementary Table�1). To model observers, we trained the neuron to fire during puffed stimuli and to remain silent during unpuffed stimuli. We used a gradient descent learning rule that maximizes the likelihood of correct discrimination (Methods). We found that the discriminative performance of the �observer� neuron increased rapidly to the theoretical limit on the training set, but when we interrupted the training at any time and evaluated the neuron�s performance on the testing set, we found poor generalization, Fig.�5b. The reason for poor generalization was that the neuron based its classification on exceedingly many sound features that by chance were slightly informative about the reinforcing air-puff, Fig.�5e and Supplementary Figure�4. \n  We then modeled experimenters by endowing the learning rule with L1 regularization. L1 regularization implements a conjunctive minimization of summed absolute synaptic weights17 that we implemented at each synaptic weight update as a small reduction of synaptic weights by an amount ?19. We used L1 regularization because it is very simple (subtractive) and because it allowed us to formulate a mechanism that dynamically regulates the regularization parameter ? in proportion to reward prediction error (Methods), known to be signaled in the vertebrate brain by a class of dopaminergic neurons20�22. According to our proposal, regularization (weight reduction) increases when the bird suddenly receives less reward than expected, as in experimenters that get hit by an air puff for the first time. Our proposed mechanism is such that when experimenters reach a high rate of success, the reward prediction error reaches zero in expectation, which settles the value of ?, Fig.�5c. The observer brain would not modulate ? because observers do not directly experience rewards and punishments during the experimenter training phase. \n  We found that interrupting the training process of the regularized neuron at any time resulted in roughly equal performances on both training and testing stimulus sets, Fig.�5d, similar to experimenters� behavior. However, the excellent generalization performance came at a cost: Because of the repeated reductions of synaptic weights in modeled experimenters, their synaptic weights and performance on the training set grew only slowly. The main effect of regularization was to concentrate the final synaptic weights on the duration feature, corresponding with our design of stimulus class, Fig.�5e. \n  We tested other explanations for the differences between experimenters and observers, such as assuming that observers learned from noisy experimenter actions, but found regularization to be the only mechanism that achieved satisfactory simulations results�(Supplementary Figure 5)."
6,1789181,0,"In this section, we first present the classification results of the proposed SOM-SNN framework for the two benchmark datasets and then compare them with other baseline models. Next, we discuss its early decision-making capability, the effectiveness of using the SOM for feature representation and its underlying hyperparameters, as well as the key differences between the feedforward SNN-based and RNN-based systems for a temporal classification task. Finally, we demonstrate the improved classification capability of the modified Maximum-Margin Tempotron learning rule and the robustness of the framework against environmental and neuronal noises."
7,1789181,1," 3.1. Classification results \n 3.1.1. RWCP dataset \n  As shown in Table ?Table1,1, the SOM-SNN model achieved a test accuracy of 99.60%, which is competitive compared with other deep learning and SNN-based models. As described in the experimental set-up, the MLP and CNN models are trained using spectrogram images of fixed dimensions, instead of explicitly modeling the temporal transition of frames. Despite their high accuracy on this dataset, it may be challenging to use them for classifying sound samples of long duration; the temporal structures will be affected inconsistently due to the necessary rescaling of the spectrogram images (Gütig and Sompolinsky, 2009). On the other hand, the RNN and LSTM models capture the temporal transition explicitly. These models are however hard to train for long sound samples due to the vanishing and exploding gradient problem (Greff et al., 2017). \n  LSF-SNN (Dennis et al., 2013) and LTF-SNN (Xiao et al., 2017) classify the sound samples by first detecting the spectral features in the power spectrogram, and then encoding these features into a spatiotemporal spike pattern for classification by a SNN classifier. In our framework, the SOM is used to learn the key features embedded in the acoustic signals in an unsupervised manner, which is more biologically plausible. Neurons in the SOM become selective to specific spectral features after training, and these features learned by the SOM are more discriminative as shown by the superior SOM-SNN classification accuracy compared with the LSF-SNN and LTF-SNN models."
8,1789181,2," 3.1.2. Tidigits dataset \n  As shown in Table ?Table2,2, it is encouraging to note that the SOM-SNN framework achieves an accuracy of 97.40%, outperforming all other bio-inspired systems on the TIDIGITS dataset. In Anumula et al. (2018), Abdollahi and Liu (2011), and Neil and Liu (2016), novel systems are designed to work with spike streams generated directly from the AER silicon cochlea sensor. This event-driven auditory front-end generates spike streams asynchronously from 64 bandpass filters spanning over the audible range of the human cochlea. Anumula et al. (Abdollahi and Liu, 2011) provide a comprehensive overview of the asynchronous and synchronous features generated from these raw spike streams, once again highlighting the significant role of discriminative feature representation in speech recognition tasks. \n  Tavanaei et al. (Tavanaei and Maida, 2017a,b) proposes two biologically plausible feature extractors constructed from SNNs trained using the unsupervised spike-timing-dependent plasticity (STDP) learning rule. The neuronal activations in the feature extraction layer are then transformed into a real-valued feature vector and used to train a traditional classifier, such as the HMM or SVM models. In our work, the features are extracted using the SOM and then used to train a biologically plausible SNN classifier. These different biologically inspired systems represent an important step toward an end-to-end SNN-based automatic speech recognition system. \n  We note that the traditional RNN based system offers a competitive accuracy of 97.90% (Anumula et al., 2018); our proposed framework, however, is fundamentally different from traditional deep learning approaches. It is worth noting that the network capacity and classification accuracy of our framework can be further improved using multi-layer SNNs."
9,1789181,3," 3.2. Early decision making capability \n  We note that the SNN-based classifier can identify temporal features within the spatiotemporal spike pattern and generate an output spike as soon as enough discriminative evidence is accumulated. This cumulative decision-making process is more biologically plausible, as it mimics how human makes decisions. A key benefit of such a decision-making process is low latency. As shown in Figure ?Figure3A,3A, the SNN classifier makes a decision before the whole pattern has been presented. On average, the decision is made when only 50% of the input is presented. \n  Additionally, we conduct experiments on the SOM-SNN, RNN, and LSTM models, whereby they are trained on the full input patterns but tested with only a partial presentation of the input. The training label is provided to the RNN and LSTM models at the end of each training sequence by default as it is not clear beforehand when enough discriminative features have been accumulated. Likewise, the training labels are provided at the end of input patterns for the SNN classifier. For testing, we increase the duration of the test input pattern presented from 10 to 100% of the actual duration, starting from the beginning of each pattern. As shown in Figure ?Figure6B,6B, the classification accuracy as a function of the input pattern percentage increases more rapidly for the SNN model. It achieves a satisfactory accuracy of 95.1% when only 50% of the input pattern is presented, much higher than the 25.7 and 69.2% accuracy achieved by the RNN and LSTM models respectively. For the RNN and LSTM models to achieve early decision-making capability, one may require that the models be trained with partial inputs or output labels provided at every time-step. Therefore, SNN-based classifiers demonstrate great potential for real-time temporal pattern classification, compared with state-of-the-art deep learning models such as the RNN and LSTM."
10,1789181,4," 3.3. Feature representation of the SOM \n  To visualize the features extracted by the SOM, we plot the BMU activation sequences and their corresponding trajectories on the SOM for a set of randomly selected samples from class �bell5,� �bottle1,� and �buzzer� in Figure ?Figure4.4. We observe low intra-class variability and high inter-class variability in both the BMU activation trajectories and sequences, which are highly desirable for pattern classification. Furthermore, we perform tSNE clustering on the concatenated input vectors entering the SOM and the BMU trajectories generated by the SOM. In Figure ?Figure5A5A (input vectors entering the SOM), it can be seen that samples from the same class are distributed over several clusters in 2D space (e.g., class 7, 10). The corresponding BMU vectors, however, merge into a single cluster as shown in Figure ?Figure5B,5B, suggesting lower intra-class variability achieved by the SOM. The class boundaries for the BMU trajectories may now be drawn as shown in Figure ?Figure5B,5B, suggesting high inter-class variability. The outliers in Figure ?Figure5B5B maybe an artifact due to the uniform rescaling performed on BMU trajectories, a necessary step for tSNE clustering. \n  We note that the time-warping problem exists in the BMU activation sequences, whereby the duration of sensory stimuli fluctuates from sample to sample within the same class. However, the SNN-based classifier is robust to such fluctuations as shown in the classification results. The decision to fire for a classifying neuron is made based on a time snippet of the spiking pattern; such is the nature of the single spike-based temporal classifier. As long as the BMU activation sequence stays similar, duration fluctuations of input sample will not affect the general trajectory of the membrane potential in each output neuron; the right classification decision, therefore, can be guaranteed. Hence, those outliers in Figure ?Figure5B5B underlying the time-warping problem may not necessarily lead to poor classification. \n  To investigate whether the feature dimension reduction of the SOM is necessary for the SNN classifier to learn different sound categories, we performed experiments that directly input the spike trains of the latency-encoded (20 neurons) (Yu et al., 2013b) or population-encoded (144 neurons) (Bohte et al., 2002) mel-scaled filter bank outputs into the SNN for classification. We find that the SNN classifier is unable to classify such low-level spatiotemporal spike patterns, and only achieve 10.2 and 46.5% classification accuracy for latency- and population-encoded spike patterns, respectively. For both latency- and population-encoded spike patterns, as all encoding neurons spike in every sound frame, albeit with different timing, the synaptic weights therefore either all strengthen or all weaken in the event of misclassification as defined in the Tempotron learning rule. Such synchronized weight updates make it challenging for the SNN classifier to find discriminative features embedded within the spike pattern. \n  As summarized in the section 1, the learning rules for the SNN can be categorized into either membrane-potential based or spike-time based; the Maximum-Margin Tempotron learning rule belongs to the former. To study the synergy between the SOM-based feature representation and spike-time based learning rule, we conducted an experiment using the ReSuMe (Ponulak and Kasi?ski, 2010) learning rule to train the SNN classifier. For a fair comparison with the Maximum-Margin Tempotron learning rule, we use one output neuron to represent each sound class and each neuron has a single desired output spike. To determine the desired spike timing for each output neuron, we first present all training spiking patterns from the corresponding sound class to the randomly initialized SNN; and monitor the membrane potential trace of the desired output neuron during the simulation. We note the time instant when the membrane potential trace reaches its maximum (denoted as Tmax) for each sound sample, revealing the most discriminative local temporal feature. We then use the mean of Tmax across all 20 training samples as the desired output spike time. As shown in Table ?Table1,1, the SNN trained with ReSuMe rule achieves a classification accuracy of 97.0%, which is competitive with other models. This, therefore, demonstrates the compatibility of features extracted by the SOM and spike-time based learning rules, whereby the intra-class variability of sound samples is circumvented by SOM feature extraction such that a single desired spike time for each class suffices. \n  We note that the SOM functions as an unsupervised sparse feature extractor that provides useful, discriminative input to downstream ANN classifiers. As shown in Table ?Table1,1, the classification accuracy of the SOM-RNN model is better than that of the RNN model alone, and the accuracy of the SOM-LSTM model is also comparable to that of the LSTM model. Additionally, we also notice faster training convergence for both the SOM-RNN and SOM-LSTM models compared to those without the SOM, requiring approximately 25% less number of epochs. This observation may be best explained by the observations made in Figure ?Figure4,4, whereby only a subset of the SOM neurons are involved in the spiking patterns of any sound sample (with low intra-class variability and high inter-class variability) which in itself is highly discriminative. \n  To analyze the effect of different hyperparameters in the SOM on classification accuracy, we perform the following experiments: \n  Neural Map Size. We sweep the SOM neural map size from 2 × 2 to 16 × 16. As shown in Figure ?Figure6,6, we notice improved SNN classification accuracy with larger neural map, which suggests that a larger SOM captures more discriminative features and therefore generates more discriminative spiking patterns for different sound classes. However, the accuracy plateaus once the number of neurons exceeds 120. We suspect that with more neurons the effect of the time-warping problem starts to dominate, leading to more misclassification. Hence, the optimum neural map size has to be empirically determined. \n  Number of Training Epochs. We sweep the number of training epochs used for the SOM from 100 to 1,000 with an interval of 100. We observe improvements in classification accuracy of the SNN classifier, with more training epochs of the SOM, which plateaus at 400 for the RWCP dataset. \n  Number of Activated Neurons. We perform experiments with different number of activated output neurons K = [1, 2, 3] for each sound frame. Specifically, the distances between the SOM output neurons' synaptic weight vectors and the input vector are computed, and the top K neurons with the closest weight vectors will emit a spike. The neural map sizes are swept from 2 × 2 to 16 × 16, with number of training epochs fixed at 400. As shown in Figure ?Figure6,6, with more activated output neurons in the SOM, the SNN achieves lower classification accuracy for neural map size below 100, while achieving higher accuracy for neural map size larger than that. It can be explained by the fact that for smaller neural maps, given the same number of feature clusters, fewer neurons are allocated to each cluster. Now, with more activated neurons per frame, either fewer clusters can be represented, or the clusters are now less distinguishable from each other. Either way, inter-class variability is reduced, and classification accuracy is adversely affected. This capacity constraint is alleviated with a larger neural map, whereby neighboring neurons are usually grouped into a single feature cluster. As shown in the inset of Figure ?Figure6,6, for neural map size larger than 100, more activated neurons per frame improves the feature representation with some redundancy and lead to better classification accuracy. However, it should be noted that with more activated neurons per frame, there are more output spikes generated in the SOM, hence increasing energy consumption. Therefore, a trade-off between classification accuracy and energy consumption has to be made for practical applications."
11,1789181,5," 3.4. Tempotron learning rule with hard maximum-margin \n  As described in section 2, we modify the original Tempotron learning rule by adding a hard margin ? to the firing threshold Vthr. With this modification, we note that the classification accuracy of the SNN increases by 2% consistently with the same SOM dimensions. \n  To demonstrate how the hard margin ? improves classification, we show two samples which have been misclassified by the SNN classifier trained with the original Tempotron rule (Figures 7A,B), but correctly classified by the Maximum-Margin Tempotron rule (Figures 7C,D). In Figure ?Figure7A,7A, both output neurons (i.e., �ring� and �bottle1�) are selective to the discriminative local feature occurring between 2 and 10 ms. While in Figure ?Figure7B,7B, the discriminative local feature is overlooked by the desired output neuron, possibly due to the time-warping, and the output neuron representing another class fires erroneously afterward. \n  When trained with the additional hard margin ?, the negative output neuron representing the �bottle1� class is suppressed and prevented from firing (Figure ?(Figure7C).7C). Similarly, the negative output neuron representing the �metal15� class is also slightly suppressed, while the positive output neuron representing the �kara� class undergoes LTP and correctly crosses the Vthr (Figure ?(Figure7D).7D). Therefore, the additional hard margin ? ensures a better separation between the positive and negative classes and improves classification accuracy. \n  Since the relative ratio between the hard margin ? and the firing threshold Vthr is an important hyper-parameter, we investigate its effect on the classification accuracy using the RWCP dataset by sweeping it from 0 to 1.2 with an interval of 0.1. The experiments are repeated 20 times for each ratio value with random weight initialization. For simplicity, we only study the symmetric cases whereby the hard margin has the same absolute value for both positive and negative neurons. For the case when the ratio is 0, the learning rule is reduced to the standard Tempotron rule. As shown in Figure ?Figure8,8, the hard margin ? improves the classification accuracy consistently for ratios below 1.0, and the best accuracy is achieved with a ratio of 0.5. The accuracy drops significantly for ratio above 0.9, suggesting a high level of margin may interfere with learning and lead to brittle models."
12,1789181,6," 3.5. Robustness to noise \n 3.5.1. Environmental noise \n  We report the classification accuracies over 10 runs with random weight initialization in Tables ?Tables3,3, ?,44 for mismatched and multi-condition training respectively. \n  We note that under the mismatched condition, the classification accuracy for all models degrades dramatically with an increasing amount of noise and falls below 50% with SNR at 10 dB. The LSF-SNN and LTF-SNN models use local key points on the spectrogram as features to represent the sound sample, and are therefore robust to noise under such conditions. However, the biological evidence for such spectrogram features is currently lacking."
13,1789181,7," 3.5.2. Spike jittering As shown in Table ?Table4,4, multi-condition training effectively addresses the problem of performance degradation under noisy conditions, whereby MLP, CNN, LSTM, and SOM-SNN models have achieved classification accuracies above 95% even at the challenging 0 dB SNR. Similar to observations made in McLoughlin et al. (2015), we note that the improved robustness to noise comes with a trade-off in terms of accuracy for clean sounds, as demonstrated in the results for the ANN models. However, the classification accuracies improve across the board for the SOM-SNN model under all acoustic conditions using the multi-condition training, achieving an accuracy of 98.7% even for the challenging case of -5 dB SNR. The SOM-SNN model hence offers an attractive alternative to other models especially when a single trained model has to operate under varying noise levels. \n  3.5.2. Spike jittering \n  As shown in Figure ?Figure9A,9A, the SOM-SNN model is shown to be highly robust to spike jittering and maintains a high accuracy independent of the number of neurons activated per sound frame in the SOM. We suspect that given only a small subset of neurons in the SOM are involved for each sound class, the requirement of the SNN for precise spike timing is relaxed."
14,1789181,8," 3.5.3. Spike deletion \n  As shown in Figure ?Figure9B,9B, the SOM-SNN model maintains a high classification accuracy when spike deletion is performed on the input to the SNN. As only a small subset of pre-synaptic neurons in the SOM deliver input spikes to the SNN for each sound class, with high inter-class variability, the SNN classifier is still able to classify correctly even with some input spike deletion. The peak membrane potential value is used in some cases to make the correct classification."
15,271920,0,"Sound-to-symbol mapping learning outcomes \n When learning outcomes were examined in all bilinguals and monolinguals, including individuals who performed below 65% accuracy, statistically equivalent performance was found between bilinguals' post-training accuracy (M = 71.5%, SD = 16.3) and monolinguals' post-training accuracy (M = 76.1%, SD = 13.1), t(65) = 1.2, p > 0.1. However, a chi-squared test examining the distribution of low-accuracy performers (<65%) across bilinguals and monolinguals was marginally significant, Chi-Squared (df = 1) = 3.8, p = 0.051, suggesting different distributions of lower learning outcomes in the bilinguals vs. monolinguals (see Participants Section). Nonparametric independent samples Mann�Whitney U tests suggested that the bilingual learners and non-learners differed on post-training and overall processing accuracies (ps < 0.001), showed a marginal difference on numbers reversed performance (p = 0.076, learners: M = 16.9, SE = 0.7; non-learners: M = 14.5, SE = 1.2), but did not differ on the remaining language history, cognitive, and linguistic measures listed in Table ?Table11. \n  When participants with overall accuracy below 65% were excluded, bilinguals (n = 27) and monolinguals (n = 27) reached similar post-training accuracies (monolinguals: M = 77.6%, SE = 2.2; bilinguals: M = 77.1%, SE = 2.1), t(52) = 0.16, p > 0.5, and response times (monolinguals: M = 3900.7 ms, SE = 215.4; bilinguals: M = 4417.8 ms, SE = 215.4), t(52) = 1.7, p = 0.1. Examination of post-training accuracies showed that monolinguals and bilinguals had equivalent mastery of the timbre dimension [main effect of group: F(1, 52) = 1.8, p > 0.1; group × timbre interaction: F(1, 52) = 0.089, p > 0.5], the pitch dimension [main effect of group: F(1, 52) = 1.8, p > 0.1; group × pitch interaction: F(1, 52) = 0.05, p > 0.5], and the duration dimension [main effect of group: F(1, 52) = 1.9, p > 0.1; group × duration interaction: F(1, 52) = 1.4, p > 0.1]. These findings suggested equivalent mastery of the learned symbolic system. Further, more efficient performance on tone-to-symbol mappings (response times divided by proportion correct) was associated with higher scores on the receptive vocabulary tasks in both monolinguals (PPVT: r = ?0.46, p < 0.05) and bilinguals (PPVT: r = ?0.36, p = 0.063; TVIP: r = ?0.22, p > 0.1; combined PPVT/TVIP: r = ?0.34, p = 0.087), suggesting that previous vocabulary knowledge is positively associated with learning success in the novel symbol system in terms of both higher accuracy rates and faster retrieval times. No associations were found between learning outcomes and performance on the matrix reasoning subtest of the WASI (ps > 0.5), numbers reversed (ps > 0.1), or on the Test of Auditory Discrimination (ps > 0.5)."
16,271920,1," Processing and competition resolution during sound-to symbol mapping \n Sound-to-symbol mapping, competition resolution and previous vocabulary knowledge \n  To examine target identification during processing of similar tone-to-symbol mappings, a mixed linear model was employed with fixed effects including trials with and without competitor symbols (competitor, filler; baseline: filler) and language group (bilingual, monolingual; baseline: monolingual). In addition, z-transformed PPVT scores were entered as a continuous predictor variable. Finally, participants and items (target type) were entered as random effects on the slope. Findings yielded a main effect of competitor, with longer and less accurate responses to competitor trials (M = 3663.0 ms/proportion correct, SE = 118.6) than to filler trials (M = 3388.8 ms/proportion correct, SE = 105.1), b = ?608.7, SE = 295.5, p < 0.05. In addition, a main effect of vocabulary skill was found, with higher PPVT skills associated with quicker and more accurate responses (b = ?44.6, SE = 295.8, p < 0.05). Finally, an interaction emerged between language group and PPVT, with a stronger association between target identification efficiency and PPVT performance in monolinguals (R2 = 0.209) relative to bilinguals (R2 = 0.025, see Figure ?Figure5),5), b = ?980.8, SE = 533.8, p = 0.05. No other effects were significant. \n  To examine the possibility that receptive vocabulary in Spanish, or in Spanish and English combined, would be a better predictor of performance in bilinguals, mixed linear models were created with performance on the Spanish TVIP and with combined performance on the PPVT and TVIP. No significant effects emerged for bilinguals involving either the TVIP or the combined PPVT and TVIP (all ps > 0.1). Together, findings suggest that (1) competition resolution during processing of novel symbolic information was comparable across bilinguals and monolinguals, (2) previous vocabulary knowledge did not influence competition resolution, and (3) previous vocabulary knowledge did influence overall response efficiency on the novel processing task, but more so in monolinguals than bilinguals. \n   Sound-to-symbol mapping, competition resolution and previous success in learning symbolic information \n  To examine the influence of learning success on target identification efficiency and competition resolution, previous symbolic learning success (z-transformed post-training accuracy) was entered into the previously-described mixed linear model instead of vocabulary skill. In addition to the previously-described main effect of competitor (b = ?600.9, SE = 286.6, p < 0.05), a main effect of training success was identified: Greater learning success was associated with greater tone-to-symbol retrieval efficiency, b = ?820.3, SE = 307.4, p < 0.01. This pattern was of statistically equivalent magnitude in bilinguals (R2 = 0.203) and monolinguals (R2 = 0.304), see Figure ?Figure6.6. No other effects were significant. Thus, (1) previous learning success did not influence competition resolution, yet (2) previous learning success did influence overall response efficiency on the novel processing task, an effect that did not differ across monolinguals and bilinguals. \n   Priming: residual activation of sound-to-symbol targets and competitors"
17,271920,2,"Residual inhibition of competitor symbols \n  To examine residual inhibition of competitor symbols after target identification, a mixed linear model was employed with fixed effects including priming probes placed in previous baseline and competitor locations (baseline, competitor; baseline: baseline) and inter-stimulus interval (200, 500, 800; baseline: 200), as well as language group (bilingual, monolingual; baseline: monolingual). In addition, z-transformed PPVT scores and post-training accuracies were separately entered as continuous variables. Finally, participants were entered as random effects on the slopes of both competitor and inter-stimulus interval effects. Results yielded an interaction between competitor location and inter-stimulus interval: At 200 ms post-target identification, response efficiency was significantly longer and less accurate to competitor probes (M = 722 ms/proportion correct, SE = 16.9) than to baseline probes (M = 698.7, SE = 16.9), b = ?38.6, SE = 15.9, p < 0.05. This finding suggested residual inhibition of the competitor at 200 ms post-target identification. While the three-way interaction between language group, inter-stimulus interval, and priming probe did not reach significance, p > 0.1, planned follow-up contrasts suggested that the difference between competitor and baseline probes was significant for bilinguals, t(26) = ?2.6, p < 0.05, but not monolinguals, t(26) = ?1.9, p = 0.07. This finding suggests that, while both bilinguals and monolinguals showed patterns of residual inhibition at 200 ms post-target identification, this effect was somewhat more robust in bilinguals, see Figure ?Figure77. \n  In addition, an interaction between language group and PPVT performance was again present, b = ?114.6, SE = 35.4, p < 0.01: Monolinguals with higher PPVT scores responded to priming probes with greater efficiency (R2 = 0.227), while no such effect was present in the bilinguals (R2 < 0.001). Consideration of Spanish vocabulary in bilinguals did not change this pattern (combined PPVT and TVIP: R2 for bilinguals = 0.004; TVIP only: R2 for bilinguals = 0.016). Finally, when learning success was entered into the model instead of vocabulary knowledge, no effect involving learning success reached significance. Together, these findings suggest that (1) a pattern of residual inhibition was identified at 200 ms post-target identification but not at 500 or 800 ms, (2), these inhibition effects were particularly robust in bilinguals, and (3) neither receptive vocabulary knowledge nor symbol learning success modulated these inhibition effects."
18,271920,3," Residual facilitation of target symbols \n  To examine residual facilitation of target symbols after target identification, a mixed linear model was employed with fixed effects including priming probes placed in previous baseline and target locations (baseline, target; baseline: baseline) and inter-stimulus interval (200, 500, 800; baseline: 200), as well as language group (bilingual, monolingual; baseline: monolingual). In addition, z-transformed PPVT scores and post-training accuracies were separately entered as continuous variables. Finally, participants were entered as random effects on the slopes of both competitor and inter-stimulus interval effects. Findings yielded a main effect of priming probe location, with shorter and more accurate responses on target (M = 642.4 ms/proportion correct, SE = 14.2) than baseline probes (M = 700.2 ms/proportion correct, SE = 14.2), b = ?54.4, SE = 15.0, p < 0.001. When PPVT performance was entered into the model, we again found the previously described interaction between language group and PPVT, b = ?104.8, SE = 33.6, p < 0.01, R2bilinguals < 0.001; R2monolinguals = 0.226. In bilinguals, inclusion of the combined PPVT/TVIP score (R2 = 0.002) or the TVIP score (R2 = 0.014) did not alter this pattern. Finally, when learning success was entered into the model, no significant effects emerged involving training success. Together, these findings suggest robust residual target activation across language groups and inter-stimulus intervals."
19,271920,4," Associations between residual and Stroop inhibition \n  Finally, we examined the relation between residual competitor inhibition after tone-to-symbol identification and performance on a nonlinguistic Stroop task. Stroop performance was analyzed with a mixed linear model with fixed factors including condition (center, congruent, incongruent; baseline: center) and language group (bilingual, monolingual; baseline: monolingual), and with participants entered as a random effect on the slope. Results yielded a main effect of condition, with responses on congruent trials (M = 458.0 ms/proportion correct, SE = 8.1) significantly faster and more accurate than responses on center trials (M = 482.9 ms/proportion correct, SE = 8.2), b = ?24.7, SE = 9.0, p < 0.01, and with incongruent trials (M = 585.9 ms/proportion correct, SE = 8.1) significantly slower and less accurate than center trials, b = 111.0, SE = 9.0, p < 0.001. No other effects were significant, suggesting equivalent Stroop inhibition performance across the bilingual and monolingual groups. \n  Consistent with Blumenfeld and Marian (2011), negative priming effects were compared with the difference score between congruent and incongruent Stroop reaction times, with smaller effects reflecting better abilities to ignore location information. The z-transformed Stroop effect was entered as a continuous variable into the previously-presented mixed linear model examining priming probes. Since relations between residual inhibition and Stroop performance were of interest, the dependent variable in this model was the negative priming effect (baseline probes minus competitor probes). A three-way interaction emerged between language group, inter-stimulus interval, and Stroop performance: at 500 ms post-target identification, in bilinguals, a smaller Stroop effect was associated with less residual competitor inhibition, relative to monolinguals, b = 38.9, SE = 18.8, p < 0.05, R2bilinguals = 0.14, R2monolinguals = 0.02."
20,2617564,0,"1. Listener performance \n Behavioral results from all experiments are presented in the right column of Figure 2, with discrimination accuracy (proportion correct) on the ordinate and testing block number on the abscissa. Given that Orthogonal discriminability is predicted to recover by the end of the experiment, omnibus analysis of variance (ANOVA) tests are likely to result in Type II error. Consequently, to retain sensitivity to differences in discriminability across conditions at different phases of the experiment, results are analyzed using planned-comparison paired-sample t-tests."
21,2617564,1," a. Experiment 1 \n  Discrimination of Consistent pairs in the first block of testing (mean?=?0.67, s.e.?=?.01) was significantly better than discrimination of Orthogonal pairs (mean?=?0.60, s.e.?=?.03) (t 39?=?2.36, p<.025, Cohen's d?=?0.44; Figure 2B). While discrimination accuracy of Consistent pairs was numerically greater than that of Orthogonal pairs in the second (mean of 0.68 versus 0.63) and third testing blocks (0.69 versus 0.65), t-tests did not reach statistical significance (second block: t 39?=?1.58, p?=?.12; third block: t 39?=?1.27, p?=?.21). This pattern of results replicates Experiment 2 of Stilp et al. [22]; discrimination of Orthogonal test pairs is initially inferior to that of Consistent test pairs supporting a robust correlation, and performance recovers through further testing so that discrimination across conditions is comparable by the final testing block. It bears mention that in their Expt. 2 (r?=?0.97), Stilp et al. [22] report superior discrimination of Consistent sound pairs relative to Orthogonal sound pairs in the first as well as second testing block. Relative to that experimental design, Expt. 1 in the present report removes Single-cue stimuli while maintaining 18 Consistent sounds and 2 Orthogonal sounds yielding nearly the same correlation (r?=?0.98). In the present experiment, Consistent discrimination was significantly more accurate than Orthogonal discrimination in the first testing block (p<.025) with only a trend toward significance in the second testing block (p?=?0.12). It is unclear why the full pattern of significance was not fully replicated despite highly similar stimuli and correlation coefficients. Independent-samples t-test indicates that the difference in Consistent and Orthogonal discrimination in the second testing block did not significantly differ across experiments (t 78?=?0.73, p?=?0.47), suggesting patterns of results are not fundamentally different from one another. Results indicate that both the correlated and orthogonal dimensions appear to become weighted proportional to the amount of variance accounted for by each dimension."
22,2617564,2," b. Experiment 2 \n Discrimination of Consistent pairs in the first block of testing (mean?=?0.66, s.e.?=?.02) was again significantly better than discrimination of Orthogonal pairs (mean?=?0.60, s.e.?=?.03) (t 39?=?2.71, p<.01, Cohen's d?=?0.43; Figure 2D). Despite restricting the range of acoustic evidence supporting the correlation, this early difference in discrimination persisted. Experiment 2 also reveals that correlation among stimulus attributes need not be nearly perfect (r?0.97) for efficient coding to occur. Discrimination did not significantly differ in either the second (Consistent mean?=?0.71, s.e.?=?.02, Orthogonal mean?=?0.69, s.e.?=?.03; t 39?=?0.67, n.s.) or third block (Consistent mean?=?0.74, s.e.?=?.02, Orthogonal mean?=?0.77, s.e.?=?.02; t 39?=?1.27, n.s.). \n Unlike previous experiments, discrimination in both conditions improved markedly across testing blocks. Owing to the inability to separate learning (improvement throughout the experiment) from effects of the correlation between AD and SS on Orthogonal discriminability (initially inferior but later comparable to that of Consistent sound pairs), performance was assessed through paired-sample t-tests contrasting early versus late (i.e., first versus third testing block) discrimination of Consistent pairs, which are predicted to remain equally discriminable throughout the experiment. Consistent discrimination significantly improved from the first to third block of Experiment 2 (t 39?=?4.39, p<.0001, Cohen's d?=?0.60), but this learning effect was not consistent across experiments. Participants in Experiment 3 exhibited a significant but more modest learning effect for Consistent trials (t 39?=?3.23, p<.01, Cohen's d?=?0.35), but no significant differences were observed in Experiments 1, 4, or 5 (all t?1.21, n.s., Cohen's d<0.18). The magnitude of the learning effect in Experiment 2 may be due to one or both of the following factors. First, reducing variability in AD and SS cues by truncating the correlation may facilitate discrimination over time. Second, listeners in Experiment 2 were presented more repetitions of stimulus pairs in a given block (12) than in other experiments (8) in the effort to make overall number of trials comparable. Nevertheless, the principal finding is superior discrimination of Consistent pairs relative to Orthogonal pairs early in testing."
23,2617564,3,"c. Experiment 3 \n Unlike previous experiments, discrimination was comparable across Consistent (mean?=?0.63, s.e.?=?.01) and Orthogonal conditions (mean?=?0.61, s.e.?=?.02) in the first testing block (t 39?=?0.75, n.s., Cohen's d?=?0.12; Figure 2F). By testing more extreme Orthogonal test pairs (i.e., less similar to Consistent pairs), differences in discrimination observed in previous experiments were extinguished. Roughly equivalent discrimination persisted throughout the experiment (Block 2: Consistent mean?=?0.66, s.e.?=?.02, Orthogonal mean?=?0.64, s.e.?=?.02 [t 39?=?0.86, n.s.]; Block 3: Consistent mean?=?0.66, s.e.?=?.02, Orthogonal mean?=?0.64, s.e.?=?.02 [t 39?=?1.54, n.s.]). This demonstrates that efficient coding of correlated acoustic attributes is sensitive to the range of physical acoustic/psychoacoustic evidence inconsistent with the primary correlation and consistent with a second orthogonal dimension. Results also demonstrate that simple strength of the primary correlation is insufficient to attenuate discriminability of orthogonal stimulus differences, as all stimulus pairs presented in Experiment 3 (r?=?�0.83) were relatively equally discriminable, but pairs presented in Experiment 2 (r?=?�0.81) produced significant differences in early performance. The explanatory power of simple strength of correlation between acoustic attributes, absent consideration of both the quantity and quality (range) of evidence that is inconsistent with the correlation, is challenged by these results."
24,2617564,4,"d. Experiment 4 \n Despite a three-fold increase in presentations, discrimination of the Orthogonal pair (mean?=?0.59, s.e.?=?.02) was still significantly worse than that of Consistent pairs (mean?=?0.63, s.e.?=?.01) in the first testing block (t 39?=?2.06, p<.05, Cohen's d?=?0.37; Figure 2H). This negligible effect of probability sheds light on the results of Experiment 3, that efficient coding was likely extinguished due to increased range of acoustic evidence supporting orthogonal variability and not the concurrent increase in Orthogonal test trials. Similar to previous experiments, performance across conditions was equivalent in the second (Consistent mean?=?0.64, s.e.?=?.02, Orthogonal mean?=?0.64, s.e.?=?.02 [t 39?=?0.36, n.s.]) and third testing blocks (Consistent mean?=?0.64, s.e.?=?.01, Orthogonal mean?=?0.61, s.e.?=?.02 [t 39?=?1.58, n.s.])."
25,2617564,5," e. Experiment 5 \n Even with ten-fold oversampling, discrimination of the Orthogonal pair (mean?=?0.60, s.e.?=?.02) was modestly worse than that of Consistent pairs (mean?=?0.63, s.e.?=?.01) in the first testing block (t 39?=?1.87, p?=?.07, Cohen's d?=?0.36; Figure 2J). It bears note that paired-sample t-tests used in all analyses are two-tailed. One could use a one-tailed t-test based on the prediction that discrimination of Consistent pairs will be greater than that of Orthogonal pairs, in which case the difference would be statistically significant (one-tailed p<.05). However, performance in the first block does not significantly differ in Experiment 5 versus Experiment 3 as indicated by independent samples t-tests on orthogonal discrimination performance (t 78?=?0.63, n.s.) and differences between Consistent and Orthogonal discrimination (t 78?=?0.71, n.s.). Perhaps surprisingly, testing the Orthogonal sound pair ten times as often as any Consistent sound pair failed to produce practice effects sufficient to promote Orthogonal discrimination exceeding Consistent discrimination (second block: Consistent mean?=?0.64, s.e.?=?.02, Orthogonal mean?=?0.62, s.e.?=?.02 [t 39?=?0.69, n.s.]; third block: Consistent mean?=?0.64, s.e.?=?.01, Orthogonal mean?=?0.62, s.e.?=?.02 [t 39?=?0.54, n.s.]). Thus, the conservative conclusion one can draw from this marginal effect is that manipulation of Orthogonal stimulus probability has little effect on listener discrimination."
26,2617564,6,"2. Model predictions \n a. Experiment 1 \n Predictions from the PCA models are presented in the first column of Figure 4, with Euclidean distance between Consistent (black) versus Orthogonal (grey) stimulus pairs on the ordinate and training epoch on the abscissa. Simulation timecourses for correlation-matrix-based (solid lines) and covariance-matrix-based (dashed lines) models are scaled to share comparable abscissas. Similar to [22], the PCA model quickly discovered the principal component (the Consistent dimension) and distances between Orthogonal pairs initially decreased considerably (Figure 4A). With further exposure to the stimulus set, the PCA model gradually captured the modest variance not explained by the first component, progressively increasing distances between Orthogonal pairs until reaching original relative values by the end of the simulation. Thus, the PCA model initially captures only variability along the principal component in the two-dimensional stimulus space at the expense of the orthogonal component, incrementally coming to capture remaining variance, matching the pattern observed in listener performance. Predictions from the correlation-based (solid lines) and covariance-based (dashed lines) versions of the PCA model were nearly identical, with a slightly larger initial decrease in Orthogonal distances predicted by the covariance model. \n Simulation results using the choice model are depicted in the middle (correlation) and right (covariance) columns of Figure 4, with percent correct discrimination along the ordinate and testing block number along the abscissa. Predictions across 40 simulations exhibited markedly less variability than listener data, but patterns of results remain excellent fits to human performance. Both correlation and covariance models predicted significantly poorer discrimination of Orthogonal stimuli in the first block of testing (correlation model [Figure 4B]: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.58, s.e.?=?.006, t 39?=?14.92, p<1e-17, Cohen's d?=?3.15; covariance model [Figure 4C]: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.57, s.e.?=?.004, t 39?=?21.50, p<4e-23, Cohen's d?=?5.09). Marked improvement in Orthogonal discrimination was evident in the second block, but this was still inferior to Consistent discrimination (correlation model: Consistent: mean?=?0.69, s.e.?=?.007; Orthogonal: mean?=?0.65, s.e.?=?.005, t 39?=?5.23, p<6e-6, Cohen's d?=?1.19; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.63, s.e.?=?.004, t 39?=?10.12, p<2e-12, Cohen's d?=?2.38). Finally, Consistent and Orthogonal stimuli were relatively equally discriminable in the third block (correlation model: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.68, s.e.?=?.006, t 39?=?0.62, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.68, s.e.?=?.004, t 39?=?0.39, n.s.)."
27,2617564,7,"b. Experiment 2 \n The initial decrease in distance between Orthogonal stimuli is smaller and recovery to baseline distances sooner than that observed for Experiment 1 (Figure 4D). These outcomes are anticipated given simulation of a more weakly correlated stimulus set (r?=?�0.81). Simulations by Stilp et al. [22] and Experiment 1 suggest that principal and second components become weighted in proportion to the amount of covariance captured by each dimension, and model predictions for Experiment 2 reveal more weight being attributed to the second (Orthogonal) dimension as it captures relatively more unshared covariance here than in other, more highly-correlated stimulus sets. Both correlation-based and covariance-based models predict significantly poorer Orthogonal discrimination in the first testing block, but models make different predictions regarding the rate of recovery to baseline distances between stimuli. The correlation-based model predicts a more extended recovery, which contributes to a larger predicted effect size in the first block (Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.64, s.e.?=?.006, t 39?=?5.65, p<2e-6, Cohen's d?=?1.40; Figure 4E) than that predicted by the covariance-based model (Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.65, s.e.?=?.005, t 39?=?4.95, p<2e-5, Cohen's d?=?1.12; Figure 4F), which predicts more rapid recovery to baseline distances. Nevertheless, both models correctly predict significantly poorer Orthogonal discrimination in the first testing block, and comparable discrimination in the second (correlation model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.68, s.e.?=?.007, t 39?=?1.12, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.62, n.s.) and third testing blocks (correlation model: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.69, s.e.?=?.005, t 39?=?0.38, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.48, n.s.), matching listener performance. Finally, neither version of the PCA model predicts overall improved performance later in the simulation (i.e., Euclidean distances in both conditions increasing over time) as observed in listener performance, suggesting insensitivity to some practice effects."
28,2617564,8,"c. Experiment 3 \n Both versions of the PCA model predict a shallow and very short-lived decrease in Orthogonal distances, with the vast majority of the simulation predicting equal discriminability across conditions (Figure 4G). Virtually identical simulation results both predict comparable performance across conditions in the first (correlation model [Figure 4H]: Consistent: mean?=?0.68, s.e.?=?.006; Orthogonal: mean?=?0.68, s.e.?=?.005, t 39?=?0.26, n.s.; covariance model [Figure 4I]: Consistent: mean?=?0.68, s.e.?=?.004; Orthogonal: mean?=?0.68, s.e.?=?.004, t 39?=?0.75, n.s.), second (correlation model: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.006, t 39?=?0.08, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.003; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.60, n.s.), and third testing blocks (correlation model: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.006, t 39?=?0.25, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.26, n.s.). These predictions mirror listener performance, and support the idea that both listeners and the model quickly exploited covariance in more extreme Orthogonal stimuli to discover the second component and facilitate Orthogonal discrimination."
29,2617564,9,"d. Experiment 4 \n Both versions of the PCA model predict a sizable initial decrease in Orthogonal distances before later recovery to original relative distances (Figure 4J). These predictions resemble those of Experiment 1, where the early difference in discrimination was both predicted and behaviorally observed, in contrast to those of Experiment 3, where largely equal discrimination throughout was both predicted and observed. Recovery to original relative distances for Orthogonal stimuli occurred much more quickly in Experiment 4 than Experiment 1, revealing some sensitivity to the fact that Orthogonal stimuli were sampled more frequently. Further, the covariance model predictions displayed a slightly larger magnitude of initial decrease in Orthogonal distances and slightly longer recovery to baseline distances than that observed for the correlation model, resulting in a slightly larger effect size in the first testing block (correlation model (Figure 4K): Consistent: mean?=?0.70, s.e.?=?.005; Orthogonal: mean?=?0.64, s.e.?=?.005, t 39?=?6.94, p<3e-8, Cohen's d?=?1.65; covariance model (Figure 4L): Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.63, s.e.?=?.005, t 39?=?7.85, p<2e-9, Cohen's d?=?1.89). Both versions of the model predicted equal discriminability in the second (correlation model: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.69, s.e.?=?.005, t 39?=?0.14, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.68, s.e.?=?.005, t 39?=?1.20, n.s.) and third testing blocks (correlation model: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.69, s.e.?=?.005, t 39?=?0.12, n.s.; covariance model: Consistent: mean?=?0.70, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.62, n.s.)."
30,2617564,10,"e. Experiment 5 \n The correlation-based PCA model predicts a shallow and very short-lived decrease in Orthogonal distances, with all but the first few epochs of the simulation predicting equal discriminability across conditions (Figure 4M). These predictions are identical to those made for Experiment 3, such that equal discriminability of Consistent and Orthogonal stimuli is predicted in all blocks of testing (Block 1: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.006, t 39?=?0.13, n.s.; Block 2: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.007, t 39?=?0.06, n.s.; Block 3: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.69, s.e.?=?.006, t 39?=?0.09, n.s.; Figure 4N). \n Similar to Experiment 4, the covariance-based PCA model predicts a slightly larger magnitude of initial decrease in Orthogonal distances and slightly longer recovery to baseline distances than that observed for the correlation model (Figure 4M). These differ from other model predictions in two significant ways. First, similar to listeners and unlike the correlation model, the covariance model predicts inferior discrimination of Orthogonal stimuli in the first testing block of Experiment 5 (Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.67, s.e.?=?.004, t 39?=?4.02, p<.0005, Cohen's d?=?0.87; Figure 4O). Second, the covariance model displays sensitivity to (and thus makes different predictions for) stimuli with the same correlation matrix but different covariance matrices (i.e., stimuli presented in Experiments 3 and 5). An independent-samples t-test confirms that the predicted difference in Consistent and Orthogonal discrimination in the first testing block of Experiment 5 (mean difference?=?.023) is significantly larger than the difference observed in the first block of Experiment 3 (mean difference?=?.005; t 78?=?2.11, p<.05). Predictions made by the correlation model for the first block of Experiment 3 versus Experiment 5 did not differ (independent-samples t-test on mean differences: t 78?=?0.28, n.s.). These results demonstrate that while the PCA model based on the correlation matrix of the inputs [26] is useful for predicting discriminability of some stimulus sets, the covariance-based PCA model is a better predictor of listener performance overall. Finally, the covariance model predicted comparable performance across conditions for remaining test blocks (Block 2: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.08, n.s.; Block 3: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.42, n.s.)."
31,2617564,11,"f. Across all experiments \n The predictive power of covariance-based PCA is further demonstrated through closed-form linear algebraic solutions in Table 1. Table 1 orders stimulus sets from Experiments 1�5 to reflect performance differences in discriminability of Consistent versus Orthogonal sound pairs in the first testing block as measured by effect size (rightmost column). Eigenvalues calculated from the correlation matrix versus covariance matrix of stimulus set before the simulation are also provided. The success with which listeners discriminate Orthogonal pairs is well predicted by the second Eigenvalue calculated from the covariance matrix reflecting true psychoacoustic distances: as the second Eigenvalue increases, greater perceptual weighting is reflected in improved listener performance on Orthogonal trials and subsequently decreased effect sizes early in the experiment (r?=??0.95, p<.025). This relationship with performance is not observed for the second Eigenvalue of correlation matrices, the first Eigenvalue of correlation or covariance matrices, or simple strength of the principal correlation. The relationship between the second Eigenvalue of the covariance matrix and effect size is similarly robust if calculated on model representations of the inputs after the first one-third of the simulation (akin to the first testing block for listeners; r?=??0.94, p<.025). No other metric calculated after one-third of the simulation reliably predicts effect sizes for the first block of testing. While some caution is warranted in generalizing this relationship given that the second Eigenvalue can be increased by multiple manipulations (removal of Consistent sounds, addition of more extreme Orthogonal sounds, oversampling of Orthogonal sounds), it does provide promising extensions of the present work in optimal weighting of statistically derived dimensions in complex sounds."
32,1911559,0,"3.1. Auditory working memory \n Digit Span Backwards (DSB) raw ability scores were converted to standardized T?Scores and compared across groups using a one?way analysis of variance (ANOVA). No significant difference was found between groups; 6?years: Mean (SD) = 56.60 (9.89); 8?years = 54.03 (9.37); 10?years = 55.07 (9.92), (F(2, 180) = 1.07, p = .345), showing that participants in each group were performing at a cognitive level expected for their age."
33,1911559,1,"3.2. Multisensory Attention Learning Task (MALT) \n To examine performance across groups on aspects of sustained attention on the learning element of the MALT, trials to criterion and number of errors were calculated."
34,1911559,2,"3.2.1. Trials to criterion \n The mean number of learning trials on the MALT in order to reach the criterion of 50 correct target responses was calculated for each group. Results of a univariate ANOVA with two between?subjects factors of Age Group (3 levels: 6, 8, and 10) and Condition (3 levels: V, A, and AV) found a significant main effect of Age Group, F(2, 172) = 4.44, p = .013, partial ?2 = .05, but not of Condition (F < 1), with 6?year?olds requiring a significantly greater number of trials (Mean = 146.98, SD = 8.05) to reach criterion than 8?year?olds (Mean = 143.18, SD = 7.92), p = .025, and trend for more trials than 10?year?olds (Mean = 143.67, SD = 6.73), p = .055. No differences were seen between 8? and 10?year?olds (p > .05)."
35,1911559,3,"3.2.2. Errors on MALT \n A univariate ANOVA to analyse mean number of commission errors (i.e., incorrectly responding to a non?target item) across Age groups and Conditions (see Table 1) found a significant main effect of Age Group, F(2, 172) = 5.05, p = .007, partial ?2 = .06, but not Condition (F < 1), driven by 6?year?olds making significantly more commission errors than 10?year?olds, p = .009 (Bonferroni?corrected pairwise comparisons). \n  Mean number of omission errors (i.e., failing to respond to the correct target) across Age groups and Conditions (Table 1), analysed as above, found a significant main effect of Age, F(2, 172) = 4.59, p = .011, partial ?2 = .05, but not Condition (F < 1). Pairwise comparisons (Bonferroni?corrected) found 6?year?olds made significantly more omission errors than 8?year?olds (p = .015) and there was a trend for 6?year?olds to make more errors than 10?year?olds (p = .061)."
36,1911559,4,"3.2.3. Category identification test \n As a measure of incidental category learning, mean number correct on the category identification task was calculated for each age group and compared across learning condition (Figure 3). Results of a univariate ANOVA with two between?subjects factors of Age Group (3 levels: 6, 8, and 10) and Condition (3 levels: V, A, and AV) found no significant Age Group by Condition interaction (F < 1). However, significant main effects of Age Group, F(2, 168) = 5.23, p = .006, partial ?2 = .06, and Condition, F(2, 168) = 17.42, p < .001, partial ?2 = .17, were identified. Pairwise comparisons (Bonferroni?corrected) for Age Group found that 6?year?olds performed reliably below 10?year?olds (p = .007), with no differences between 6 and 8 years, or 8 and 10 years (p > .05, for all). For Condition, pairwise comparisons indicated that participants scored significantly higher following the Audiovisual learning condition (Mean = 14.07) than either the Auditory (Mean = 10.32) or Visual?only (Mean = 10.97) conditions (p < .001 for both). No difference was found between Auditory and Visual groups (p = .996). \n  To examine whether incidental categorization performance differed from chance, data were analysed for each Age group and Condition using one?sample t?tests with a test value of 8. Six?year?olds were found to score significantly above chance on the Visual?only (t(19)�=�2.73, p�=�.013) and Audiovisual (t(19)�=�4.23, p�<�.001) conditions, but not in the Auditory?only condition (p�=�.095). The 8? and 10?year?olds scored significantly above chance on all learning conditions (p�>�.05, for all), indicative of a high level of categorization performance in these groups across conditions. \n  An examination of the relationship (Pearson's r) between age (collapsed across groups) and performance on the category identification task for each condition indicated a significant positive correlation in the Audiovisual learning condition, r�=�.334, p�=�.011, and a trend for a positive correlation in the Auditory?only learning condition, r�=�.249, p�=�.055, but not in the Visual?only learning condition (p�=�.319). Data are presented in Figure�4. \n  An investigation of the relationships (Pearson's r) between incidental learning (total correct on category task) and auditory working memory (DSB), sustained attention skills (omission errors) and inhibitory control skills (commission errors) found no significant correlations across any age groups or conditions (p�>�.05, for all)."
37,1911559,5," 3.2.4. Explicit categorization knowledge test \n  As well as an examination of incidental knowledge, following the category identification task, each participant was asked to state verbally what they judged the differences between the two families of frogs to be and how they reached their categorization choices. Verbal responses were scored as follows; don't know/none given�=�0 points, related categorical description given but inaccurate (e.g., �they had different coloured spots�)�=�1 point, partially correct family description (i.e. citing 1 feature but not both in AV condition, e.g., number of spots, but no mention of auditory features)�=�2 points, fully correct family description (i.e. �different number of spots and different croak sounds� in AV condition or �croaks to log were deeper than croaks to lily pad� for A condition)�=�3 points. A mean explicit categorization score was calculated for each group and condition (Figure�5). Although a high correlation was found between incidental and explicit scores (r�=�.455, p�<�.001), results of a univariate ANOVA with two between?subjects factors of Age and Condition for explicit knowledge data indicate a different pattern of performance than seen in the incidental knowledge test. That is, although results found a main effect of Age Group, F(2, 172)�=�7.86, p�=�.001, partial ?2�=�.08, with 6?year?olds significantly less able to express the correct reason for categorizing than the older two groups (p�=�.002 and p�=�.003), no main effect of Condition, F(2, 172)�=�2.22, p�=�.112, partial ?2�=�.03, was found. This suggests that there is an age?related difference in the ability to verbally express categorization knowledge compared to the incidental learning element of the task."
38,1911559,6," 3.2.5. Discrimination task \n  To examine the saliency and discriminability level of the visual and auditory features of target exemplars, the same discrimination task as used in the initial pilot study (see above description in Stimuli discrimination) was conducted with 15 participants randomly selected from each age group (including five participants from each condition). Mean accuracy score for visual and auditory discriminators was calculated for each age group. Results of a one?way ANOVA found a significant difference across groups between visual and auditory score; F(2, 42)�=�4.17, p�=�.023, driven by 6?year?olds scoring significantly below 10?year?olds in visual discrimination. Paired samples t?tests to examine differences in visual and auditory accuracy scores for each age group separately revealed significantly lower visual than auditory discrimination ability only in 6?year?olds; Mean (SD) visual�=�11.33 (2.35), auditory�=�12.47 (1.46), t(14)�=�?2.20, p�=�.045. No significant difference between visual and auditory discrimination ability was found for 8?year?olds; Mean (SD) visual�=�13.07 (1.39), auditory�=�13.27 (.88), p�=�.647, or for 10?year?olds; Mean (SD) visual�=�13.33 (2.02), auditory�=�12.80 (2.51), p�=�.217."
39,271124,0,"The results are presented in three parts: (a) a comparison of total raw accuracy in pre-training vs. post-training tests, irrespective of Training Mode (AO/AV) and test mode (ao/av) in an Age (6 vs. 8 years) × Language Background (Bilingual vs. Monolingual) × Tone Language Experience (Tonal vs. Non-tonal) × (Mean Test Score � Pre-/Post-Training) design with repeated measures on Pre- vs. Post-Training scores; (b) an analysis of a percentage gain due to training dependent variable derived from the Pre- and Post-Test scores (see formula below) in an Age × Language Background × Tone Language Experience × Training Mode (AO/AV) × (ao vs. av Tests) design, with repeated measures on ao vs. av tests; and (c) a set of correlations between the phoneme deletion and word and non-word reading ability tests and with the pre- and post-tests and gain due to training for the three English-speaking groups (Mono-Eng, Bi-Eng/Arabic, Bi-Eng/Thai) for whom data on the phonological awareness and reading tests was collected."
40,271124,1,"Raw accuracy \n  Raw percentage correct data were first analyzed to show the absolute level of performance Post-Training compared to Pre-Training as a product of the group factors. A 2 × 2 × 2 × (2) Analysis of Variance (ANOVA) was conducted with Age, Language Background and Tone Experience as between-subject factors and Phase (Pre- vs. Post-training test), as the within-subject factor. All factors have two levels so no planned contrasts were required. Alpha was set at 0.05 and the effect sizes are given for significant differences (critical F = 3.898). \n  The results are graphically presented in Figure ?Figure2.2. As can be seen there was a general improvement from pre-training to post-training and this Phase main effect was significant, F(1,65) = 7.61, p < 0.01, ?p2 = 0.077, with Post-Training Mean = 28.43, and SD = 0.09, and Pre-Training Mean = 25.76, and SD = 0.06. \n  As can be seen in Figure ?Figure2,2, there was Pre- to Post-Training improvement for three of the four 6-year-old groups, and all of the four 8-year-old groups, with other interactions also apparent. Accordingly, while the Phase main effect was unaffected by Language Background, Monolingual vs. Bilingual, it was qualified by Age and Tone Experience: there was a Phase × Age, F(1,65) = 9.90, p < 0.005, ?p2 = 0.395, and a Phase × Age × Tone Experience, F(1,65) = 15.40, p < 0.001, ?p2 = 0.505, interaction. As can be seen in Figure ?Figure2,2, these interactions are due to (i) greater improvement from pre- to post-training by 8-year-olds than by 6-year-olds, and (ii) especially greater improvement for 8-year-olds with Tone Language experience, irrespective of whether the tonal experience is in a monolingual or bilingual context. \n  The decrease in performance from pre- to post-training by the monolingual tone language (Thai) 6-year-olds is puzzling. These children had just begun instruction in reading and writing at school, including learning the orthographic representation of Thai tones (a regular but complicated 4-way interaction of initial consonant class, final consonant manner, vowel length, and tone diacritics (Kasisopa et al., 2013, 2016; see Davis et al., 2015). It is possible that these, as yet non-automatic controlled, processes involved in learning the orthographic representation of Thai tones coupled with intensive training on foreign (Mandarin) tones, resulted in overload and confusion at the perceptual level interference from L1 phoneme-to-grapheme/grapheme-to-phoneme levels. This explanation is clearly speculative and requires further research."
41,271124,2," Performance gain \n  While the above analysis shows effects of training on tone perception, it may be noted that many of Pre- and some of the Post-test scores hover around chance level (25%, given there are 4 Mandarin tones). This raises the issue of the degree of improvement given the initial level of performance and the equivalence of improvements from an initial level of chance responding vs. a higher level of initial responding. To accommodate such differences a dependent variable was derived as follows: \n  Thus if a child had 20% correct on Pre-Training and 30% on Post-Training�the Performance Gain would be 50%; or if there was the same absolute increase of 10% from 50% on Pre-training to 60% on Post-training, the percentage improvement would be 20%. Thus this measure takes into account the initial level of performance in the pre-training test and represents the percent improvement in relation to that level. Mean and Standard Error Performance Gain for each of the four Language Background × Bilingual Status groups are shown for AO/AV training groups in ao and av tests in Figure ?Figure33 as well as in Table ?Table11 alongside the number and percentage of participants who showed pre- to post-training improvement in each group (see also Table B in the Supplementary Material for individual Performance Gain scores for each participant). \n  Performance Gain scores were analyzed in an Age × Language Background x Tone Experience × Training Mode between-subject factor × Test Type (ao or av) within-subject factor ANOVA. The only significant main effect was for Age, F(1,65) = 8.09, p < 0.01, ?p2 = 0.111. Age also interacted with two other factors: there was an interaction of Age × Tone, F(1,65) = 15.19, p < 0.001, ?p2 = 0.189, and of Age × Tone × ao/av test, F(1,65) = 9.54, p < 0.01, ?p2 = 0.128. This set of results is represented in Figure ?Figure4.4. As can be seen, 8-year-olds showed more Performance Gain than 6 year-olds. There was more Performance Gain for Tone language than Non-Tone language background children, but this was only evident in the 8-year-olds. Finally, while the Tone > Non-Tone advantage for 8-year-olds was evident in both ao and av tests, Performance Gain was greater when indexed in ao tests. \n  The above Age and Tone Language background results are independent of whether the children were monolingual or bilingual and whether they were trained with AO or with AV stimuli. Turning to Training Mode and Monolingual/Bilingual, the Training Mode and Monolingual/Bilingual interaction, and the Training Mode × Monolingual/Bilingual × ao/av interaction were both very close to significance Training Mode × Monolingual/Bilingual, F(1, 65) = 3.91, p > 0.05, ?p2 = 0.057; Training Mode × Monolingual/Bilingual × ao/av tests, F = 3.76, p>0.05, ?p2 = 0.055 (critical F = 3.98). Given these close to significant interactions and the significant interaction of ao vs. av tests with Age and Tone Language results above, and in order to avoid a Type II error in this first test of the effect of training mode on lexical tone perception, these two approaching significance results were followed up in simple effect tests of Training Mode × Monolingual/Bilingual at each level of the test type, ao tests and av tests. These revealed a non-significant Training Mode × Monolingual/Bilingual interaction for av tests, F(1, 65) = 0.70, p > 0.1, ?p2 = 0.011, but a significant Monolingual/Bilingual interaction for ao tests, F(1, 65) = 5.19, p < 0.03, ?p2 = 0.074. This set of results is represented in Figure ?Figure5.5. As can be seen Bilingual participants show greater Performance Gain after training with AO stimuli, whereas Monolingual participants show greater Performance Gain after training with AV stimuli, and this is especially the case when indexed by ao test trials."
42,271124,3," Correlations with phonological awareness and reading \n  Correlations, with age partialed out, between the phoneme deletion, word and non-word reading tests with the pre-training, post-training, and performance gain due to training were conducted for the three groups with English as one of their languages (Mono-Eng, Bi-Eng/Arabic, Bi-Eng/Thai). \n  There were, not surprisingly, correlations between the three language measures �phoneme deletion and word reading r(62) = 0.50, p < 0.001, phoneme deletion and non-word reading r(62) = 0.59, p < 0.001, and word and non-word reading, r(62) = 0.75, p < 0.001. \n  More important are correlations between any of the three language measures and the tone training scores. The only significant correlation of this nature was between phoneme deletion and the pre-training av-test, r(62) = 0.26, p < 0.05. This indicates that children's phonological awareness, in this case their proficiency on a phoneme deletion task, is positively related to their initial identification of the four Mandarin tones presented in auditory-visual mode."
43,1303382,0,"2.1. Assessment of Task Specific Variations in Frequency Discrimination Abilities \n Figure 1 and Table 1 summarise performance of the three groups of participants on the two psychophysical tasks (2I_6A_X versus 3I_2AFC). \n  First, regardless of group, there is considerable individual variation in discrimination thresholds for both task designs and for each ISI in the 2I_6A_X task. Though contrary to prediction, individual variations in JND are less marked for the 3I_2AFC compared to any ISI condition in the 2I_6A_X task. \n  To explore the differences among the two tasks, the data from the 2I_6A_X task for the ISI = 200 ms condition were entered into a repeated-measures ANOVA with the data from the 3I_2AFC task. This ISI condition was most similar to that of the 3I_2AFC task. Confirming the impression that participants obtained better overall JNDs with the 3I_2AFC than the 2I_6A_X task, a significant effect was observed for Task (F(1, 73) = 57.88, p < 0.001, ?2 = 0.442). There was also a significant main effect for Group (F(2, 74) = 7.65, p < 0.001, ?2 = 0.173, ? = 0.879) reflecting both lower JNDs and reduced individual variation in performance in the student group for both tasks. \n  The mean thresholds for the 2I_6A_X task increase with increasing ISI in all three groups. To investigate this last effect further, the data from this task were entered into a repeated-measures ANOVA with ISI (10, 200, 1000 ms) as the within-subjects measure and Group (Par-TD, Par-LI, Student) as the between-subjects measure. Mauchly�s test of sphericity was significant (p = 0.007) and degrees of freedom were adjusted using Greenhouse-Geisser correction factors. A significant effect was observed for ISI reflecting the progressive increase in discrimination threshold with increasing ISI (F(1.78, 131.32) = 58.89, p < 0.001, ?2 = 0.443, ? = 0.887). Post hoc Bonferroni tests indicated that mean thresholds for all three ISIs differed significantly from each other. There was also a significant main effect for Group (F(2, 74) = 3.486, p < 0.05, ?2 = 0.086, ? = 0.635), reflecting the lower thresholds observed among the student group. The two parent groups had comparable JNDs. There was no significant Group x ISI interaction (i.e., JNDs for all three groups were similarly affected by increasing ISI). "
44,1303382,1," 2.2. Training Effects on JND Estimation in the 2I_6A_X Task \n  Neither the large variability in JNDs measured using the 2I_6A_X task, nor the lower JNDs for the 3I_2AFC task, were predicted at the outset of the study. Initial piloting with students suggested that the 2I_6A_X task was procedurally more difficult than the 3I_2AFC task. The study protocol was consequently set so that the 3I_2AFC task was always presented first. Then the ISI = 400 ms condition was used as a training session for the 2I_6A_X task and each condition started with four condition specific training trials. This testing protocol was expected to minimise any training effects on performance for the 2I_6A_X task. However, varying degrees of experience with the 2I_6A_X task may still have contributed to the individual variation observed, since the order of presentation of the remaining ISI conditions in the task was randomised. The data were therefore entered into a repeated-measures ANOVA, ISI (3) × Group (3) × Order (6) to test for such effects. A significant effect for ISI was found (p < 0.001), but there was no effect (or indeed any trend) for order of presentation of ISI condition. There was also no significant interaction between Order × Group. Thus individual differences in experience with the task did not significantly contribute to the broad individual variation observed in performance on it."
45,1303382,2," 2.3. Task-Specific Susceptibility to Individual Differences \n  To investigate susceptibility of the two different task designs to individual differences in musical experience (listening and training), nonverbal IQ (NVIQ) and SES, these variables were entered as predictors (forced entry) into a series of multiple linear regression analyses with ln(JND) for each task/ISI condition as outcome measure. Initial models were optimised to retain only those predictors that significantly contributed to each outcome measure. \n  The data were first checked for evidence of significant multicollinearity between predictors (correlations greater than 0.8), or correlation between errors (Durbin-Watson statistic, values less than 1 or greater than 3). The effect of influential cases was assessed by checking for data points where Cook�s distances were greater than 1, Mahalanobis distances were greater than 15, or leverage values were greater than twice the average leverage value (i.e., for the 2I_6A_X task > 0.08; for the 3I_2AFC task > 0.05). One participant was excluded from the 2I_6A_X dataset because of a marked bias for responding �different� (d? = 2.15, criterion c = ?0.84) resulting in very low JND estimates which contrasted with the JND observed for the 3I_2AFC task (172.5 Hz versus, for example, 3 Hz (ISI = 1000 ms)). \n  The regression weights for each analysis are summarised in Table 2. Predictors making nonsignificant contributions are shown to the right of the table. The inputs into the final models are bolded together with the amount of variance (R2) explained by each model. \n  SES and musical training were the only factors to significantly contribute to variance in JND estimates in the 2I_6A_X task. The amount of variance explained by these predictors increased with increasing ISI to a maximum of 43% for the longest ISI (1000 ms), as compared with an initial 27% for the shortest ISI (10 ms). The regression weights for musical training across the 200 and 1000 ms ISI conditions are equivalent. Musical training predicts more individual variation in JND in these two ISI conditions, than it does for the 10 ms ISI condition. SES explains more variation in JND for the 10 and 1000 ms ISI conditions, than it does for the 200 ms condition. \n  By contrast with the 2I_6A_X task, only musical training explained significant variance in JNDs for the 3I_2AFC task and the amount explained by it was considerably less than that explained by SES or musical training for any condition in the 2I_6A_X task. Overall, the 3I_2AFC task is less susceptible to individual differences in the factors assessed here than the 2I_6A_X task."
46,1303382,3," Effect of Different Task Requirements on Observed Threshold \n  If the higher thresholds and more variable performance in the 2I_6A_X task reflect the fact that it is more demanding than the 3I_2AFC task, then the participants who are least able to cope with the extra demands of the task will have the highest thresholds for it. They would therefore be expected to show the greatest amount of improvement in the easier task [21] which stresses their weaker cognitive skills less. To test this prediction, correlations were performed between threshold estimates obtained on the 2I task versus amount of improvement observed for the 3I task. Significant positive correlations (p < 0.001) were observed for all ISI conditions (ISI 10: r = 0.715; ISI 200: r = 0.724; ISI 1000: r = 0.731), confirming this prediction and suggesting that the 2I_6A_X task was inherently more difficult to do than the 3I_2AFC."
47,1303382,4," 2.4. Contribution of Frequency Discrimination to Nonword Repetition \n  To assess contributions of frequency discrimination to verbal short-term memory, discrimination thresholds in the 3I_2AFC task and the three ISI conditions of the 2I_6A_X task were entered into a multiple linear regression analysis (forced entry), with �schooling� (proxy for vocabulary knowledge), and �music training�. This latter factor was included in the model because of the relationship to frequency discrimination performance observed in this study, and also because musical training is thought to enhance efficiency of auditory processing and hence support language learning [33]. \n  Only two predictors explained significant variance in nonword repetition: schooling, and JNDs measured using the 3I_2AFC task. The three ISI conditions of the 2I_6A_X task demonstrated high multicollinearity (r ? 0.8) with each other which contrasted with the low correlations (<0.38) of each measure with the JNDs observed for the 3I task. None of the JNDs for any ISI condition explained significant variance in nonword repetition and they were deleted from the final model, together with musical training which also explained little or no variance in nonword repetition. Table 3 summarises the final regression model together with observations from the initial exploratory analyses. \n"
48,2521573,0," The ERP responses at FZ to the standard and deviant stimuli, together with the resultant difference waves are plotted in Figure 1 for each participant group."
49,2521573,1," Analysis of MMN amplitude and latency \n  As a first analysis, we compared the amplitudes of the MMN for the two groups of nonword-repeaters across the four deviants (Electrode × Deviant × Group). A significant main effect was found for Electrode [F(5, 53)?=?4.807, p?=?.001, ?2?=?0.312], but there was no main effect for Group nor did any interaction with Group approach significance. Thus the two groups did not differ in early consonant change detection. \n  In a similar analysis, peak latencies for the MMN responses were also compared between the groups. No significant main effects or interactions were obtained, i.e., the two groups did not differ in rate of processing during early consonant change discrimination."
50,2521573,2," Analysis of LDN amplitude and latency \n Figure 2 compares mean LDN and MMN amplitudes collapsed across the six electrodes for the two groups as a function of deviant. As illustrated, strong LDN responses were obtained to all four deviants in the good nonword-repeaters. By contrast, an attenuated LDN response to D3 was observed in the poor nonword-repeaters. \n  Statistical analyses showed that, in addition to a significant main effect for Electrode [F(5, 53)?=?5.725, p<.001; ?2?=?0.351], there was a significant main effect for Deviant [F(3, 53) 3.629, p<.01; ?2?=?0.165] and importantly, a significant Group × Deviant interaction [F(3, 55) 6.9, p<.01, ?2?=?0.273]. The analysis was repeated with the good nonword-repeaters subdivided into three groups of 14�15 participants each, and the interaction with deviant position was replicated, F (9, 165)?=?2.67, p?=?.006. The interaction was further explored by repeating the within-subjects analysis for good and poor nonword-repeaters separately. For the poor nonword-repeaters, there was a significant effect of deviant position, F (3,12)?=?7.7, p?=?.004, ?2?=?0.657, and specific contrasts revealed this reflected a significant quadratic term, F (1, 14)?=?8.2, p?=?.013, ?2?=?0.368, reflecting the bow-shaped function seen in the LDN. For the good nonword-repeaters, there was also a significant effect of deviant position, F (3, 41)?=?3.6, p?=?.022, ?2?=?0.207, but neither linear nor quadratic terms were significant (F-ratios<1). \n  This analysis was followed up with one sample t-tests on average mismatch responses across the six fronto-central electrodes to determine whether the LDN differed significantly from zero. For the good nonword-repeaters, a significant LDN was found at all syllable positions (i.e., for positions 1, 3, and 4, p<.001; for position 2, p<.01). By contrast, for the poor nonword-repeaters, LDN responses significantly greater than zero were recorded at positions 1, 2, and 4 (with p values of <.001), but not at position 3. In sum, there is a significant difference in magnitude of LDN response to consonant change between the two groups at the third syllable and this difference associates with differences in overall nonword repetition score. \n  To further test this association, we performed a correlation between nonword repetition score and mean LDN amplitude in response to the four deviants. A strong correlation was observed between nonword repetition score and mean LDN amplitude at syllable 3 only (r?=??0.407, p<.001), i.e., smaller LDN amplitudes at this position were associated with lower nonword repetition scores. \n  As with the MMN response, peak latencies were submitted to analysis to test for differences in rate of processing deviance detection between the two groups. Though a significant effect for Electrode was obtained [F(3, 55) 3.404, p?=?.01, ?2?=?0.243], there was no main effect for Group nor any interaction with Group suggesting similar rates of processing among the two groups during this stage of consonant change detection. \n  \n  \n  \n  \n "
51,2521573,3," Relationship of MMN to LDN \n  The LDN and the MMN are both elicited in response to a change in stimulus, yet only differences in LDN were associated with nonword repetition ability. A question thus arises regarding the extent to which these two negative deflections provide different information about the process of change discrimination in this paradigm. To assess this, mean MMN and LDN amplitudes across the six electrodes were calculated and a series of one-tailed Pearson product moment correlations were performed between the amplitudes of the two components for each deviant. We predicted a direct relationship between the two components if they reflected common processes. \n  Correlations between the LDN and the MMN amplitudes in response to deviant syllables 1, 2 and 3 fell far short of significance (r?=??.18, ?21, .00 respectively) when all participants were included in the analysis. The correlation between MMN and LDN for deviant syllable 4 when both groups were included was .34 (p?=?.009), which was significantly different from zero, even after Bonferroni correction (critical p-value of .012). \n  Correlations between the LDN and MMN amplitudes were also tested for each group separately applying the Bonferroni corrected critical p-value of 0.012. No evidence was found for significant correlations between LDN and MMN in the poor nonword-repeaters. In the good nonword-repeaters, weak correlations were observed between LDN and MMN at syllables 1 and 4 (r?=?.37, .32 respectively) which did not survive correction for multiple testing. \n  Overall, with the possible exception of the final syllable, the evidence for common processes being involved in the generation of the MMN and LDN responses was not compelling."
52,2521573,4," Family history and nonword repetition ability \n  There were more parents of children with SLI in the poor nonword-repeater group. This raises a question regarding the role of family history for SLI in our findings. To test this, LDN amplitude × Deviant was entered into a repeated measures analysis with Group × Family history (+FH, ?FH). The numbers are not sufficient for a powerful analysis, but no significant interaction was observed between family history and deviant position. A plot of the mean LDN amplitudes for each of the four groups (Figure 3) clearly demonstrates a reduction in LDN amplitude in response to the consonant change which, regardless of family history, occurs on the third syllable in the poor nonword-repeaters."
53,2562735,0, 1. Descriptives
54,2562735,1,"Grand average waveforms \n Figure 2 shows the grand average standard, deviant and MMR waveforms of the adults in the current study (right) and, for comparison, of the infants in [4] (left), at eight electrodes, for each Distribution Type (unimodal vs. bimodal) pooled over Standard Vowel. The figure confirms the negative polarity and the expected latency and fronto(central) scalp distribution of the adult MMN (Method section 6): the red curve, which is the MMR waveform, deviates in the negative direction (notice that negative polarities are plotted upwards) from the baseline between 150 and 250 ms, and seems to do so more at frontocentral sites then elsewhere. The figure also confirms that the infant MMR contains less pronounced peaks [55] and that its scalp distribution is less defined than in adults (e.g., [54], see also [4]). Also, in accordance with several previous studies (e.g., [25], [48]�[50]), the polarity of the infant MMR is positive."
55,2562735,2," Scalp distributions  \n Figure 3 depicts the scalp distributions, which were made in Praat [43], for the unimodally (top) and bimodally (bottom) trained adults in the current study (right) and, for comparison, for the infants in [4] (left). The adult distributions were measured between 167 and 217 ms after stimulus onset, i.e., in a 50-ms window around the average MMR latency (i.e., the time of the most negative voltage occurring in the grand average waveform at Fz between 150 and 250 ms), which was at 192 ms. The infant distributions were measured between 100 and 500 ms after stimulus onset (Method section 6). Just as the grand average waveforms in Figure 2, the topographies of the MMR in Figure 3 illustrate the adult negative polarity (always blue, never red) and frontocentral distribution (darkest blue at frontocentral sites). For the infants, the positive polarity (red) and less specified distribution (darkest colors are spread over the scalp) are clearest for the bimodally trained infants. The MMR was not significantly different from zero for the unimodally trained infants (details are provided in Results section 2)."
56,2562735,3," MMR amplitudes \n  The MMR amplitude in the overall window where the response was expected (i.e., between 150 and 250 ms after stimulus onset; see Method 6) was significantly negative for both the bimodally trained adults (mean?=??0.45 �V, 95% confidence interval [henceforth CI]?=??0.95??0.05 �V, t[19]?=??1.89, p?=?0.037) and the unimodally trained adults (?0.80 �V, 95% CI?=??1.39??0.20 �V, t[18]?=??2.82, p?=?0.006), thus suggesting that both groups discriminated the two test vowels to some extent. \n  Subsequently, for each adult participant the MMR amplitude was calculated at Fz in a 50-ms window around the MMR latency for the participant�s group (see Method 6). This group latency was 193 ms for Unimodal [æ], 196 ms for Bimodal [æ], and 189 ms for Unimodal [?] and Bimodal [?]. The MMR amplitudes, averaged over the participants per Distribution Type and Standard Vowel, are presented in Table 2, together with their standard deviations and confidence intervals. For comparison, the corresponding numbers of the infant MMR amplitudes (see Method 6) are also shown. \n  In [4], no significant difference had been observed between the infant MMR amplitudes at frontal, central and temporal electrodes (Fz, F3, F4, Cz, C3, C4, T7, T8). To further explore the frontocentral scalp distribution observed in the adult grand average waveforms and scalp topographies, we performed an analysis of variance (ANOVA) with Electrode (the same eight electrodes as for the infants) as a within-subject factor. The effect of Electrode was significant (F [7?, 266?, ??=?0.504]?=?9.94, Greenhouse�Geisser corrected p<0.001). The amplitude at T7 (mean?=??0.19 �V) was significantly less negative (�smaller�) than the amplitudes at all frontal and central electrodes (mean at Fz?=??0.91 �V, mean at Cz?=??0.90 �V, mean at F3?=??0.77 �V, mean at F4?=??0.93 �V, mean at C3?=??0.85 �V, mean at C4?=??0.84 �V; all ps?0.002), and not significantly different from the amplitude at T8 (mean?=??0.50 �V, p?=?0.80). These results are in line with a predominantly frontocentral distribution of the adult MMN."
57,2562735,4," 2. No significant effect of distributional vowel training in Dutch adults \n  Recall (Method section 1) that in order to test whether there was a difference between the unimodally and bimodally trained participants, while controlling for differences in the presented standard, we performed an ANOVA with the MMR amplitude at Fz as the dependent variable, and with Distribution Type (unimodal vs. bimodal) and Standard Vowel ([æ] vs. [?]) as between-subject factors. The main and interaction effects were not significant (for Distribution Type: mean difference bimodal � unimodal?=?+0.30 �V, 95% CI?=??0.50?+1.10 �V, F<1, p?=?0.45; for Standard Vowel: mean difference [æ]�[?]?=??0.40 �V, 95% CI?=??1.19?+0.40 �V, F[1, 35]?=?1.02, p?=?0.32; for the interaction: F[1, 35]?=?1.41, p?=?0.24). Because the effects involving Standard Vowel were not significant, the amplitude data do not show proof of any perceptual asymmetry (Method section 1). The insignificance of all effects involving Distribution Type implies that the amplitude data do not provide sound evidence that bimodally trained Dutch adult learners have a different amplitude (mean?=??0.78 �V, 95% CI?=??1.34??0.23 �V) and thus benefit differently from distributional training than unimodally trained learners (mean?=??1.08 �V, 95% CI?=??1.65??0.51 �V). For comparison, the corresponding ANOVA for the infants in [4], which also included Time Bin and Electrode as within-subject factors (see Method 6), had yielded a significant effect of Distribution Type (mean difference bimodal � unimodal?=?+1.06 �V, 95% CI?=?+0.08?+2.04 �V, F[1, 18]?=?7.03, p?=?0.016), with a larger positive MMR, and thus a larger effect of distributional training, for the bimodally trained infants (mean?=?+1.37 �V, 95% CI?=?+0.68?+2.05 �V) than for the unimodally trained infants (mean?=?+0.31 �V, 95% CI?=??0.38?+1.00 �V)."
58,2562735,5, 3. Smaller effectiveness of distributional training in adults than in infants
59,2562735,6," From the statistical significance of the distributional effect in infants [4] and the statistical non-significance of the effect in adults (the present paper) we cannot yet conclude that the effect is greater in infants than in adults. A valid test requires a direct comparison of the two age groups. The difference in MMR amplitude between the Bimodal and Unimodal groups (i.e., Bimodal MMR � Unimodal MMR) for the adults was +0.30 �V (?=??0.78 �V�?1.08 �V; i.e., in the unexpected direction, though non-significant), whereas that for the infants [4] was +1.06 �V (?=?+1.37 �V�+0.31 �V). This age difference does not appear to be due to adults having a smaller MMR amplitude in general than infants, because the literature review in the Method section (section 7) suggested that this amplitude is probably greater in adults than in infants. The age difference could therefore be due to a truly smaller effect of distributional training in adults than in infants. To verify this, the current section presents a numerical comparison of the infant and adult MMR amplitudes. As determined by the literature review in the Method section (section 7), the comparison requires a normalization of the MMR amplitudes, which should include a correction for the opposite polarity of adult and infant MMRs and a scaling of the size of the MMR. To implement the normalization (or something equivalent to normalization), we multiplied each adult�s MMR amplitude by ?1 to correct for the negative polarity, and we multiplied each infant�s MMR amplitude by a scaling factor to correct for the smaller size. Before applying the scaling factors estimated from the literature, which were 1.18 and 1.41 (Method section 7), we present the results for a more conservative scaling factor of 1.00 (i.e. no scaling), which is smaller than the estimates; this scaling turns the mean MMR for adults into ?0.30 �V, and that for the infants into +1.06 �V, giving a difference of 1.36 �V."
60,2562735,7," Scaling factor of 1 \n  Using a conservative scaling factor of 1, we performed an ANOVA with the normalized MMR amplitude as the dependent variable, and Age Group (infant vs. adult), Distribution Type (unimodal vs. bimodal) and Standard Vowel ([æ] vs. [?]) as between-subject factors (given that in [4] a strong interaction was observed between Distribution Type and Standard Vowel, Standard Vowel was included to be able to extract possible interactions with this variable). The ANOVA yielded the following normalized MMR amplitudes per Age Group and Distribution Type (as visible in Figure 4): infant unimodal 0.31 �V (CI?=??0.38?+1.00 �V), infant bimodal 1.37 �V (CI?=?+0.68?+2.05 �V), adult unimodal 1.08 �V (CI?=?+0.56?+1.60 �V) and adult bimodal 0.78 �V (CI?=?+0.27?+1.29 �V). \n  Crucially, the interaction between Age Group and Distribution Type was significant (F[1, 53]?=?5.05, p?=?0.029). Thus, the effect of distributional training differed between infants and adults (see below). Further, the interaction between Distribution Type and Standard Vowel was significant (F[1, 53]?=?4.85, p?=?0.032), as well as the triple interaction between Age Group, Distribution Type and Standard Vowel (F[1, 53]?=?13.99, p?=?0.0005). The other interaction effect (between Age Group and Standard Vowel) and the main effects were not significant (all p-values >0.21). \n  As the number of participants was not the same in all groups, it is relevant to note that the crucial interaction between Age Group and Distribution Type did not depend much on the way the terms for the ANOVA were entered in the linear model. With �Type-III sums of squares�, the p-value for each main or interaction effect is calculated from a comparison between the full model (i.e. the model with all main and interaction terms) and the full model from which only this one term was dropped. This led to the above-mentioned p-value of 0.029 for the interaction between Age Group and Distribution Type. With �Type-I sums of squares�, the terms are entered into the linear model one by one and the p-value for each term depends on when the term is added. Under the constraint that the three two-way interaction terms are added after the three main terms and before the three-way interaction term, the p-value for the interaction between Age Group and Distribution Type depended only slightly on the order in which the two-way interactions entered into the model: it was 0.027 if this term was entered first, 0.024 if it was entered after Distribution Type × Standard Vowel but before Standard Vowel × Age Group; 0.025 if it was entered after Standard Vowel × Age Group but before Distribution Type × Standard Vowel; and 0.023 if it was entered last. By contrast, the interaction between Distribution Type and Standard Vowel was not robust to such variation. With Type-III sums of squares, the p-value of the interaction was as shown above (i.e., p?=?0.032), while with Type-I sums of squares the effect was non-significant, irrespective of the chosen order of factors (i.e., the p-value ranged from 0.23 to 0.27). This difference in significance is due to the strong effect of the three-way interaction term: only if this triple term is present and has taken away much of the variance does the interaction between Distribution Type and Standard Vowel provide a significant improvement to the model. The robustness of the interaction of Age Group and Distribution Type, together with the lack of robustness of the interaction of Distribution Type and Standard Vowel, means that the former effect has been shown more credibly than the latter. \n  The observed interaction between Age Group and Distribution Type is pictured in Figure 4. The figure suggests that the difference in the normalized MMR amplitude between unimodally and bimodally trained participants was larger (i.e., more positive after normalization) for the infants than for the adults. When controlling for a possible effect of Standard Vowel, this difference is significant for the infants (mean difference normalized bimodal � unimodal?=?+1.06 �V, 95% CI?=?+0.09?+2.03 �V), thus indicating an effect of distributional training, and not significant for the adults (mean difference normalized bimodal � unimodal?=??0.30 �V, 95% CI?=??1.03?+0.43 �V). In view of the significance of the interaction between Age Group and Distribution Type, it is now possible to interpret the significant effect of distributional training for the infants as indeed being larger (i.e., +1.06�?0.30 �V?=?+1.36 �V, 95% CI?=?+0.15?+2.57 �V) than the non-significant effect for the adults (if that effect exists at all)."
61,2562735,8," Other scaling factors \n  The statistical significance of the result depended on the size of the scaling factor by which the infant MMR amplitude was multiplied. With the conservative value of 1.00 used above, the p-value for the interaction between Age Group and Distribution Type was 0.029 (Type-III sums of squares). With the scaling factors estimated above (Method section 7), namely 1.18 and 1.41, which express the idea that adult MMRs are bigger than infant MMRs, the p-value would be lowered to 0.018 and 0.010, respectively. With a scaling factor of 0.8172, which expresses the opposite assumption from that derived from the literature, namely that infants have a somewhat larger MMR amplitude than adults, the p-value would become exactly 0.05. We can conclude that for a large range of plausible scaling factors, the effect of distributional training is reliably smaller for adults than for infants."
62,1695972,0,"Psychometric and behavioral data \n The two groups did not differ in terms of general cognitive capability (KAI t(22)?=?0.423, p?=?0.676; MWT t(22)?=?0.642, p?=?0.528) or alertness (t(19)?=?0.617, p?=?0.545). Otherwise, the generalized linear mixed model (i.e., 2 groups?×?2 time points) revealed a main effect of time point (z?=??2.391, p?=?0.0403) as well as group?×?time point interaction effect (z?=?2.016, p?=?0.0438). As visible in Fig.�1A, the main effect of time point originated from a better discrimination at T1 (mean correct responses?=?63.04%) compared to T0 (mean correct responses?=?48%), whereas the group?×?time point interaction was related to a higher performance of the TG compared to the PG at T1 (mean correct responses, TG T0?=?45.09%, PG T0?=?50.46%, TG T1?=?74.09%, PG T1?=?53.69%)."
63,1695972,1," FFRs responses \n  A one-sample t-test computed against zero (i.e., no lag) across all participants in order to exclude electromagnetic interference induced by the headphones (Bonferroni corrected p value for two tests?=?0.025) yielded significant results at both T0 (t(23)?=?7.825, p?<?0.001) and T1 (t(23)?=?8.475, p?<?0.001). These results are in line with previous literature13 and indicate the presence of genuine FFRs (Fig.�2) characterized by a mean delay of about 8?ms (i.e., T0, mean?=?7.825?ms, sd?=?1.917?ms; T1, mean?=?8.475?ms, sd?=?1.468?ms) reflecting signal transfer time from the ear to rostral brainstem structures13. \n  The evaluation of between-group f1 peak amplitudes (Fig.�3) by means of a t-test (i.e., percent signal change) yielded a significant group difference (t(22)?=??2.147, p?=?0.043). Post-hoc t-tests against zero calculated separately for the two groups (i.e., Bonferroni corrected p value for two tests?=?0.025) revealed that the TG was characterized by a significant signal reduction (t(10)?=??2.704, p?=?0.022; mean % signal change?=??21.36, neural adaptation, Fig.�4), whereas brain activity did not change within the PG (t(12)?=?0.349, p?=?0.733, mean % signal change?=?2.74). Finally, even though we did not have any a priori-hypotheses, for reasons of completeness, we also evaluated percent signal change in f0 (i.e., added responses) and higher harmonics (i.e., subtracted responses, f2, f3, and f4) between the two groups. Since we did not reveal group differences in these additional parameters (f0, t(22)?=??0.193, p?=?0.849; f2, t(22)?=??0.881, p?=?0.388; f3, t(22)?=??0.586, p?=?0.564; f4, t(22)?=??0.035, p?=?0.972), results indicate a specificity of brainstem responses to the trained stimulus attribute (i.e., f1)."
64,1695972,2,"FFR: stimulus-response correlations \n  Potential group differences in stimulus-response correlations (i.e., stimulus tracking and lag) as a function of treatment were evaluated by contrasting the percent signal change between the two groups by means of t-tests (Bonferroni corrected p value for two tests?=?0.025). These analyses did not reveal significant group differences in signal tracking (t(22)?=?0.508, p?=?0.617) nor in lag (t(22)?=??0.182, p?=?0.857)."
65,1695972,3," FFR: brain-behavior relationships \n  In order to provide further evidence for the specificity of the functional changes observed within the TG at the processing level of the brainstem, we correlated percent f1 signal change with the learning performance during the training session (i.e., ? percent correct responses between run 6 and run 1 of the training session). Results revealed a significant negative correlation (i.e., see Fig.�4D) between the two variables (r?=??0.607, p?=?0.024, one-tailed)."
66,1695972,4," MMN responses \n  Between-group differences in MMN area and latency in response to spectral (i.e., early MMN) and temporal (i.e., late MMN) manipulations were evaluated by means of separate t-tests (i.e., percent signal change; Bonferroni corrected p value for 4 tests?=?0.0125). These statistical analyses did not reveal significant group differences (spectral area t(22)?=??1.167, p?=?0.256; temporal area t(22)?=?1.656, p?=?0.112; spectral latency t(22)?=?1.085, p?=?0.29; temporal latency t(22)?=??0.514, p?=?0.613). Furthermore, in order to rule out the possibility that a general adaptation of the auditory cortex (i.e., see Fig.�5) as a consequence of repeated auditory stimulation between the two measurements points (i.e., T0 and T1) may have accounted for the lack of group differences, we performed additional post-hoc analyses within the two groups (one sample t-test against zero, two-tailed, Bonferroni corrected p value for 4 tests?=?0.0125). These supplementary analyses did not reach significance (TG MMN area early, t(10)?=??1.536, p?=?0.155; TG MMN area late, t(10)?=??1.493, p?=?0.166; PG MMN area early, t(12)?=?1.173, p?=?0.264; PG MMN area late, t(12)?=??2.466, p?=?0.030)."
67,1695972,5," MMN sources \n  LORETA source estimation (Table ?(Table1)1) consistently revealed MMN maxima originating from posterior superior temporal areas, irrespective of group affiliation (i.e., TG and PG), time point (i.e., T0 and T1), and condition (i.e., spectral and temporal). These findings point to a main contribution of the auditory cortex to MMN responses."
68,1695972,6," Training-related cortical-subcortical relationships \n  Putative changes in cortical-subcortical interactions within the TG were evaluated by correlating (according to Pearson�s r, two-tailed) the percent signal change of early MMN area and latency with f1 signal change (Bonferroni corrected p value for two tests?=?0.025). These correlative analyses did not reach significance (rMMN area_f1 amplitude?=?0.155, p?=?0.65; rMMN latency_f1 amplitude?=?0.355, p?=?0.285)."
