,ID,TITLE,DOI,WEB,Result_ID_WEB,Discussion_ID_WEB,Result_Content,Discussion_Content
0,232756,"""Learning auditory discriminations from observation is efficient but less robust than learning from experience""","""10.1038/s41467-018-05422-y""",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6089935/,Sec2,Sec9,"Observation learning induces rapid auditory discrimination:

During a pre-training phase, experimenters (EXP) were accustomed to air-puffs that followed one of two auditory stimuli of different duration. Then a training phase followed, during which we exposed EXP to the full training set of 10 auditory stimuli (Fig.�2a left panel and Supplementary methods). Gradually, EXP learned to escape from the perch more often in puffed trials; their escape probabilities (cumulated from trial onset to trial end) became larger on puffed trials than on unpuffed trials (Fig.�2b left and right). We quantified the birds� ability to discriminate stimulus class by the difference in (cumulative) escape probabilities (dPesc) between puffed and unpuffed trials (Fig.�2b, c, d, e). EXP attained a statistical performance criterion (based on the perching behavior in the most recent 800 trials,�see Methods and Supplementary Figure�1d) after 4700 [800, 10500] trials (median [range], n?=?10 birds). This criterion defined the end of the training phase, at which time EXP displayed a dPesc of 0.35 [0.27, 0.46] (median [range], dPesc averaged over the last 3 blocks of training, including the criterion block). After the training phase (or observation phase for observers), the experimenter was replaced by the observer (OBS) and a naive bird was placed in the observer�s cage. Then we began testing the OBS using the same pre-training and training paradigms it was previously allowed to observe. We refer to the training of observers as testing, Fig.�2a right panel.
 At the beginning of the testing phase (first 3 testing blocks), OBS displayed a significantly higher discrimination performance than EXP at the beginning of their training phase (dPesc in first 300 trials: EXP (n?=?10) 0.2 [0 0.32], OBS (n?=?9) 0.4 [0.16 0.64]; EXP � OBS, median difference?=??0.22, p?=?0.013, test statistic?=?15; two-sided Wilcoxon rank sum test; 95% CI?=?[-Inf ?0.1]), Fig.�2d. Surprisingly, OBS� initial performance was no worse than that of EXP who had reached the learning criterion (average initial dPesc?=?0.40 in n?=?9 OBS vs average final dPesc?=?0.36 in n?=?10 EXP). OBS reached the performance criterion nearly instantaneously, in only 900 [800, 5600] trials (median [range], n?=?9 birds), less than a third of the trials required by EXP (two-sided Wilcoxon rank sum test with alternative hypothesis: EXP ? OBS, median difference?=?3100, p?=?0.015 (not exact), test statistic?=?75; 95% CI not computed because of ties), Fig.�2f. After reaching the criterion, OBS showed a significantly higher discrimination performance than EXP (dPesc at criterion in OBS?=?0.46 [0.29, 0.65]; EXP � OBS, median difference=??0.17, p?=?0.005, test statistic?=?12; two-sided Wilcoxon rank sum test; 95% CI?=?[?0.2 ?0.031]), Fig.�2e.
 
 Observers generalize poorly compared to experimenters
 
 To compare generalization in experimenters and observers, first, we allowed generalization observers (GENOBS) to watch generalization experimenters (GENEXP) learn to discriminate the stimuli in the training set, after which we tested both groups of birds on the generalization set of stimuli, Fig.�3a. Contrary to our findings on the training set, GENOBS initially showed significantly poorer discrimination on the generalization set (average dPesc over the first 3 blocks (median [range]) in GENEXP: 0.41 [0.34, 0.6] and in GENOBS: 0.2 [?0.02, 0.54]; GENEXP � GENOBS, median difference?=?0.24, p?=?0.019, test statistic?=?67, two-sided Wilcoxon rank sum test, 95% CI?=?[0.016, 0.36]), Fig.�3b, c. GENOBS also took more time than GENEXP to reach criterion (3600 [800, 13300] trials in n?=?9 GENOBS versus 800 [800, 2200] trials in n?=?9 GENEXP; GENEXP�GENOBS median difference�?=??2800, p?=?0.006 (not exact), test statistic?=?10, two-sided Wilcoxon rank sum test; 95% CI not computed because of ties), Fig.�3d.
 GENOBS needed more trials to reach the learning criterion than did OBS (GENOBS�OBS, median difference?=?2100 trials, p?=?0.044, test statistic?=?63.5, two-sided Wilcoxon rank sum test), demonstrating that observers reacted to small differences between stimuli from the training and generalization sets. Thus, overall, observers seemed to associate the perch-escape behaviors by experimenters much more exclusively with the presented auditory stimuli than did the experimenters themselves, who associated the air puffs inclusively with the stimuli (to include similar stimuli from the generalization set).
 We inspected the escape behaviors of observers and experimenters. We found that after reaching the learning criterion, EXP and OBS displayed similar perch escape strategies. That is, they tended to abruptly increase their perch escape rates just before air-puff onsets (Supplementary Figure�2a, b), suggesting that birds responded by learning to escape the air puffs rather than by learning to stay when no puff was imminent.
 Observers do not learn through passive perceptual processes
 We set out to characterize the requirements for observation learning. To test whether observers learned from experimenters� actions in response to the air-puffs, we allowed experimenter and observer pairs to experience several thousand (mean?�?standard deviation?=?7.5?�?3.6*103) stimulus playbacks including the sound of air-puffs, but not the tactile sensation of the puffs. We realized this perceptual paradigm by directing the air outlet away from the experimenters, Fig.�4a. Consequently, experimenters never experienced the air-puff as a force against their body. We refer to observers in such pairs as perceptual learners (PLs), because they could potentially learn from the pairing of stimuli with air-puff sounds.
 Experimenters in this perceptual paradigm never produced dPesc values different from 0 (average dPesc after 5000 training trials in 3 experimenters: [?0.065, ?0.002, 0.007], p?=?0.81, p?=?0.25, p?=?0.64, respectively; z-test of individual proportions), hence they did not show the discriminative behavior that we suspected would drive learning in observers. When we tested PLs (n?=?7 birds) with air-puffs directed at them, they needed significantly more trials to reach criterion than OBS (4200 [1800, 20,300] trials in PLs versus 900 [800, 5600] in OBS; OBS � PL median difference?=??2400; two-sided Wilcoxon rank sum test of alternative hypothesis PL ? OBS, p?=?0.016 (not exact), test statistic?=?8.5; 95% CI not computed because of ties), Fig.�4e. PLs were slower than OBS even after removing an outlier bird (trials to criterion?=?20300) in the PL group (median difference?=???2389,�p?=?0.032 (not exact), test statistic = 8.5, 95% C.I not computed). PL performance at criterion was comparable to OBS performance (0.33 [0.064, 0.63] in PL versus 0.46 [0.29, 0.65] in OBS; OBS- PL; median difference?=?0.16, p?=?0.142, test statistic?=?46, two-sided Wilcoxon rank sum test, 95% CI?=?[?0.077 0.338]) and was not statistically different from performance in EXP (EXP � PL; median difference?=?0.06, p?=?0.41, test statistic?=?26, 95% C.I?=?[?0.2 0.2], two-sided Wilcoxon rank sum test). The absence of rapid learning in PLs suggests that learning in OBS required an experimenter engaged in the task and responding to air puffs.
 Observers do not learn from naive experimenters
 We expected observation learning to be most effective when information is provided by an expert. To probe for sensitivity to experimenter performance, we tested a group of Valence Learners (VLs, n?=?5) that observed na�ve experimenters who did not reach the performance criterion within (on average) 5600 [4360, 11436] trials. These na�ve experimenters were hit by air puffs on average 539 times out of 1000 puffed trials, and escaped in unpuffed trials on average on 400/1000 trials. In addition, to give VLs direct experience of the reinforcer (its valence), 3/5 of these VL birds were initially exposed to air puffs (approximately 500 strong 1-s air puffs, see Methods). When tested, VLs were much slower than OBS to reach the learning criterion (trials to criterion in VL [n?=?5], median [range]: 6700 [6200, 12,100] versus OBS [n?=?9]:900 [800, 5600]; OBS�VL median difference?=??5500, two-sided Wilcoxon rank sum test of alternative hypothesis VL ? OBS, p?=?0.006 (not exact), test statistic?=?0, 95% CI not computed), Fig.�4e. The performance of VLs at criterion was lower than the performance of OBS (dPesc for VL [n?=?5]: 0.26 [0.13, 0.45] versus for OBS [n?=?9]:0.46 [0.29, 0.65], median difference =?0.21, p?=?0.007, test statistic?=?42, two-sided Wilcoxon rank sum test, 95% CI?=?[0.034 0.355]), and there was a trend of lower performance in VL compared to EXP (VL�EXP, median difference?=??0.11, p?=?0.07, test statistic?=?10, 95% C.I?=?[?0.21 0.05], two-sided Wilcoxon rank sum test). The poor testing results in VLs suggest that OBS did not learn by predicting the reward value experienced by EXP�and by converting this prediction into an optimal action during testing. Instead, VL behavior suggests that OBS focus on experimenters� discriminative actions, which must necessarily contain the information required for observation learning. In combination, PLs and VLs emphasize the importance of experimenters� discriminative actions for observation learning.
 Vocal exchanges are not required for observation learning
 Given the importance of experimenter actions, we speculated that rapid learning in OBS could depend on vocal exchanges between EXP and OBS through calls occurring during and following stimulus presentation, Fig.�4c. Indeed, on the last day of the training phase, when EXP had reached the learning criterion, we found a difference in calling behavior between puffed and unpuffed trials. In six EXP-OBS pairs (on one day each), we inspected calling rates (defined as the probability of observing at least one call) during the stimulus period (from stimulus onset to stimulus offset) and during the delay period (defined from stimulus offset to air-puff onset), Fig.�4d. In puffed trials, the calling rate was lower in the delay period than in the stimulus period: stim call probability 0.44 [0.14, 0.88] vs delay call probability 0.27 [0.07, 0.45], median difference (Delay � Stim) ?0.15, p?=?3.8*10?6, test statistic?=?0, two-sided Wilcoxon sign rank test, n?=?6 EXP-OBS pairs. In unpuffed trials, there was merely a trend of reduced calling during the delay period: stim call probability 0.35 [0.08, 0.65] vs delay call probability 0.36 [0.16, 0.91], median difference 0.08 (Delay � Stim), p?=?0.052, test statistic?=?327, two-sided Wilcoxon sign rank test, n?=?6 EXP-OBS pair. In combination, the reduction in calling rate was much more pronounced during puffed trials: difference in median call probabilities for puffed (Delay � Stim) � unpuffed (Delay � Stim)?=??0.23, p?=?10?6, test statistic?=?592, two-sided Wilcoxon rank sum test, n?=?6 EXP-OBS pairs). Hence, the significant reduction in calling rates during puffed trials could signal the imminent arrival of an air puff.
 To test whether observers used calls as a learning cue, we housed experimenters and observers (n?=?5 pairs) in separate soundproof boxes and gave them visual access to each other by virtue of two adjacent windows. Moreover, to trigger social interest, we allowed birds to vocally interact with each other using a custom digital communication system composed of two microphones and loudspeakers and an echo cancellation filter (Supplementary methods). We suppressed vocal exchanges during stimulus presentation by interrupting the communication system from stimulus onset to air-puff offset. We termed the observers in this paradigm no-trial-communication learners (-TCOM). Despite elimination of vocal interactions during the discrimination task, we found that -TCOM acquired stimulus-discriminative information in amounts comparable to OBS (trials to criterion: -TCOM (n?=?5): 800 [800, 4900]; OBS (n?=?9): 900 [800, 5600]; OBS � TCOM�median difference ?=?0.00001, p?=?0.77, test statistic?=?25, two-sided Wilcoxon rank sum test, 95% CI?=?[?1200 2300]), Fig.�4e. Hence, it follows that OBS did not require immediate vocal interactions. They could learn from visual displays only or from vocal exchanges following trials.
 Regularized logistic regression differentiates OBS from EXP
 Observer behavior was reminiscent of a machine learning system that overfits the training data and generalizes poorly because it contains too many parameters and is trained on too few examples. In this sense, observers seemed to lack regularization, which is an umbrella term for all kinds of processes that prevent overfitting by introducing additional information, for example to use as few nonzero parameters as possible during fitting. Essentially, regularization methods improve generalization performance by dynamically regulating the use of parameters and of training data16,17.
 In the context of our findings, these insights from statistical learning theory suggest that direct experience of the reinforcing learning cue is associated with regularization whereas observation is not. We tested the hypothesis that regularization could set the divide between experimenter and observer behaviors, by training a simple artificial neuron with a logistic activation function to discriminate between the two stimulus sets, Fig.�5a. The neuron received input from a group of at least 22 input neurons tuned to diverse sound features such as amplitude, pitch, duration, and Wiener Entropy, collectively defining the feature set used in Sound Analysis Pro (SAP), a popular birdsong analysis software18 (Supplementary Figure�4 and Supplementary Table�1). To model observers, we trained the neuron to fire during puffed stimuli and to remain silent during unpuffed stimuli. We used a gradient descent learning rule that maximizes the likelihood of correct discrimination (Methods). We found that the discriminative performance of the �observer� neuron increased rapidly to the theoretical limit on the training set, but when we interrupted the training at any time and evaluated the neuron�s performance on the testing set, we found poor generalization, Fig.�5b. The reason for poor generalization was that the neuron based its classification on exceedingly many sound features that by chance were slightly informative about the reinforcing air-puff, Fig.�5e and Supplementary Figure�4.
 We then modeled experimenters by endowing the learning rule with L1 regularization. L1 regularization implements a conjunctive minimization of summed absolute synaptic weights17 that we implemented at each synaptic weight update as a small reduction of synaptic weights by an amount ?19. We used L1 regularization because it is very simple (subtractive) and because it allowed us to formulate a mechanism that dynamically regulates the regularization parameter ? in proportion to reward prediction error (Methods), known to be signaled in the vertebrate brain by a class of dopaminergic neurons20�22. According to our proposal, regularization (weight reduction) increases when the bird suddenly receives less reward than expected, as in experimenters that get hit by an air puff for the first time. Our proposed mechanism is such that when experimenters reach a high rate of success, the reward prediction error reaches zero in expectation, which settles the value of ?, Fig.�5c. The observer brain would not modulate ? because observers do not directly experience rewards and punishments during the experimenter training phase.
 We found that interrupting the training process of the regularized neuron at any time resulted in roughly equal performances on both training and testing stimulus sets, Fig.�5d, similar to experimenters� behavior. However, the excellent generalization performance came at a cost: Because of the repeated reductions of synaptic weights in modeled experimenters, their synaptic weights and performance on the training set grew only slowly. The main effect of regularization was to concentrate the final synaptic weights on the duration feature, corresponding with our design of stimulus class, Fig.�5e.
 We tested other explanations for the differences between experimenters and observers, such as assuming that observers learned from noisy experimenter actions, but found regularization to be the only mechanism that achieved satisfactory simulations results�(Supplementary Figure 5).","We introduced a new comparative approach to observation learning of a discrimination task. We quantified task performance in terms of learning speed and ability to generalize, analogous to studies on observational learning of motor tasks, in which performance is quantified in terms of reaction times and generalization across motor effectors23,24.
 We found that zebra finches can learn to discriminatively respond to auditory stimuli by observing expert performers. Experimenter and observers� behaviors were subject to a tradeoff that depended on whether the learning cue was experienced or observed. We inferred this cue dependence thanks to our experiment design in which the stream of auditory stimuli was identical for experimenters and observers. Therefore, any differences in their abilities to learn and to generalize must have been entirely due to the learning cue, which was an aversive air-puff for experimenters and an observable action for observers. Our findings suggest that an experienced cue favors robust generalization, whereas an observed cue favors rapid learning.
 Part of our findings are in line with social learning theories which suggest that to learn from others is a successful strategy with high payoff under a wide range of conditions25,26. However, our findings also suggest a limitation to the ubiquitous success of social learning strategies. Namely, we find that social learning can lack robustness when environmental conditions even slightly change. As in the case of children who perform poorly in exams after neglecting their homework, insights gained through observation seem not to transfer well to new task instances.
 Currently, there is no reason to think that all forms of observation learning will be subject to lack of robustness. For example, it is not clear that male zebra finches would exhibit similar behaviors given the known sex differences in social learning27 also in airpuff paradigms28. Furthermore, it is not clear whether our findings will generalize to other reinforcers including reward and strong punishment (e.g. by electric shock). It is even uncertain whether to be observed played a role for experimenters� robust learning. In the light of all these possibilities, our work raises the question as to whether there exist some forms of observation learning that promote robust transfer to new task instances.
 Our work raises many interesting questions on the behavioral and neurobiological mechanisms used by observers to acquire stimulus-discriminative information. Behaviorally, observers could learn through social mechanisms of action imitation, of observational conditioning, and of stimulus enhancement, or a combination of these. Note that the definitions of these mechanisms are not strict enough to allow a discrete categorization of social learning in any one study29. Our findings de-emphasize some known social learning mechanisms such as perceptual learning (evidenced by PL learners) and simple stimulus enhancement (evidenced by lack of discriminative behavior during pre-testing, Supplementary Figure 3). Our experiments also de-emphasize vocal communication as a mechanism but reveal the importance of vision (-TCOM learners). Overall, the importance of a demonstrating expert suggests that experimenters signal statistical differences between puffed and unpuffed stimuli via their perching behavior such as their rates of leaving the perch. Possibly, observers focused their attention more on the diverse�actions of experimenters and their relationships with the stimuli, which is why observers apparently failed to identify the simplest environmental signal that can explain experimenters� behavior, which in our case was syllable duration.
 Similar speed-robustness learning tradeoffs as the one we find exist in rapidly evolving artificial systems, in which high discrimination performance tends to be associated with slow learning as an unwanted side effect30. The tradeoff we find between robustness in one learning paradigm and speed in another is most closely paralleled by regularization methods that control inference through synaptic weight subtraction. Excellent generalization of experimenters agrees with strongly regularized classifiers whereas fast learning in observers agrees with weakly regularized classifiers. Our work suggests that the benefits of regularization may be inherent to experimenting but not to observing31.
 It is far from clear how a brain could implement dynamic regularization. Our speculative proposal is that the balance between learning and regularizing is controlled by a neuromodulatory signal. Such signals are ubiquitous in the animal kingdom and are well suited to convey the amount of regularization, given that they respond sensitively to external reinforcements and their prediction errors32�36. One possibility is that air-puff reinforcers drive changes in regularization via experimenters� escape actions, which is supported by the representation of action-specific reward values in brain areas innervated by neuromodulatory neurons37. This proposal delineates a possible neural system for comparative studies of learning from experience and from observation. It has been shown that reward prediction error and reinforcement learning algorithms in general, may be utilized by humans in order to understand the social value of others� behavior38,39, to feel vicarious rewards from their success or failure40 or from their approval41. We believe that the computational role of reward prediction error can be extended to that of regularization of learning, mediated by neuromodulator systems such as acetylcholine�or dopamine. Furthermore, subtractive weight depression through heterosynaptic competition has been observed in the amygdala31, which provides biological plausibility to L1 regularisation in the brain. We hypothesize that some form of synaptic depression is seen in zebra finches when they are experimenting, but not�when they are observing.
 The speculative implications of our simulations are that a prerequisite for the evolution of observation learning was a sufficiently large brain capacity that provided rich sensory representations and put few constraints on usable neural resources for sensory processing. Evolution might have chosen traits in observers that are complementary to those associated with experimenting, explaining the apparent differences in what these learning strategies extract from the sensory environment."
1,1789181,"""A Spiking Neural Network Framework for Robust Sound Classification""","""10.3389/fnins.2018.00836""",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6252336/,s3,s4,"In this section, we first present the classification results of the proposed SOM-SNN framework for the two benchmark datasets and then compare them with other baseline models. Next, we discuss its early decision-making capability, the effectiveness of using the SOM for feature representation and its underlying hyperparameters, as well as the key differences between the feedforward SNN-based and RNN-based systems for a temporal classification task. Finally, we demonstrate the improved classification capability of the modified Maximum-Margin Tempotron learning rule and the robustness of the framework against environmental and neuronal noises.
 3.1. Classification results
3.1.1. RWCP dataset
 As shown in Table ?Table1,1, the SOM-SNN model achieved a test accuracy of 99.60%, which is competitive compared with other deep learning and SNN-based models. As described in the experimental set-up, the MLP and CNN models are trained using spectrogram images of fixed dimensions, instead of explicitly modeling the temporal transition of frames. Despite their high accuracy on this dataset, it may be challenging to use them for classifying sound samples of long duration; the temporal structures will be affected inconsistently due to the necessary rescaling of the spectrogram images (G�tig and Sompolinsky, 2009). On the other hand, the RNN and LSTM models capture the temporal transition explicitly. These models are however hard to train for long sound samples due to the vanishing and exploding gradient problem (Greff et al., 2017).
 LSF-SNN (Dennis et al., 2013) and LTF-SNN (Xiao et al., 2017) classify the sound samples by first detecting the spectral features in the power spectrogram, and then encoding these features into a spatiotemporal spike pattern for classification by a SNN classifier. In our framework, the SOM is used to learn the key features embedded in the acoustic signals in an unsupervised manner, which is more biologically plausible. Neurons in the SOM become selective to specific spectral features after training, and these features learned by the SOM are more discriminative as shown by the superior SOM-SNN classification accuracy compared with the LSF-SNN and LTF-SNN models.
 3.1.2. Tidigits dataset
 As shown in Table ?Table2,2, it is encouraging to note that the SOM-SNN framework achieves an accuracy of 97.40%, outperforming all other bio-inspired systems on the TIDIGITS dataset. In Anumula et al. (2018), Abdollahi and Liu (2011), and Neil and Liu (2016), novel systems are designed to work with spike streams generated directly from the AER silicon cochlea sensor. This event-driven auditory front-end generates spike streams asynchronously from 64 bandpass filters spanning over the audible range of the human cochlea. Anumula et al. (Abdollahi and Liu, 2011) provide a comprehensive overview of the asynchronous and synchronous features generated from these raw spike streams, once again highlighting the significant role of discriminative feature representation in speech recognition tasks.
 Tavanaei et al. (Tavanaei and Maida, 2017a,b) proposes two biologically plausible feature extractors constructed from SNNs trained using the unsupervised spike-timing-dependent plasticity (STDP) learning rule. The neuronal activations in the feature extraction layer are then transformed into a real-valued feature vector and used to train a traditional classifier, such as the HMM or SVM models. In our work, the features are extracted using the SOM and then used to train a biologically plausible SNN classifier. These different biologically inspired systems represent an important step toward an end-to-end SNN-based automatic speech recognition system.
 We note that the traditional RNN based system offers a competitive accuracy of 97.90% (Anumula et al., 2018); our proposed framework, however, is fundamentally different from traditional deep learning approaches. It is worth noting that the network capacity and classification accuracy of our framework can be further improved using multi-layer SNNs.
 3.2. Early decision making capability
 We note that the SNN-based classifier can identify temporal features within the spatiotemporal spike pattern and generate an output spike as soon as enough discriminative evidence is accumulated. This cumulative decision-making process is more biologically plausible, as it mimics how human makes decisions. A key benefit of such a decision-making process is low latency. As shown in Figure ?Figure3A,3A, the SNN classifier makes a decision before the whole pattern has been presented. On average, the decision is made when only 50% of the input is presented.
 Additionally, we conduct experiments on the SOM-SNN, RNN, and LSTM models, whereby they are trained on the full input patterns but tested with only a partial presentation of the input. The training label is provided to the RNN and LSTM models at the end of each training sequence by default as it is not clear beforehand when enough discriminative features have been accumulated. Likewise, the training labels are provided at the end of input patterns for the SNN classifier. For testing, we increase the duration of the test input pattern presented from 10 to 100% of the actual duration, starting from the beginning of each pattern. As shown in Figure ?Figure6B,6B, the classification accuracy as a function of the input pattern percentage increases more rapidly for the SNN model. It achieves a satisfactory accuracy of 95.1% when only 50% of the input pattern is presented, much higher than the 25.7 and 69.2% accuracy achieved by the RNN and LSTM models respectively. For the RNN and LSTM models to achieve early decision-making capability, one may require that the models be trained with partial inputs or output labels provided at every time-step. Therefore, SNN-based classifiers demonstrate great potential for real-time temporal pattern classification, compared with state-of-the-art deep learning models such as the RNN and LSTM.
 3.3. Feature representation of the SOM
 To visualize the features extracted by the SOM, we plot the BMU activation sequences and their corresponding trajectories on the SOM for a set of randomly selected samples from class �bell5,� �bottle1,� and �buzzer� in Figure ?Figure4.4. We observe low intra-class variability and high inter-class variability in both the BMU activation trajectories and sequences, which are highly desirable for pattern classification. Furthermore, we perform tSNE clustering on the concatenated input vectors entering the SOM and the BMU trajectories generated by the SOM. In Figure ?Figure5A5A (input vectors entering the SOM), it can be seen that samples from the same class are distributed over several clusters in 2D space (e.g., class 7, 10). The corresponding BMU vectors, however, merge into a single cluster as shown in Figure ?Figure5B,5B, suggesting lower intra-class variability achieved by the SOM. The class boundaries for the BMU trajectories may now be drawn as shown in Figure ?Figure5B,5B, suggesting high inter-class variability. The outliers in Figure ?Figure5B5B maybe an artifact due to the uniform rescaling performed on BMU trajectories, a necessary step for tSNE clustering.
 We note that the time-warping problem exists in the BMU activation sequences, whereby the duration of sensory stimuli fluctuates from sample to sample within the same class. However, the SNN-based classifier is robust to such fluctuations as shown in the classification results. The decision to fire for a classifying neuron is made based on a time snippet of the spiking pattern; such is the nature of the single spike-based temporal classifier. As long as the BMU activation sequence stays similar, duration fluctuations of input sample will not affect the general trajectory of the membrane potential in each output neuron; the right classification decision, therefore, can be guaranteed. Hence, those outliers in Figure ?Figure5B5B underlying the time-warping problem may not necessarily lead to poor classification.
 To investigate whether the feature dimension reduction of the SOM is necessary for the SNN classifier to learn different sound categories, we performed experiments that directly input the spike trains of the latency-encoded (20 neurons) (Yu et al., 2013b) or population-encoded (144 neurons) (Bohte et al., 2002) mel-scaled filter bank outputs into the SNN for classification. We find that the SNN classifier is unable to classify such low-level spatiotemporal spike patterns, and only achieve 10.2 and 46.5% classification accuracy for latency- and population-encoded spike patterns, respectively. For both latency- and population-encoded spike patterns, as all encoding neurons spike in every sound frame, albeit with different timing, the synaptic weights therefore either all strengthen or all weaken in the event of misclassification as defined in the Tempotron learning rule. Such synchronized weight updates make it challenging for the SNN classifier to find discriminative features embedded within the spike pattern.
 As summarized in the section 1, the learning rules for the SNN can be categorized into either membrane-potential based or spike-time based; the Maximum-Margin Tempotron learning rule belongs to the former. To study the synergy between the SOM-based feature representation and spike-time based learning rule, we conducted an experiment using the ReSuMe (Ponulak and Kasi?ski, 2010) learning rule to train the SNN classifier. For a fair comparison with the Maximum-Margin Tempotron learning rule, we use one output neuron to represent each sound class and each neuron has a single desired output spike. To determine the desired spike timing for each output neuron, we first present all training spiking patterns from the corresponding sound class to the randomly initialized SNN; and monitor the membrane potential trace of the desired output neuron during the simulation. We note the time instant when the membrane potential trace reaches its maximum (denoted as Tmax) for each sound sample, revealing the most discriminative local temporal feature. We then use the mean of Tmax across all 20 training samples as the desired output spike time. As shown in Table ?Table1,1, the SNN trained with ReSuMe rule achieves a classification accuracy of 97.0%, which is competitive with other models. This, therefore, demonstrates the compatibility of features extracted by the SOM and spike-time based learning rules, whereby the intra-class variability of sound samples is circumvented by SOM feature extraction such that a single desired spike time for each class suffices.
 We note that the SOM functions as an unsupervised sparse feature extractor that provides useful, discriminative input to downstream ANN classifiers. As shown in Table ?Table1,1, the classification accuracy of the SOM-RNN model is better than that of the RNN model alone, and the accuracy of the SOM-LSTM model is also comparable to that of the LSTM model. Additionally, we also notice faster training convergence for both the SOM-RNN and SOM-LSTM models compared to those without the SOM, requiring approximately 25% less number of epochs. This observation may be best explained by the observations made in Figure ?Figure4,4, whereby only a subset of the SOM neurons are involved in the spiking patterns of any sound sample (with low intra-class variability and high inter-class variability) which in itself is highly discriminative.
 To analyze the effect of different hyperparameters in the SOM on classification accuracy, we perform the following experiments:
 Neural Map Size. We sweep the SOM neural map size from 2 � 2 to 16 � 16. As shown in Figure ?Figure6,6, we notice improved SNN classification accuracy with larger neural map, which suggests that a larger SOM captures more discriminative features and therefore generates more discriminative spiking patterns for different sound classes. However, the accuracy plateaus once the number of neurons exceeds 120. We suspect that with more neurons the effect of the time-warping problem starts to dominate, leading to more misclassification. Hence, the optimum neural map size has to be empirically determined.
 Number of Training Epochs. We sweep the number of training epochs used for the SOM from 100 to 1,000 with an interval of 100. We observe improvements in classification accuracy of the SNN classifier, with more training epochs of the SOM, which plateaus at 400 for the RWCP dataset.
 Number of Activated Neurons. We perform experiments with different number of activated output neurons K = [1, 2, 3] for each sound frame. Specifically, the distances between the SOM output neurons' synaptic weight vectors and the input vector are computed, and the top K neurons with the closest weight vectors will emit a spike. The neural map sizes are swept from 2 � 2 to 16 � 16, with number of training epochs fixed at 400. As shown in Figure ?Figure6,6, with more activated output neurons in the SOM, the SNN achieves lower classification accuracy for neural map size below 100, while achieving higher accuracy for neural map size larger than that. It can be explained by the fact that for smaller neural maps, given the same number of feature clusters, fewer neurons are allocated to each cluster. Now, with more activated neurons per frame, either fewer clusters can be represented, or the clusters are now less distinguishable from each other. Either way, inter-class variability is reduced, and classification accuracy is adversely affected. This capacity constraint is alleviated with a larger neural map, whereby neighboring neurons are usually grouped into a single feature cluster. As shown in the inset of Figure ?Figure6,6, for neural map size larger than 100, more activated neurons per frame improves the feature representation with some redundancy and lead to better classification accuracy. However, it should be noted that with more activated neurons per frame, there are more output spikes generated in the SOM, hence increasing energy consumption. Therefore, a trade-off between classification accuracy and energy consumption has to be made for practical applications.
 3.4. Tempotron learning rule with hard maximum-margin
 As described in section 2, we modify the original Tempotron learning rule by adding a hard margin ? to the firing threshold Vthr. With this modification, we note that the classification accuracy of the SNN increases by 2% consistently with the same SOM dimensions.
 To demonstrate how the hard margin ? improves classification, we show two samples which have been misclassified by the SNN classifier trained with the original Tempotron rule (Figures 7A,B), but correctly classified by the Maximum-Margin Tempotron rule (Figures 7C,D). In Figure ?Figure7A,7A, both output neurons (i.e., �ring� and �bottle1�) are selective to the discriminative local feature occurring between 2 and 10 ms. While in Figure ?Figure7B,7B, the discriminative local feature is overlooked by the desired output neuron, possibly due to the time-warping, and the output neuron representing another class fires erroneously afterward.
 When trained with the additional hard margin ?, the negative output neuron representing the �bottle1� class is suppressed and prevented from firing (Figure ?(Figure7C).7C). Similarly, the negative output neuron representing the �metal15� class is also slightly suppressed, while the positive output neuron representing the �kara� class undergoes LTP and correctly crosses the Vthr (Figure ?(Figure7D).7D). Therefore, the additional hard margin ? ensures a better separation between the positive and negative classes and improves classification accuracy.
 Since the relative ratio between the hard margin ? and the firing threshold Vthr is an important hyper-parameter, we investigate its effect on the classification accuracy using the RWCP dataset by sweeping it from 0 to 1.2 with an interval of 0.1. The experiments are repeated 20 times for each ratio value with random weight initialization. For simplicity, we only study the symmetric cases whereby the hard margin has the same absolute value for both positive and negative neurons. For the case when the ratio is 0, the learning rule is reduced to the standard Tempotron rule. As shown in Figure ?Figure8,8, the hard margin ? improves the classification accuracy consistently for ratios below 1.0, and the best accuracy is achieved with a ratio of 0.5. The accuracy drops significantly for ratio above 0.9, suggesting a high level of margin may interfere with learning and lead to brittle models.
 3.5. Robustness to noise
3.5.1. Environmental noise
 We report the classification accuracies over 10 runs with random weight initialization in Tables ?Tables3,3, ?,44 for mismatched and multi-condition training respectively.
 We note that under the mismatched condition, the classification accuracy for all models degrades dramatically with an increasing amount of noise and falls below 50% with SNR at 10 dB. The LSF-SNN and LTF-SNN models use local key points on the spectrogram as features to represent the sound sample, and are therefore robust to noise under such conditions. However, the biological evidence for such spectrogram features is currently lacking.
 3.5.2. Spike jittering As shown in Table ?Table4,4, multi-condition training effectively addresses the problem of performance degradation under noisy conditions, whereby MLP, CNN, LSTM, and SOM-SNN models have achieved classification accuracies above 95% even at the challenging 0 dB SNR. Similar to observations made in McLoughlin et al. (2015), we note that the improved robustness to noise comes with a trade-off in terms of accuracy for clean sounds, as demonstrated in the results for the ANN models. However, the classification accuracies improve across the board for the SOM-SNN model under all acoustic conditions using the multi-condition training, achieving an accuracy of 98.7% even for the challenging case of -5 dB SNR. The SOM-SNN model hence offers an attractive alternative to other models especially when a single trained model has to operate under varying noise levels.
 3.5.2. Spike jittering
 As shown in Figure ?Figure9A,9A, the SOM-SNN model is shown to be highly robust to spike jittering and maintains a high accuracy independent of the number of neurons activated per sound frame in the SOM. We suspect that given only a small subset of neurons in the SOM are involved for each sound class, the requirement of the SNN for precise spike timing is relaxed.
 3.5.3. Spike deletion
 As shown in Figure ?Figure9B,9B, the SOM-SNN model maintains a high classification accuracy when spike deletion is performed on the input to the SNN. As only a small subset of pre-synaptic neurons in the SOM deliver input spikes to the SNN for each sound class, with high inter-class variability, the SNN classifier is still able to classify correctly even with some input spike deletion. The peak membrane potential value is used in some cases to make the correct classification.","In this paper, we propose a biologically plausible SOM-SNN framework for automatic sound classification. This framework integrates the auditory front-end, feature representation learning and temporal classification in a unified framework. Biological plausibility is a key consideration in the design of our framework, which distinguishes it from many other machine learning frameworks.
 The SOM-SNN framework is organized in a modular manner, whereby acoustic signals are pre-processed using a biologically plausible auditory front-end, the mel-scaled filter bank, for frequency content analysis. This framework emulates the functionality of the human cochlea and the non-linearity of human perception of sound (Bear et al., 2016). Although it is still not clear how information is represented and processed in the auditory cortex, it has been shown that certain neural populations in the cochlear nuclei and primary auditory cortex are organized in a tonotopic fashion (Pantev et al., 1995; Bilecen et al., 1998). Motivated by this, the biologically plausible SOM is used for the feature extraction and representation of mel-scaled filter bank outputs. The selectivity of neurons in the SOM emerges from unsupervised training and organizes in a tonotopic fashion, whereby adjacent neurons share similar weight vectors. The SOM effectively improves pattern separation, whereby each sound frame originally represented by a 20-dimensional vector (mel-scaled filter bank output coefficients) is translated into a single output spike. The resulting BMU activation sequences are shown to have the property of low intra-class variability and high inter-class variability. Consequently, the SOM provides an effective and sparse representation of acoustic signals as observed in the auditory cortex (Hrom�dka et al., 2008). Additionally, the feature representation of the SOM was shown to be useful inputs for RNN and LSTM classifiers in our experiments.
 Although the SOM is biologically inspired by cortical maps in the human brain, it lacks certain characteristics of the biological neuron, such as spiking output and access to only local information. Other studies (Rumbell et al., 2014; Hazan et al., 2018) have shed light on the feasibility of using spiking neurons and spike-timing dependent plasticity (STDP) learning rule (Song et al., 2000) to model the SOM. We would investigate how we may integrate the spiking-SOM and the SNN classifier for classification tasks in the future.
 Acoustic signals exhibit large variations not only in their frequency contents but also in temporal structures. State-of-the-art machine learning based ASC systems model the temporal transition explicitly, using the HMM, RNN or LSTM, while our work focuses on building a biologically plausible temporal classifier based on the SNN. For efficient training, we use supervised temporal learning rules, namely the membrane-potential based Maximum-Margin Tempotron and spike-timing based ReSuMe. The Maximum-Margin Tempotron (combining the Tempotron rule with the maximum-margin classifier) ensures a better separation between the positive and negative classes, improving classification accuracy in our experiments. As demonstrated in our experiments, the SOM-SNN framework achieves comparable classification results on both the RWCP and TIDIGITS datasets against other deep learning and SNN-based models.
 We further discover that the SNN-based classifier has an early decision making capability: making a classification decision when only part of the input is presented. In our experiments, the SNN-based classifier achieves an accuracy of 95.1%, significantly higher than those of the RNN and LSTM (25.7% and 69.2% respectively) when only 50% of the input pattern is presented. This early decision making capability can be further exploited in noisy environments, as exemplified by the cocktail party problem (Haykin and Chen, 2005). The SNN-based classifier can potentially identify discriminative temporal features and classify accordingly from a time snippet of the acoustic signals that are less distorted, which is desirable for an environment with fluctuating noise.
 Environmental noise poses a significant challenge to the robustness of any sound classification systems: the accuracy of many such systems degrade rapidly with an increasing amount of noise as shown in our experiments. Multi-condition training, whereby the model is trained with noise-corrupted sound samples, is shown to overcome this challenge effectively. In contrast to the DNN and SVM classifiers (McLoughlin et al., 2015), there is no trade-off in performance for clean sounds in the SOM-SNN framework with multi-condition training; probably because the classification decision is made based on local temporal patterns. Additionally, noise is also known to exist in the central nervous system (Schneidman, 2001; van Rossum et al., 2003) which can be simulated by spike jittering and deletion. Notably, the SOM-SNN framework is shown to be highly robust to such noises introduced to spike inputs arriving at the SNN classifier.
 The SNN classifier makes a decision based on a single local discriminative feature which often only lasts for a fraction of the pattern duration, as a direct consequence of the Maximum-Margin Tempotron learning rule. We expect improved accuracy when more such local features within a single spike pattern are utilized for classification, which may be learned using the multi-spike Tempotron (G�tig, 2016; Yu et al., 2018). The accuracy of the SOM-SNN model trained with the ReSuMe learning rule may also be improved by using multiple spike times. However, defining these desired spike times is a challenge exacerbated by increasing intra-class variability. Although the existing single-layer SNN classifier has achieved promising results on both benchmark datasets, it is not clear how the proposed framework may scale for more challenging datasets. Recently, there is progress made in training multi-layer SNNs (Lee et al., 2016; Neftci et al., 2017; Wu et al., 2018b), which could significantly increase model capacity and classification accuracy. For future work, we would investigate how to incorporate these multi-spike and multi-layer SNN classifiers into our framework for more challenging large-vocabulary speech recognition tasks.
 For real-life applications such as audio surveillance, we may add inhibitory connections between output neurons to reset all neurons once the decision has been made (i.e., a winner-takes-all mechanism). This allows output neurons to compete once again and spike upon receipt of a new local discriminative spike pattern. The firing history of all output neurons can then be analyzed so as to understand the audio scene.
 The computational cost and memory bandwidth requirements of our framework would be the key concerns in a neuromorphic hardware implementation. As the proposed framework is organized in a pipelined manner, the computational cost could be analyzed independently for the auditory front-end, SOM and SNN classifier. For the auditory front-end, our implementation is similar to that of the MFCC. As evaluated in Anumula et al. (2018), the MFCC implementation is computationally more costly compared to the spike trains generated directly from the neuromorphic cochlea sensor. Our recent work (Pan et al., 2018) proposes a novel time-domain frequency filtering scheme which addresses the cost issue in MFCC implementation. We expect the SOM to be the main computational bottleneck of the proposed framework. For each sound frame, the calculation of the Euclidean distance of synaptic weights from the input vector is done for each SOM neuron. Additionally, the distances are required to be sorted so as to determine the best-matching units. However, this computational bottleneck can be addressed with the spiking-SOM implementation (Rumbell et al., 2014; Hazan et al., 2018), whereby the winner neuron spikes the earliest and inhibits all other neurons from firing (i.e., a winner-takes-all mechanism) and hence by construction, the BMU. The spiking-SOM also facilitates the implementation of the whole framework on a neuromorphic hardware. In tandem with the SNN classifier, a fully SNN-based framework when implemented would translate to significant power saving.
 As for memory bandwidth requirements, the synaptic weight matrices connecting the auditory front-end with the SOM and the SOM with the SNN classifier are the two major components for memory storage and retrieval. For the synaptic connections between the auditory front-end and the SOM, the memory bandwidth increases quadratically with the product of the number of neurons in the SOM and the dimensionality of the filter banks. Since the number of output neurons is equal to the total number of classes and hence fixed, the memory bandwidth only increases linearly with the number of neurons in the SOM. Therefore, the number of neurons in the SOM should be carefully designed for a particular application considering the trade-off between classification accuracy and hardware efficiency."
2,271920,"""Learning and processing of nonverbal symbolic information in bilinguals and monolinguals""","""10.3389/fpsyg.2014.01147""",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4199272/,s3,s4,"Sound-to-symbol mapping learning outcomes
When learning outcomes were examined in all bilinguals and monolinguals, including individuals who performed below 65% accuracy, statistically equivalent performance was found between bilinguals' post-training accuracy (M = 71.5%, SD = 16.3) and monolinguals' post-training accuracy (M = 76.1%, SD = 13.1), t(65) = 1.2, p > 0.1. However, a chi-squared test examining the distribution of low-accuracy performers (<65%) across bilinguals and monolinguals was marginally significant, Chi-Squared (df = 1) = 3.8, p = 0.051, suggesting different distributions of lower learning outcomes in the bilinguals vs. monolinguals (see Participants Section). Nonparametric independent samples Mann�Whitney U tests suggested that the bilingual learners and non-learners differed on post-training and overall processing accuracies (ps < 0.001), showed a marginal difference on numbers reversed performance (p = 0.076, learners: M = 16.9, SE = 0.7; non-learners: M = 14.5, SE = 1.2), but did not differ on the remaining language history, cognitive, and linguistic measures listed in Table ?Table11.
 When participants with overall accuracy below 65% were excluded, bilinguals (n = 27) and monolinguals (n = 27) reached similar post-training accuracies (monolinguals: M = 77.6%, SE = 2.2; bilinguals: M = 77.1%, SE = 2.1), t(52) = 0.16, p > 0.5, and response times (monolinguals: M = 3900.7 ms, SE = 215.4; bilinguals: M = 4417.8 ms, SE = 215.4), t(52) = 1.7, p = 0.1. Examination of post-training accuracies showed that monolinguals and bilinguals had equivalent mastery of the timbre dimension [main effect of group: F(1, 52) = 1.8, p > 0.1; group � timbre interaction: F(1, 52) = 0.089, p > 0.5], the pitch dimension [main effect of group: F(1, 52) = 1.8, p > 0.1; group � pitch interaction: F(1, 52) = 0.05, p > 0.5], and the duration dimension [main effect of group: F(1, 52) = 1.9, p > 0.1; group � duration interaction: F(1, 52) = 1.4, p > 0.1]. These findings suggested equivalent mastery of the learned symbolic system. Further, more efficient performance on tone-to-symbol mappings (response times divided by proportion correct) was associated with higher scores on the receptive vocabulary tasks in both monolinguals (PPVT: r = ?0.46, p < 0.05) and bilinguals (PPVT: r = ?0.36, p = 0.063; TVIP: r = ?0.22, p > 0.1; combined PPVT/TVIP: r = ?0.34, p = 0.087), suggesting that previous vocabulary knowledge is positively associated with learning success in the novel symbol system in terms of both higher accuracy rates and faster retrieval times. No associations were found between learning outcomes and performance on the matrix reasoning subtest of the WASI (ps > 0.5), numbers reversed (ps > 0.1), or on the Test of Auditory Discrimination (ps > 0.5).
 Processing and competition resolution during sound-to symbol mapping
Sound-to-symbol mapping, competition resolution and previous vocabulary knowledge
 To examine target identification during processing of similar tone-to-symbol mappings, a mixed linear model was employed with fixed effects including trials with and without competitor symbols (competitor, filler; baseline: filler) and language group (bilingual, monolingual; baseline: monolingual). In addition, z-transformed PPVT scores were entered as a continuous predictor variable. Finally, participants and items (target type) were entered as random effects on the slope. Findings yielded a main effect of competitor, with longer and less accurate responses to competitor trials (M = 3663.0 ms/proportion correct, SE = 118.6) than to filler trials (M = 3388.8 ms/proportion correct, SE = 105.1), b = ?608.7, SE = 295.5, p < 0.05. In addition, a main effect of vocabulary skill was found, with higher PPVT skills associated with quicker and more accurate responses (b = ?44.6, SE = 295.8, p < 0.05). Finally, an interaction emerged between language group and PPVT, with a stronger association between target identification efficiency and PPVT performance in monolinguals (R2 = 0.209) relative to bilinguals (R2 = 0.025, see Figure ?Figure5),5), b = ?980.8, SE = 533.8, p = 0.05. No other effects were significant.
 To examine the possibility that receptive vocabulary in Spanish, or in Spanish and English combined, would be a better predictor of performance in bilinguals, mixed linear models were created with performance on the Spanish TVIP and with combined performance on the PPVT and TVIP. No significant effects emerged for bilinguals involving either the TVIP or the combined PPVT and TVIP (all ps > 0.1). Together, findings suggest that (1) competition resolution during processing of novel symbolic information was comparable across bilinguals and monolinguals, (2) previous vocabulary knowledge did not influence competition resolution, and (3) previous vocabulary knowledge did influence overall response efficiency on the novel processing task, but more so in monolinguals than bilinguals.
  Sound-to-symbol mapping, competition resolution and previous success in learning symbolic information
 To examine the influence of learning success on target identification efficiency and competition resolution, previous symbolic learning success (z-transformed post-training accuracy) was entered into the previously-described mixed linear model instead of vocabulary skill. In addition to the previously-described main effect of competitor (b = ?600.9, SE = 286.6, p < 0.05), a main effect of training success was identified: Greater learning success was associated with greater tone-to-symbol retrieval efficiency, b = ?820.3, SE = 307.4, p < 0.01. This pattern was of statistically equivalent magnitude in bilinguals (R2 = 0.203) and monolinguals (R2 = 0.304), see Figure ?Figure6.6. No other effects were significant. Thus, (1) previous learning success did not influence competition resolution, yet (2) previous learning success did influence overall response efficiency on the novel processing task, an effect that did not differ across monolinguals and bilinguals.
  Priming: residual activation of sound-to-symbol targets and competitors
Residual inhibition of competitor symbols
 To examine residual inhibition of competitor symbols after target identification, a mixed linear model was employed with fixed effects including priming probes placed in previous baseline and competitor locations (baseline, competitor; baseline: baseline) and inter-stimulus interval (200, 500, 800; baseline: 200), as well as language group (bilingual, monolingual; baseline: monolingual). In addition, z-transformed PPVT scores and post-training accuracies were separately entered as continuous variables. Finally, participants were entered as random effects on the slopes of both competitor and inter-stimulus interval effects. Results yielded an interaction between competitor location and inter-stimulus interval: At 200 ms post-target identification, response efficiency was significantly longer and less accurate to competitor probes (M = 722 ms/proportion correct, SE = 16.9) than to baseline probes (M = 698.7, SE = 16.9), b = ?38.6, SE = 15.9, p < 0.05. This finding suggested residual inhibition of the competitor at 200 ms post-target identification. While the three-way interaction between language group, inter-stimulus interval, and priming probe did not reach significance, p > 0.1, planned follow-up contrasts suggested that the difference between competitor and baseline probes was significant for bilinguals, t(26) = ?2.6, p < 0.05, but not monolinguals, t(26) = ?1.9, p = 0.07. This finding suggests that, while both bilinguals and monolinguals showed patterns of residual inhibition at 200 ms post-target identification, this effect was somewhat more robust in bilinguals, see Figure ?Figure77.
 In addition, an interaction between language group and PPVT performance was again present, b = ?114.6, SE = 35.4, p < 0.01: Monolinguals with higher PPVT scores responded to priming probes with greater efficiency (R2 = 0.227), while no such effect was present in the bilinguals (R2 < 0.001). Consideration of Spanish vocabulary in bilinguals did not change this pattern (combined PPVT and TVIP: R2 for bilinguals = 0.004; TVIP only: R2 for bilinguals = 0.016). Finally, when learning success was entered into the model instead of vocabulary knowledge, no effect involving learning success reached significance. Together, these findings suggest that (1) a pattern of residual inhibition was identified at 200 ms post-target identification but not at 500 or 800 ms, (2), these inhibition effects were particularly robust in bilinguals, and (3) neither receptive vocabulary knowledge nor symbol learning success modulated these inhibition effects.
 Residual facilitation of target symbols
 To examine residual facilitation of target symbols after target identification, a mixed linear model was employed with fixed effects including priming probes placed in previous baseline and target locations (baseline, target; baseline: baseline) and inter-stimulus interval (200, 500, 800; baseline: 200), as well as language group (bilingual, monolingual; baseline: monolingual). In addition, z-transformed PPVT scores and post-training accuracies were separately entered as continuous variables. Finally, participants were entered as random effects on the slopes of both competitor and inter-stimulus interval effects. Findings yielded a main effect of priming probe location, with shorter and more accurate responses on target (M = 642.4 ms/proportion correct, SE = 14.2) than baseline probes (M = 700.2 ms/proportion correct, SE = 14.2), b = ?54.4, SE = 15.0, p < 0.001. When PPVT performance was entered into the model, we again found the previously described interaction between language group and PPVT, b = ?104.8, SE = 33.6, p < 0.01, R2bilinguals < 0.001; R2monolinguals = 0.226. In bilinguals, inclusion of the combined PPVT/TVIP score (R2 = 0.002) or the TVIP score (R2 = 0.014) did not alter this pattern. Finally, when learning success was entered into the model, no significant effects emerged involving training success. Together, these findings suggest robust residual target activation across language groups and inter-stimulus intervals.
 Associations between residual and Stroop inhibition
 Finally, we examined the relation between residual competitor inhibition after tone-to-symbol identification and performance on a nonlinguistic Stroop task. Stroop performance was analyzed with a mixed linear model with fixed factors including condition (center, congruent, incongruent; baseline: center) and language group (bilingual, monolingual; baseline: monolingual), and with participants entered as a random effect on the slope. Results yielded a main effect of condition, with responses on congruent trials (M = 458.0 ms/proportion correct, SE = 8.1) significantly faster and more accurate than responses on center trials (M = 482.9 ms/proportion correct, SE = 8.2), b = ?24.7, SE = 9.0, p < 0.01, and with incongruent trials (M = 585.9 ms/proportion correct, SE = 8.1) significantly slower and less accurate than center trials, b = 111.0, SE = 9.0, p < 0.001. No other effects were significant, suggesting equivalent Stroop inhibition performance across the bilingual and monolingual groups.
 Consistent with Blumenfeld and Marian (2011), negative priming effects were compared with the difference score between congruent and incongruent Stroop reaction times, with smaller effects reflecting better abilities to ignore location information. The z-transformed Stroop effect was entered as a continuous variable into the previously-presented mixed linear model examining priming probes. Since relations between residual inhibition and Stroop performance were of interest, the dependent variable in this model was the negative priming effect (baseline probes minus competitor probes). A three-way interaction emerged between language group, inter-stimulus interval, and Stroop performance: at 500 ms post-target identification, in bilinguals, a smaller Stroop effect was associated with less residual competitor inhibition, relative to monolinguals, b = 38.9, SE = 18.8, p < 0.05, R2bilinguals = 0.14, R2monolinguals = 0.02.","In the current study, we compared bilinguals' and monolinguals' performance during a nonlinguistic learning task that involved mapping tones to symbols within a novel symbolic system that consisted of three distinctive features (timbre, pitch, and duration). Both learning and subsequent processing were examined in bilinguals vs. monolinguals. Subtle differences were evident across the two groups, particularly in the processing domain. These findings suggest that, even when bilingual advantages are not present, bilinguals may differ from monolinguals on tasks that resemble lexical mapping and involve competition resolution.
Acquisition of novel tone-to-symbol mappings in bilinguals vs. monolinguals
 On the sound-to-symbol matching task, bilinguals did not show a learning advantage. These results are consistent with previous findings that bilingual learning advantages may be determined by how the novel information relates conceptually to the previously established language systems. For example, Kaushanskaya and Rechtzigel (2012) suggest that learning of a novel word that is tied to a concrete (vs. abstract) translation equivalent will more widely activate bilinguals' previous two languages and may thus yield a more facilitative context for learning and integration of new knowledge. In contrast to Kaushanskaya and Rechtzigel's concrete learning condition, the current study required participants to map a new symbolic system in the absence of relevant previous conceptual representations. In this sense, the current study may be likened to an extreme version of Kaushanskaya and Rechtzigel's abstract word learning condition, and is consistent with the prediction that bilinguals may only outperform monolingual learners if their previous knowledge can be directly employed to scaffold new learning.
 Perhaps because our task does not relate to bilinguals' previous language knowledge, the current findings stand in contrast with a previous nonverbal learning task where bilinguals showed advantages in learning a Morse code system (Bartolotti et al., 2011). One possible explanation for the absence in auditory processing advantages in the present study is that the current bilinguals had no previous language-based experience with the pitch, timbre, and duration dimensions in the current study, and in fact performed equivalently to monolinguals when learning these dimensions. Indeed, previous research has suggested that bilingual experience may reconfigure attention to linguistic and extralinguistic cues in the environment based on their relevance in previous learning experiences (e.g., Deutsch et al., 2004; Bialystok et al., 2005; Brojde et al., 2012). While natural language processing relies on listeners' capacity to make distinctions between pitch, timbre (i.e., formant structure) and duration, it is possible that the nature and constellation of these dimensions was too far removed from English-Spanish processing to allow for transfer of skills. For example, it is possible that Spanish-English bilinguals have some previous training on the fine-grained duration dimension that was critical in Bartolotti et al.'s learning task, given their awareness of temporal phonetic characteristics across their two languages, such as voice onset time discrimination in English vs. Spanish (e.g., Ju and Luce, 2004). However, the challenging combination of pitch, timbre, and duration dimensions may have differed from their previous linguistic experiences and clouded potential subtle advantages (e.g., Krumanshl and Iverson, 1992).
 It is also possible that subtle cognitive differences between bilinguals and monolinguals contributed to advantages on Bartolotti et al.'s learning task but not the current learning task. For example, bilingualism has previously been associated with advantages in auditory working memory (e.g., Adesope et al., 2010), and such advantages in working memory may in turn be linked to statistical learning success (Misyak and Christiansen, 2012). While Bartolotti et al. did not include an auditory working memory task (only a forward digit span task was included), bilinguals in the current study did not differ from their monolingual peers on an auditory backward digit span measure. Yet, auditory working memory skills may in part account for bilinguals who were not successful learners. Specifically, across all linguistic and cognitive measures, follow-up analyses did not yield significant differences between unsuccessful (<65% accuracy) and successful (>65% accuracy) bilingual learners, with only a marginal difference in numbers reversed present between the two groups (p = 0.076). While no significant correlation was present between post-training accuracy and numbers reversed in the bilingual non-learners (r = 0.33, p > 0.1), this working memory difference nevertheless may have contributed to learning outcomes. In fact, a positive correlation between overall accuracy and numbers reversed skills was present across all bilingual learners and non-learners (r = 0.4, p = 0.01). It is thus possible that reliance on working memory within the bilingual group was in part responsible for the larger proportion of weaker bilingual learners. Working memory has previously been linked to learning outcomes (e.g., Papagno and Vallar, 1995), and lower working memory in the current bilingual sample was also associated with lower PPVT scores (r = 0.4, p < 0.05, for similar findings, see Kaushanskaya et al., 2011). No such correlations were found in monolinguals (working memory and training outcomes: r = 0.04, p > 0.5; working memory and vocabulary: r = 0.17, p > 0.4).
 Beyond auditory working memory, several factors may account for the low tone-to-symbol mapping accuracies in the bilingual non-learners. In fact, combined learning of novel auditory and visual information was challenging for most participants (see post-training accuracies). For example, the length of both the training and processing phases required sustained attention and thus motivation to perform well. It may therefore be that sustained attention skills in general differentiated learners from non-learners, a possibility that can be explored in future research. Interestingly, while Spanish skills and language immersion were not significantly related to learning outcomes in the successful bilingual learners, in the bilingual non-learners higher Spanish skills and less English exposure were related to more successful learning (TVIP: r = 0.68, p < 0.05; English exposure: r = ?0.83, p < 0.01). Of the non-learners, 9 were Spanish-English bilinguals, one was a simultaneous bilingual, and one was an early English-Spanish bilingual. Thus, in the bilinguals who struggled to learn, skill in the native language appeared to support tone-to-symbol mapping. The reason for this observed link between L1 vocabulary and learning performance in monolinguals and bilingual non-learners may be that underlying cognitive strengths facilitate both vocabulary acquisition and better task performance. It is possible that L1 vocabulary is a particularly strong indicator of underlying word learning skills while L2 vocabulary may be more context-specific and thus a reflector of experience more than word-learning skills per se. In sum, the current findings contribute to limiting the scope of bilingual learning advantages. Further they raise new questions on the nature of bilingual learning advantages, as well as pre-requisite cognitive-linguistic skills, perhaps suggesting that aspects of bilingualism may provide richer opportunities for scaffolding during specific new learning contexts, but that bilingual experience may not modulate fundamental learning mechanisms.
 Sound-to-symbol processing differences between bilinguals and monolinguals
 Studying processing of newly-learned nonlinguistic information can eliminate group differences in content knowledge associated with bilingual status, thus providing an opportunity to compare competition resolution across groups in the absence of proficiency effects. Current findings across bilinguals and monolinguals that were equivalent on learning outcomes suggest subtle processing differences between the two groups. These differences emerged only when we examined the relation between sound-to-symbol retrieval and previous vocabulary knowledge and when the time course of inhibitory control was considered.
 During the processing task, the bilinguals and monolinguals, who had attained similar skill levels with the new symbol system, also showed similar symbol retrieval efficiency. Moreover, consistent with previous explanations of bilingual retrieval disadvantages (e.g., Ivanova and Costa, 2008; Gollan et al., 2011b), participants who had attained lower learning outcomes on the novel tone-to-symbol system also showed less efficient retrieval skills. This relation between learning success and subsequent retrieval efficiency was present to an equal extent in both bilinguals and monolinguals, mimicking previous patterns from linguistic tasks (Gollan et al., 2008; Whitford and Titone, 2012), and confirming that less robust learning of content influences sound-to-content links and shapes retrieval success.
 While retrieval efficiency could be in part explained by previous learning success in both bilinguals and monolinguals, a stronger link was identified between previous vocabulary knowledge and tone-to-symbol retrieval in the monolingual group. Specifically, in monolinguals, learners who had stronger English receptive vocabulary skills (as indexed by the PPVT) also were more efficient in retrieving sound-to-symbol mappings in the processing environment where these items had to be identified from competing alternatives. This association between receptive vocabulary knowledge and retrieval efficiency was not limited to trials with competitor items, but was found across competitor and no-competitor trials. These findings suggest that competition resolution during tone-to-symbol mapping was not modulated by previous receptive vocabulary. Rather, it appears that the ability to efficiently identify a newly-learned sound-to-symbol mapping among four alternatives was positively influenced by previous vocabulary. It is thus possible that skills that aid in the mapping of new vocabulary transferred to the novel task. Further, this effect also persisted during monolinguals' priming trials, perhaps suggesting that higher-vocabulary monolinguals used fewer cognitive resources during sound-to-symbol trials, allowing quicker responses on priming probes, or that higher-vocabulary monolinguals deployed attentional processes more efficiently in orienting toward relevant information on the displays.
 In contrast to monolinguals, no association was found between bilinguals' English receptive vocabulary and their performance on the sound-to-symbol mapping or priming trials. When combined English/Spanish or Spanish-only receptive vocabulary skills were considered, this association was not significantly strengthened. It is possible that, in monolinguals, a more centralized and less distributed lexical system may better capture general word learning skills and related cognitive factors that might contribute to mapping a new symbolic system. It is possible that since, in bilinguals, vocabulary skills are frequently more context-specific due to language immersion tied to specific social settings, it is more challenging to index their core vocabulary knowledge through standardized measures such as the ones employed here. As a result, core knowledge that may point to underlying word learning skills was perhaps not as successfully indexed in the bilinguals. Alternatively, it is possible that bilinguals, due to word-learning experiences across linguistic contexts, may have word mapping skills that are not necessarily associated with their overall word knowledge. Interestingly, in the bilinguals who did not succeed on the learning task, a link between Spanish receptive vocabulary and sound-to-symbol mapping success was in fact evident. These findings must be treated with care given the small sample of bilingual non-learners (n = 11). Yet, they speak to a shared scaffolding mechanism for newly learned sound-to-symbol mappings in monolinguals and bilinguals. Additional research is needed to examine L1 and L2 lexical contributions to novel word learning in bilinguals. In sum, the ability to identify tone-to-symbol targets among competing options was modulated by different yet related variables in bilinguals and monolinguals, with learning success predicting retrieval efficiency in both groups, but with previous vocabulary knowledge predicting symbol retrieval efficiency more in monolinguals than bilinguals.
 In addition to similarities in retrieval skills, monolinguals and bilinguals also showed similar competition effects within the novel symbol system. Findings of similar competition effects in monolinguals and bilinguals are consistent with previous language studies where linguistic competition resolution was examined and similar competition resolution patterns were found in the two groups (e.g., for lexical competition during word recognition, see Blumenfeld and Marian, 2011; for competition within a sentence context, see Paap and Yunyun, 2014). In the linguistic domain, comparisons of competition effects in bilinguals vs. monolinguals may be influenced by group differences in experience and proficiency, potentially obscuring bilingual advantages in competition resolution. However, the current findings suggest that, based on equivalent training and attainment, competition effects prior to target identification continue to have the same magnitude in the two groups.
 Further, competition effects were not modulated by previous vocabulary knowledge or by learning success. These results are consistent with previous findings that language-based competition effects may not be modulated by proficiency during naming (e.g., see Marian et al., 2013, for equivalent Stroop effects across trilinguals' languages with varying proficiency levels). Similarly, Marian and Spivey (2003) found comparable lexical competition effects in L1 and L2 during auditory word identification in proficient late bilinguals. Nevertheless, other sources suggest that, in bilinguals, conflict monitoring skills may be honed to better identify ambiguities as they arise (e.g., Abutalebi et al., 2012). It is possible that novel representations must be more established before effects of previous experience on competition resolution can become visible. As might be expected in very novice learners who might show more variability in responses (e.g., Hulstijn et al., 2009), considerable variability across items and participants may have occluded subtle influences on competition effects at this early stage of learning. As such, a possible relation between competition resolution and previous vocabulary can be examined at various proficiency levels in future research.
 While competition effects were similar in bilinguals and monolinguals, subtle group differences emerged in the nature of inhibition mechanisms that were deployed to resolve this competition. At 200 ms post-target identification, significant competitor inhibition effects were identified for bilinguals, with somewhat less robust inhibition effects in monolinguals. Interestingly, smaller Stroop inhibition effects were associated with less residual competitor inhibition at 500 ms post-target identification for bilinguals, with no such correlations in monolinguals. This correlation is suggestive of a time window where inhibition may be gradually lifted, given the absence of significant inhibition effects at this time. Together, it appears that inhibition effects lingered somewhat longer in bilinguals. These findings are consistent with Treccani et al. (2009)'s findings on a nonlinguistic priming task, and suggest that bilinguals may exert somewhat stronger inhibition effects than monolinguals to separate competitors from targets in novel symbolic processing environments.
 While in the nonlinguistic domain findings suggest that bilinguals may maintain inhibition longer than monolinguals, a different pattern may be present in the linguistic domain. In a linguistic context that is analogous to the current study, Blumenfeld and Marian (2011) showed inhibition of linguistic competitors at 500 ms post-target identification for monolinguals but not bilinguals. Instead, a correlation was present where bilinguals with smaller Stroop effects showed less residual competitor inhibition at 500 ms post-target identification. Therefore, while the timecourse of inhibition appears identical across nonlinguistic and linguistic domains in bilinguals, monolinguals show more sustained inhibition effects in the linguistic domain. Additional research is needed to better explicate this difference across modalities. It is possible that, as bilinguals become more proficient with content knowledge (as is the case in the linguistic domain), they may show faster competition resolution, also leading to earlier release of inhibition mechanisms post-target identification (e.g., Mishra et al., 2012). Monolinguals may sustain inhibition longer in a linguistic environment to protect against intrusion from similar-sounding words, while bilinguals may release such inhibition sooner to allow for language switches. As was the case for competition resolution prior to target identification, the magnitude of residual inhibition effects post-target identification was not modulated by experiential factors. These findings suggest that, at least for newly-learned symbolic information, the magnitude of inhibition may not be related to linguistic knowledge per se but may relate to participants' domain-general cognitive skills.
 Together, findings from the linguistic and nonlinguistic processing domains suggest that, while bilinguals and monolinguals are very similar in their efficiency of competition resolution (as indexed by response efficiency on tone-symbol mapping trials with vs. without competitors), they show subtle differences in the time course along which they maintain inhibition after word identification. In turn, as in Blumenfeld and Marian (2011), bilinguals and monolinguals showed equivalent magnitudes of target facilitation during the time immediately following target identification. It is likely that target facilitation acts as a competition resolution mechanism that complements inhibition of irrelevant information (e.g., Paradis, 2004), and previous work suggests that it outlasts inhibition effects across time (Tanaka and Shimojo, 2000). The current findings where residual activation was probed at three times post-target identification, confirm these patterns."
3,2617564,"""Efficient Coding and Statistically Optimal Weighting of Covariance among Acoustic Attributes in Novel Sounds""","""10.1371/journal.pone.0030845""",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3264631/,s3,s4,"1. Listener performance
Behavioral results from all experiments are presented in the right column of Figure 2, with discrimination accuracy (proportion correct) on the ordinate and testing block number on the abscissa. Given that Orthogonal discriminability is predicted to recover by the end of the experiment, omnibus analysis of variance (ANOVA) tests are likely to result in Type II error. Consequently, to retain sensitivity to differences in discriminability across conditions at different phases of the experiment, results are analyzed using planned-comparison paired-sample t-tests.
 a. Experiment 1
 Discrimination of Consistent pairs in the first block of testing (mean?=?0.67, s.e.?=?.01) was significantly better than discrimination of Orthogonal pairs (mean?=?0.60, s.e.?=?.03) (t 39?=?2.36, p<.025, Cohen's d?=?0.44; Figure 2B). While discrimination accuracy of Consistent pairs was numerically greater than that of Orthogonal pairs in the second (mean of 0.68 versus 0.63) and third testing blocks (0.69 versus 0.65), t-tests did not reach statistical significance (second block: t 39?=?1.58, p?=?.12; third block: t 39?=?1.27, p?=?.21). This pattern of results replicates Experiment 2 of Stilp et al. [22]; discrimination of Orthogonal test pairs is initially inferior to that of Consistent test pairs supporting a robust correlation, and performance recovers through further testing so that discrimination across conditions is comparable by the final testing block. It bears mention that in their Expt. 2 (r?=?0.97), Stilp et al. [22] report superior discrimination of Consistent sound pairs relative to Orthogonal sound pairs in the first as well as second testing block. Relative to that experimental design, Expt. 1 in the present report removes Single-cue stimuli while maintaining 18 Consistent sounds and 2 Orthogonal sounds yielding nearly the same correlation (r?=?0.98). In the present experiment, Consistent discrimination was significantly more accurate than Orthogonal discrimination in the first testing block (p<.025) with only a trend toward significance in the second testing block (p?=?0.12). It is unclear why the full pattern of significance was not fully replicated despite highly similar stimuli and correlation coefficients. Independent-samples t-test indicates that the difference in Consistent and Orthogonal discrimination in the second testing block did not significantly differ across experiments (t 78?=?0.73, p?=?0.47), suggesting patterns of results are not fundamentally different from one another. Results indicate that both the correlated and orthogonal dimensions appear to become weighted proportional to the amount of variance accounted for by each dimension.
 b. Experiment 2
Discrimination of Consistent pairs in the first block of testing (mean?=?0.66, s.e.?=?.02) was again significantly better than discrimination of Orthogonal pairs (mean?=?0.60, s.e.?=?.03) (t 39?=?2.71, p<.01, Cohen's d?=?0.43; Figure 2D). Despite restricting the range of acoustic evidence supporting the correlation, this early difference in discrimination persisted. Experiment 2 also reveals that correlation among stimulus attributes need not be nearly perfect (r?0.97) for efficient coding to occur. Discrimination did not significantly differ in either the second (Consistent mean?=?0.71, s.e.?=?.02, Orthogonal mean?=?0.69, s.e.?=?.03; t 39?=?0.67, n.s.) or third block (Consistent mean?=?0.74, s.e.?=?.02, Orthogonal mean?=?0.77, s.e.?=?.02; t 39?=?1.27, n.s.).

Unlike previous experiments, discrimination in both conditions improved markedly across testing blocks. Owing to the inability to separate learning (improvement throughout the experiment) from effects of the correlation between AD and SS on Orthogonal discriminability (initially inferior but later comparable to that of Consistent sound pairs), performance was assessed through paired-sample t-tests contrasting early versus late (i.e., first versus third testing block) discrimination of Consistent pairs, which are predicted to remain equally discriminable throughout the experiment. Consistent discrimination significantly improved from the first to third block of Experiment 2 (t 39?=?4.39, p<.0001, Cohen's d?=?0.60), but this learning effect was not consistent across experiments. Participants in Experiment 3 exhibited a significant but more modest learning effect for Consistent trials (t 39?=?3.23, p<.01, Cohen's d?=?0.35), but no significant differences were observed in Experiments 1, 4, or 5 (all t?1.21, n.s., Cohen's d<0.18). The magnitude of the learning effect in Experiment 2 may be due to one or both of the following factors. First, reducing variability in AD and SS cues by truncating the correlation may facilitate discrimination over time. Second, listeners in Experiment 2 were presented more repetitions of stimulus pairs in a given block (12) than in other experiments (8) in the effort to make overall number of trials comparable. Nevertheless, the principal finding is superior discrimination of Consistent pairs relative to Orthogonal pairs early in testing.
c. Experiment 3
Unlike previous experiments, discrimination was comparable across Consistent (mean?=?0.63, s.e.?=?.01) and Orthogonal conditions (mean?=?0.61, s.e.?=?.02) in the first testing block (t 39?=?0.75, n.s., Cohen's d?=?0.12; Figure 2F). By testing more extreme Orthogonal test pairs (i.e., less similar to Consistent pairs), differences in discrimination observed in previous experiments were extinguished. Roughly equivalent discrimination persisted throughout the experiment (Block 2: Consistent mean?=?0.66, s.e.?=?.02, Orthogonal mean?=?0.64, s.e.?=?.02 [t 39?=?0.86, n.s.]; Block 3: Consistent mean?=?0.66, s.e.?=?.02, Orthogonal mean?=?0.64, s.e.?=?.02 [t 39?=?1.54, n.s.]). This demonstrates that efficient coding of correlated acoustic attributes is sensitive to the range of physical acoustic/psychoacoustic evidence inconsistent with the primary correlation and consistent with a second orthogonal dimension. Results also demonstrate that simple strength of the primary correlation is insufficient to attenuate discriminability of orthogonal stimulus differences, as all stimulus pairs presented in Experiment 3 (r?=?�0.83) were relatively equally discriminable, but pairs presented in Experiment 2 (r?=?�0.81) produced significant differences in early performance. The explanatory power of simple strength of correlation between acoustic attributes, absent consideration of both the quantity and quality (range) of evidence that is inconsistent with the correlation, is challenged by these results.
 
d. Experiment 4
Despite a three-fold increase in presentations, discrimination of the Orthogonal pair (mean?=?0.59, s.e.?=?.02) was still significantly worse than that of Consistent pairs (mean?=?0.63, s.e.?=?.01) in the first testing block (t 39?=?2.06, p<.05, Cohen's d?=?0.37; Figure 2H). This negligible effect of probability sheds light on the results of Experiment 3, that efficient coding was likely extinguished due to increased range of acoustic evidence supporting orthogonal variability and not the concurrent increase in Orthogonal test trials. Similar to previous experiments, performance across conditions was equivalent in the second (Consistent mean?=?0.64, s.e.?=?.02, Orthogonal mean?=?0.64, s.e.?=?.02 [t 39?=?0.36, n.s.]) and third testing blocks (Consistent mean?=?0.64, s.e.?=?.01, Orthogonal mean?=?0.61, s.e.?=?.02 [t 39?=?1.58, n.s.]).
 e. Experiment 5
Even with ten-fold oversampling, discrimination of the Orthogonal pair (mean?=?0.60, s.e.?=?.02) was modestly worse than that of Consistent pairs (mean?=?0.63, s.e.?=?.01) in the first testing block (t 39?=?1.87, p?=?.07, Cohen's d?=?0.36; Figure 2J). It bears note that paired-sample t-tests used in all analyses are two-tailed. One could use a one-tailed t-test based on the prediction that discrimination of Consistent pairs will be greater than that of Orthogonal pairs, in which case the difference would be statistically significant (one-tailed p<.05). However, performance in the first block does not significantly differ in Experiment 5 versus Experiment 3 as indicated by independent samples t-tests on orthogonal discrimination performance (t 78?=?0.63, n.s.) and differences between Consistent and Orthogonal discrimination (t 78?=?0.71, n.s.). Perhaps surprisingly, testing the Orthogonal sound pair ten times as often as any Consistent sound pair failed to produce practice effects sufficient to promote Orthogonal discrimination exceeding Consistent discrimination (second block: Consistent mean?=?0.64, s.e.?=?.02, Orthogonal mean?=?0.62, s.e.?=?.02 [t 39?=?0.69, n.s.]; third block: Consistent mean?=?0.64, s.e.?=?.01, Orthogonal mean?=?0.62, s.e.?=?.02 [t 39?=?0.54, n.s.]). Thus, the conservative conclusion one can draw from this marginal effect is that manipulation of Orthogonal stimulus probability has little effect on listener discrimination.

2. Model predictions
a. Experiment 1
Predictions from the PCA models are presented in the first column of Figure 4, with Euclidean distance between Consistent (black) versus Orthogonal (grey) stimulus pairs on the ordinate and training epoch on the abscissa. Simulation timecourses for correlation-matrix-based (solid lines) and covariance-matrix-based (dashed lines) models are scaled to share comparable abscissas. Similar to [22], the PCA model quickly discovered the principal component (the Consistent dimension) and distances between Orthogonal pairs initially decreased considerably (Figure 4A). With further exposure to the stimulus set, the PCA model gradually captured the modest variance not explained by the first component, progressively increasing distances between Orthogonal pairs until reaching original relative values by the end of the simulation. Thus, the PCA model initially captures only variability along the principal component in the two-dimensional stimulus space at the expense of the orthogonal component, incrementally coming to capture remaining variance, matching the pattern observed in listener performance. Predictions from the correlation-based (solid lines) and covariance-based (dashed lines) versions of the PCA model were nearly identical, with a slightly larger initial decrease in Orthogonal distances predicted by the covariance model.

Simulation results using the choice model are depicted in the middle (correlation) and right (covariance) columns of Figure 4, with percent correct discrimination along the ordinate and testing block number along the abscissa. Predictions across 40 simulations exhibited markedly less variability than listener data, but patterns of results remain excellent fits to human performance. Both correlation and covariance models predicted significantly poorer discrimination of Orthogonal stimuli in the first block of testing (correlation model [Figure 4B]: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.58, s.e.?=?.006, t 39?=?14.92, p<1e-17, Cohen's d?=?3.15; covariance model [Figure 4C]: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.57, s.e.?=?.004, t 39?=?21.50, p<4e-23, Cohen's d?=?5.09). Marked improvement in Orthogonal discrimination was evident in the second block, but this was still inferior to Consistent discrimination (correlation model: Consistent: mean?=?0.69, s.e.?=?.007; Orthogonal: mean?=?0.65, s.e.?=?.005, t 39?=?5.23, p<6e-6, Cohen's d?=?1.19; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.63, s.e.?=?.004, t 39?=?10.12, p<2e-12, Cohen's d?=?2.38). Finally, Consistent and Orthogonal stimuli were relatively equally discriminable in the third block (correlation model: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.68, s.e.?=?.006, t 39?=?0.62, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.68, s.e.?=?.004, t 39?=?0.39, n.s.).

b. Experiment 2
The initial decrease in distance between Orthogonal stimuli is smaller and recovery to baseline distances sooner than that observed for Experiment 1 (Figure 4D). These outcomes are anticipated given simulation of a more weakly correlated stimulus set (r?=?�0.81). Simulations by Stilp et al. [22] and Experiment 1 suggest that principal and second components become weighted in proportion to the amount of covariance captured by each dimension, and model predictions for Experiment 2 reveal more weight being attributed to the second (Orthogonal) dimension as it captures relatively more unshared covariance here than in other, more highly-correlated stimulus sets. Both correlation-based and covariance-based models predict significantly poorer Orthogonal discrimination in the first testing block, but models make different predictions regarding the rate of recovery to baseline distances between stimuli. The correlation-based model predicts a more extended recovery, which contributes to a larger predicted effect size in the first block (Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.64, s.e.?=?.006, t 39?=?5.65, p<2e-6, Cohen's d?=?1.40; Figure 4E) than that predicted by the covariance-based model (Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.65, s.e.?=?.005, t 39?=?4.95, p<2e-5, Cohen's d?=?1.12; Figure 4F), which predicts more rapid recovery to baseline distances. Nevertheless, both models correctly predict significantly poorer Orthogonal discrimination in the first testing block, and comparable discrimination in the second (correlation model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.68, s.e.?=?.007, t 39?=?1.12, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.62, n.s.) and third testing blocks (correlation model: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.69, s.e.?=?.005, t 39?=?0.38, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.48, n.s.), matching listener performance. Finally, neither version of the PCA model predicts overall improved performance later in the simulation (i.e., Euclidean distances in both conditions increasing over time) as observed in listener performance, suggesting insensitivity to some practice effects.

c. Experiment 3
Both versions of the PCA model predict a shallow and very short-lived decrease in Orthogonal distances, with the vast majority of the simulation predicting equal discriminability across conditions (Figure 4G). Virtually identical simulation results both predict comparable performance across conditions in the first (correlation model [Figure 4H]: Consistent: mean?=?0.68, s.e.?=?.006; Orthogonal: mean?=?0.68, s.e.?=?.005, t 39?=?0.26, n.s.; covariance model [Figure 4I]: Consistent: mean?=?0.68, s.e.?=?.004; Orthogonal: mean?=?0.68, s.e.?=?.004, t 39?=?0.75, n.s.), second (correlation model: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.006, t 39?=?0.08, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.003; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.60, n.s.), and third testing blocks (correlation model: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.006, t 39?=?0.25, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.26, n.s.). These predictions mirror listener performance, and support the idea that both listeners and the model quickly exploited covariance in more extreme Orthogonal stimuli to discover the second component and facilitate Orthogonal discrimination.

d. Experiment 4
Both versions of the PCA model predict a sizable initial decrease in Orthogonal distances before later recovery to original relative distances (Figure 4J). These predictions resemble those of Experiment 1, where the early difference in discrimination was both predicted and behaviorally observed, in contrast to those of Experiment 3, where largely equal discrimination throughout was both predicted and observed. Recovery to original relative distances for Orthogonal stimuli occurred much more quickly in Experiment 4 than Experiment 1, revealing some sensitivity to the fact that Orthogonal stimuli were sampled more frequently. Further, the covariance model predictions displayed a slightly larger magnitude of initial decrease in Orthogonal distances and slightly longer recovery to baseline distances than that observed for the correlation model, resulting in a slightly larger effect size in the first testing block (correlation model (Figure 4K): Consistent: mean?=?0.70, s.e.?=?.005; Orthogonal: mean?=?0.64, s.e.?=?.005, t 39?=?6.94, p<3e-8, Cohen's d?=?1.65; covariance model (Figure 4L): Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.63, s.e.?=?.005, t 39?=?7.85, p<2e-9, Cohen's d?=?1.89). Both versions of the model predicted equal discriminability in the second (correlation model: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.69, s.e.?=?.005, t 39?=?0.14, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.68, s.e.?=?.005, t 39?=?1.20, n.s.) and third testing blocks (correlation model: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.69, s.e.?=?.005, t 39?=?0.12, n.s.; covariance model: Consistent: mean?=?0.70, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.62, n.s.).

e. Experiment 5
The correlation-based PCA model predicts a shallow and very short-lived decrease in Orthogonal distances, with all but the first few epochs of the simulation predicting equal discriminability across conditions (Figure 4M). These predictions are identical to those made for Experiment 3, such that equal discriminability of Consistent and Orthogonal stimuli is predicted in all blocks of testing (Block 1: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.006, t 39?=?0.13, n.s.; Block 2: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.007, t 39?=?0.06, n.s.; Block 3: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.69, s.e.?=?.006, t 39?=?0.09, n.s.; Figure 4N).

Similar to Experiment 4, the covariance-based PCA model predicts a slightly larger magnitude of initial decrease in Orthogonal distances and slightly longer recovery to baseline distances than that observed for the correlation model (Figure 4M). These differ from other model predictions in two significant ways. First, similar to listeners and unlike the correlation model, the covariance model predicts inferior discrimination of Orthogonal stimuli in the first testing block of Experiment 5 (Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.67, s.e.?=?.004, t 39?=?4.02, p<.0005, Cohen's d?=?0.87; Figure 4O). Second, the covariance model displays sensitivity to (and thus makes different predictions for) stimuli with the same correlation matrix but different covariance matrices (i.e., stimuli presented in Experiments 3 and 5). An independent-samples t-test confirms that the predicted difference in Consistent and Orthogonal discrimination in the first testing block of Experiment 5 (mean difference?=?.023) is significantly larger than the difference observed in the first block of Experiment 3 (mean difference?=?.005; t 78?=?2.11, p<.05). Predictions made by the correlation model for the first block of Experiment 3 versus Experiment 5 did not differ (independent-samples t-test on mean differences: t 78?=?0.28, n.s.). These results demonstrate that while the PCA model based on the correlation matrix of the inputs [26] is useful for predicting discriminability of some stimulus sets, the covariance-based PCA model is a better predictor of listener performance overall. Finally, the covariance model predicted comparable performance across conditions for remaining test blocks (Block 2: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.08, n.s.; Block 3: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.42, n.s.).

f. Across all experiments
The predictive power of covariance-based PCA is further demonstrated through closed-form linear algebraic solutions in Table 1. Table 1 orders stimulus sets from Experiments 1�5 to reflect performance differences in discriminability of Consistent versus Orthogonal sound pairs in the first testing block as measured by effect size (rightmost column). Eigenvalues calculated from the correlation matrix versus covariance matrix of stimulus set before the simulation are also provided. The success with which listeners discriminate Orthogonal pairs is well predicted by the second Eigenvalue calculated from the covariance matrix reflecting true psychoacoustic distances: as the second Eigenvalue increases, greater perceptual weighting is reflected in improved listener performance on Orthogonal trials and subsequently decreased effect sizes early in the experiment (r?=??0.95, p<.025). This relationship with performance is not observed for the second Eigenvalue of correlation matrices, the first Eigenvalue of correlation or covariance matrices, or simple strength of the principal correlation. The relationship between the second Eigenvalue of the covariance matrix and effect size is similarly robust if calculated on model representations of the inputs after the first one-third of the simulation (akin to the first testing block for listeners; r?=??0.94, p<.025). No other metric calculated after one-third of the simulation reliably predicts effect sizes for the first block of testing. While some caution is warranted in generalizing this relationship given that the second Eigenvalue can be increased by multiple manipulations (removal of Consistent sounds, addition of more extreme Orthogonal sounds, oversampling of Orthogonal sounds), it does provide promising extensions of the present work in optimal weighting of statistically derived dimensions in complex sounds.","The present results replicate and extend reports by Stilp et al.
[22] of rapid efficient coding of redundancy among acoustic dimensions in novel complex sounds. Three manipulations, each of which attenuates correlation among attributes, were tested separately to examine the perceptual significance of each. Overall, simple strength of the primary correlation (principal component) is inadequate to predict listener performance. Initial superiority of discrimination for statistically consistent sound pairs was relatively insensitive to truncation of evidence supporting the correlation (Experiment 2) and to increases in the frequency of Orthogonal test trials (Experiments 4, 5). However, increased evidence of an orthogonal dimension provided by greater acoustic/psychoacoustic range (Experiment 3) proved highly salient, resulting in equivalent discrimination performance throughout the experiment.
 Patterns of performance cannot be explained by independent weighting of acoustic dimensions (AD, SS), as changes in discriminability can only be attributed to the correlation or covariance orthogonal to it. This perceptual adherence to derived statistical structure, and not physical acoustic dimensions per se, is not without precedent. There is good evidence that auditory cortical representations decreasingly correspond to physical stimulus dimensions [37]�[39]. Wang [39] refers to this as �non-isomorphic� transformations of the input. Examples of non-isomorphic stimulus representations in auditory cortex include encoding spectral shape across varying absolute frequencies [38], gross representation of rapid change in click trains with short inter-click intervals versus phase-locking to trains with slower inter-click intervals [40], [41], and encoding pitch versus individual frequency components [42], [43]. Such non-isomorphic transformations may be similar to the loss of acoustic dimensions (AD, SS) seen here, as more efficient dimensions better capture perceptual performance. Results are in agreement with Stilp and Kluender [44], who report efficient coding of redundant acoustic dimensions in the face of unrelated variability in a third acoustic feature.
 Optimal combination and weighting of individual stimulus dimensions has received considerable attention in vision research. Models of Bayesian inference and ideal perceptual performance have been shown to effectively capture aspects of perception of objects [45], [46], edges [47], movement [48], and slant or orientation [49]�[52]. These ideal observer models have been extended to perceptual combination of sensory cues from different modalities, such as integrating visual and auditory cues to location [53], visual and motor cues to performing certain actions [54]�[57], and visual and haptic cues to height [58], shape [59], and even thoroughly trained arbitrary associations such as one between luminance and stiffness [19].
 Three important points distinguish these earlier studies from the present findings in auditory perception. First, such studies often must address inherent weights or biases ascribed to each cue. For example, visual information is habitually weighted more heavily than auditory or haptic information. Here, acoustic dimensions AD and SS were adjusted through extensive control studies to be equally available perceptually, so a priori perceptual weights are equated. Second, many cue weighting studies examine performance as a function of relative noisiness (relative ?) of respective cues. Sensibly, when multiple cues are available but one is or becomes more noisy (larger ?), perceptual weights are greater for less noisy cues that better inform behavior. Optimal cue combination occurs when one cue (typically the one weighted more heavily absent experimental manipulation) is made noisier and perceptual weights shift toward a less noisy source of information (e.g., making the visual signal noisier and observing increased weight attributed to haptic information [58]). Cues AD and SS share equal psychoacoustic variability as measured by JNDs. Third and most importantly, these examples from vision or multimodal research demonstrate optimal weighting of individual physical stimulus dimensions. The present findings indicate optimal weighting of derived dimensions that capture statistical relationships between attributes. This likely suggests a more sophisticated level of processing than that observed for reports of combination or integration of individual physical stimulus cues.
 Behavioral results were consistently predicted by the PCA network model [26]. Perceptual processes first capture the principal component of variation in the two-dimensional stimulus space at the expense of the orthogonal component [22]. From listener performance and models, it appears that both principal and second components become weighted proportional to the amount of variance accounted for by each. In the stimulus sets tested here, this entailed relatively modest weights on the second component, corresponding to initially reduced discriminability. Following further exposure to the stimulus set, variance not explained by the principal correlation is detected and exploited, improving discrimination of Orthogonal sound pairs back to baseline levels. Only when evidence for the orthogonal dimension was increased through greater covariance not shared with the principal component (Experiment 3) was sufficient weight attributed to the second component, extinguishing early differences in discriminability. Otherwise, given that correlations tested here were attenuated in different manners, simulations primarily varied in how the initial decrease in Euclidean distance between Orthogonal stimuli gets smaller and/or recovery to baseline distances occurs sooner.
 One shortcoming of Sanger's [26] network model is that it assumes the correlation matrix of the inputs. PCA can operate over either a correlation or covariance matrix, and there are reasons to prefer a covariance matrix for psychoacoustically-normed experimental materials employed here. The predictive power of the PCA model [26] was improved when modified to operate on the covariance matrix of the input rather than the correlation matrix. The modified model provided predictions that better fit listener performance. Further, Eigenvalues from covariance- but not correlation-based PCA analyses closely reflect listener performance (Table 1). Greater Eigenvalues on the second component (orthogonal to the main correlation) predicted better discrimination of orthogonal variation. At least for these stimuli, covariance among acoustic attributes appears to be a better estimate of perceptual performance than correlation, but given markedly different ways to manipulate covariance captured by a particular component in PCA (stimulus addition/deletion, over/undersampling, etc.), further studies are required to better understand this relationship.
 The particular PCA model investigated here [26] is certainly oversimplified and is unlikely to precisely reflect neural learning mechanisms. Dimensions of AD and SS are almost certainly encoded across a large number of neurons and not the localist representation tested here. A more serious challenge is to identify neurally plausible mechanisms for instantiating PCA-like performance. Conceivably, circuitry of auditory cortical and association areas may provide the required connectivities. Precortical processes might also be implicated, given that PCA has proven practical for depicting correlations across neurons in the vibrissal sensory area of rat thalamus [60]. Lower subcortical auditory nuclei are also candidates given that, relative to the visual system, much more processing (more synapses and hence greater neural recoding) occurs within the brainstem before cortex [37]. Identification of neural substrates supporting perceptual changes demonstrated here and by Stilp and colleagues [22] would facilitate development of more authentic computational models.
 The present experiments have investigated how listeners adapt to strong covariance structure coupled with varying types of orthogonal variation. This form of structure is particularly amenable to decomposition via PCA, but other models are better suited for a broader array of cases such as those presented by statistical distributions for some speech sounds (e.g. distributions of vowels in formant (F1-F2-F3) space are not orthogonal). For extraction of independent dimensions that are not necessarily orthogonal, techniques such as linear independent component analysis (ICA), which efficiently encodes structure into latent components that minimize mutual information (redundancy) between outputs (e.g., [61]), may provide a better statistical analog to perceptual organization.
 The present results could provide insights into models of perceptual organization for complex sounds such as speech. While the novel sounds tested here only varied along two complex dimensions, patterns of covariance naturally scale to high-dimensional feature spaces. In complex natural stimuli such as speech, multiple forms of stimulus attribute redundancy exist concurrently and successively [20], [21], [62]�[65]. To the extent that patterns of covariance among acoustic attributes in natural sounds are efficiently coded, the present results may inform how the auditory system exploits different patterns of redundancy to learn and distinguish different speech sounds.
 While some have suggested the importance of correlations among stimulus attributes are central to perceptual organization for speech [22], [63], [66]�[68], it has been more common to emphasize 1st-order statistics (e.g., probability density) as a means to characterize distributions of speech sounds [69]�[73] or cues [74]�[77]. In experiments that oversampled the Orthogonal sound pair (Experiments 4 and 5), manipulations of probability density had little to no effect on patterns of performance. At least in this particular paradigm, higher-order redundancy (covariance) was more perceptually salient than lower-order redundancy (probability density). Future research that explores relative influences of these different types of statistical structure will inform models of perceptual organization and categorization of speech.
 Covariance among complex acoustic attributes in novel stimuli is exploited quickly and automatically in the present experiments. Perception only later comes to encode residual variability in ways that reflect optimal statistical weighting of covariance not accounted for by the principal component of the stimuli. Results illuminate stimulus characteristics that support coding of stimulus redundancy that is rapid, unsupervised, efficient, and statistically optimal."
4,1911559,"""Incidental learning in a multisensory environment across childhood""","""10.1111/desc.12554""",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5873275/,desc12554-sec-0010,desc12554-sec-0018,"3.1. Auditory working memory
Digit Span Backwards (DSB) raw ability scores were converted to standardized T?Scores and compared across groups using a one?way analysis of variance (ANOVA). No significant difference was found between groups; 6?years: Mean (SD) = 56.60 (9.89); 8?years = 54.03 (9.37); 10?years = 55.07 (9.92), (F(2, 180) = 1.07, p = .345), showing that participants in each group were performing at a cognitive level expected for their age.

3.2. Multisensory Attention Learning Task (MALT)
To examine performance across groups on aspects of sustained attention on the learning element of the MALT, trials to criterion and number of errors were calculated.

3.2.1. Trials to criterion
The mean number of learning trials on the MALT in order to reach the criterion of 50 correct target responses was calculated for each group. Results of a univariate ANOVA with two between?subjects factors of Age Group (3 levels: 6, 8, and 10) and Condition (3 levels: V, A, and AV) found a significant main effect of Age Group, F(2, 172) = 4.44, p = .013, partial ?2 = .05, but not of Condition (F < 1), with 6?year?olds requiring a significantly greater number of trials (Mean = 146.98, SD = 8.05) to reach criterion than 8?year?olds (Mean = 143.18, SD = 7.92), p = .025, and trend for more trials than 10?year?olds (Mean = 143.67, SD = 6.73), p = .055. No differences were seen between 8? and 10?year?olds (p > .05).

3.2.2. Errors on MALT
A univariate ANOVA to analyse mean number of commission errors (i.e., incorrectly responding to a non?target item) across Age groups and Conditions (see Table 1) found a significant main effect of Age Group, F(2, 172) = 5.05, p = .007, partial ?2 = .06, but not Condition (F < 1), driven by 6?year?olds making significantly more commission errors than 10?year?olds, p = .009 (Bonferroni?corrected pairwise comparisons).
 Mean number of omission errors (i.e., failing to respond to the correct target) across Age groups and Conditions (Table 1), analysed as above, found a significant main effect of Age, F(2, 172) = 4.59, p = .011, partial ?2 = .05, but not Condition (F < 1). Pairwise comparisons (Bonferroni?corrected) found 6?year?olds made significantly more omission errors than 8?year?olds (p = .015) and there was a trend for 6?year?olds to make more errors than 10?year?olds (p = .061).

3.2.3. Category identification test
As a measure of incidental category learning, mean number correct on the category identification task was calculated for each age group and compared across learning condition (Figure 3). Results of a univariate ANOVA with two between?subjects factors of Age Group (3 levels: 6, 8, and 10) and Condition (3 levels: V, A, and AV) found no significant Age Group by Condition interaction (F < 1). However, significant main effects of Age Group, F(2, 168) = 5.23, p = .006, partial ?2 = .06, and Condition, F(2, 168) = 17.42, p < .001, partial ?2 = .17, were identified. Pairwise comparisons (Bonferroni?corrected) for Age Group found that 6?year?olds performed reliably below 10?year?olds (p = .007), with no differences between 6 and 8 years, or 8 and 10 years (p > .05, for all). For Condition, pairwise comparisons indicated that participants scored significantly higher following the Audiovisual learning condition (Mean = 14.07) than either the Auditory (Mean = 10.32) or Visual?only (Mean = 10.97) conditions (p < .001 for both). No difference was found between Auditory and Visual groups (p = .996).
 To examine whether incidental categorization performance differed from chance, data were analysed for each Age group and Condition using one?sample t?tests with a test value of 8. Six?year?olds were found to score significantly above chance on the Visual?only (t(19)�=�2.73, p�=�.013) and Audiovisual (t(19)�=�4.23, p�<�.001) conditions, but not in the Auditory?only condition (p�=�.095). The 8? and 10?year?olds scored significantly above chance on all learning conditions (p�>�.05, for all), indicative of a high level of categorization performance in these groups across conditions.
 An examination of the relationship (Pearson's r) between age (collapsed across groups) and performance on the category identification task for each condition indicated a significant positive correlation in the Audiovisual learning condition, r�=�.334, p�=�.011, and a trend for a positive correlation in the Auditory?only learning condition, r�=�.249, p�=�.055, but not in the Visual?only learning condition (p�=�.319). Data are presented in Figure�4.
 An investigation of the relationships (Pearson's r) between incidental learning (total correct on category task) and auditory working memory (DSB), sustained attention skills (omission errors) and inhibitory control skills (commission errors) found no significant correlations across any age groups or conditions (p�>�.05, for all).
 3.2.4. Explicit categorization knowledge test
 As well as an examination of incidental knowledge, following the category identification task, each participant was asked to state verbally what they judged the differences between the two families of frogs to be and how they reached their categorization choices. Verbal responses were scored as follows; don't know/none given�=�0 points, related categorical description given but inaccurate (e.g., �they had different coloured spots�)�=�1 point, partially correct family description (i.e. citing 1 feature but not both in AV condition, e.g., number of spots, but no mention of auditory features)�=�2 points, fully correct family description (i.e. �different number of spots and different croak sounds� in AV condition or �croaks to log were deeper than croaks to lily pad� for A condition)�=�3 points. A mean explicit categorization score was calculated for each group and condition (Figure�5). Although a high correlation was found between incidental and explicit scores (r�=�.455, p�<�.001), results of a univariate ANOVA with two between?subjects factors of Age and Condition for explicit knowledge data indicate a different pattern of performance than seen in the incidental knowledge test. That is, although results found a main effect of Age Group, F(2, 172)�=�7.86, p�=�.001, partial ?2�=�.08, with 6?year?olds significantly less able to express the correct reason for categorizing than the older two groups (p�=�.002 and p�=�.003), no main effect of Condition, F(2, 172)�=�2.22, p�=�.112, partial ?2�=�.03, was found. This suggests that there is an age?related difference in the ability to verbally express categorization knowledge compared to the incidental learning element of the task.
 3.2.5. Discrimination task
 To examine the saliency and discriminability level of the visual and auditory features of target exemplars, the same discrimination task as used in the initial pilot study (see above description in Stimuli discrimination) was conducted with 15 participants randomly selected from each age group (including five participants from each condition). Mean accuracy score for visual and auditory discriminators was calculated for each age group. Results of a one?way ANOVA found a significant difference across groups between visual and auditory score; F(2, 42)�=�4.17, p�=�.023, driven by 6?year?olds scoring significantly below 10?year?olds in visual discrimination. Paired samples t?tests to examine differences in visual and auditory accuracy scores for each age group separately revealed significantly lower visual than auditory discrimination ability only in 6?year?olds; Mean (SD) visual�=�11.33 (2.35), auditory�=�12.47 (1.46), t(14)�=�?2.20, p�=�.045. No significant difference between visual and auditory discrimination ability was found for 8?year?olds; Mean (SD) visual�=�13.07 (1.39), auditory�=�13.27 (.88), p�=�.647, or for 10?year?olds; Mean (SD) visual�=�13.33 (2.02), auditory�=�12.80 (2.51), p�=�.217.","The current study used a novel category?learning task to examine the effects of unisensory and multisensory cues on incidental category learning across middle childhood. As expected, the results indicate a significant improvement in incidental learning from 6 to 10�years of age. In addition, as early as 6�years of age in this study, children demonstrated greater performance on an incidental categorization task following exposure to multisensory (audiovisual) cues compared to unisensory information (visual or auditory alone).
 Multisensory information has previously been shown to improve encoding (Bahrick & Lickliter, 2012) and better facilitate subsequent learning compared to unisensory stimulation in children as young as 3 to 4�years of age (Jordan & Baker, 2011). Similarly, on speeded RT tasks, children as young as 4�years of age were able to integrate audiovisual information to improve performance to a greater extent than with the presentation of unimodal stimuli, but were less efficient than older children and adults (Nardini et�al., 2015). Other developmental studies that have examined multisensory integration on tasks that did not require speeded responses also report the pooling of bimodal signals to be sub?optimal until even later in childhood, around 8 to 12�years of age (Gori et�al., 2008; Gori et�al., 2012; Nardini et�al., 2010; Nardini et�al., 2008; Petrini et�al., 2014). In sum, such findings suggest that although multisensory information may be pooled to a certain extent at this young age, mature integration of bimodal signals undergoes a more protracted developmental course.
 The emphasis in the current study was on incidental category learning during a sustained attention task. This differed from the aforementioned previous studies and their focus on developmental changes in the pooling of redundant cues on explicit learning or perceptual tasks. Incidental acquisition of information occurs across multiple learning tasks in educational environments (Postman, 1964), and is therefore an important area of focus for research examining the role of multisensory stimuli on learning. In the current study, the simultaneous presentation of complementary visual and auditory information, in which both features were informative to family membership, resulted in enhanced performance on the incidental learning of categories across all age groups.
 Although no significant interaction between age and learning condition was found, others have found that the pooling of multisensory cues may become more advanced with age (Barutchu et�al., 2009; Gori et�al., 2008; Gori et�al., 2012). The emphasis on learning in the current study may therefore underlie the differences in findings from studies examining the development of pooling bimodal cues. That said, despite a lack of reliable difference in the pattern of performance with age in the current study, some age?related changes in the benefits of multisensory cues were identified. For instance, performance on the category identification task following audiovisual learning positively correlated with age, and with a trend for a positive relationship between age and auditory?only learning. In contrast, performance following visual?only learning did not correlate with age. These results are therefore somewhat in line with previous findings that argue for a refining of the ability to use multisensory information across this age span (e.g., Nardini et�al., 2015). This would afford the conclusion that the use of multisensory cues for learning may still undergo some development during the primary school years. Of note, however, is that there was also a trend for improved performance with age in the auditory?only condition, suggesting that these findings may reflect age?related changes in the use of auditory information to support learning. This is particularly supported by our findings that 6?year?olds performed at chance following learning with auditory?only cues, but above chance with visual and audiovisual cues. Others have also reported age?related improvements in auditory processing throughout childhood and into adolescence that may affect responses to perceptual training (Huyck & Wright, 2013). Similarly, differences in the processing of visual and auditory stimuli with age have been seen on multisensory tasks, with children and adolescents, compared to adults, showing reduced processing of auditory distractors compared to visual and bimodal (Downing, Barutchu, & Crewther, 2014).
 In this study, therefore, although younger children used visual information (both in the visual?only and multisensory conditions) to the same level as older children, changes with age were seen in the extent to which auditory cues were considered useful for learning. Initially, this could be considered a matter of cue saliency, with the auditory stimuli not having been as salient as the visual information. However, this explanation is contested by our seemingly contradictory findings that children at this age were less able to discriminate between visual targets than between auditory exemplars, but with an equal level of discriminability between the different modality exemplars above 8�years of age. Furthermore, no differences in categorical learning were found between unisensory visual and auditory cues in any group in this study, including 6?year?olds, suggesting that visual and auditory stimuli were equally salient and usable.
 As an alternative explanation, the findings may allude to a visual processing bias in younger children. This is in contrast to findings of an auditory processing dominance in young children, with a change to visual dominance in older children and adults (Napolitano & Sloutsky, 2004; Sloutsky & Napolitano, 2003). By 4�years of age there is some flexibility observed in terms of modality dominance that is dependent on the task demands, wherein stimuli are only processed in the preferred modality when different sensory cues are of equal salience (Robinson & Sloutsky, 2004). Therefore, children aged 6�years may already demonstrate visual dominance on tasks such as the one presented here. Given that no age and condition interactions were identified, however, such conclusions can only be met tentatively. Indeed, it is also worth noting that neither of the oldest two groups demonstrated this visual processing dominance, despite robust findings of visual modality dominance in older children and adults on other tasks (Koppen & Spence, 2007; Sinnett, Soto?Faraco, & Spence, 2008; Spence, 2009).
 As well as an analysis of group differences on an incidental category?learning task, we also reported the findings from the attention trials on the main MALT task. Here, no differences were found across the different MALT learning conditions, suggesting that effects of condition in incidental learning were not related to the attentional aspects of the original task. Although differences were seen between age groups, all groups demonstrated a comparable pattern of performance.
 Furthermore, although 6?year?olds required more trials to criterion, all participants included in the analyses experienced a total of 50 target exemplars travelling to the two habitats before the category task was presented. Analyses of these learning task parameters therefore only highlight age group differences rather than differences across learning conditions. This is in line with what would be expected on measures of sustained attention in these age groups. As such, age?related differences on this aspect of the task likely reflect improvements in speed of processing visual and auditory information, developmental changes in levels of inhibition (Levy, 1980), as indicated in a reduction in commission errors, and improved attention, as measured by decreasing omission errors, from the youngest to oldest age groups.
 As well as a measure of incidental category learning, the current study examined explicit categorical knowledge across groups. A difference was found in the pattern of performance in the incidental learning compared to the explicit knowledge tests, with no effect of condition observed in the latter, and the youngest children (6?year?olds) demonstrating particular difficulty in expressing correct categorical information. While no feedback was given on the incidental categorization task, this finding may be related to the participants being made aware of categorical differences both in the incidental task and being posed a question of this nature in the subsequent explicit knowledge task. This may have cued participants to devise a plausible explanation for categorical differences. Thus, being asked to verbally express categorical information before the presentation of the incidental category identification task may have resulted in a levelling of performance across the two different tests. Alternatively, this finding may be reflective of different processing systems for explicit and incidental learning (Gabay et�al., 2015; Tricomi et�al., 2006).
 Our results raise the question as to whether similar findings would also be observed not only on other novel categorical learning tasks, but also other learning tasks such as associative learning, and in different domains such as language and numerical learning. Jordan and Baker (2011) found that in young children aged 3 to 5�years, learning to match numerosities was facilitated when given multisensory rather than unisensory information about the number. A key difference in these studies is in the nature of incidental learning in the current task as opposed to explicit mathematical concept learning in the above?mentioned study. A further difference is that our analyses were not concerned with speed of responses, but rather the accuracy of categorical selection. In addition, in the study by Jordan and Baker (2011), audiovisual trials provided a greater total amount of stimulation in comparison to unimodal trials. That is, only on audiovisual trials were participants exposed to both visual and auditory information. This may have resulted in enhanced arousal to stimulus properties and subsequent representations. In the current study, all learning trials (regardless of learning condition) included both auditory and visual events, with learning conditions differing only on the basis of the informative nature of the cues (i.e., the features that could be used for categorical judgements). Findings from the current study therefore refute the assumption that better performance in a multisensory learning condition compared to unisensory is a result of enhanced stimulation from multisensory trials. In conclusion, even in light of the differences in tasks used across studies, the comparable results of improved learning following exposure to multisensory cues compared to unisensory, even in children as young as 6�years, is a robust finding.
 As mentioned previously, on some tasks, multisensory integration is not as efficient in young children as it is in older children and adults (Burr & Gori, 2012; Gori et�al., 2008; Nardini et�al., 2010; Nardini et�al., 2008), a finding somewhat reflected in the current study. Conclusions from earlier studies imply that combining audio and visual stimuli either at the level of attention or at a neural level of stimuli integration may be more difficult for younger children and therefore not facilitate learning to the same extent as in older children. However, there are likely to be numerous cortical and subcortical mechanisms involved in multisensory integration that may develop at different rates (e.g., Molholm et�al., 2002; Noesselt et�al., 2007; Stekelenburg & Vroomen, 2007). This may underlie the disparity in the reported ages at which mature levels of multisensory facilitation are observed, particularly given that performance on different multisensory tasks may be associated with distinct neural substrates. The examination of multisensory cues on incidental category learning in children younger than 6�years of age would be an important avenue for future research in order to elucidate this further.
 In the current study, it was only the nature of cues for categorical learning that differed across learning conditions. It is not clear therefore whether multisensory stimulation in some learning contexts would have a distracting effect on performance or would lead to increased focus of attention; particularly when multimodal stimuli are not task?related, as would typically be encountered within a learning environment. For instance, difficulties in encoding unisensory cues have been found when multisensory properties compete for attention (Lickliter & Bahrick, 2004). Given known developmental changes in attention, there may also be differing patterns of response to multisensory distraction across development. Further research should therefore examine the use of unimodal and bimodal noise (distractors), or an increased working memory load within and between modalities on a similar learning task.
 This study provides important insight into the use of multisensory information in an educational environment on incidental category learning. The intersensory redundancy hypothesis (IRH; Bahrick & Lickliter, 2012) posits that the pooling of multisensory cues presented in synchrony leads to enhanced perception. Given the nature of the current task, theoretical assumptions of the IRH can only go some way to explaining the current results of enhanced category learning following multisensory cue exposure compared to unisensory. Essentially, the current study included complementary but not redundant amodal stimuli in order to better emulate sensory information typically found in learning environments. Even in light of this difference, the results suggest a reliable facilitatory effect of multisensory stimuli presentation between 6 and 10�years of age. Moreover, our results are in accord with findings that multisensory integration (particularly with the integration of auditory and visual information) may undergo a protracted developmental course through the early primary school years. This has particular implications for the deployment of multisensory learning tasks within primary education. In particular, multisensory information may not be as beneficial to younger children when information from a single sense is dominant. For instance, the results are indicative of a relative difficulty in the use of auditory information to support category learning in 6?year?olds, unless combined with complementary visual information. This has implications for the use of auditory information on categorical learning tasks in children below 8�years of age. Where the simultaneous presentation of auditory information with visual cues may better support a representation and subsequent learning, this may be particularly relevant for younger children who demonstrate poorer performance than older children on unimodal auditory tasks."
5,271124,"""Training Children to Perceive Non-native Lexical Tones: Tone Language Background Bilingualism and Auditory-Visual Information""","""10.3389/fpsyg.2018.01508""",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6131621/,s4,s5,"The results are presented in three parts: (a) a comparison of total raw accuracy in pre-training vs. post-training tests, irrespective of Training Mode (AO/AV) and test mode (ao/av) in an Age (6 vs. 8 years) � Language Background (Bilingual vs. Monolingual) � Tone Language Experience (Tonal vs. Non-tonal) � (Mean Test Score � Pre-/Post-Training) design with repeated measures on Pre- vs. Post-Training scores; (b) an analysis of a percentage gain due to training dependent variable derived from the Pre- and Post-Test scores (see formula below) in an Age � Language Background � Tone Language Experience � Training Mode (AO/AV) � (ao vs. av Tests) design, with repeated measures on ao vs. av tests; and (c) a set of correlations between the phoneme deletion and word and non-word reading ability tests and with the pre- and post-tests and gain due to training for the three English-speaking groups (Mono-Eng, Bi-Eng/Arabic, Bi-Eng/Thai) for whom data on the phonological awareness and reading tests was collected.
Raw accuracy
 Raw percentage correct data were first analyzed to show the absolute level of performance Post-Training compared to Pre-Training as a product of the group factors. A 2 � 2 � 2 � (2) Analysis of Variance (ANOVA) was conducted with Age, Language Background and Tone Experience as between-subject factors and Phase (Pre- vs. Post-training test), as the within-subject factor. All factors have two levels so no planned contrasts were required. Alpha was set at 0.05 and the effect sizes are given for significant differences (critical F = 3.898).
 The results are graphically presented in Figure ?Figure2.2. As can be seen there was a general improvement from pre-training to post-training and this Phase main effect was significant, F(1,65) = 7.61, p < 0.01, ?p2 = 0.077, with Post-Training Mean = 28.43, and SD = 0.09, and Pre-Training Mean = 25.76, and SD = 0.06.
 As can be seen in Figure ?Figure2,2, there was Pre- to Post-Training improvement for three of the four 6-year-old groups, and all of the four 8-year-old groups, with other interactions also apparent. Accordingly, while the Phase main effect was unaffected by Language Background, Monolingual vs. Bilingual, it was qualified by Age and Tone Experience: there was a Phase � Age, F(1,65) = 9.90, p < 0.005, ?p2 = 0.395, and a Phase � Age � Tone Experience, F(1,65) = 15.40, p < 0.001, ?p2 = 0.505, interaction. As can be seen in Figure ?Figure2,2, these interactions are due to (i) greater improvement from pre- to post-training by 8-year-olds than by 6-year-olds, and (ii) especially greater improvement for 8-year-olds with Tone Language experience, irrespective of whether the tonal experience is in a monolingual or bilingual context.
 The decrease in performance from pre- to post-training by the monolingual tone language (Thai) 6-year-olds is puzzling. These children had just begun instruction in reading and writing at school, including learning the orthographic representation of Thai tones (a regular but complicated 4-way interaction of initial consonant class, final consonant manner, vowel length, and tone diacritics (Kasisopa et al., 2013, 2016; see Davis et al., 2015). It is possible that these, as yet non-automatic controlled, processes involved in learning the orthographic representation of Thai tones coupled with intensive training on foreign (Mandarin) tones, resulted in overload and confusion at the perceptual level interference from L1 phoneme-to-grapheme/grapheme-to-phoneme levels. This explanation is clearly speculative and requires further research.
 Performance gain
 While the above analysis shows effects of training on tone perception, it may be noted that many of Pre- and some of the Post-test scores hover around chance level (25%, given there are 4 Mandarin tones). This raises the issue of the degree of improvement given the initial level of performance and the equivalence of improvements from an initial level of chance responding vs. a higher level of initial responding. To accommodate such differences a dependent variable was derived as follows:
 Thus if a child had 20% correct on Pre-Training and 30% on Post-Training�the Performance Gain would be 50%; or if there was the same absolute increase of 10% from 50% on Pre-training to 60% on Post-training, the percentage improvement would be 20%. Thus this measure takes into account the initial level of performance in the pre-training test and represents the percent improvement in relation to that level. Mean and Standard Error Performance Gain for each of the four Language Background � Bilingual Status groups are shown for AO/AV training groups in ao and av tests in Figure ?Figure33 as well as in Table ?Table11 alongside the number and percentage of participants who showed pre- to post-training improvement in each group (see also Table B in the Supplementary Material for individual Performance Gain scores for each participant).
 Performance Gain scores were analyzed in an Age � Language Background x Tone Experience � Training Mode between-subject factor � Test Type (ao or av) within-subject factor ANOVA. The only significant main effect was for Age, F(1,65) = 8.09, p < 0.01, ?p2 = 0.111. Age also interacted with two other factors: there was an interaction of Age � Tone, F(1,65) = 15.19, p < 0.001, ?p2 = 0.189, and of Age � Tone � ao/av test, F(1,65) = 9.54, p < 0.01, ?p2 = 0.128. This set of results is represented in Figure ?Figure4.4. As can be seen, 8-year-olds showed more Performance Gain than 6 year-olds. There was more Performance Gain for Tone language than Non-Tone language background children, but this was only evident in the 8-year-olds. Finally, while the Tone > Non-Tone advantage for 8-year-olds was evident in both ao and av tests, Performance Gain was greater when indexed in ao tests.
 The above Age and Tone Language background results are independent of whether the children were monolingual or bilingual and whether they were trained with AO or with AV stimuli. Turning to Training Mode and Monolingual/Bilingual, the Training Mode and Monolingual/Bilingual interaction, and the Training Mode � Monolingual/Bilingual � ao/av interaction were both very close to significance Training Mode � Monolingual/Bilingual, F(1, 65) = 3.91, p > 0.05, ?p2 = 0.057; Training Mode � Monolingual/Bilingual � ao/av tests, F = 3.76, p>0.05, ?p2 = 0.055 (critical F = 3.98). Given these close to significant interactions and the significant interaction of ao vs. av tests with Age and Tone Language results above, and in order to avoid a Type II error in this first test of the effect of training mode on lexical tone perception, these two approaching significance results were followed up in simple effect tests of Training Mode � Monolingual/Bilingual at each level of the test type, ao tests and av tests. These revealed a non-significant Training Mode � Monolingual/Bilingual interaction for av tests, F(1, 65) = 0.70, p > 0.1, ?p2 = 0.011, but a significant Monolingual/Bilingual interaction for ao tests, F(1, 65) = 5.19, p < 0.03, ?p2 = 0.074. This set of results is represented in Figure ?Figure5.5. As can be seen Bilingual participants show greater Performance Gain after training with AO stimuli, whereas Monolingual participants show greater Performance Gain after training with AV stimuli, and this is especially the case when indexed by ao test trials.
 Correlations with phonological awareness and reading
 Correlations, with age partialed out, between the phoneme deletion, word and non-word reading tests with the pre-training, post-training, and performance gain due to training were conducted for the three groups with English as one of their languages (Mono-Eng, Bi-Eng/Arabic, Bi-Eng/Thai).
 There were, not surprisingly, correlations between the three language measures �phoneme deletion and word reading r(62) = 0.50, p < 0.001, phoneme deletion and non-word reading r(62) = 0.59, p < 0.001, and word and non-word reading, r(62) = 0.75, p < 0.001.
 More important are correlations between any of the three language measures and the tone training scores. The only significant correlation of this nature was between phoneme deletion and the pre-training av-test, r(62) = 0.26, p < 0.05. This indicates that children's phonological awareness, in this case their proficiency on a phoneme deletion task, is positively related to their initial identification of the four Mandarin tones presented in auditory-visual mode.","Summary of results
This study examined the role of tone vs. non-tone language experience, monolingualism vs. bilingualism, and auditory-only vs. auditory-visual training of foreign lexical tone contrasts. The results are summarized under four headings below, followed by discussion of the results.
Training�effects of age and language factors
 Training was effective: there was a general improvement in performance from pre- to post-training. Training was most effective for 8-year-olds; 6-year-olds showed only limited effects of training. Training was more effective if children had tone language experience, an advantage evident in the 8- but not the 6-year-olds. These effects of age and tone language on training were most clearly indexed by the ao rather than the av pre- and post-training tests.
 Language background and training mode
 There was a differential effect for the type of training: Monolingual children improved markedly with AV training but not at all with AO training, whereas Bilingual children improved markedly with AO training and to a lesser extent with AV training. However, these effects were only apparent when indexed by ao tests.
 Correlation with language measures
 For children with English as their only, or as one of their, language(s), proficiency on a phoneme deletion task was positively related to Mandarin tone identification in auditory-visual pre-training test trials. As this was before training began, it shows that those children good at manipulating phonemes in (one of) their native language(s) were also good at perceiving what were completely novel phonological elements for the Mono-Eng, the Bi-Eng/Arabic and the Bi-Eng/Thai groups. This advantage did not extend to training, there was no advantage for good phoneme deleters in learning about foreign tones, just in their initial perception of foreign tones.
 The results bear on a number of issues which are discussed below ahead of a discussion of limitations and suggestions for future research.
 age
 There are two possible reasons why training was more effective with the older 8-year-olds than the younger 6-year-olds: task difficulty, and reduced sensitivity to foreign sounds. First it may be that the task employed here was demanding in terms of the degree of sustained attention required. For example, while in the procedure used here the pre- and post-training trials were the same, the training trials incorporated variation of both speakers and words. Wang et al. (1999) trained adults on a variety of monosyllabic Mandarin words spoken by a variety of speakers and found especially resilient learning. In an adaptation for children Wang and Kuhl (2003) also found a high degree of learning. However, over their six training sessions they graded the difficulty of the tasks (2 weeks ABX, 2 weeks 2AFC identification, then 2AFC with speaker variation) and within each pair of sessions they trained easier tone pairs first. While the Wang and Kuhl (2003) study and the study reported here shared the variability of speakers and words, here the task would have been more difficult because (i) tasks were not graded and (ii) a single presentation 4AFC identification task was used. It remains for future studies to adapt the procedures here and those in the Wang studies (Wang et al., 1999; Wang and Kuhl, 2003) to derive optimal, L2 training regimes especially for younger, e.g., 6-year-old children.
 Secondly, irrespective of task difficulty, 6-year-old children may have reduced sensitivity to foreign sounds. Burnham and colleagues (Burnham et al., 1991; Burnham, 2003) investigating what has been called a second period of perceptual attunement, have shown that 6-year-olds, compared with both 8-year-olds and also 4-year-olds, have reduced sensitivity to L2 sounds and suggest that this is an adaptive device which facilitates attention to the difficult task of phoneme-to-grapheme mapping involved in reading. Burnham contends that at 4 years this process has not begun, and by 8 years the process has become relatively automated, whereas at 6 years this attentional filtering is most useful. Whether this explains the results here cannot be fully ascertained without a 4-year-old comparison group, and it remains for future research to investigate this issue further.
 Test trials and generalization of training
 In this experiment children were given both ao- and av-test trials pre- and then post-training. The training was either with AO stimuli in one group and AV stimuli in another group. In addition, the stimulus words and speakers were different in the pre- and post-training test phase on the one hand and in the Training trials on the other. Therefore, generalization of training can be indexed in two ways. First, any improvement after training, can be considered generalization because the training and test stimuli differed (although there could be an across-the-board improvement because the pre- and post-training stimuli were from the same pool). In this sense then, any performance gain from pre- to post-training, such as those gains found in this study, can be considered as both learning, and generalization of learning. Second, generalization can be indexed by any performance gain across both the ao- and the av-tests, irrespective of whether the training used AO or AV materials. A confounding factor in the interpretation of the results with respect to this type of generalization is that ao-tests proved to be more sensitive indices of performance gain than were av-tests. Nevertheless, it can be concluded that, in general, generalization of training was best for 8-year-olds, and especially for 8-year-olds with tone language experience whether that be monolingual (Mono-Thai) or bilingual experience (Bi-Eng/Thai).
 Tone language experience
 Participants with tone-language experience (the Bi-Eng/Thai and Mono-Thai groups) benefitted more from training than those with no tone language experience (Bi-Eng/Arabic and Mono-Eng), irrespective of whether the children were monolingual or bilingual. In addition, those with tone language experience (especially the 8-year-olds) also showed better generalization of training across test type�ao and av. This supports previous findings that tone language experience facilitates adult lexical tone perception (e.g., Burnham et al., 2014) and extends these findings to children. Moreover, these data provide information about two aspects of language learning. First, the data tell us that there is some perceptual or conceptual information about lexical tones that is general across tone languages (or at least for the two tone languages here, Mandarin (the target language) and Thai (the language experience language). Second, the data tell us that any metalinguistic advantage or extra skills learned as a product of learning more than one language is independent of the skills required for learning to perceive lexical tone in a tone language. Each of these is discussed in further detail below.
 Task difficulty and differences between tone languages
 Mandarin and Thai tone inventories differ on a number dimensions: Mandarin has 4 tones and Thai 5; Thai has 2 level tones and 3 contour tones, Mandarin has 1 level and 3 contour tones; all 5 Thai tones are of similar duration, whereas Mandarin tones differ markedly in duration. Thus Mandarin and Thai are quite distinct with respect to their tones and this has two interesting implications with respect to the results obtained here. Firstly, given these differences, it is reassuring that there was an effect of (Thai) tone language background on the learning of the target tones in Mandarin, i.e., that there was transfer of learning from Thai tones to learning Mandarin tones. Second, the differences between Thai and Mandarin may have played a part in the relatively small performance gains in tone perception here. Further studies in which the background language and target tone language are more similar with respect to their tones, e.g., Thai and Cantonese (6 tones: 3 level and 3 contour, all tones of similar duration), may result in more performance gains. More generally, the relative salience of differences between tones within a particular language and the relative difficulty of discriminating tones in one tone system vs. that in another system is largely unknown (but see Burnham et al., 2017). Recent studies have shown that tone perception develops for a specific tone system (Yeung, et al., 2013) and that non-native tone language speakers have difficulty with tones that are similar or overlap with their native tone systems (Hao, 2012). Much more research is required on what particular parameters make particular tones or tone systems easier or more difficult to learn.
 Monolingual and bilingual children
 While monolingual vs. bilingual status of the children did not in itself facilitate tone learning in children, it did contribute to the mode of training that was most effective, as measured by the performance gain between pre- and post-training ao-test trials. The Auditory-Visual (AV) mode of training was the most effective for monolingual children, whereas for bilingual children Auditory-Only (AO) training, and, to a lesser extent, AV training resulted in performance gains. The source of this difference is not clear. One possibility is that exposure to a greater range of linguistic differences and devices, as would be the case for bilingual children, allowed them to (i) learn from a range of parameters, including auditory information alone or auditory and visual information combined, and (ii) learn that, even though there is visual information for tone (Burnham et al., 2001a,b, 2014; Smith and Burnham, 2012) the auditory information is by far the most salient. This is speculative and requires more definitive evidence.
 Phonological awareness
 English phoneme deletion ability (in the Mono-Eng, Bi-Eng/Arabic, and Bi-Eng/Thai groups) was positively related to pre-training auditory-visual test trial performance. Although there was no relationship here between reading and tone perception, the results are reminiscent of those of Burnham et al. (2011) who found a significant relationship between Thai children's reading ability and their phonological and tonological awareness, and between Australian English children's reading and their phonological awareness. Thus here, the ability to manipulate phonemes is related to the ability to perceive foreign speech sounds and in Burnham et al. (2011) reading ability is related to the ability to manipulate (foreign) phonemes and tonemes. Further research is required to investigate the nature of any three-way relationship between reading, phonological awareness, and foreign speech sound (and of especial interest here, lexical tones), the findings of which could be relevant to children's propensity to learn a second language, especially a tone language.
 Limitations and future directions
A number of limitations can be noted.
Training and test
 The post-training test implicitly tested for generalization across speakers and words, and, in addition, these trials provided implicit tests of generalization from training mode (be it AO or AV) to test mode, as both ao and av tests were given irrespective of training. The downside of this is that tests between trained and untrained stimuli and voices could not be conducted. It is possible that children, even the younger 6-year-olds, may have performed better on trained than untrained stimuli and voices. This should be remedied in future studies. The upside is that any improvement as a result of training indicated generalization of training. So the performance gains obtained here, while modest, are robust.
 A related point concerns variability. As discussed above, variability improves the robustness of learned distinctions (Wang et al., 1999), but variability should be optimized for the age and maybe the language background of the children. Here it was not.
 A final point on this theme is that for both clusters of results�the age and tone language experience cluster, and the training mode and monolingual/bilingual language experience cluster�the ao-tests were more sensitive measures of improvement than were the av-tests. And, even though auditory and auditory-visual modes differentially affected training outcomes in monolingual and bilingual children, the indexation of such training was still generally better on ao-tests. The reason for this is unclear. In future studies it would seem that ao-tests should be preferred.
 Phonological awareness
We included English language tests of phonological awareness here and found a positive relationship between phoneme deletion and pre-training auditory-visual test performance. Future studies should investigate this further by including reading tests across languages, phonological awareness tests across languages, and also tests of morphological awareness (McBride-Chang et al., 2003) and even executive function, in order to determine predictors of good lexical tone learning.

Instructions
No specific instructions were given. Children were simply told to pay attention to both the auditory and visual aspects of the speakers as we wished to determine whether children naturally pick up relevant lexical tone cues in an experimental setting. In real-life L2 learning situations such experimentally objective procedures may not be desired; indeed any relevant cue could and should be made available. In this regard, Chen and Massaro (2008) tested Mandarin perceivers' Visual-Only (VO) identification of the four Mandarin tones. (Remember that Mandarin language adults are worse than English language adults in VO tone perception�Smith and Burnham, 2012; Burnham et al., 2014). Initially the Chen and Massaro adults performed only just above chance and were better for the 55 and 214 tones than the 35 or the 51 tones. In a follow-up test adults were told about visible movements in tone perception and instructed to pay attention to movements of the neck, head, and mouth. Visual-Only tone perception improved significantly. Further work on perceivable visible cues for tone perception is required to facilitate L2 tone learning regimes.

Tone difficulty
The Chen and Massaro (2008) results also raise the issue of the relative difficulty of identification of individual tones and discrimination of tone pairs. Although the results of this study reported here were based on perception across all Mandarin tones, the data also showed some differences of how the participants of different ages and language backgrounds learned the Mandarin tones in this study. Details of performance on the different tones for each language background group and each age are shown in Table C (Supplementary Material) and some comments on these are provided here. Generally, high Static tone (T55) was the easiest tone to learn for monolingual non-tonal group while the Dynamic tones (either T241 or T51) were the most difficult. The results for the monolingual tonal group were exactly the opposite: the Static (T55) the most difficult to learn while the dynamic tones (T214 and T55) were the easiest. The data is a little less definite for the bilingual language background groups. Nevertheless, it appears that 6 year-olds in both bilingual groups found the Static tone (T55) the easiest to learn while the other Dynamic tones (T35, T241, and T51) were similarly difficult; whereas the 8 year-old bilingual groups found that the Dynamic (T214) was the easiest to learn. The fact that the participants WITH A TONAL BACKGROUND found the generally difficult DYNAMIC tones T35 and T214 (Chang, 2011) in Mandarin relatively easy to learn in this study is quite interesting. However, as the task used in this study was tone identification, some distinctive contours, rising and dipping, of these two rising tones might help in identifying them. The results might well be different if participants were asked to discriminate between these two rising tones; the task might be much more difficult. Future work must take into account such differences, but at the moment there are no objective criteria for determining difficulty of tone perception within and between languages. We (Burnham et al., 2017) are currently collecting data on the perception of tone pairs from three different tone languages by adults from five different language backgrounds in order to leach out some such criteria."
6,1303382,"""Psychophysical Estimates of Frequency Discrimination: More than Just Limitations of Auditory Processing""","""10.3390/brainsci3031023""",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4061867/,__sec3,__sec9,"2.1. Assessment of Task Specific Variations in Frequency Discrimination Abilities
Figure 1 and Table 1 summarise performance of the three groups of participants on the two psychophysical tasks (2I_6A_X versus 3I_2AFC).
 First, regardless of group, there is considerable individual variation in discrimination thresholds for both task designs and for each ISI in the 2I_6A_X task. Though contrary to prediction, individual variations in JND are less marked for the 3I_2AFC compared to any ISI condition in the 2I_6A_X task.
 To explore the differences among the two tasks, the data from the 2I_6A_X task for the ISI = 200 ms condition were entered into a repeated-measures ANOVA with the data from the 3I_2AFC task. This ISI condition was most similar to that of the 3I_2AFC task. Confirming the impression that participants obtained better overall JNDs with the 3I_2AFC than the 2I_6A_X task, a significant effect was observed for Task (F(1, 73) = 57.88, p < 0.001, ?2 = 0.442). There was also a significant main effect for Group (F(2, 74) = 7.65, p < 0.001, ?2 = 0.173, ? = 0.879) reflecting both lower JNDs and reduced individual variation in performance in the student group for both tasks.
 The mean thresholds for the 2I_6A_X task increase with increasing ISI in all three groups. To investigate this last effect further, the data from this task were entered into a repeated-measures ANOVA with ISI (10, 200, 1000 ms) as the within-subjects measure and Group (Par-TD, Par-LI, Student) as the between-subjects measure. Mauchly�s test of sphericity was significant (p = 0.007) and degrees of freedom were adjusted using Greenhouse-Geisser correction factors. A significant effect was observed for ISI reflecting the progressive increase in discrimination threshold with increasing ISI (F(1.78, 131.32) = 58.89, p < 0.001, ?2 = 0.443, ? = 0.887). Post hoc Bonferroni tests indicated that mean thresholds for all three ISIs differed significantly from each other. There was also a significant main effect for Group (F(2, 74) = 3.486, p < 0.05, ?2 = 0.086, ? = 0.635), reflecting the lower thresholds observed among the student group. The two parent groups had comparable JNDs. There was no significant Group x ISI interaction (i.e., JNDs for all three groups were similarly affected by increasing ISI). 
 2.2. Training Effects on JND Estimation in the 2I_6A_X Task
 Neither the large variability in JNDs measured using the 2I_6A_X task, nor the lower JNDs for the 3I_2AFC task, were predicted at the outset of the study. Initial piloting with students suggested that the 2I_6A_X task was procedurally more difficult than the 3I_2AFC task. The study protocol was consequently set so that the 3I_2AFC task was always presented first. Then the ISI = 400 ms condition was used as a training session for the 2I_6A_X task and each condition started with four condition specific training trials. This testing protocol was expected to minimise any training effects on performance for the 2I_6A_X task. However, varying degrees of experience with the 2I_6A_X task may still have contributed to the individual variation observed, since the order of presentation of the remaining ISI conditions in the task was randomised. The data were therefore entered into a repeated-measures ANOVA, ISI (3) � Group (3) � Order (6) to test for such effects. A significant effect for ISI was found (p < 0.001), but there was no effect (or indeed any trend) for order of presentation of ISI condition. There was also no significant interaction between Order � Group. Thus individual differences in experience with the task did not significantly contribute to the broad individual variation observed in performance on it.
 2.3. Task-Specific Susceptibility to Individual Differences
 To investigate susceptibility of the two different task designs to individual differences in musical experience (listening and training), nonverbal IQ (NVIQ) and SES, these variables were entered as predictors (forced entry) into a series of multiple linear regression analyses with ln(JND) for each task/ISI condition as outcome measure. Initial models were optimised to retain only those predictors that significantly contributed to each outcome measure.
 The data were first checked for evidence of significant multicollinearity between predictors (correlations greater than 0.8), or correlation between errors (Durbin-Watson statistic, values less than 1 or greater than 3). The effect of influential cases was assessed by checking for data points where Cook�s distances were greater than 1, Mahalanobis distances were greater than 15, or leverage values were greater than twice the average leverage value (i.e., for the 2I_6A_X task > 0.08; for the 3I_2AFC task > 0.05). One participant was excluded from the 2I_6A_X dataset because of a marked bias for responding �different� (d? = 2.15, criterion c = ?0.84) resulting in very low JND estimates which contrasted with the JND observed for the 3I_2AFC task (172.5 Hz versus, for example, 3 Hz (ISI = 1000 ms)).
 The regression weights for each analysis are summarised in Table 2. Predictors making nonsignificant contributions are shown to the right of the table. The inputs into the final models are bolded together with the amount of variance (R2) explained by each model.
 SES and musical training were the only factors to significantly contribute to variance in JND estimates in the 2I_6A_X task. The amount of variance explained by these predictors increased with increasing ISI to a maximum of 43% for the longest ISI (1000 ms), as compared with an initial 27% for the shortest ISI (10 ms). The regression weights for musical training across the 200 and 1000 ms ISI conditions are equivalent. Musical training predicts more individual variation in JND in these two ISI conditions, than it does for the 10 ms ISI condition. SES explains more variation in JND for the 10 and 1000 ms ISI conditions, than it does for the 200 ms condition.
 By contrast with the 2I_6A_X task, only musical training explained significant variance in JNDs for the 3I_2AFC task and the amount explained by it was considerably less than that explained by SES or musical training for any condition in the 2I_6A_X task. Overall, the 3I_2AFC task is less susceptible to individual differences in the factors assessed here than the 2I_6A_X task.
 Effect of Different Task Requirements on Observed Threshold
 If the higher thresholds and more variable performance in the 2I_6A_X task reflect the fact that it is more demanding than the 3I_2AFC task, then the participants who are least able to cope with the extra demands of the task will have the highest thresholds for it. They would therefore be expected to show the greatest amount of improvement in the easier task [21] which stresses their weaker cognitive skills less. To test this prediction, correlations were performed between threshold estimates obtained on the 2I task versus amount of improvement observed for the 3I task. Significant positive correlations (p < 0.001) were observed for all ISI conditions (ISI 10: r = 0.715; ISI 200: r = 0.724; ISI 1000: r = 0.731), confirming this prediction and suggesting that the 2I_6A_X task was inherently more difficult to do than the 3I_2AFC.
 2.4. Contribution of Frequency Discrimination to Nonword Repetition
 To assess contributions of frequency discrimination to verbal short-term memory, discrimination thresholds in the 3I_2AFC task and the three ISI conditions of the 2I_6A_X task were entered into a multiple linear regression analysis (forced entry), with �schooling� (proxy for vocabulary knowledge), and �music training�. This latter factor was included in the model because of the relationship to frequency discrimination performance observed in this study, and also because musical training is thought to enhance efficiency of auditory processing and hence support language learning [33].
 Only two predictors explained significant variance in nonword repetition: schooling, and JNDs measured using the 3I_2AFC task. The three ISI conditions of the 2I_6A_X task demonstrated high multicollinearity (r ? 0.8) with each other which contrasted with the low correlations (<0.38) of each measure with the JNDs observed for the 3I task. None of the JNDs for any ISI condition explained significant variance in nonword repetition and they were deleted from the final model, together with musical training which also explained little or no variance in nonword repetition. Table 3 summarises the final regression model together with observations from the initial exploratory analyses.","In this study, we compared frequency discrimination in the same groups of participants for two tasks designed to address different problems with the standard 2-interval psychoacoustic task designs. Our results suggest the 3I_2AFC design is less susceptible to non-auditory specific differences among participants than the 2I_6A_X design. These findings were surprising given that this latter design is often cited as minimising problems with sensory memory trace formation [12], auditory attention [24] and formation of perceptual anchors [34]. In the following, as part of addressing the issue of task susceptibility to task external effects like musical training, we consider why different results were obtained to those reported by France et al. [12]. We conclude by addressing the question of whether or how frequency discrimination may support language development.
 3.1. Performance Variability on the 2I_6A_X Task
 An appealing aspect of the 2I_6A_X task design was that it did not appear to be susceptible to non-auditory specific differences among individuals [12] suggesting it could be reliably employed in studies involving heterogeneous populations. We did not, however, replicate this observation. A number of possible explanations come to mind to explain our different findings. 
 Firstly, in the earlier study [12] a two-step process of threshold estimation was applied. Rough estimates were obtained of discrimination threshold and then a final threshold was estimated using an initial ?F close to the expected final threshold together with a more refined (i.e., smaller step size) adaptive staircase procedure. The small initial ?F for the second estimation would have also limited the range in which variation could be observed and all participants would have had considerable experience on the task at the point of final threshold estimation, minimising training effects. This approach to threshold estimation, better approximates standard psychophysical procedures and it is likely that had we adopted a similar strategy, we would have observed lower thresholds and reduced individual variation across the groups. However, we were primarily interested in task designs that could be reliably applied to address clinical or developmental questions, where one rarely has the luxury of applying such techniques. 
 Secondly, although France et al. [12] provide little information about their participants, it is clear they were high functioning. The mean IQs for both the reading disabled and normal readers were more than 1 standard deviation above the population mean. The majority of the participants were therefore likely to have been students, who, as our own data demonstrate, tend to perform better than the general population on psychophysical tasks. Moreover, they tend to be more homogeneous in terms of education and socio-economic status which will also limit the impact of such individual differences on thresholds observed. 
 Thirdly, and related to the preceding point, there is an interesting literature suggesting 2I tasks stress cognitive abilities [22] more than other tasks designs [21,24,25]. We did not expect the 2I_6A_X design to be similarly demanding since the inclusion of a stream of six repeated standard tones should have minimised cognitive demands, first by enhancing sensory memory for the standard relative to the target tone and second by cueing the presentation of the target tone to enhance temporal focus of attention [24]. However, in an analogous analysis to that used by Bishop et al. [21] to compare backward-masking in child populations using 2I or 3I tasks, we observed how the participants who performed worst on the 2I_6A_X task demonstrated the greatest improvements on the 3I task. Moreover, despite designing our protocol to maximise experience on the 2I_6A_X task prior to testing, some participants had final thresholds that were greater than the initial starting point of ?F = 160 Hz (Figure 1) though they got sufficient numbers of catch trials at this level correct. Together these observations suggest the poor performance on the 2I task was less about perceptual limitations, than about task-specific cognitive demands. This raises a question regarding why this design should be so cognitively demanding. In response to this, we can only provide the anecdotal evidence of our participants. Many commented that they found it more difficult than the 3I_2AFC task. Some noted how they had to concentrate harder when doing the task, while others commented that the target tone was always different, because it was longer as well as higher than the preceding six tones. Target and standard tones can have a variable perceptual quality particularly around threshold which contributes to the difficulty of correctly identifying the target tone. The comments of our participants suggest the presentation format for the 2I_6A_X task may have complicated the auditory decision-making process by promoting confusions in auditory percept. 
 Finally, although we have focused entirely on issues to do with task design, it is also possible that differences in the stimuli may have also contributed to the variations in individual differences apparent between the two tasks. Roving of the standard frequency in a frequency discrimination task, as we did in the 2I_6A_X task, makes it cognitively more demanding, resulting in greater individual differences in performance [35]. Differences in stimulus duration may also have contributed since the tones in the 2I_6A_X task were longer than those used in the 3I_2AFC task. Our design does not allow us to assess these stimulus-specific effects, though work by Banai and colleagues suggest they may be outweighed by effects specific to the task [22].
 3.2. Contributions to Task Performance of Different Environmental Factors
 Environmental effects such as socioeconomic status (SES) and more particularly, active musical training, but not passive music listening, had a significant effect on threshold estimates for both the 2I_6A_X and 3I_2AFC tasks. Musical training may support frequency discrimination by developing a more sophisticated sense of how different sounds relate to each other. The SES measure used here incorporated among other things differences in education which may impact of an individual�s ability to develop different strategies to cope with varying task demands. The 2I_6A_X task was particularly sensitive to these factors with the relative impact on task performance increasing with increasing ISI. This supports our earlier conclusion, that it is a cognitively demanding task and further suggests that it became more cognitively demanding as the time interval between standard and target increased meaning listeners became increasingly reliant on other (non-auditory) skills to support processes involved in their decision-making. The increasing contribution of musical training to performance on the longer ISI conditions in the 2I task further suggests that musical training may enhance skills associated with auditory imaging [36] which in turn would support sensory memory for the standard tone. This idea is reminiscent of rehearsal mechanisms which support information storage in the Baddeley and Hitch [37] model of verbal short-term memory.
 We are not the first to note how musical training makes a significant contribution to frequency discrimination abilities. Micheyl et al. [20] have demonstrated excellent frequency discrimination abilities in professional musicians. However, our data suggest, very little musical training is required to enhance frequency discrimination abilities, since none of the participants in this study were professionally trained. 
 Bishop [15] has previously noted how exposure to music in the home was an important environmental factor for predicting performance on a test of rapid temporal processing in a study investigating auditory and cognitive abilities in twins. We did not replicate this finding; nonetheless, both our study and that of Bishop [15] demonstrate the sensitivity of the auditory system to environmental factors like musical training or listening.
 3.3. Relationships between Frequency Discrimination and Nonword Repetition
 Auditory sensory memory is hypothesised to support verbal short term memory and we were ultimately interested in assessing the suitability of the 2I_6A_X task for further studying this component of verbal short-term memory especially since France et al. [12] had reported a relationship between frequency discrimination thresholds for the 2I_6A_X task and digit span�a measure of short-term and working memory. We therefore predicted that we would also observe a relationship (particularly for the long (1000 ms) ISI condition) with the nonword repetition task (another measure of short-term memory). However, no evidence of a relationship with nonword repetition was observed for any ISI condition in the 2I_6A_X task. By contrast, a small but significant association was observed between nonword repetition and JNDs estimated using the 3I_2AFC task. These observations add to a body of literature reporting similar such associations between frequency discrimination and performance on a range of tasks including, reading and phonological decoding skills [4,38], nonword same/different discrimination [22], as well as nonword repetition [39]. Such associations suggest frequency discrimination may impact on speech perception and hence on ability to develop language and literacy. However, we do not think the relationship is quite so direct. Gathercole and Baddeley [40] found no association with speech perception and repetition of short nonwords. In a similar vein, Rosen and Manganari [41] were unable to demonstrate a clear link between deficits in auditory processing and speech perception skills in a group of children with dyslexia. Finally, Halliday and Bishop [39] showed how, despite having deficits in frequency discrimination, children with mild to moderate hearing losses did not obligatorily demonstrate difficulties in reading or nonword repetition.
 Overall, while we did observe a link between the frequency discrimination and nonword repetition using a task that was relatively robust to the individual differences assessed in this study, our study does not rule out the involvement of a third higher cognitive capacity which is separately relevant to both nonword repetition and frequency discrimination. Similar arguments have also been put forward by Halliday and Bishop [39] and Banai and Ahissar [22]. Halliday and Bishop proposed auditory attention as a possible candidate for this third cognitive capacity, while Banai and colleagues have argued that whatever the capacity, it may not be specifically auditory in nature, and is likely to be mediated by higher level processes involving the engagement of the pre-frontal cortex which associates both with attention and with memory."
7,2521573,"""Mismatch Response to Polysyllabic Nonwords: A Neurophysiological Signature of Language Learning Capacity""","""10.1371/journal.pone.0006270""",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2707009/,s2,s3,"The ERP responses at FZ to the standard and deviant stimuli, together with the resultant difference waves are plotted in Figure 1 for each participant group.
 Analysis of MMN amplitude and latency
 As a first analysis, we compared the amplitudes of the MMN for the two groups of nonword-repeaters across the four deviants (Electrode � Deviant � Group). A significant main effect was found for Electrode [F(5, 53)?=?4.807, p?=?.001, ?2?=?0.312], but there was no main effect for Group nor did any interaction with Group approach significance. Thus the two groups did not differ in early consonant change detection.
 In a similar analysis, peak latencies for the MMN responses were also compared between the groups. No significant main effects or interactions were obtained, i.e., the two groups did not differ in rate of processing during early consonant change discrimination.
 Analysis of LDN amplitude and latency
Figure 2 compares mean LDN and MMN amplitudes collapsed across the six electrodes for the two groups as a function of deviant. As illustrated, strong LDN responses were obtained to all four deviants in the good nonword-repeaters. By contrast, an attenuated LDN response to D3 was observed in the poor nonword-repeaters.
 Statistical analyses showed that, in addition to a significant main effect for Electrode [F(5, 53)?=?5.725, p<.001; ?2?=?0.351], there was a significant main effect for Deviant [F(3, 53) 3.629, p<.01; ?2?=?0.165] and importantly, a significant Group � Deviant interaction [F(3, 55) 6.9, p<.01, ?2?=?0.273]. The analysis was repeated with the good nonword-repeaters subdivided into three groups of 14�15 participants each, and the interaction with deviant position was replicated, F (9, 165)?=?2.67, p?=?.006. The interaction was further explored by repeating the within-subjects analysis for good and poor nonword-repeaters separately. For the poor nonword-repeaters, there was a significant effect of deviant position, F (3,12)?=?7.7, p?=?.004, ?2?=?0.657, and specific contrasts revealed this reflected a significant quadratic term, F (1, 14)?=?8.2, p?=?.013, ?2?=?0.368, reflecting the bow-shaped function seen in the LDN. For the good nonword-repeaters, there was also a significant effect of deviant position, F (3, 41)?=?3.6, p?=?.022, ?2?=?0.207, but neither linear nor quadratic terms were significant (F-ratios<1).
 This analysis was followed up with one sample t-tests on average mismatch responses across the six fronto-central electrodes to determine whether the LDN differed significantly from zero. For the good nonword-repeaters, a significant LDN was found at all syllable positions (i.e., for positions 1, 3, and 4, p<.001; for position 2, p<.01). By contrast, for the poor nonword-repeaters, LDN responses significantly greater than zero were recorded at positions 1, 2, and 4 (with p values of <.001), but not at position 3. In sum, there is a significant difference in magnitude of LDN response to consonant change between the two groups at the third syllable and this difference associates with differences in overall nonword repetition score.
 To further test this association, we performed a correlation between nonword repetition score and mean LDN amplitude in response to the four deviants. A strong correlation was observed between nonword repetition score and mean LDN amplitude at syllable 3 only (r?=??0.407, p<.001), i.e., smaller LDN amplitudes at this position were associated with lower nonword repetition scores.
 As with the MMN response, peak latencies were submitted to analysis to test for differences in rate of processing deviance detection between the two groups. Though a significant effect for Electrode was obtained [F(3, 55) 3.404, p?=?.01, ?2?=?0.243], there was no main effect for Group nor any interaction with Group suggesting similar rates of processing among the two groups during this stage of consonant change detection.
 Relationship of MMN to LDN
 The LDN and the MMN are both elicited in response to a change in stimulus, yet only differences in LDN were associated with nonword repetition ability. A question thus arises regarding the extent to which these two negative deflections provide different information about the process of change discrimination in this paradigm. To assess this, mean MMN and LDN amplitudes across the six electrodes were calculated and a series of one-tailed Pearson product moment correlations were performed between the amplitudes of the two components for each deviant. We predicted a direct relationship between the two components if they reflected common processes.
 Correlations between the LDN and the MMN amplitudes in response to deviant syllables 1, 2 and 3 fell far short of significance (r?=??.18, ?21, .00 respectively) when all participants were included in the analysis. The correlation between MMN and LDN for deviant syllable 4 when both groups were included was .34 (p?=?.009), which was significantly different from zero, even after Bonferroni correction (critical p-value of .012).
 Correlations between the LDN and MMN amplitudes were also tested for each group separately applying the Bonferroni corrected critical p-value of 0.012. No evidence was found for significant correlations between LDN and MMN in the poor nonword-repeaters. In the good nonword-repeaters, weak correlations were observed between LDN and MMN at syllables 1 and 4 (r?=?.37, .32 respectively) which did not survive correction for multiple testing.
 Overall, with the possible exception of the final syllable, the evidence for common processes being involved in the generation of the MMN and LDN responses was not compelling.
 Family history and nonword repetition ability
 There were more parents of children with SLI in the poor nonword-repeater group. This raises a question regarding the role of family history for SLI in our findings. To test this, LDN amplitude � Deviant was entered into a repeated measures analysis with Group � Family history (+FH, ?FH). The numbers are not sufficient for a powerful analysis, but no significant interaction was observed between family history and deviant position. A plot of the mean LDN amplitudes for each of the four groups (Figure 3) clearly demonstrates a reduction in LDN amplitude in response to the consonant change which, regardless of family history, occurs on the third syllable in the poor nonword-repeaters.","There is considerable controversy regarding what exactly the nonword repetition task is tapping into that makes it such a good predictor of language learning. In this study, we employed stimuli that were designed to explore the functioning of a hypothesized phonological storage system. We exploited the electrophysiologically-measured mismatch response to test for sensitivity to change at different syllable positions in good and poor nonword-repeaters. We predicted that if nonword repetition ability was determined by factors ancillary to the phonological loop, then depending on which factor was primary, we would see either:
 (a) Significantly reduced MMN responses for poor nonword-repeaters to the deviants at all four syllable positions which would point to deficits in early auditory discrimination; or
 (b) No group or syllable-position effect if differences in nonword repetition derive from factors extrinsic to the phonological loop, such as differences in motor ability or in vocabulary knowledge.
 Alternatively, if a syllable-specific group difference emerged, this would suggest that factors associated with a capacity-limited storage system were impacting on the efficiency of information processing and change detection.
 In the context of our three predictions, two findings are particularly noteworthy. First, the two groups of nonword-repeaters had similar early consonant change discrimination abilities as indicated by the MMN response i.e., accuracy of early encoding of incoming auditory information was similar between the groups. In the context of children with SLI, Gathercole and Baddeley [13] first argued that deficits in nonword repetition ability could not be wholly attributed to differences in speech discrimination ability. Our findings with adults with poor nonword repetition skills are consistent with that view. Second, in the poor nonword-repeaters, the LDN response was abolished for the consonant change occurring at the third syllable of the CV-string, resulting in a significant Group � Deviant interaction. As noted above, this pattern of results is not consistent with the idea that the group difference on behavioral tests of nonword repetition is explicable solely in terms of factors such as pre-existing vocabulary knowledge or differences in articulation skills.
 Rather different conclusions were reached by ?eponien? et al. [23], who compared responses to deviant changes using a similar paradigm to ours to investigate the discrimination of just noticeable differences in two nonsense syllables �ba-ka� versus �ba-ga� in young good and poor nonword-repeaters. Contrary to our own conclusions with adult participants, their data suggest a role for discrimination deficits in young poor nonword-repeaters. However, their stimuli, unlike ours, were difficult to discriminate by design and shorter in length. Moreover their participants were younger. It is likely that the different conclusions arrived at by ?eponien? et al. reflect a range of factors including the subtlety of the acoustic differences to be discriminated and maturational differences between the participants in the two studies.
 Gathercole and Baddeley [13] suggested three possible candidates directly associated with the phonological loop as impacting on its function: quality of initial encoding into the loop; storage capacity; and the rate of fading of the memory trace once encoded there.
 At first glance, poor encoding seems inadequate to explain the results, because of the intact MMN responses seen in poor nonword-repeaters at all syllable positions, indicating adequacy of the early stages of speech discrimination. A simple storage account is also hard to reconcile with the results. If, for instance, poor nonword-repeaters could retain few syllables in memory, we might expect to see more pronounced deficits in their discriminative responses for both the third and fourth syllables, whereas the LDN attenuation was found for the third syllable only.
 The notion of a rapidly fading memory trace has been proposed to explain deficits in verbal working memory [22], [37], but seems implausible to account for our results for two reasons. First, in an earlier task, using pure tone stimuli with variable inter-stimulus intervals, Barry, Hardiman, Line, White, Yasin, and Bishop [38] showed that, although parents of children with SLI have less durable sensory memory traces than parents of typically-developing children, these differences did not associate with differences in nonword repetition ability. Second, in this paradigm, the temporal gap (and hence opportunity for decay) was held constant between each standard syllable and its deviant analogue. If it was only rate of memory trace decay that distinguished the two groups of participants, one would not predict the observed syllable-specific position effect that was observed here.
 It seems then that whatever differentiates good from poor nonword-repeaters is associated with information-processing under conditions of high input load. The position-specific group differences were not reflected in the early MMN response. They only became apparent in the LDN response. This, together with a lack of correlation between the two mismatch response types, suggests that the LDN provides different information about the processing of the auditory input. In the light of previous research, we suggest that the LDN is an index of formation of a phonological representation. This corresponds to a process of encoding into short-term memory, giving a more robust representation that can persist long enough to allow comparison between deviant and standard nonwords.
 Why should this encoding process be selectively impaired for the third syllable of a four syllable nonword? One interpretation is in terms of the demands the task places on rapid processing of sequential information. The notion of differences in rate of processing of incoming auditory information derives from the SLI literature, where it has been hypothesized that ability to rapidly process incoming auditory stimuli is deficient in people affected by a language or literacy disorder [39]. The results from both behavioral and electrophysiological studies probing the validity of this hypothesis have been fairly mixed, but in a meta-analysis of studies investigating mismatch responses to syllables in children with language or literacy problems, Bishop [40] concluded that deficits in auditory processing were more likely to be observed when stimuli were presented in rapid succession.
 Previous MMN studies in populations with language impairments have mostly focused on single syllables, but it may be that deficits in rate of processing only become apparent when processing multiple syllables. This hypothesis was tested by Kujala, Halmetoja, N��t�nen, Alku, Lyytinen, et al. [41] who assessed the ability of participants with dyslexia to discriminate changes in vowel durations embedded in three syllable CV-strings (e.g., �ta-ta-ta� versus �ta-taa-ta�). They observed no deficits pre-attentively to the change in vowel duration. However, when the participants were required to attend to the stimuli, they were less accurate at locating the change in syllable duration and they showed a significantly reduced N2b component in response to duration changes in the final syllable of the CV-string. These findings are somewhat reminiscent of our own findings. As such they are of interest given the overlap between dyslexia and SLI and given the fact that deficits in nonword repetition have been reported for both disorders [42].
 Within the context of the behavioral literature on SLI, Gathercole [43] observed that nonword repetition by language-impaired children was more accurate when nonsense syllables were presented singly with short intervals between them, than when they were presented in a string. Again this supports the notion that ability to rapidly process incoming sequences of stimuli embedded within other complex stimuli plays an important role in nonword repetition and hence in language learning.
 One problem for this account of findings is that one might expect to see effects on peak latencies of MMN and/or LDN, reflecting the slower rate of syllable-processing in the poor nonword-repeaters. This was not observed. Nevertheless, in other regards, the hypothesis makes sense of the specific pattern of results obtained here. A slower rate of processing of incoming speech would have a cumulative effect across the CV-string up to the final syllable where, because there is no subsequent syllable, perceptual analysis could be completed with a consequent recovery in LDN amplitude. In effect, this is an explanation in terms of deficits in encoding. It maintains that despite adequate early discrimination processes, poor nonword-repeaters fail to generate a robust phonological representation memory. These problems however, only become evident at rapid rates of stimulus presentation.
 A radically different type of encoding account is suggested by the literature on perceptual grouping. Horv�th, Czigler, Sussman, & Winkler [44] demonstrated that mismatch responses can be elicited by both global and local features of stimuli. In our design, we treated the global stimulus �ba-bi-bu-be� as the standard to be compared with deviants differing on one syllable. However, this stimulus contains within it a local repeated phoneme, /b/, which potentially acts as a standard. Thus on hearing �ba-bi-du-be� the response to the third syllable might be influenced both by the deviance from the standard, but also by the deviant /d/ after a train of preceding /b/ consonants, both within the same syllable and from the preceding nonwords. Limited ability to segment individual phonemes has been mooted as a possible cause of poor nonword repetition [21], raising the possibility that poor nonword-repeaters fail to engage in local processing and so are influenced solely by global mismatch. Although this explanation fits well with prior theoretical speculations about nonword repetition, it does not readily account for the pattern of results obtained here, because when progressing through the four syllables of the nonword, one would expect to see a steadily increasing impact of local mismatch, as the number of prior standards increases. We cannot rule out the possibility that such a process contributes to the profile of results obtained here, but it would need further testing with materials designed to evaluate this explanation. If local processing is involved in mismatch generation only in good nonword-repeaters, then a clear prediction is that mismatch responses will be reduced (and resemble those seen in poor nonword-repeaters) if a different consonant were used for each syllable of the standard.
 Overall, the results from this study suggest a link between two different theoretical accounts of factors affecting language learning. The auditory temporal processing account of Tallal [45] has a long history, but evidence has been mixed [46]. Most empirical studies have considered discrimination of pairs of tones or speech sounds, whereas the current study would suggest that, as the impact of slow processing is cumulative so that longer sequences of sounds are needed to reveal a deficit. The notion that phonological short-term memory is important for language-learning also has a long history. Within the context of these this theory, but the focus has been on explaining poor nonword repetition in terms of storage limitations or of rapid decay of representations. Encoding explanations have tended to be dismissed on the grounds that such problems should be apparent in short nonwords with one- or two-syllables. We suggest that this view is mistaken, because encoding is affected by the presence of adjacent syllables, and so will become apparent only in the later syllables of longer nonwords. The problem of poor nonword-repeaters seems to reflect an inability of encoding mechanisms to keep pace with incoming input. This would explain why nonword repetition is a more sensitive index of language difficulties than more conventional verbal memory span tasks, which typically adopt a slower rate of presentation.
 Though the focus of this study has been on factors affecting nonword repetition, our participants were heterogeneous with respect to the language learning status of their child. The poor nonword-repeater group included a sizable minority of parents of typically-developing children, just as the good nonword-repeater group included many parents of children with SLI. However, as a further analysis of the data showed (Figure 3), the effects reported here are specific to nonword repetition ability and not necessarily associated with having a language impairment child per se. One must therefore ask, given the composition of our participant groups, what implications do our findings have for current understanding of the etiology of developmental disorders such as dyslexia and SLI?
 Much of the research published to date has focused on finding a single underlying cause for a developmental language disorder, but it is becoming increasingly clear that a deficit in any one single underlying cognitive skill is unlikely to explain the broad range of phenotypes captured under simple umbrella terms such as SLI or dyslexia. Instead as Bishop [47] has argued, these disorders are more likely to develop out of a confluence of risk and protective factors, some of which are heritable. In the context of this study, deficits in the ability to process rapidly presented incoming auditory input seem to represent one such risk factor.
 In sum, previous suggestions for language specialization in the human brain have focused mainly on categorical speech perception, speech production, processing of serial order, and syntactic processing [1]. Our data suggest that human language learning capacity is boosted by being able to process sequentially-presented verbal material rapidly enough to permit the accurate recognition of syllables occurring at the rate of 5 per second, without earlier syllables interfering with the processing of later ones. We conclude that without this ability, it is hard to learn polysyllabic words or to discriminate the non-redundant information contained within a rapidly changing speech stream."
8,2562735,"""Distributional Vowel Training Is Less Effective for Adults than for Infants. A Study Using the Mismatch Response""","""10.1371/journal.pone.0109806""",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4188590/,s3,s4," 1. Descriptives
Grand average waveforms
Figure 2 shows the grand average standard, deviant and MMR waveforms of the adults in the current study (right) and, for comparison, of the infants in [4] (left), at eight electrodes, for each Distribution Type (unimodal vs. bimodal) pooled over Standard Vowel. The figure confirms the negative polarity and the expected latency and fronto(central) scalp distribution of the adult MMN (Method section 6): the red curve, which is the MMR waveform, deviates in the negative direction (notice that negative polarities are plotted upwards) from the baseline between 150 and 250 ms, and seems to do so more at frontocentral sites then elsewhere. The figure also confirms that the infant MMR contains less pronounced peaks [55] and that its scalp distribution is less defined than in adults (e.g., [54], see also [4]). Also, in accordance with several previous studies (e.g., [25], [48]�[50]), the polarity of the infant MMR is positive.
 Scalp distributions 
Figure 3 depicts the scalp distributions, which were made in Praat [43], for the unimodally (top) and bimodally (bottom) trained adults in the current study (right) and, for comparison, for the infants in [4] (left). The adult distributions were measured between 167 and 217 ms after stimulus onset, i.e., in a 50-ms window around the average MMR latency (i.e., the time of the most negative voltage occurring in the grand average waveform at Fz between 150 and 250 ms), which was at 192 ms. The infant distributions were measured between 100 and 500 ms after stimulus onset (Method section 6). Just as the grand average waveforms in Figure 2, the topographies of the MMR in Figure 3 illustrate the adult negative polarity (always blue, never red) and frontocentral distribution (darkest blue at frontocentral sites). For the infants, the positive polarity (red) and less specified distribution (darkest colors are spread over the scalp) are clearest for the bimodally trained infants. The MMR was not significantly different from zero for the unimodally trained infants (details are provided in Results section 2).
 MMR amplitudes
 The MMR amplitude in the overall window where the response was expected (i.e., between 150 and 250 ms after stimulus onset; see Method 6) was significantly negative for both the bimodally trained adults (mean?=??0.45 �V, 95% confidence interval [henceforth CI]?=??0.95??0.05 �V, t[19]?=??1.89, p?=?0.037) and the unimodally trained adults (?0.80 �V, 95% CI?=??1.39??0.20 �V, t[18]?=??2.82, p?=?0.006), thus suggesting that both groups discriminated the two test vowels to some extent.
 Subsequently, for each adult participant the MMR amplitude was calculated at Fz in a 50-ms window around the MMR latency for the participant�s group (see Method 6). This group latency was 193 ms for Unimodal [�], 196 ms for Bimodal [�], and 189 ms for Unimodal [?] and Bimodal [?]. The MMR amplitudes, averaged over the participants per Distribution Type and Standard Vowel, are presented in Table 2, together with their standard deviations and confidence intervals. For comparison, the corresponding numbers of the infant MMR amplitudes (see Method 6) are also shown.
 In [4], no significant difference had been observed between the infant MMR amplitudes at frontal, central and temporal electrodes (Fz, F3, F4, Cz, C3, C4, T7, T8). To further explore the frontocentral scalp distribution observed in the adult grand average waveforms and scalp topographies, we performed an analysis of variance (ANOVA) with Electrode (the same eight electrodes as for the infants) as a within-subject factor. The effect of Electrode was significant (F [7?, 266?, ??=?0.504]?=?9.94, Greenhouse�Geisser corrected p<0.001). The amplitude at T7 (mean?=??0.19 �V) was significantly less negative (�smaller�) than the amplitudes at all frontal and central electrodes (mean at Fz?=??0.91 �V, mean at Cz?=??0.90 �V, mean at F3?=??0.77 �V, mean at F4?=??0.93 �V, mean at C3?=??0.85 �V, mean at C4?=??0.84 �V; all ps?0.002), and not significantly different from the amplitude at T8 (mean?=??0.50 �V, p?=?0.80). These results are in line with a predominantly frontocentral distribution of the adult MMN.
 2. No significant effect of distributional vowel training in Dutch adults
 Recall (Method section 1) that in order to test whether there was a difference between the unimodally and bimodally trained participants, while controlling for differences in the presented standard, we performed an ANOVA with the MMR amplitude at Fz as the dependent variable, and with Distribution Type (unimodal vs. bimodal) and Standard Vowel ([�] vs. [?]) as between-subject factors. The main and interaction effects were not significant (for Distribution Type: mean difference bimodal � unimodal?=?+0.30 �V, 95% CI?=??0.50?+1.10 �V, F<1, p?=?0.45; for Standard Vowel: mean difference [�]�[?]?=??0.40 �V, 95% CI?=??1.19?+0.40 �V, F[1, 35]?=?1.02, p?=?0.32; for the interaction: F[1, 35]?=?1.41, p?=?0.24). Because the effects involving Standard Vowel were not significant, the amplitude data do not show proof of any perceptual asymmetry (Method section 1). The insignificance of all effects involving Distribution Type implies that the amplitude data do not provide sound evidence that bimodally trained Dutch adult learners have a different amplitude (mean?=??0.78 �V, 95% CI?=??1.34??0.23 �V) and thus benefit differently from distributional training than unimodally trained learners (mean?=??1.08 �V, 95% CI?=??1.65??0.51 �V). For comparison, the corresponding ANOVA for the infants in [4], which also included Time Bin and Electrode as within-subject factors (see Method 6), had yielded a significant effect of Distribution Type (mean difference bimodal � unimodal?=?+1.06 �V, 95% CI?=?+0.08?+2.04 �V, F[1, 18]?=?7.03, p?=?0.016), with a larger positive MMR, and thus a larger effect of distributional training, for the bimodally trained infants (mean?=?+1.37 �V, 95% CI?=?+0.68?+2.05 �V) than for the unimodally trained infants (mean?=?+0.31 �V, 95% CI?=??0.38?+1.00 �V).
 3. Smaller effectiveness of distributional training in adults than in infants
 From the statistical significance of the distributional effect in infants [4] and the statistical non-significance of the effect in adults (the present paper) we cannot yet conclude that the effect is greater in infants than in adults. A valid test requires a direct comparison of the two age groups. The difference in MMR amplitude between the Bimodal and Unimodal groups (i.e., Bimodal MMR � Unimodal MMR) for the adults was +0.30 �V (?=??0.78 �V�?1.08 �V; i.e., in the unexpected direction, though non-significant), whereas that for the infants [4] was +1.06 �V (?=?+1.37 �V�+0.31 �V). This age difference does not appear to be due to adults having a smaller MMR amplitude in general than infants, because the literature review in the Method section (section 7) suggested that this amplitude is probably greater in adults than in infants. The age difference could therefore be due to a truly smaller effect of distributional training in adults than in infants. To verify this, the current section presents a numerical comparison of the infant and adult MMR amplitudes. As determined by the literature review in the Method section (section 7), the comparison requires a normalization of the MMR amplitudes, which should include a correction for the opposite polarity of adult and infant MMRs and a scaling of the size of the MMR. To implement the normalization (or something equivalent to normalization), we multiplied each adult�s MMR amplitude by ?1 to correct for the negative polarity, and we multiplied each infant�s MMR amplitude by a scaling factor to correct for the smaller size. Before applying the scaling factors estimated from the literature, which were 1.18 and 1.41 (Method section 7), we present the results for a more conservative scaling factor of 1.00 (i.e. no scaling), which is smaller than the estimates; this scaling turns the mean MMR for adults into ?0.30 �V, and that for the infants into +1.06 �V, giving a difference of 1.36 �V.
 Scaling factor of 1
 Using a conservative scaling factor of 1, we performed an ANOVA with the normalized MMR amplitude as the dependent variable, and Age Group (infant vs. adult), Distribution Type (unimodal vs. bimodal) and Standard Vowel ([�] vs. [?]) as between-subject factors (given that in [4] a strong interaction was observed between Distribution Type and Standard Vowel, Standard Vowel was included to be able to extract possible interactions with this variable). The ANOVA yielded the following normalized MMR amplitudes per Age Group and Distribution Type (as visible in Figure 4): infant unimodal 0.31 �V (CI?=??0.38?+1.00 �V), infant bimodal 1.37 �V (CI?=?+0.68?+2.05 �V), adult unimodal 1.08 �V (CI?=?+0.56?+1.60 �V) and adult bimodal 0.78 �V (CI?=?+0.27?+1.29 �V).
 Crucially, the interaction between Age Group and Distribution Type was significant (F[1, 53]?=?5.05, p?=?0.029). Thus, the effect of distributional training differed between infants and adults (see below). Further, the interaction between Distribution Type and Standard Vowel was significant (F[1, 53]?=?4.85, p?=?0.032), as well as the triple interaction between Age Group, Distribution Type and Standard Vowel (F[1, 53]?=?13.99, p?=?0.0005). The other interaction effect (between Age Group and Standard Vowel) and the main effects were not significant (all p-values >0.21).
 As the number of participants was not the same in all groups, it is relevant to note that the crucial interaction between Age Group and Distribution Type did not depend much on the way the terms for the ANOVA were entered in the linear model. With �Type-III sums of squares�, the p-value for each main or interaction effect is calculated from a comparison between the full model (i.e. the model with all main and interaction terms) and the full model from which only this one term was dropped. This led to the above-mentioned p-value of 0.029 for the interaction between Age Group and Distribution Type. With �Type-I sums of squares�, the terms are entered into the linear model one by one and the p-value for each term depends on when the term is added. Under the constraint that the three two-way interaction terms are added after the three main terms and before the three-way interaction term, the p-value for the interaction between Age Group and Distribution Type depended only slightly on the order in which the two-way interactions entered into the model: it was 0.027 if this term was entered first, 0.024 if it was entered after Distribution Type � Standard Vowel but before Standard Vowel � Age Group; 0.025 if it was entered after Standard Vowel � Age Group but before Distribution Type � Standard Vowel; and 0.023 if it was entered last. By contrast, the interaction between Distribution Type and Standard Vowel was not robust to such variation. With Type-III sums of squares, the p-value of the interaction was as shown above (i.e., p?=?0.032), while with Type-I sums of squares the effect was non-significant, irrespective of the chosen order of factors (i.e., the p-value ranged from 0.23 to 0.27). This difference in significance is due to the strong effect of the three-way interaction term: only if this triple term is present and has taken away much of the variance does the interaction between Distribution Type and Standard Vowel provide a significant improvement to the model. The robustness of the interaction of Age Group and Distribution Type, together with the lack of robustness of the interaction of Distribution Type and Standard Vowel, means that the former effect has been shown more credibly than the latter.
 The observed interaction between Age Group and Distribution Type is pictured in Figure 4. The figure suggests that the difference in the normalized MMR amplitude between unimodally and bimodally trained participants was larger (i.e., more positive after normalization) for the infants than for the adults. When controlling for a possible effect of Standard Vowel, this difference is significant for the infants (mean difference normalized bimodal � unimodal?=?+1.06 �V, 95% CI?=?+0.09?+2.03 �V), thus indicating an effect of distributional training, and not significant for the adults (mean difference normalized bimodal � unimodal?=??0.30 �V, 95% CI?=??1.03?+0.43 �V). In view of the significance of the interaction between Age Group and Distribution Type, it is now possible to interpret the significant effect of distributional training for the infants as indeed being larger (i.e., +1.06�?0.30 �V?=?+1.36 �V, 95% CI?=?+0.15?+2.57 �V) than the non-significant effect for the adults (if that effect exists at all).
 Other scaling factors
 The statistical significance of the result depended on the size of the scaling factor by which the infant MMR amplitude was multiplied. With the conservative value of 1.00 used above, the p-value for the interaction between Age Group and Distribution Type was 0.029 (Type-III sums of squares). With the scaling factors estimated above (Method section 7), namely 1.18 and 1.41, which express the idea that adult MMRs are bigger than infant MMRs, the p-value would be lowered to 0.018 and 0.010, respectively. With a scaling factor of 0.8172, which expresses the opposite assumption from that derived from the literature, namely that infants have a somewhat larger MMR amplitude than adults, the p-value would become exactly 0.05. We can conclude that for a large range of plausible scaling factors, the effect of distributional training is reliably smaller for adults than for infants.","The current study provides the first evidence in a direct comparison that distributional training of speech sounds is less effective in adulthood, when new languages must be mastered, than in the first months of life, when infants start acquiring native speech sounds. Specifically, an earlier study [4] showed that Dutch 2-to-3-month-old infants who are exposed to a bimodal distribution encompassing the Southern British English vowel contrast /�/?/?/, have a larger MMR amplitude, and thus supposedly discriminate the two test vowels [�] and [?] better, than infants exposed to a unimodal distribution. The current study demonstrates that this bimodal advantage is smaller (if at all present) in Dutch adults than in Dutch infants.
 The presence of a bimodal advantage in Dutch adults is uncertain, because the difference in test vowel perception between bimodally and unimodally trained adults was not significant. It may be hypothesized that this non-significance was due to a ceiling effect (i.e., top discrimination) in both groups. After all, in the Netherlands English is a compulsory subject of study in middle school and high school, and it is also a language that can be listened to easily on television and other media. However, such a ceiling effect is unlikely. The MMR amplitudes in both groups were rather small (with 95% confidence intervals close to zero), suggesting relatively poor discrimination (cf., the amplitudes in adults listed in Table 1). Moreover, it has been shown that despite their experience with English, Dutch adults have trouble distinguishing the English vowels that were used in the current study [6]�[9]. Similar results have also been obtained with other languages: for instance, adult native speakers of Spanish have considerable trouble in discriminating tokens of Dutch /?/- and /a/, irrespective of the length of exposure to the Dutch language [56].
 Notwithstanding our efforts to make a sound comparison of the effect of distributional training in infants and adults, it is clear that future research is needed to replicate our results and to confirm the feasibility of our approach. For confirming this feasibility, it will be particularly important to ascertain that infant MMRs truly reflect behavioral discrimination just as adult MMRs do (section 1 below). Relatedly, future research should aim to get a much more detailed understanding of the neural processes underlying infant and adult MMRs, so that differences between them can be explained better (section 2 below presents a tentative rough explanation for the current results).
 1. Measuring learning in adults and infants
 The comparison of the effect of distributional training in adults versus infants was based on the MMR amplitudes. Our approach featured a minimization of methodological differences between testing infants and testing adults, and a normalization of the MMR amplitudes prior to statistical analysis in order to filter out possible residual differences between adult and infant MMRs. We presented a range of feasible normalization factors to account for the scarcity of information available for estimating such a factor in the literature, and to accommodate different possibilities of calculating such a factor.
 Still, an important concern in our approach remains, which, notably, also applies to other outcome measures (such as looking times) in other paradigms. This concern is that the MMR may not reflect the same processes in adults as in infants. In particular, it is important to ascertain in future research whether the infant MMR indeed reflects behavioral discrimination. This has been assumed widely on the basis of evidence in adults (for a review see [23]), but has never been verified experimentally. In this context it is noteworthy that a discrepancy between behavioral and neurophysiological measures also exists in the literature on auditory thresholds. These thresholds appear to be much higher in infants than in adults in the behavioral literature [57], but less so in research where auditory brainstem responses have been measured [58]. It has been suggested that this discrepancy occurs due to the co-existence of a mature auditory system and an immature system necessary for making efficient use of this auditory system; the discrepancy can then arise when behavioral measures tap the immature system, while neurophysiological measures tap the mature system [58], [59]. To examine whether the infant MMR truly reflects behavioral discrimination, it seems therefore important to relate behavioral measures (such as high-amplitude sucking measures for the youngest infants, and eye-tracking measures for older infants) with MMR recordings.
 2. Top-down influence on bottom-up learning
 It is not certain whether the observed smaller effect of distributional training in adults than in infants is due to a weakened distributional learning mechanism, which is generally considered to represent a purely stimulus-driven, and thus bottom-up learning mechanism [1], [2], or rather to strengthened top-down processing, or perhaps to both of these factors. Top-down processing refers to the modulation of stimulus-driven neural activity in lower-level areas (e.g., the primary auditory cortex) by higher-level linguistic representations (e.g., phonological word forms). In 2-to-3-month olds such top-down influence is lacking, because they do not have such higher-level representations yet [60]�[64].
 The first scenario (i.e., a weakened bottom-up learning mechanism) matches the decline of neural plasticity in the course of childhood, which has been related to an increase in the difficulty of �learning� with age [65], and which has been included in successful computer simulations of distributional learning [1], [2]. The second scenario (i.e., strengthened top-down processing) is in accordance with the observation that distributional learning of human speech sounds can be measured in adult rats [66], thus suggesting that it is a low-level mechanism that remains in place after neural plasticity has reduced to adult levels. In this scenario, distributional learning can be observed in the rats, because, similarly to the 2-to-3-month olds, they do not have linguistic representations that could modulate lower-level neural activity.
 A top-down influence of higher- on lower-level representations may already emerge after 4 to 5 months of life, as implied by research on the histological structure and development of the human auditory cortex [67]�[69]. This research shows that the six cortical layers that children and adults have, are not present from birth but develop in the first year of life and become visible in post-mortem tissue around 4 to 5 months. Crucially, the division into multiple layers seems to be a prerequisite for top-down influence from higher- to lower-level cortical areas [70]. A look at the functional organization of the layers may clarify this. Roughly, layer IV receives input from the thalamus and projects primarily to layers II and III (�supragranular layers�), which in turn target other parts of the cortex; layers V and VI (�infragranular layers�) receive input from the supragranular layers and project to the thalamus and other subcortical structures [71]. This functional division suggests that in order to make top-down influence from higher- to lower-level representations possible, the infant cortex must first develop supragranular layers, so that incoming signals can reach higher-level areas, where higher-level representations can be formed, and it must develop infragranular layers that receive top-down influence from these higher-level representations. At 4 to 5 months, rudimentary layering becomes visible in the tissue [68]. Although it is possible that some top-down influence from higher-level to lower-level cortical areas occurs before this time via layer I, which is the only layer that is clearly visible in post-mortem tissue at birth [67]�[69], the infrastructure for canonical top-down cortical influence thus emerges just before infants begin to perceive speech sounds in a language-specific way, which is from 6 months of life ([72], [3]; review in [4]). This opens up the possibility that this language-specific speech perception relies on top-down influence of higher-level speech sound representations. At the same time, neural plasticity is still high at 6 months (e.g., [73]), so that the possibility remains that the onset of language-specific speech perception (also) relies on bottom-up learning.
 If in adults the distributional learning mechanism tends to be �suppressed� by top-down influence of higher-level native linguistic representations, the previous significant effects of adult distributional training might have been obtained because the experimental setting (entailing the absence of a natural language context) reduced the influence of these representations on perception. Alternatively, the way the training stimuli were presented may have attracted participants� attention to the differences between the speech sounds in the tested contrast. If this is true, the observed effects of distributional training would be due to �attention�, which can be related to top-down processes in the brain (e.g., [74], [75]) rather than to distributional training, which is a strictly bottom-up mechanism.
 In this respect it is noteworthy that for the adult Spanish learners of the Dutch vowel contrast /?/~/a:/ in [20]�[22], enhanced bimodal training in particular seemed effective. Here the acoustic difference between the minimum and the maximum value along the presented continuum of the training distribution was made larger. From previous research in the second-language literature where other training paradigms than distributional training were used, it is known that widening the acoustic distance between presented stimuli in the training phase can draw participants� attention to the differences between these stimuli and improve subsequent discrimination and categorization performance [76]�[78]. Thus, it is possible that the previous observations of �distributional learning� in adults were related to attention instead.
 All in all, distributional learning as a mechanism for learning speech sounds seems to be weaker later in life than in infancy. The reduced prominence in adulthood may be due to fainter bottom-up learning as well as to the presence (versus the virtual absence in newborns) of higher-level linguistic representations and of a cortical infrastructure that enables top-down influence of these representations on bottom-up learning."
9,1695972,"""Human Brainstem Exhibits higher Sensitivity and Specificity than Auditory-Related Cortex to Short-Term Phonetic Discrimination Learning""",10.1038/s41598-017-07426-y,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5547112/,Sec2,Sec10,"Psychometric and behavioral data
The two groups did not differ in terms of general cognitive capability (KAI t(22)?=?0.423, p?=?0.676; MWT t(22)?=?0.642, p?=?0.528) or alertness (t(19)?=?0.617, p?=?0.545). Otherwise, the generalized linear mixed model (i.e., 2 groups?�?2 time points) revealed a main effect of time point (z?=??2.391, p?=?0.0403) as well as group?�?time point interaction effect (z?=?2.016, p?=?0.0438). As visible in Fig.�1A, the main effect of time point originated from a better discrimination at T1 (mean correct responses?=?63.04%) compared to T0 (mean correct responses?=?48%), whereas the group?�?time point interaction was related to a higher performance of the TG compared to the PG at T1 (mean correct responses, TG T0?=?45.09%, PG T0?=?50.46%, TG T1?=?74.09%, PG T1?=?53.69%).
 FFRs responses
 A one-sample t-test computed against zero (i.e., no lag) across all participants in order to exclude electromagnetic interference induced by the headphones (Bonferroni corrected p value for two tests?=?0.025) yielded significant results at both T0 (t(23)?=?7.825, p?<?0.001) and T1 (t(23)?=?8.475, p?<?0.001). These results are in line with previous literature13 and indicate the presence of genuine FFRs (Fig.�2) characterized by a mean delay of about 8?ms (i.e., T0, mean?=?7.825?ms, sd?=?1.917?ms; T1, mean?=?8.475?ms, sd?=?1.468?ms) reflecting signal transfer time from the ear to rostral brainstem structures13.
 The evaluation of between-group f1 peak amplitudes (Fig.�3) by means of a t-test (i.e., percent signal change) yielded a significant group difference (t(22)?=??2.147, p?=?0.043). Post-hoc t-tests against zero calculated separately for the two groups (i.e., Bonferroni corrected p value for two tests?=?0.025) revealed that the TG was characterized by a significant signal reduction (t(10)?=??2.704, p?=?0.022; mean % signal change?=??21.36, neural adaptation, Fig.�4), whereas brain activity did not change within the PG (t(12)?=?0.349, p?=?0.733, mean % signal change?=?2.74). Finally, even though we did not have any a priori-hypotheses, for reasons of completeness, we also evaluated percent signal change in f0 (i.e., added responses) and higher harmonics (i.e., subtracted responses, f2, f3, and f4) between the two groups. Since we did not reveal group differences in these additional parameters (f0, t(22)?=??0.193, p?=?0.849; f2, t(22)?=??0.881, p?=?0.388; f3, t(22)?=??0.586, p?=?0.564; f4, t(22)?=??0.035, p?=?0.972), results indicate a specificity of brainstem responses to the trained stimulus attribute (i.e., f1).
FFR: stimulus-response correlations
 Potential group differences in stimulus-response correlations (i.e., stimulus tracking and lag) as a function of treatment were evaluated by contrasting the percent signal change between the two groups by means of t-tests (Bonferroni corrected p value for two tests?=?0.025). These analyses did not reveal significant group differences in signal tracking (t(22)?=?0.508, p?=?0.617) nor in lag (t(22)?=??0.182, p?=?0.857).
 FFR: brain-behavior relationships
 In order to provide further evidence for the specificity of the functional changes observed within the TG at the processing level of the brainstem, we correlated percent f1 signal change with the learning performance during the training session (i.e., ? percent correct responses between run 6 and run 1 of the training session). Results revealed a significant negative correlation (i.e., see Fig.�4D) between the two variables (r?=??0.607, p?=?0.024, one-tailed).
 MMN responses
 Between-group differences in MMN area and latency in response to spectral (i.e., early MMN) and temporal (i.e., late MMN) manipulations were evaluated by means of separate t-tests (i.e., percent signal change; Bonferroni corrected p value for 4 tests?=?0.0125). These statistical analyses did not reveal significant group differences (spectral area t(22)?=??1.167, p?=?0.256; temporal area t(22)?=?1.656, p?=?0.112; spectral latency t(22)?=?1.085, p?=?0.29; temporal latency t(22)?=??0.514, p?=?0.613). Furthermore, in order to rule out the possibility that a general adaptation of the auditory cortex (i.e., see Fig.�5) as a consequence of repeated auditory stimulation between the two measurements points (i.e., T0 and T1) may have accounted for the lack of group differences, we performed additional post-hoc analyses within the two groups (one sample t-test against zero, two-tailed, Bonferroni corrected p value for 4 tests?=?0.0125). These supplementary analyses did not reach significance (TG MMN area early, t(10)?=??1.536, p?=?0.155; TG MMN area late, t(10)?=??1.493, p?=?0.166; PG MMN area early, t(12)?=?1.173, p?=?0.264; PG MMN area late, t(12)?=??2.466, p?=?0.030).
 MMN sources
 LORETA source estimation (Table ?(Table1)1) consistently revealed MMN maxima originating from posterior superior temporal areas, irrespective of group affiliation (i.e., TG and PG), time point (i.e., T0 and T1), and condition (i.e., spectral and temporal). These findings point to a main contribution of the auditory cortex to MMN responses.
 Training-related cortical-subcortical relationships
 Putative changes in cortical-subcortical interactions within the TG were evaluated by correlating (according to Pearson�s r, two-tailed) the percent signal change of early MMN area and latency with f1 signal change (Bonferroni corrected p value for two tests?=?0.025). These correlative analyses did not reach significance (rMMN area_f1 amplitude?=?0.155, p?=?0.65; rMMN latency_f1 amplitude?=?0.355, p?=?0.285).","
General discussion
In the present work, we used a test-training-retest procedure in two groups of participants who performed one hour of phonetic discrimination training, or were passively exposed to the same stimulus material, with the aim to (1) infer putative changes in the brainstem and auditory cortex as a function of short-term training, (2) estimate whether these short-term changes are reflected in neural facilitation or adaptation, (3) and to describe mutual interdependences between auditory cortex and brainstem. Results demonstrated that the brainstem but not the auditory cortex distinctively altered its response properties after short-term training. Most notably, this functional change was manifested in terms of neural adaptation and restricted to the frequency range (i.e., f1) corresponding to the trained stimulus attribute (i.e., F1). Since this frequency-specific neural adaptation was negatively correlated with the behavioral improvement of the participants during training, results point to a close relationship (~36% explained variance) between behavior and the underlying brainstem physiology.
 Brainstem responses
 Nowadays, it is generally acknowledged that the human brainstem constitutes a highly plastic entity13 that can alter its response properties as a function of both long-8 and short-term training34. For example, Carcagno and Plack44 evaluated the FFR before and after ten hours of pitch discrimination training consisting of differentiating complex tones with a static-, raising-, or falling pitch contour, and found a more robust phase locking of the FFR to the static and dynamic f0 after training. Furthermore, neural activity in the brainstem has previously been shown to be specifically modulated as a function of long-term language experience as reflected by increased f0 magnitudes in Chinese compared to English speakers in response to iterated rippled noise with Mandarin pitch contours45 or high rising Mandarin lexical tones46. However, until now, only two EEG studies specifically addressed causal changes in the brainstem induced by speech discrimination training11, 12. In a first study, Russo and co-workers11 reported that after long-term training (i.e., 35�40 sessions of one hour each) children suffering from learning disabilities exhibited brainstem responses that were more resistant to the detrimental effect of background noise than before treatment. Similarly, Song and colleagues12 demonstrated that native English-speaking participants who learned to incorporate foreign lexical pitch patterns varying in f0 (i.e., 8 sessions � 30?minutes, accomplished in 14 consecutive days) were characterized by a more faithful representation of f0 stimulus contour.
 In the present work, we provide evidence for short-term changes in the human brainstem after only one hour of phonetic discrimination training. However, contrary to previous studies that used professional musicians as a model for long-term training8, 47, results revealed functional changes that were manifested in terms of neural adaptation and not facilitation. Interestingly, a similar neural adaptation at the processing level of the brainstem has previously been reported by Slabu and colleagues48 in the context of a passive oddball paradigm. Thereby, the authors revealed a reduction of FFRs to deviant stimuli compared to standard ones, leading to suggest that the brainstem is able to encode statistical regularities34 by suppressing responses to rare stimulus events. Even though in the present study the �deviant� stimulus (i.e.,/go/) presented during brainstem measurements occurred with a low probability during the training session, the experimental manipulation we used precludes that results were driven by stimulus statistics34 or even by repetition suppression28. In fact, the PG was passively exposed to the same stimulus material as the TG, however, without showing a modulation of brainstem responses in pre-post comparisons. In addition, since brainstem changes were restricted to the solely discriminative physical attribute enabling to distinguish the trained stimuli, namely F1, results clearly point to feature-specific changes possibly reflecting increased neural efficiency28. This perspective is further supported by the negative correlation we revealed within the TG between percent f1 signal change and behavioral improvement during the training session.
 Neural adaptation constitutes an intrinsic organizational property of the auditory system across the entire hierarchical tree, ranging from the periphery to the auditory cortex (for a review consider49). In this context, it is noteworthy to mention a previous EEG study targeting at evaluating the encoding of statistical regularities while participants learned to segment complex tone patterns embedded in concatenated sound sequences. Interestingly, the authors revealed decreased brainstem responses to the patterned compared- to a pseudo-random condition after only fifteen minutes of task34. However, by looking at brain responses of the single participants, Skoe and colleagues34 noticed that neural adaptation and facilitation can go hand in hand with remarkable inter-individual differences. Furthermore, the authors revealed a positive relationship between brainstem physiology and behavior, such that better performance was related to greater neural enhancement. Notably, our results are comparable with those of Skoe and colleagues34 in that the TG demonstrated decreased f1 magnitudes after short-term learning compared to the PG. Otherwise, in contrast to Skoe and co-workers, we revealed a negative instead of a positive relationship between the magnitude of brainstem responses and behavioral improvement. From a physiological perspective, the adaptation we revealed at the processing level of the brainstem can be explained at least by three different phenomena. The first possibility is that short-term training may have altered the response properties of brainstem neurons by uncoupling neural entities that were not relevant for discriminating task-specific acoustic features, resulting in activation of fewer neurons, and consequently neural adaptation28. A second possibility is that the observed brainstem changes may have been indirectly mediated by performance feedback. In fact, since in the present study only the TG received such a feedback, it is thoroughly possible that reward and motivation may have modulated brainstem activity. This perspective is supported by previous work showing that the human reward system is responsive to high-order rewards (i.e., intellectual, artistic, or altruistic pleasures)31 and that feedback confirming reward expectation can modulate activity in auditory-related brain regions32, 33. Finally, since active learning requires a stronger engagement of attention functions compared to passive listening, we cannot rule out that this variable may have played a role in mediating neural adaptation29, 30. Such an influence of attention could, for example, have been mediated by the cortex through corticofugal projections. In fact, such a contribution of the cortex to auditory learning mechanisms via the corticofugal system has previously been demonstrated in animals by using both ablation and pharmacological interventions49, 50.
 A disadvantage of the EEG technique is that it does not enable to exactly determine the specific origin of the brainstem signal measured. However, currently there is evidence showing that neurons situated in the inferior colliculi are highly frequency-selective51, 52 as well as sensitive to the direction of frequency modulation53, 54. Since the TG was specifically trained to recognize subtle F1 signal changes only in one direction (i.e., always from/gu/to/go/, in the range between 364�480?Hz), we may speculate whether this specific experimental manipulation may have altered the response properties of neurons being selective to the direction of frequency modulation or rather frequency-selective neurons per se. In addition, since we did not reveal group differences in stimulus-response cross-correlations (i.e., lag and signal tracking), results suggest that during short-term training the brainstem is more likely prone to change its response properties to the spectrum of the trained stimulus attribute than to the waveform periodicity. This result is somehow in opposition with those previously reported by Russo and colleagues11 who revealed an increased temporal alignment of FFRs after training, as reflected by increased quiet-to-noise inter-response correlations. However, in this previous work the authors measured children with learning disabilities that were trained for a much longer period of time (namely 35�40?hours) compared to the present work. The same is true for the work of Anderson and colleagues55 where the authors evaluated the impact of an 8 weeks computer-based auditory training program in elderly subjects, and reported earlier brainstem peak latencies in both quiet and noise conditions after treatment. Taken together, these previous results substantiate the suspicion that brainstem changes in timing parameters may necessitate longer training periods.
 MMN responses
 A further goal of this study was to evaluate the functional malleability of the auditory cortex as indexed by altered MMN responses. In addition, based on previous studies indicating that neuronal entities which are sensitive to temporal and spectral acoustic attributes lie side by side in the auditory cortex56, we evaluated putative transfer effects57 from phonetic discrimination training to temporal aspects of speech processing. Reconstructed sources revealed MMN maxima originating from posterior superior temporal areas across groups (i.e., TG and PG), conditions (i.e., spectral and temporal manipulation), and time points (i.e., T0 and T1). This finding is in line with previous literature58 and points to a main contribution of the auditory cortex to MMN responses. In the present work, we did not reveal group differences in the modulation of MMN responses (i.e., MMN area and latency) as a function of treatment, leading to suggest that the auditory cortex was not specifically modulated by training. Interestingly, previous training studies consistently revealed increased MMN responses that were accompanied by an improved behavioral performance, however, especially after multiple training sessions lasting several days or weeks22, 59, 60. In particular, Ylinen et al.60 measured native Finnish (i.e., quantitative language) and English speakers before and after 10 training session of 25?minutes each consisting of learning to discriminate spectral and temporal cues of English vowels. As a main result the authors reported that after training the Finnish speakers were better able to discriminate spectral vowel cues, as reflected by increased MMN responses. In a further EEG study, Tamminen and colleagues59 applied a three-day phonetic-listen- and repeat training in a sample of Finnish speakers who learned voicing contrasts in fricative sounds (i.e., fricatives are not differentiated by voicing in Finnish) and revealed significantly increased MMN responses after the second but not the first training day. Taken together, these previous results lead to suggest that functional changes in the auditory cortex can most reliably be induced by multiple training sessions. Therefore, we may speculate whether a consolidation period is necessarily required for inducing detectable plastic changes in the auditory cortex61, 62.
 An alternative explanation that may account for the apparent insensitivity of MMN responses to training is that the constant serial order of the cortical and subcortical EEG measurements (i.e., FFRs were always collected first) may possibly have blurred neural facilitation through a superimposed signal adaptation. However, since between the two measurement points (i.e., T0 and T1) the two groups were additionally exposed to acoustic stimulation for one hour, we should have observed such an effect in pre-post comparisons (i.e., a significant percent MMN change against zero), irrespective of group affiliation. Finally, based on the fact that phonetic discrimination learning is an active perceptual process that operates under the influence of attentive functions, future training studies should evaluate short-term changes in the auditory cortex by combining active and passive oddball paradigms.
 Cortical-subcortical coupling mechanisms
 To the best of our knowledge, until now only four studies conjointly recorded FFRs and AEPs while participants were exposed to CV syllables36, 37 or vowels15, 35. In particular, Musacchia and colleagues36 measured musicians and non-musicians while participants were repeatedly exposed to the syllable/da/, and reported a positive relationship between subcortical f0 amplitude and cortical P1-to-N1 slope. Otherwise, Bidelman and colleagues35 measured young and older adults while the participants categorized vowels that spanned a perceptual continuum from/u/to/a/and revealed that older adults were characterized by slower and more variable speech classification performance than younger listeners. This differential behavioral performance was reflected by reduced brainstem amplitudes, increased cortical AEPs, as well as by a negative relationship between f1 and cortical N1/P2 amplitudes. In a second study of the same group15, the authors recorded cortical and subcortical brain responses in older adults with and without music training while the participants categorized vowels along a continuum. Even though the authors did not find between-group differences in terms of cortical (i.e., P1-N1-P2 complex) or subcortical (i.e., f0 amplitude) brain responses, musicians showed a closer relationship between neural activity and behavioral performance. Finally, Parbery-Clark et al.37 investigated the effect of background noise on both brainstem and auditory cortex activity, and reported a relationship between subcortical response fidelity and cortical N1 magnitude that was predictive of speech-in-noise perception. In the present work, we did not find evidence for a relationship between auditory cortex and brainstem changes as a function of training. However, this may rather be a byproduct of unmodulated MMN responses as a function of training rather than an evidence for the inexistence of cortical-subcortical coupling mechanisms. In this context, it is also important to mention that our experimental design profoundly differed from the previous studies mentioned above. In fact, Musacchia and colleagues36 as well as Bidelman et al.15 measured musicians, a specific group of subjects that has previously repeatedly been shown to constitute a suitable model for evaluating the influence of long-term training on auditory processing16, 63, 64. Otherwise, the group of Parbery-Clark37 evaluated cortical-subcortical coupling mechanisms in normal hearing young adults while performing a speech-in-noise perception task, an experimental condition which is well known to place stronger demands on cognitive control mechanisms that have a modulatory influence on brainstem activity through the corticofugal system34."
