doc_id,result_id,text
1421389,0.0,"A 49-year-old Caucasian woman with a history of migraines and herpes labialis presented to the emergency department (ED) with headache, and numbness and tingling in the left side of her face and her left leg. She related a history of recurrent sinusitis related to seasonal allergies, but with no recent nasal or pulmonary symptoms. She had developed peri-oral fever blisters, a low-grade fever, and a disabling left temporal headache four weeks earlier. Her headache was unlike the typical migraines that she periodically experienced, which usually responded to a combination of acetaminophen, aspirin, and caffeine. In addition, she experienced nausea, vomiting, and decreased appetite in association with her headaches that were accompanied by a 7.7 kg weight loss. She also exhibited personality changes and short-term memory loss. Her blisters healed in two weeks, but her headache and fatigue persisted. She subsequently developed numbness and subjective weakness in the left side of her face and her left leg one week prior to presentation. She sought care from her primary care provider, who diagnosed her with Bell's palsy and prescribed metoclopramide for her nausea. She was also referred to a neurologist who began treatment with aspirin for suspected transient ischemic attack. An MRI of the brain was pending at the time of her presentation to the ED. "
1421389,1.0," On admission, the patient's temperature was 37.9°C, blood pressure 166/96 mmHg, pulse 89 beats/minute, respiration rate 18 breaths/minute, and oxygen saturation 97.5% on room air. Her mental status and affect were normal. The distribution of dysesthesias was confirmed to be in the V2/V3 and L4/L5 dermatomes on physical examination. No motor deficits, other neurologic abnormalities, or lymphadenopathy were noted. A basic metabolic panel was remarkable for 3.2 mEq potassium/L (normal range 3.5 to 5.0). A complete blood count revealed 11.82 × 109 WBC/L, with 7.304 × 103 absolute lymphocytes/μL. Her CSF was clear and contained 6 WBCs/μL (89% lymphocytes), 63 RBCs/μL, 54 mg glucose/dL, and 49 mg total protein/dL; cell counts were taken from the fourth tube of CSF collected. Results of a chest radiograph were normal, and an MRI scan of the brain showed left greater than right ventriculitis, basal meningitis, and encephalitis of the peri-ventricular and right basal ganglia white matter (see Figure 1). "
1421389,2.0," Treatment with intravenous dexamethasone, ceftriaxone, and aciclovir was initiated and the low potassium was replaced. The patient's headache and dysesthesias rapidly improved. On day 2, the hospital's pathology lab reported small, mature-appearing lymphocytes and smudge cells in her peripheral blood smear. Further immunological investigation revealed 259 absolute CD4+ T cells (normal range 400 to 1500), 389 absolute CD8+ T cells (normal range 275 to 780), and a CD4/CD8 ratio of 0.7 (normal range 0.9 to 3.7). Results of a CSF polymerase chain reaction (PCR) test for HSV-1 were positive, and results of serum HIV-1 and 2 antibody tests were negative. Ceftriaxone and dexamethasone were subsequently discontinued. The serum and CSF studies performed to rule out other infectious and vasculitic processes are listed in Table 1. "
1421389,3.0," A diagnosis of CLL was confirmed by the expression of CD5, CD19, and CD20 antigens on monoclonal B cells with κ light chain restriction on blood flow cytometry. Fluorescent in situ hybridization later revealed a 13 q deletion, the most common cytogenetic abnormality seen among patients with CLL. The patient's γ-globulin level was 839 mg/dL (normal range 700 to 1600). After eight days on intravenous aciclovir, her symptoms had completely resolved and she was discharged on oral valaciclovir. She remained well for the next few weeks. "
1421389,4.0," Then, one month after discharge, she developed new bilateral numbness of the hands and feet and was found to have cervical lymphadenopathy on physical examination. A repeat MRI showed increased numbers and size of peri-ventricular lesions (see Figure 1), and she was readmitted. A repeat CSF PCR test for HSV-1 was negative, but 10 oligoclonal bands and a myelin basic protein level of 5.7 ng/mL (normal value <1.5) were found. Table 2 details other laboratory test results for comparison between the patient's first and second admissions. Computed tomography (CT) scans revealed extensive cervical lymphadenopathy, slightly enlarged axillary nodes bilaterally, and early lymphadenopathy among the mesentery. A brain biopsy was performed to rule out CNS lymphoma, and it demonstrated gliosis consistent with MS with no evidence of lymphoma (see Figure 2). She received high-dose parenteral steroids for five days, with symptom resolution occurring within the first two to three days. She was discharged on oral prednisone treatment, to follow up with her neurologist and oncologist. Six months later, the patient was still asymptomatic, having started interferon-β therapy for MS and not yet needing treatment for Rai stage zero CLL. "
653044,0.0,"Comparison between model estimates and MRI measures The model correctly reproduced local flow direction in all its segments (Fig. 2). Figure 3 shows the comparison between the flow rate measured with PC MRI and the corresponding model estimate. The number of vessels correctly imaged and the p-value of the signed rank test are also reported. We did not measure SSr or SSl flow rates as it was not possible to correctly image these vessels solely in the perpendicular plane. The flow rate measured with MRI was not significantly different from the model estimate for the following veins: IJVr, IJVl, VVr, VVl, ICVr, RVr, RVl, SPSl, SPSr, SRS, posterior part of SSS, TSl, TSr. The flow rates of ISS, ICVl and anterior SSS estimated with the model were statistically different from those measured with MRI. The median flow rate obtained with MRI for anterior SSS (not shown in Fig. 3) and its 95 % CI were 2.5 [1.1–3.1] ml/s, which is statistically different (p<0.0001) from that estimated by the model (7.1 ml/s). "
653044,1.0," Venous obstruction simulation The structure of the lumped parameter set allowed for separate analysis of the effects of upper and lower circulation anatomical anomalies. As the upper and lower parts of the model were decoupled, changes in the portion above the cardiac level did not affect the one below, and vice versa. "
653044,2.0," IJV obstruction The intracranial pressure estimated by the model had a specific trend related with the degree of IJV diameter reduction as shown in Fig. 4a. The amplitude depends on the specific node. Figure 4a provides, as an example, the pressure at the confluence of RVs to GV. At this level, intracranial pressure doubled its baseline value when both the IJVs were obstructed, in particular when one of them had a diameter reduction of at least 80 % and the other one of at least 90 %. Fig. 4b shows how the SSS posterior end pressure increases with different IJVs constrictions, with respect to the baseline value, which was removed from each value. The simulations carried out with IJV diameters of 1 cm [29] and 0.7 cm [32] showed intracranial pressure increase for lower IJV diameter reductions. At the level of the RVs confluence to GV, pressure doubled its baseline value for bilateral IJVs obstruction of 70 % in the latter and 60 % in the former (Additional files 2 and 3) case. In regards to the IJV upstream pressure, it doubled its initial value for IJV diameter reduction of at least 20 %. When the total occlusion of one IJV was simulated, retrograde flow in the corresponding SS was computed whenever a partial diameter reduction of the other IJV was modeled. The simulation of bilateral IJV occlusion greater than 90 % produced retrograde flow in the CS, IPS (Fig. 5b) and SPS. The simulations carried out with IJV diameters of 1 cm [29] and 0.7 cm [32] showed reflux of intracranial vessels for lower percentage of bilateral IJV diameter reduction (80 % in the former and of 70 % in the latter case). The results obtained with IJV collaterals differed from those obtained without collaterals by less than 3.5 %. The reflux was observed in the same vessels as without collaterals. "
653044,3.0," Vertebral vein obstruction The simulation of VV diameter reduction showed an increase in global high pressure in the cervical and vertebral areas, with higher values for severe VVs obstruction. Conversely, the intracranial area was less affected, where the pressure increases by less than 14 %. The CPa and CPp upstream, respectively the confluences of the BP and the OS to the cervical and vertebral areas, were highly affected by VV obstruction. Retrograde flow in POS, POSl and POSr was observed for bilateral VV occlusion higher than 60 %. "
653044,4.0," Azygos obstruction The obstruction of the proximal azygos segments caused a pressure increment along the azygos. The pressure progressively increased as the azygos diameter was reduced. The obstruction effect was higher for the nodes near to the obstruction itself and lower for the distal parts. We reported (Fig. 6a) the pressure between AZY4 and AZY5, and AZY5 and AZY6 as representative of the former, and the one between AZY11 and AZY12 for the latter. Retrograde flows were computed in the azygos itself and in the thoracic plexus: the higher the degree of diameter reduction, the higher the number of distal azygos and thoracic plexus segments affected by the reflux. Figure 6b shows the flow rate trend with progressive azygos diameter reduction for AZY1, AZY5, and AZY11, as representative of segments from proximal to distal azygos. "
653044,5.0," EchoColor Doppler results ECD data of MS patients showed IJV abnormalities caused by stenosis, membranous obstruction or hypoplasia in 86 % of cases. Among the stenotic or hypoplastic cases, unilateral IJV occlusion was detected in 28 patients (21 of them had unilateral IJV but not VV occlusion), while bilateral in 37 (17 without VV occlusions). Intracranial reflux was observed in 21/28 subjects with monolateral IJV occlusion (17/21 considering those without VV occlusions), in 28/37 subjects with bilateral IJV occlusion (15/17 considering those without VV occlusions). The reflux was always located in CS, IPS and SPS, but never located in the RV. "
654927,0.0,"Table 2 shows the demographic and clinical characteristics of patients participating in the PREMiSe study. In total, 15 patients signed an informed consent in phase 1 and 30 in phase 2 after prescreening qualification procedures were completed. Of those, 5 in phase 1 and 10 in phase 2 did not fulfill noninvasive screening procedure requirements on DS. Therefore, 10 patients in phase 1 and 20 in phase 2 were enrolled in the invasive screening portion of the PREMiSe study. All noninvasive and invasive study procedures were well-tolerated. No intra- or postprocedural complications, including vessel rupture, thrombosis side effects to the contrast media or mortality were recorded at 24 hours or 1 month. "
654927,1.0," Frequency of venous abnormalities on noninvasive and invasive imaging techniques in phase 2 of the PREMiSe All 20 patients fulfilled DS screening criteria that showed anomalies in their IJVs and/or VVs (Figure 1). Of those, one patient did not fulfill invasive screening criteria for endovascular intervention (venous lumen diameter reduction ≥50%). In particular, 19 (95%) patients showed venous abnormality of the right and 19 (95%) of the left IJV, whereas there were 7 (35%) patients who showed venous abnormality of the VVs. The MRV venous abnormalities were found in 7 (35%) of the right and 7 (35%) of the left IJVs and in 3 (15%) of the VVs (Figure 2). Seventeen (85%) patients showed the presence of collateral neck veins on MRV in the right and 15 (75%) on the left side, both on TOF and TRICKS. There were a total of 2.3 (SD 1.2, range 0–4) collateral neck veins on TOF and 2.3 (SD 1.2, range 0–4) on TRICKS. Eleven (55%) patients showed venous abnormality on CV of the right IJV, 14 (73.6%) of the left IJV and 10 (50%) of the azygos veins (Figure 3). Of all stenotic lesions detected by CV in the right IJVs, 11 (100%) were in the lower segment (J3) and 3 (30%) were in the upper segment (J1 or J2), whereas in the left IJVs, 11 (78.6%) of the 14 stenotic veins had lesions detected in the lower segment (J3) and 10 (76.9%) in the upper segment (J1 or J2). The stenotic segment in the azygos vein was in the same location (descending part of the azygos vein distal to the azygos arch). Two of the 20 (10%) left IJVs were not examined by IVUS and one (10%) by CV because of the difficulty to access with the wire. Only 13 of the 14 cases who showed venous abnormality in the left IJV were considered for comparison between CV and IVUS, as one case overlapped with one of the 2 cases who did not get examined with IVUS. Epidural collateral veins were found in 14 (70%) right and 16 (88.9%) left IJVs and in 16 (80%) of the azygos veins. Other collaterals were less common. In total, 10 (50%) right and 15 (83.3%) left IJVs and 17 (85%) azygos veins, demonstrated an IVUS abnormality (Figure 4). The stenosis on IVUS was detected in 7 (35%) right and 11 (61%) left IJVs and in 8 (40%) azygos veins. Reduced respiratory pulsatility was observed in 7 (35%) right and 10 (55.5%) left IJVs and in 7 (35%) azygos veins. Intraluminal abnormalities (septa, vein divided into multiple channels, IHFD and DPL) were detected in all vessels. "
654927,2.0," Sensitivity and specificity analyses between noninvasive and invasive venous abnormality findings in phase 2 of the PREMiSe study Table 3 shows sensitivity analyses of noninvasive and invasive imaging techniques vs. DS (as a ""gold standard/benchmark"") for the detection of abnormal findings in the IJVs and in azygos vein/VVs. The sensitivity of CV + IVUS was 68.4% for the right and 100% for the left IJV, compared to venous anomalies detected on DS. The sensitivity of IVUS to detect venous anomalies in azygos vein/VVs was high when compared to DS (85.7%). Table 4 shows the sensitivity, specificity, PPV, NPV and OR of noninvasive and invasive imaging techniques vs. MRV as the ""gold standard/benchmark"" for the detection of abnormal findings in the IJVs and in azygos vein/VVs. Compared to the venous anomalies detected on MRV, the sensitivity for the detection of venous abnormalities on CV + IVUS was 71.4% in the right and 100% in left IJVs and 100% in azygos but the specificity was 38.5%, 38.9% and 11.8%, respectively. The sensitivity, specificity, PPV, NPV and OR of IVUS vs. CV as the ""gold standard/benchmark"" for the detection of abnormal findings in the IJVs and in azygos vein/VVs is shown in Table 5. The sensitivity of IVUS ranged from 72.7% for right IJV to 90% for the azygos vein, although the IVUS showed a higher rate of venous anomalies than CV. Table 6 shows the sensitivity, specificity, PPV, NPV and OR of invasive imaging techniques vs. DS + MRV combined as the ""gold standard/benchmark"" for the detection of abnormal findings in the IJVs and in azygos vein/VVs. Again, because the inclusion criteria for the study were having a presence of ≥2 VH extracranial criteria, we were able to derive only sensitivity findings. The sensitivity for the detection of venous anomalies using invasive imaging techniques did not increase compared to DS + MRV. "
432103,0.0,"Co-incubation of A. polyphaga and M. ulcerans results in intracellular bacilli frequently, Using light microscopy, AFB were observed co-localizing with amoebae after co-incubation of each M. ulcerans strain with A. polyphaga for 3 hours (Figure 2). Electron microscopy was used to confirm the intracellular localization (Figure 3). The bacilli were seen in phagocytic vacuoles with the phagosomal membrane tightly opposed to the bacillary surface (tight phagosomes) (Figure 3D) or, inside ‘‘spacious vacuoles’’ (Figure 3C). The phagosomes contained single (Figure 3C and D) or groups of bacilli (not shown). About 45% of the bacilli in the electron micrographs looked normal according to the parameters previously defined [47], including the presence of an asymmetric profile of the cytoplasmic membrane with the outer layer thicker and denser than the inner layer (Figure 3B). As is typical of the ultrastructure of normal mycobacterial cell envelopes [48], an electron-transparent layer of the cell wall of M. ulcerans was observed (Figure 3B). No electron-transparent zone [49] was seen around the intracellular bacilli (Figure 3). Figure 4 shows that viable M. ulcerans persisted within A. polyphaga for the duration of the experiment (two weeks) although their numbers decreased with 1 to 2 log. "
432103,1.0," Distribution of amoebae in natural water bodies in Ghana 181 amoeba cultures were obtained from 134 out of 148 collected samples (90.5%). The isolation frequency of amoebae did not differ significantly between BU endemic and non-endemic sites (p = 0.954, x2 1 = 0.004). Different habitats yielded different frequencies of amoeba isolation (p = 0.044, x2 3 = 8.084), with the highest detection frequency in detritus (97.8% vs. 76.9% in water, and 88.9% in biofilms). There was no significant difference between the sampled water bodies (estimated effect: 0.03; 95% CI: 20.19 to 0.24). Because 15 of the 181 amoeba cultures did not survive transportation and/or storage, mycobacteria were only searched for in the remaining 166 amoeba cultures (isolated from 124 different samples). "
432103,2.0," Detection of M. ulcerans in samples and amoeba cultures IS2404 was detected by real-time PCR in 3 out of 148 samples, after extracting the DNA directly from these samples. In only one of them IS2606 and KR-B were also detected, strongly suggesting the presence of M. ulcerans in that sample (Table 1). The D CT (IS2606 - IS2404) value of 1.96 approaches the known fold difference in copy numbers between IS2404 and IS2606 for M. ulcerans, i.e. 2.3 [44]. However, the high CT values in all 3 of the positive assays (Table 1) imply the presence of less than a genome in the 1 mL DNA extract added to the PCR-mixture so that the D CT’s cannot be considered as true representations of the relative copy numbers of the repeated sequences. Therefore in the two IS2404 positive yet IS2606 and KR-B negative samples the presence of M. ulcerans cannot be denied nor confirmed. Out of the 166 amoeba cultures tested (originating from 124 different samples), seven were positive for IS2404 (Table 1). Again, given the high CT values (Table 1), also here less than a genome was present in the 1 mL of DNA extract added to the PCR mixture. The IS2404 positive amoeba cultures were isolated from BU endemic as well as BU non-endemic communities and from the IS2404-containing different microbial habitats. None of amoeba cultures tested positive for IS2606 or KR-B. However, because of the low mycobacterial DNA content neither the absence or presence of M. ulcerans can be confirmed. None of IS2404 positive amoeba cultures were isolated from samples that had already been found positive for IS2404 in DNA extracted directly from the samples. The following amoebae were identified among the IS2404 positive cultures: Vahlkampfia avara (99% identical with the V. avara sequence in Genbank), a close relative of V. inornata (92% identical with the V. lenticulata (T5 genotype), Acanthamoeba sp. T11 genotype and Acanthamoeba spp. T4 genotype. One of that supposedly supported an amoeba culture did not contain amoebae at the time of IS2404 detection. inornata sequence in Genbank), A. the IS2404 positive agar plates Identification of the IS2404 negative amoebae will be detailed in a subsequent study by Amissah et al. (in preparation). The geographical origins of the IS2404 positive samples and amoeba cultures did not show any distribution pattern. We detected IS2404 in at least 1 sample and/or amoeba culture from all sampled localities, except Bebuso. "
432103,3.0," Mycobacteria are commonly found intracellularly in the environment and are often detected in amoeba cultures As described in the methods section, subsamples were made to cultivate extracellular and intracellular mycobacteria. Twenty-six of the 148 samples were excluded from further analysis due to contamination of one or both of the subsamples. From 15 samples (12.2%) only intracellular mycobacteria were isolated, from 17 samples (13.9%) only extracellular mycobacteria, and from 32 samples (26.2%) both intra- and extracellular mycobacteria were isolated. Details are given in Table 2. In general the difference between the isolation frequency of extracellular and intracellular mycobacteria was not significant (x2 1 = 0.17, p = 0.89). To assess whether the intracellular life style was more frequent in certain sites or certain habitats, we determined the relative isolation frequency of intracellular mycobacteria (i.e. the number of samples from which intracellular mycobacteria were cultivated divided by the total number of samples from which we cultivated mycobac- teria –intracellular and/or extracellular), and related this to BU endemicity, sampling sites and habitat type. The relative isolation frequency of intracellular mycobacteria did not differ between BU endemic and non-BU endemic areas (0.77 vs. 0.68; p = 0.86, x2 1 = 0.03). The type of habitat, however, did have a significant effect on the relative occurrence of intracellular mycobacteria (p = 0.002; x2 intracellular mycobacteria were more frequently isolated from detritus (relative isolation frequency of 0.95) than from biofilm samples (relative isolation frequency of 0.63; p = 0.01). 3 = 15.1): samples Based on a 821 to 837 bp portion of their 16S-rRNA gene sequence, 76 isolated mycobacteria (of intra- and extracellular origin) could be identified to the species level, with their sequence .99% identical to reference strains of which the sequence is present in GenBank. For 27 isolates, 16S rRNA-DNA sequence based identification was not possible due to the presence of a mixture of different species in the culture. An overview of the identified mycobacterial isolates is shown in Table 3 and Table S1. Species diversity did not show a marked difference between any type of isolation source (Table 3, S1). Mycobacterial 16S-rRNA-DNA was detected in 29 amoeba cultures (17.5%), isolated from 25 out of 124 samples (20.2%). Mycobacterial presence was confirmed by microscopy in 13 of these positive cultures; 1 to 100 AFB were detected per 100 fields, which approximates to orders of 103 to 105 bacilli per culture of amoebae. No AFB were observed co-localising with the amoebae, however. "
2442696,0.0,"Clinical and demographic data Of the 180 enrolled patients, 173 subjects were eligible for statistical analysis (89 RR-MS and 84 PP-MS) of which 4 RR patients were excluded because of carotid atherosclerosis (1 man) and unavailable transtemporal bone windows (1 man and 2 women), while 1 PP woman abandoned the study because of a previously undiagnosed thyroid enlargement. 82 age and sex matched HCs were selected from general population according to exclusion criteria. Demographic and clinical characteristics of the enrolled groups are showed in table 1. No age and sex differences were found in any of the control or disease groups. Mean basal arterial pressure and beat-rate (in clinostatism) were similar in both groups. 64 of the 85 RR-MS and 18 of the 83 PP-MS patients were on disease-modifying therapy. "
2442696,1.0," Arterial and Venous blood volume flow A significant asymmetry of the venous CSA (>50%) in supine position were observed in 19 (22.3%) RR-MS, 17 (20.2%) PP-MS patients and 16 (19.5%) HCs with prevalent reduction of left IJV diameter. A negative ΔCSA value was observed in 3 (3.5%) RR-MS, 1 PP-MS (1.2%) and 3 (3.6%) controls. Mean global CBF and CVF values in clinostatism are showed in table 2. The slight reduction of both global CBF and mean total CVF resulted no statistically significant. ΔCVF was negative in 108/173 MS patients (62.4%) and 11/82 (13.4%) HCs (p<0.001). According to clinical phenotype, ΔCVF was negative in 45/85 (52.9%) RR-MS and 63/83 (75.9%) PP-MS (p = 0.01) (figure 1). Age and sex-related differences of CBF, CFV and ΔCVF were not statistically significant. There were no significant correlation among negative ΔCVF and significant asymmetry of venous CSA or negative ΔCSA value. A significantly higher prevalence of negative ΔCVF was observed in EDSS>5 subgroup (42/50, 84%) than in EDSS<5 subgroup (66/118, 55.9%) (p<0.01). "
2442696,2.0," Intracranial haemodynamic parameters Mean values of PSVs, EDVs and MFVs on TCD examination were similar in all examined arteries between groups (table 3). Postural variations of MFVs in both MCAs were reported in table 4. In sitting position, mean values of MFVs on both MCAs were significantly reduced in RR-MS and PP-MS patients than in control either after 90 s or after 2 min. No significant differences were observed according to age, sex and disease duration. Mean MFV values after 90 s of sitting position were prevalently reduced in patients with EDSS ≥5 than in patients with EDSS<5 (48.3±2 cm/s vs. 54.6±3 cm/s, p = 0.01). BHI values were similar among three groups (RR-MS: 0.88±0.2; PP-MS = 0.86±0.4; HC: 0.88±0.3; p = 0.892). Postural variation of MAP and CPP was reported in table 5. No significant differences in MAP and non-invasive CPP were observed within and between group. Single cerebral veins were inconstantly detected by means of TCDS among subjects without differences between patients and controls and the relative percentages are reported in table 6. Significant reflux was not found in patients or controls and velocity values were within a normal range in all study groups. "
1150,0.0,"Distribution of suitable habitat, and its relationship to Buruli ulcer In Akonolinga there was a significantly positive correl- ation between Buruli ulcer prevalence and average habi- tat suitability, for both Naucoridae and Belostomatidae, in the wet season (Table 2, Figure 4). This relationship was significant at multiple buffer distances. In contrast, in Bankim there was no significant correlation between Buruli ulcer prevalence and Belostomatidae or Naucoridae average habitat suitability, in either wet or dry seasons or at any buffer distance (Table 3). "
1150,1.0," Ecologically important variables in the distribution of the aquatic insect families Variable importance was evaluated using Jackknife vari- able removal. Jacknife removes a variable and evaluates the effect of variable removal on the model. In the dry season Belostomatidae and Naucoridae responded in broadly similar fashions; the variable whose removal had the largest effect was GLC 5 km (Figure 5). The land cover categories most suitable for both Belostomatidae and Naucoridae are water bodies, artificial areas, rain fed croplands and forest/grassland mosaics (Figure 6). If one of these categories is the dominant category in 5 km ra- dius, in the dry season, the likelihood of encountering the insect is higher. Unsuitable categories were forest and vegetation/cropland mosaic. In the wet season precipitation is more important than land cover. Precipitation suitability peaks at approxi- mately 300 millimeters per month, and diminishes above or below this (Figure 6). For the dry season there is a simple increase in habitat suitability with increasing precipitation. Flow accumulation had a negative association with habitat suitability, and wetness index had a positive asso- ciation, regardless of season, for both Belostomatidae and Naucoridae. "
1150,2.0," Model performance AICc for Naucoridae adults (dry season) was 14.6, and 14.2 in the wet season, as in Table 2. For Belostomatidae adults (dry season) the AICc was 12.5, and 12.2 in the wet season. Scores of overfitting are relative; these scores indicate the Belostomatidae model was less prone to overfitting than the Naucoridae model. The AG data set was also used in model validation. In the dry season Naucoridae adults had an AG AUC of 0.83, and 0.80 in the wet season. Belostomatidae adults had an AG AUC of 0.80 in the dry season, and 0.86 in the wet season. These scores indicate that the models are able to describe the distribution of the insects with good accuracy; the model based on SME dataset is able to accurately replicate the independently collected AG dataset. "
1287608,0.0,"Protocol Table 3 provides an overview of data collection and analysis from MRI scans. PC-VIPR scans were successfully performed and analyzed for 163/172 (94.8%) of all subjects in the head, 155/172 (90.1%) in the neck, and 146/172 (88.9%) in the AV. The main reason for acquisition or analysis failure was due to data archiving problems (head—n = 5; neck—n = 7; AV—n = 9). CE-MRV of the neck was successfully scanned and scored in 97.3% of cases, while that of the chest was slightly lower at 96.1%. CCSVI US scans were successfully performed in all subjects the same day the MRI exam was performed. "
1287608,1.0," MRI flow analysis Figure 2 displays group-wise bar plot results of total flow and %RF across all vessels measured using PC-VIPR. No major differences are observed for any flow parameter or in any vessel between groups. No statistically significant differences were observed for any flow parameter (total flow, peak flow, or %RF) across all vessels and between all combinations of groups. Likewise, no statistically significant differences were observed between age- and sex-matched pairs. "
1287608,2.0," CE-MRV analysis Good IJV image quality scores were observed (all subjects averaged: reader 1 = 3.3 ± 0.7, reader 2 = 2.8 ± 0.5), with moderate inter-rater reliability in morphology scores (κ = 0.56). For dichotomized IJV scoring, inter-rater reliability was greater (κ = 0.60). For the AV in the chest, image quality scores were good (all subjects averaged: reader 1 = 3.2 ± 0.9, reader 2 = 2.7 ± 0.5), yet inter-rater reliability in morphology scores was poor (κ = 0.16). Despite variable inter-rater reliability scores, no statistically significant differences between any group combinations were observed for CE-MRV morphology measurements, for either reader. "
1287608,3.0," MRI flow and US assessment Subjects with %RF > 5% in any part of the MRI regional flow assessment (head, IJVs, AV) were considered to exhibit “CCVSI-like” criteria. The percentage of total subjects showing this feature was compared to the percentage of subjects with ≥ 2 US CCSVI criteria and is shown in Table 4. The number of subjects that exhibited %RF in one or more regions and tested positively for CCSVI criteria from the US exam was nine (14.1%) in MS patients, five (11.4%) in HC subjects, and one (3.2%) in subjects with other neurological disease. "
1287608,4.0," Trimodality IJV narrowing assessment Figure 3 demonstrates percent of total subjects exhibiting IJV narrowing across groups and readers (as well as flow and US results). Higher occurrence of narrowing is evident in the left IJV, and greater variability is seen for both PC-VIPR and US compared with CE-MRV. "
1128341,0.0,"Genome sequence comparisons of 179 M. ulcerans isolates from Central Africa. To understand the dynamics and timing of the spread of M. ulcerans across Central Africa, we sequenced the genomes of 179 clinical isolates that were obtained between 1962 and 2014 and spanned most of the known areas of BU endemicity in the Democratic Republic of the Congo, The Republic of the Congo, and Angola (see Table S1 in the supplemental material). To prevent mapping the obtained sequence reads to a reference that diverged signiﬁcantly from these isolates, we assembled a new, complete closed DRC M. ulcerans reference chromosome using PacBio reads. This reference chromosome received the strain name SGL03 (for Songololo territory 2003). SGL03 comprises a single 5,625,184-bp (6,422 bp smaller than the Ghanaian reference chromosome Agy99) circular bacterial chromosome with a G⫹C content of 65.5%. Whole-genome comparisons between SGL03 and Agy99 revealed exten- sive synteny and collinearity. However, a total of 12 large (⬎100 bp) indels were identiﬁed between SGL03 and Agy99 (see Table S2). Most indel events were mediated by copies of insertion (IS) elements IS2404 and IS2606; these either ﬂanked deletions or they were present in the deleted or substituted sequence stretches. Well represented in the deleted sequences were pseudogenes that either contained frameshift mutations or were disrupted by IS elements. Illumina sequence reads of the sample panel were aligned to the newly assembled SGL03 chromosome and, after removing any diversity detected in repetitive IS elements and ignoring small indel polymorphisms, we found 6,655 single nucleotide polymor- phisms (SNPs) uniformly distributed along the bacterial chromosome, which amounts to 1 SNP per 846 bp (see Fig. S2). A total of 161 clones (unique genomes) were discerned among the isolate panel. A Bayesian time-measured phylogeny was inferred from a whole-genome alignment of the isolates (Fig. 1). Both known lineages of African M. ulcerans were identiﬁed within the Central African isolate panel: 178/179 (99.4%) corresponded to lineage Mu_A1 and 1/179 (0.6%) corresponded to the uncommon lineage Mu_A2. The average pairwise SNP difference (SNPΔ) between Mu_A1 Central African isolates was low (59 SNPs, standard deviation [SD] ⫽ 42), as the majority of the discovered diversity derived from the relatively large genetic distance (5,270 SNPs, SD ⫽ 7) between Mu_A1 and the single Mu_A2 isolate from the region. The Mu_A2 isolate (ITM130340) originated from a patient (female [F], 40 years old) from the hamlet Kilima in the Songololo territory (Nkamuna health area) (see Fig. S4). We were unable to retrospectively interview the patient to identify any travel history or activity that could explain the unexpected Mu_A2 distribution. "
1128341,1.0," Phylogenetic analysis reveals strong geographical restrictions on M. ulcerans dispersal at high-level geographical scales. Within an M. ulcerans phylogeny of the entire African continent (see Fig. S3), the single Songololo Mu_A2 isolate clustered together with a clade of 8 other Mu_A2 isolates originating from Benin, Gabon, and Cameroon. Furthermore, a distinct Mu_A1 isolate from The Republic of the Congo (ITM_071925) clustered together with a small clade of Nigerian and Cameroonian M. ulcerans isolates. More importantly, however, all other 177 Mu_A1 isolates of the Central African panel formed a monophyletic group within that continental African phylogeny. There was distinct spatial clustering of M. ulcerans from the different endemic BU foci within the phylogeny. For instance, all 123 isolates of the endemic BU focus of the Songololo territory formed a strongly supported monophyletic group (Fig. 2). The Songololo territory isolates had an average pairwise SNPΔ of 46 (SD ⫽ 18) and were unrelated to the four isolates from the neighboring Tshela territory (north- west in the Kongo Central province) that formed a separate monophyletic group (Fig. 2). We cannot identify a speciﬁc historic geographical route that these bacterial lineages followed, but the phylogenetic evidence clearly links these separate clonal expansions as a single epidemic. "
1128341,2.0," The clustering of M. ulcerans genotypes ends at ﬁne geographical scales. We then explored the geographical distribution of M. ulcerans genotypes at a ﬁner geographical scale: that of the Songololo territory. The 123 Songololo isolates originating from 123 individual patients were spread evenly over the territory, and the majority of health areas with a “modest” to “high” BU burden were well represented (Fig. S4). Bayesian model-based inference of the genetic population structure revealed the existence of six groups (designated BAPS groups 1 to 6) within the territory (Fig. 3). The six groups generally cooccurred, as in some regions of the territory, multiple groups were found to be circulating simultaneously. In the health area of Lovo for instance, up to ﬁve different groups were cocirculating (BAPS 1 to 5). The groups were, however, distrib- uted differently over the study region: groups 2, 4, and 5 were found widely dispersed, while groups 1, 3, and 6 were more restricted (Fig. 3). Group 1 (n ⫽ 20) was found almost exclusively in the eastern Kimpese health area, while group 3 (n ⫽ 31) was localized in the western Nsona-Pangu health area (see Fig. S5). Group 6 was uncommon (n ⫽ 4) and found solely in the southwest. Within groups, there were some distinct subgroups, which very occasionally also had a limited distribution across the region. For example, one speciﬁc subgroup of BAPS group 2 consisted of seven isolates that all originated from a 90-km2 zone covering the neighboring health areas of Mukimbungu and Kasi (Fig. S5). However, other subgroups were far more broadly distributed, with the extreme example of identical genomes identiﬁed in different BU patients separated by larger distances (Fig. 3, I to X). A total of ten such genomes that were identiﬁed multiple times in the Songololo territory were discerned (Table 1). The average geo- graphical distance between the domiciles of patients identiﬁed with isolates with identical genomes was 17.3 ⫾ 18.1 km. "
1128341,3.0," The Central African mutation rate of M. ulcerans is similar to that inferred on a continental scale. We derived a timed phylogeny of Central African M. ulcerans while simultaneously inferring mutation rates and dates of divergence of key M. ulcerans clades (Fig. 1). In this process, a molecular clock was estimated using correlations between phylogenetic divergence and isolation times of heterochronous disease iso- lates. As a result, a mean genome wide substitution rate of 4.38E⫺8 per site per year (95% highest posterior density [HPD] interval, 2.83E⫺8 to 6.03E⫺8]) was demonstrated, which corresponds to an accumulation rate of 0.23 SNPs per bacterial chromosome per year (95% HPD interval, 0.15 to 0.32). The Bayesian phylogenetic analysis indicates that lineage Mu_A1 had been intro- duced in Central Africa multiple hundreds of years ago (tMCRA [Mu_A1], 1372; 95% HPD, 913 to 1776), while the timing of the BU introduction event in the Songololo territory was estimated at around 1865 (95% HPD, 1803 to 1915) (Fig. 1). Finally, the time tree also indicates that the separated “eastern” (tMCRA [BAPS-1], 1941; 95% HPD, 1908 to 1969) and “western” (tMCRA [BAPS-3], 1922; 95% HPD, 1885 to 1954) Songololo groups have most likely remained segregated over a timespan of half a century. "
1128341,4.0," Demographic history of M. ulcerans in the Songololo territory. The reconstruc- tion of the demographic history of M. ulcerans in the Songololo territory involved the coestimation of its time tree, the mycobacterial population size at different points along the timescale of that phylogeny, and all other parameters of the employed model of molecular evolution. Consequently, the resulting plot of the population history includes credibility intervals that represent the combined phylogenetic and coalescent uncer- tainties. An inspection of the extended Bayesian skyline plot (EBSP) (Fig. 4) indicated that the M. ulcerans population size remained stable until the early 1980s, after which it increased slightly during the course of the 1990s, until it reached a peak around 2004. This was followed by a small decline that persisted until 2014. We identiﬁed temporal parallels between the observed past population dynamics of M. ulcerans from the Songololo territory and the timing of health policy changes managing the BU epidemic in that region (Fig. 4), though we need to recognize overlap in credibility intervals surrounding the estimates during these periods. We checked for factors that might bias the reconstruction of the mycobacterial population size over time by conducting extensive resampling and randomization experiments (see Fig. S6). "
432129,0.0,"Distribution of M. ulcerans in aquatic ecosystems. MU was broadly distributed within both regions, and was found at least once in more than 80% of sites sampled during the year, with different distribution patterns for each region (Figure 1). In Akonolinga, MU was detected in all sites at least once during the year regardless of the geographical location or the type of ecosystem sampled. MU distribution in Bankim was more restricted, with 4 out of 16 sites found negative all year long, notably from streams in the northern part of the region. Overall, the proportion of positive sample-pools (hereafter defined as ‘‘pool positivity’’ or ‘‘pool prevalence’’) ranged from 0 to 25% in the different sites, with the highest rates distributed along the road in the southern part of Bankim between the Mape´ Dam and the Mbam River, and close to the basin of the Nyong river in Akonolinga (in swamps and streams nearby). Aquatic ecosystems with stagnant waters appeared to be associated with higher MU presence (Figure 2). We found MU in aquatic organisms from all four types of aquatic ecosystems sampled, with an average of 7.7% of positive sample-pools across ecosystems. Overall, positivity rate was 4.9% in rivers, 4.6% in flooded areas, 10.0% in swamps and 6.2% in streams. We found that swamps had significantly higher positivity than all other ecosystems in Bankim, with positivity in swamps 3 and 5 times higher than in streams and flooded areas respectively (x2 test, p-value ,0.0001 for both). However, no significant differences in MU presence were found for any given environment in Akonolinga, although positivity in flooded areas and swamps was slightly higher. "
432129,1.0," Distribution of M. ulcerans in the aquatic community. A total number of 238,496 individuals were collected and classified over the course of the study, 200,918 in Akonolinga and 37,578 in Bankim. According to the pooling strategy described above, 145,255 of those (61%) were distributed in 3,084 sample-pools and analyzed by qPCR. 65 distinctive taxa were identified (Table S1). 85% of the whole aquatic community overall was made up of only 5 taxonomic orders: Coleoptera, Diptera, Ephemeroptera, Odonata and Hemiptera (Table 1). Among these, the most abundant families were Baetidae (18%), Noteridae (12%), Chiron- omidae (11%) and Hydrophilidae (7%). Aquatic vertebrates (fishes, tadpoles) and semi-aquatic or terrestrial orders (Araneae, Lepidop- tera larvae, Collembola) represented 4% and 2%, respectively. Among aquatic ecosystems, water bodies with standing and slow flowing waters had less biodiversity in terms of number of orders, and were dominated by the 5 most abundant orders mentioned above (Table S2). Conversely, streams had higher biodiversity, with a larger proportion of other groups such as Decapoda and Trichoptera. MU was present in nearly all taxonomic groups of the aquatic community and it was approximately evenly distributed among the whole aquatic community (Table 2). Pool prevalence for most of the groups was between 5–15%. Larvae of the order Lepidoptera had the highest pool prevalence overall (13.6%), followed by Annelida (12.3%) and Hemiptera (11.4%). However, regional differences in MU distribution should be noted: most of positive Lepidoptera and Annelida came from Bankim, where positivity was nearly 3 times higher for both groups than in Akonolinga (20.8 and 17.7% in Bankim compared to 5.0 and 6.7% in Akonolinga, respectively), although these differences were not significant. The lowest pool prevalence among positive groups was found in Acari (2.8%), Mollusca (3.3%) and Araneae (5.6%). Finally, we failed to detect MU only in two taxonomic groups: Trichoptera (89 pools tested, 1,434 individuals) and Collembola (28 pools tested, 79 individuals). "
432129,2.0," Monthly fluctuations of M. ulcerans presence in aquatic ecosystems. MU was present in aquatic ecosystems nearly all year long. In Akonolinga, where samples were collected every month, MU was only absent in May, and in Bankim we detected MU in all four time steps sampled (every three months). In this section, only the dynamics for the 12 months in Akonolinga are shown (Figures S1 and S2 show the dynamics in Bankim). MU presence fluctuated through time (Figure 3), with changes from 0 to 15% in total pool positivity. The largest peak in pool positivity was found in August and October, and we found a progressive drop in pool positivity from October to February. Each ecosystem had distinct temporal variations and a favorable time of the year for MU presence (Figure 3). In rivers and flooded areas, MU was absent for a long period of time (4 and 8 months respectively) and then experienced a sudden increase in pool positivity (in April and July respectively). As a result, more than half of positive sample-pools in these ecosystems were found in a specific season, the low rainy season for rivers and the low dry season for flooded areas (Figure 4). In swamps and streams, the seasonal effect was less pronounced with presence of MU most of the year and fluctuations in pool positivity that ranged from 0 to 15% for swamps and to 30% in streams. Over one third of positive sample-pools in swamps and streams were found during the low rainy season and around one third were found in another season (high dry season for swamps and low dry season for streams). Of all ecosystems, only MU positivity dynamics for rivers were correlated to rainfall dynamics (Figure S5). "
432129,3.0," Temporal dynamics of M. ulcerans presence in the aquatic community. MU colonization dynamics for the different taxonomic groups were highly variable (Figure 5). Hemipterans were the only group positive during 11 months of the year, whereas the order Coleoptera was repeatedly negative for more than half a year (from November to May). The highest peaks in pool positivity at any given month were for Hemiptera in June (.30%) and for Diptera in August (25%). Pool positivity in other orders was lower than 20% all year long. Out of the 5 orders systematically tested for all sites and months for MU presence, none of their colonization dynamics were correlated to rainfall (Figure S6). "
432234,0.0,"Comparison of a mycolactone-based enoyl reductase (ER) PCR target to an IS2404 PCR target for detection of M. ulcerans IS2404 PCR has been widely used for detection of M. ulcerans in the environment and patients because of the high copy number of the IS element (213) within the M. ulcerans genome [28] However, evidence from the M. ulcerans genome as well as results from length polymorphisms of IS2404 suggests restriction fragment considerable heterogeneity between copies, as well as the presence of incomplete copies which could lead to production of multiple products [29]. For this reason we developed a PCR method based on amplification of the ER domain of mlsA which encodes a polyketide synthase that produces the mycolactone core, and compared the sensitivity of ER PCR and IS2404 PCR using environmental samples, as well as M. ulcerans cultures. M. ulcerans in Aquatic Environments in Ghana In this study 319 invertebrate and vertebrate samples were analyzed using IS2404 PCR and the PCR products were sequenced. A PCR product of appropriate size was obtained from eight invertebrate samples. However, DNA sequencing showed that only four of the samples contained IS2404 DNA. Although adjustment of PCR parameters improved specificity somewhat, many non-specific products were still amplified. ER PCR of the initial eight IS2404 positive samples yielded four ER positive samples. DNA sequence results confirmed that all four ER positive samples contained ER sequence. Further analysis of DNA from 71 ER positive samples showed that ER DNA was the product in every case. ER is present four times on the mycolactone plasmid. Although there is no evidence concerning plasmid copy number, most large plasmids are present in only 1 or 2 copies per cell making the copy number for the ER target 4–8 [3]. Because we initially assumed there was a clear correlation between copy number and PCR sensitivity, we were concerned that the lower copy number of the ER domain, with respect to IS2404, might influence the sensitivity of the method. Thus the relative sensitivity of ER and IS2404 PCR was evaluated using 10-fold dilutions of M. ulcerans culture. As few as 1021 CFU of M. ulcerans could be detected using either method (Figure 2). These results suggested that ER PCR was adequately sensitive for detection of M. ulcerans in environmental samples where few copies of M. ulcerans might be present. "
432234,1.0, ER and VNTR primer sets are sensitive at low concentrations of M. ulcerans DNA Sensitivity of the primer sets targeting VNTR loci and ER for environmental samples was also determined by spiking samples of belostomatids with serial dilutions of M. ulcerans DNA and performing ER and VNTR PCR. Results from this study show that ER and VNTR DNA could be detected at predicted concentrations as low as 0.1 CFU (Figure S2). 
432234,2.0," ER PCR based evidence of M. ulcerans in environmental samples from endemic and non-endemic villages in Ghana During 2004–2006 1,068 invertebrate and vertebrate samples were collected from 14 endemic and 12 non-endemic sites with a focus on the Ashanti and Greater Accra regions of Ghana (Figure 3). Samples included material collected within 1 m2 quadrats (N = 3) as well as those obtained by sweep sampling through vegetation. Identical sampling methods were used for all sites. Endemic sites yielded more samples than non-endemic sties. Of the 1,068 samples obtained, 572 (54%) were obtained from endemic sites whereas 496 (46%) were from non-endemic sampling sites. M. ulcerans DNA was detected in only 7% (78/ 1,068) of the total samples (Table 4) using ER PCR. From the 78 ER positive samples, 42 (54%) were from aquatic environments endemic for Buruli ulcer; whereas 36 (46%) samples were from non-endemic sites. The largest number of ER positive invertebrate samples was collected from Afuaman where 18 invertebrate pooled or individual samples were found to be positive. Six sites yielded only one ER positive pooled or individual sample. These included three endemic sites (Tontokrom, Bowkrom, and Amasa- man) and three non-endemic sites (Bretsekrom, Dodowa, and Keedmos). Eight sites yielded zero ER positive invertebrate or vertebrate samples (five endemic and three non-endemic). The remaining eleven sites (six non-endemic and five endemic) had a range of 2 to 10 PCR positive pooled or individual invertebrate samples. All ER PCR positive results were confirmed by DNA sequencing. ER positive DNA was detected in a broad spectrum of the 89 taxa vertebrates and invertebrates representing 30 of identified. Many taxa, such as Crambidae (moth) larvae and Araneae were found repeatedly positive at specific sites during the 2 year sampling period. Two pools of Crambidae larvae were found positive from Subin; one collected 2005 and the other collected 2006. Araneae have been found positive from sampling of Amasaman 2004, 2005, and 2006. Although some taxa, such as Belostomatidae and Naucoridae have been found IS2404 positive by others [12,13,14] most ER PCR positive taxa reported in this study have not previously been identified as potential sources of M. ulcerans. M. ulcerans positive taxa represented a wide variety of functional invertebrate feeding groups and life stages (Table 2) [30]. Although most of the positive taxa represented predators, positive results were obtained from collector-gatherers such as those from the family Elmidae (beetle) and scrapers such as those from the family Baetidae (mayfly). A complete description of the demography and identification of positive taxa per site are presented in a separate paper (in preparation). Previous reporting of M. ulcerans in Belostomatidae and Naucoridae led us to selectively collect additional samples from these taxa. Seventy-one additional belostomatids and twenty additional naucorids were obtained through selective collection. Of those, 3/71 (4%) belostomatids and 7/20 (35%) naucorids were found to contain ER positive DNA. Although these results suggest that M. ulcerans DNA is widely distributed in invertebrates, the majority of taxa identified (59/89) were repeatedly negative for M. ulcerans DNA (Table S1). In some cases where a taxon was represented by a single sample, such as with Calonoida (copepod), little can be said about the absence of M. ulcerans. In other cases such as with Coenagrinidae (damselfly M. ulcerans in Aquatic Environments in Ghana larvae) and Pleidae (backswimmer), over 100 individuals were sampled. The absence of ER PCR positive results from these taxa is more meaningful. Out of 260 samples of water filtrate tested (130 from non-endemic and 130 from endemic sampling sites), 97 (36%) were ER PCR positive. Sixty of the 97 ER positive filtrate samples (61%) were from areas non-endemic for Buruli ulcer, while 37 (38%) of the ER positive filtrate samples were from endemic areas. PCR was also conducted on 100 soil samples; 50 of which were from endemic sites and 50 from non-endemic sites. M. ulcerans DNA was detected in 3% (3/100) of the soil samples (Table 4). Each of these three samples was collected from the floor of the water body. Two of the three ER PCR positive soil samples were from an area endemic for Buruli ulcer (Nyame-Bekyere and Subin) while the third was from an area non- endemic for Buruli Ulcer (Abbeypanya). "
432234,3.0," VNTR analysis reveals heterogeneity with M. ulcerans and distinguishes M. ulcerans from other MPM Although ER PCR is a reasonable preliminary test for the identification of M. ulcerans, the discovery of other mycolactone producing mycobacteria (MPM) in fish and frogs revealed that mycolactone genes are not M. ulcerans specific [26,31]. In order to distinguish between M. ulcerans and other MPM, a VNTR-based method was developed based on published VNTR sequence [23,24,25]. For this analysis, a panel of 6 Ghanaian M. ulcerans isolates obtained from patients in the same regions where the environmental samples were collected was compared to a panel of MPM species. Primers targeting VNTR loci 4, 8, 14, 15, 18, and MIRU 9 did not distinguish between Ghanaian isolates of M. ulcerans and other MPM, although several of these loci had been previously used to discriminate between Beninese M. ulcerans and other MPM [24,25]. Although some studies have found only 1 biovar of M. ulcerans in West Africa suggesting very little heterogeneity among M. ulcerans isolates within Africa [24,25] one paper, which investigated a large group of M. ulcerans isolates from Ghana identified three different biovars [23]. In this paper, VNTR analysis of 6 M. ulcerans isolates from the Greater Accra, Central and Ashanti regions revealed three M. ulcerans VNTR profiles, A, B, and C based on MIRU 1, locus 6 and STI (Table 5). Profile A strains contained one copy of MIRU 1, one copy of locus 6, and one copy of ST1 (1,1,1). Profile B strains had three copies of MIRU 1, one copy of locus 6, and one copy of ST1 (3,1,1) and profile C consisted of a single isolate with three copies of MIRU 1, one copy of locus 6, and two copies of ST1 (3,1,2). Two of these VNTR profiles, B and C, were previously identified by Hilty et al [23] whereas profile A, characterized by a single copy of MIRU 1 and one copy of ST1 represented a new profile. These VNTR loci also distinguished M. ulcerans from other MPM (Table 5). Finally, the addition of locus 19 made it possible to distinguished M. liflandii, a newly discovered frog pathogen, from mycolactone producing fish pathogens M. marinum and M. pseudoshottsii (Table 5). Two separate VNTR profiles were identified among mycolac- tone producing M. marinum isolates and these were associated with different habitats (Table 5). Whereas fish from salt water had profile D, those from freshwater had profile E (Table 5). Profile D included one copy of MIRU1, four copies of locus 6, two copies of ST1, and two copies of locus 19 (1,4,2,2), and profile E had one copy of MIRU1, two copies of locus 6, one copy of ST1, and two copies of locus 19 (1,2,1,2). Despite the great geographical distance between the Red and Mediterranean Seas and the Chesapeake Bay, MPM M. marinum isolated from sea bass (Siganus nivulatus) and M. pseudoshottsii isolated from striped bass (Morone saxatilis) shared identical 1,4,2,2 VNTR profiles. VNTR analysis revealed a single VNTR profile for M. liflandii (1,2,2,1). These results showed that VNTR could be used to differentiate MPM found in environ- mental samples in Ghana. "
432234,4.0," M. ulcerans and other MPM are present in both Buruli ulcer endemic and non-endemic sites To discriminate between M. ulcerans and other MPM, 78 ER- PCR positive samples collected from standardized sampling and 10 ER positive belostomatids and naucorids (3 belostomatids and 7 naucorids) that were selectively collected were tested for the presence and copy number of MIRU1, locus 6, STL and if applicable, locus 19. Of these samples, VNTR profiles were obtained from 67 invertebrate/vertebrate samples (Table 6). The remaining 31 samples could not be VNTR typed presumably due to insufficient material. VNTR profiling showed that only 12 of these 67 samples (18%) had a VNTR profile which matched M. ulcerans (Table 6). Seven of these were collected from aquatic environments endemic for Buruli ulcer, and five of these were from non-endemic water bodies. M. ulcerans Profile A was identified in 9 different invertebrate species, whereas M. ulcerans profile C, found in the genome sequence strain Agy99 was detected in specimens of a Nepidae (Order Hemiptera), a Belostomatidae and an unidentified spider. VNTR MPM profile D was found in three samples, including a tadpole (Anura) and two predacious aquatic insects (Coleoptera: Families Hydrophilidae and Dytisci- dae, Table 4). M. ulcerans VNTR profile A and MPM profile D was obtained from different samples of Dytiscidae, Anura and Hydrophilidae. Both Anura and Hydrophilidae samples were collected from the same endemic site. The Dytiscidae samples were collected from two different endemic sites. M. ulcerans profiles A and C were identified in two separate Belostomatidae samples collected from separate sites, one endemic and one non-endemic. These results suggest that M. ulcerans and other MPM occupy the same water body. VNTR analysis of 82 ER PCR positive water filtrates yielded 8 M. ulcerans positive samples. One of these was profile B whereas the other 7 typed as profile A. Four of these samples were from non-endemic areas, while the remaining four samples were from endemic areas. Four of the 82 ER PCR positive water filtrates yielded MPM profile E. Two of these were from endemic regions whereas two were from non-endemic sites. The identity of all VNTR products was confirmed by sequence analysis. Represen- tative gels illustrating VNTR profiles from various sample types are given in Figure S1. These data suggest that human endemicity data do not reliably predict the presence of M. ulcerans in Ghana. "
432234,5.0," Physical evidence consistent with the presence of mycobacteria can be obtained by collection of biofilm communities on glass slides Ninety-six glass slides were submerged in water bodies associated with human use in the communities of Amasaman (endemic) and Adigon, (non-endemic). From these, 47 slides were collected at 21, 42 and 98 days. At 21 days, biofilm formation on slides collected from Adigon was sparse, but became progressively denser over the course of the experiment. In contrast, at Amasaman, the endemic site, biofilms were very dense by 21 days, but became less dense over the course of the study (Figure 4). Acid-fast bacilli were found on 45 of 47 slides (Figure 4). Microscopic analysis of the biofilm community showed the presence of diatoms and fungus as well as a mixed population of bacteria and considerable detritus. Acid-fast bacilli occurred in clusters or small groups, but were not associated with other flora present on the slide consistent with the ability of mycobacteria to adhere to glass [32]. "
432234,6.0," Adigon (non-endemic) Of the 47 biofilm slides analyzed, 37 were ER PCR positive (Table 4). VNTR profiles of 17 (46%) of these matched M. ulcerans, while 8 matched VNTR profiles of other MPM. VNTR analysis of slides collected from Adigon at 21 days was not conducted because all samples were ER negative (Figure 5). Three of five ER positive slides (60%) collected at 42 days from Adigon had M. ulcerans VNTR profile A, whereas one of the slides had a VNTR profile matching other MPM (profile D). M. ulcerans VNTR profiles were found at Adigon at 98 days although VNTR patterns not matching MPM were found on two slides. One of these corresponded to M. liflandii (profile F) while the other matched that of MPM associated with fish (profile E). "
432234,7.0," Amasaman (endemic) Nine of the twelve (75%) ER positive slides taken from Amasaman at 21 days had a M. ulcerans VNTR profile matching profile A, whereas a VNTR profile matching that of M. liflandii (profile F) was found on two slides. Five of six (83%) ER positive slides taken at 42 days from Amasaman had M. ulcerans profiles. M. ulcerans was not detected on the slides taken from Amasaman at 98 days although three slides (60%) produced VNTR signatures matching fish-associated MPMs (D and E). These results show the evolution of biofilm communities through time. The absence of M. ulcerans at 98 days is particularly interesting and could be explained by spontaneous detachment of the biofilm, or by grazing by tadpoles or invertebrates. "
432234,8.0," M. ulcerans DNA is not detected in ER negative environmental samples The analysis of VNTR data from environmental samples is complicated by many factors not present when analysis is performed on a pure bacterial colony. DNA extracted from insects, frogs, fish or filters contains DNA from a complex population of organisms. If VNTR profiling is a valid tool for detection of M. ulcerans in environmental samples, ER negative samples should also be negative for M. ulcerans by VNTR PCR. If however, specific VNTR sequences are present in a number of different organisms, or in bacteria which do not produce mycolactone, VNTR analysis of ER negative sites could yield a M. ulcerans or MPM profile. For example, if 1 repeat of MIRU1, locus 6 and ST1 were present in each of three different bacteria within a single environmental sample, this sample would produce a VNTR profile consistent with M. ulcerans. If this were the case, VNTR analysis of environmental samples would have little value in the identification of M. ulcerans. To address this possibility, VNTR analysis was performed on two sets of ER negative samples. The first set consisted of ER negative DNA from 35 samples representing a broad spectrum of samples collected at many different sites. The second set of samples was a complete sample set of 34 samples from a single ER negative site. Invertebrate, vertebrate, water filtrate, and soil samples were represented in each set. Though some of these samples produced bands for an individual locus, none of these samples produced a M. ulcerans VNTR profile. "
432234,9.0," Mycobacterium ulcerans and MPM are widely distributed within endemic and non-endemic sites in the Ashanti and Greater Accra regions Twenty-six sites were sampled from 2004–2006 (Table 7). Fourteen were endemic and twelve were non-endemic. These sites represented water bodies from south-central regions in Ghana with a focus on the Greater Accra and the Ashanti regions. All samples from seven sites were ER negative suggesting the absence of any MPM including M. ulcerans. Six sites had samples with DNA insufficient for VNTR analysis. VNTR profiling was performed on the remaining thirteen sites, seven endemic and six non-endemic sites. M. ulcerans profile A was found in 6 of the endemic sites. Three endemic sites had only one VNTR profile: Ampa Abena and Nyame-Bekyere had M. ulcerans profile A, and Subin had MPM profile E. Two or more VNTR profiles were found within the same water body at four of the endemic sites. Bonsaaso was found to contain M. ulcerans VNTR profiles A, B and C. Along with M. ulcerans profile A, Bowkrom and Afuaman also had MPM profiles E and D, respectively. Amasaman was found to contain two M. ulcerans VNTR profiles (A and B), one of the MPM M. marinum VNTR profiles (profile D), and the profile corresponding to M. liflandii (profile F). than endemic sites. Four of Samples from six non-endemic sites produced VNTR profiles. However, there was less diversity of VNTR profiles from the non- endemic sites these sites were represented by one M. ulcerans profile (either profile A or C), and one of the sites, Afienya, had only a MPM M. marinum VNTR profile (profile E). Adigon was the only non-endemic site which yielded multiple VNTR profiles. VNTR profiles of M. ulcerans (profile A), MPM M. marinum (profiles D and E), and M. liflandii (profile F) were all obtained from biofilm samples collected in Adigon. VNTR profiles representing M. ulcerans and other MPMs were obtained from sites from both the Greater Accra and the Ashanti regions (Figure 3). M. ulcerans and MPM VNTR profiles were found within the same site more frequently in the Greater Accra region than in the Ashanti region. M. ulcerans VNTR profiles A, B and C (1,1,1, 3,1,1 and 3,1,2 respectively) were found in both the Greater Accra and the Ashanti regions. MPM M. marinum profile D was found only in the Greater Accra region, whereas profile E was found in both regions. Profile F (M. liflandii) was found in two sites of the Greater Accra region. "
434379,0.0,"Identification of potential M. ulcerans antigens Forty-seven chromosomally-encoded CDS, potentially unique to M. ulcerans were identified by bioinformatic comparison of the M. ulcerans genome to 21 other mycobacterial genomes (see Materials and Methods for genomes used). We then excluded CDS ,50 codons in length and the insertion sequence elements IS2404 and IS2606 and also applied the following criteria to include only those CDS likely to generate an immune response: i) predicted membrane association; ii) predicted secretion signal; or iii) previously confirmed as expressed in a proteomic study [32], resulting in 34 chromosomal CDS of interest. We also identified 33 unique CDS on the pMUM001 plasmid and in addition we included in our analysis the sequences encoding the 12 unique functional domains of the mycolactone polyketide synthases (MlsA1, MlsA2 & MlsB) as representative of the entire genetic variability present in this locus [9]. Due to the close genetic relationship between M. ulcerans and M. marnium and the knowledge that M. marinum M, does not reflect the genetic diversity in the M. marinum complex [10], 30 genetically diverse M. marinum isolates were tested for the presence of the selected chromosomal CDS by PCR. The M. marinum strains do not contain pMUM plasmids, so these isolates were not tested for the presence of any of the plasmid CDS. Eleven of the CDS identified as M. ulcerans specific by bioinformatic comparisons were found to be present in at least one of the other M. marinum strains tested and were thus excluded from further analyses (Table 1). The pMUM plasmids are known to vary in both size and gene content between M. ulcerans strains [11,33], and so we tested a selection of 26 geographically distinct M. ulcerans isolates, by PCR, for the presence of each of the plasmid sequences (Table 1). Additionally, we examined these strains for the presence of each of the selected chromosomal sequences by PCR, and found that six of the plasmid CDS and four of the chromosomally encoded CDS were present in all of the M. ulcerans strains tested (Table 1). Because the focus of our study is to develop diagnostic reagents for use in African patients where the need for BU control is most urgent, we particularly focused on the distribution of sequences of interest in African isolates of M. ulcerans. The 23 M. ulcerans specific chromosomal CDS were found in all 10 of the African M. ulcerans strains the plasmid-borne mycolactone polyketide synthase (mls) sequences were found in all M. ulcerans strains tested, and also 32 of 33 non-mls plasmid sequences were present in all African strains. MUP038 was absent by PCR from a single African strain (M. ulcerans strain Kob), which confirms previous findings for this strain showing it has a plasmid DNA deletion [33] (Table 1). tested. As expected, The completed list of M. ulcerans unique CDS selected for further study included 13 chromosomal and 30 plasmid CDS (12 mls and 18 non-mls) and is shown in Table S3. In addition we included as positive controls two CDS encoding proteins Hsp65 and Hsp18 (MUL_2232) which have been reported to be antigenic but which are present in other mycobacteria species [34,35]. This resulted in a total of 45 proteins under investigation. "
434379,1.0," Cloning, expression and purification of M. ulcerans sequences in E. coli All 45 of these selected M. ulcerans sequences were amplified from strain Agy99 genomic DNA and 44 were cloned using the Gateway system into at least one of three different expression vectors, pDEST17 (N-terminal 6xHis tag), pET-DEST42 (C- terminal 6xHis tag) or pBAD-DEST49 (N-terminal thioredoxin tag, C-terminal 6xHis tag). We then successfully expressed 37 of 44 (84.1%) of the target sequences in E. coli as either N-terminal or C- terminal 6xHis tagged proteins or both at or near their predicted molecular weight (Table S3). Whilst 37 proteins could be expressed in quantities sufficient for western blotting, only 33 of these 37 were able to be produced in quantities sufficient for ELISA analysis. Seven proteins were unable to be expressed in E. coli as either N- or C-terminal 6xHis tagged fusions. Expression of two of these proteins (MUP016 and MUP017) from either pDEST17 or pET- DEST42 proved to be toxic to E. coli. Sequencing of the remaining five constructs showed in-frame fusions had been made and western blots on WCLs of E. coli bearing these constructs showed an absence of recombinant protein expression after induction (data not shown). Further attempts were made to salvage these seven proteins by cloning into pBAD-DEST49, a vector with arabinose inducible expression, an N-terminal thioredoxin tag and a C- terminal 6xHis tag, designed to improve protein expression and solubility, and by using E. coli strain C43, which has been optimized for the expression of toxic or membrane proteins [29,36]. However, these efforts were also unsuccessful and so these proteins were unable to be produced to levels sufficient for purification. "
434379,2.0," Diagnostic potential of M. ulcerans specific antigens To evaluate the potential for these proteins to be used to diagnose M. ulcerans infection or assess exposure to the bacterium, sera was collected from 39 IS2404 PCR confirmed BU patients (designated: patient) and 24 controls with no past or current diagnosis of BU (designated: endemic control). Both these groups came from the high BU prevalence Oue´me´ region in Benin. Sera were also obtained from 30 additional control subjects who lived in the BU non-endemic Ouidah region of Benin (designated: control). A pre-study decision was taken to analyze in these three groups rather than only patients versus non-endemic controls as previous studies had indicated the possibility of asymptomatic exposure to M. ulcerans in BU endemic areas [34]. Screening of 33 proteins by ELISA uncovered significantly higher IgG antibody responses in patients compared to non- endemic controls for the following seven proteins; MUP045, MUP057, MUL_0513, Hsp65, and the mycolactone Mls domains (p,0.05, Figure 1). (AT-propionate, ER, and KR-A domains) However, IgG responses of the endemic controls were not significantly different to those of patients for any of the seven proteins (Figure 1). Endemic controls had IgG responses that were significantly higher than those of non-endemic controls for the six of these seven proteins, suggesting that residents of endemic regions with no history of BU might have been exposed to M. ulcerans. The remaining 26 proteins, including the positive control antigen MUL_2232 (Hsp18), had no ability to elicit discriminatory antibody responses between any groups (Figure S1). When serum antibody responses for the proteins shown in Figure 1 were analysed according to disease state (i.e, plaque, plaque and oedema, ulcer, or plaque and ulcer), there was no significant difference in reactivity between disease state and endemic controls for each protein except for ER (Figure 2). Mean ELISA absorbance values for sera from patients with ulcers were significantly higher in their reactivity to the ER domain of the mycolactone PKS than endemic controls and other lesion types (p,0.05, Figure 2). "
434379,3.0," Seroepidemiological potential of M. ulcerans specific antigens We examined six of the seven proteins shown in Figure 1 to test if they could effectively distinguish subjects from BU endemic and BU non-endemic regions of Benin. We performed receiver- operator curve (ROC) analyses for each of these six antigens by combining the ELISA absorbance values for patient and endemic control groups (collectively referred to as BU-endemic) (Table 2) to calculate sensitivity and the non-endemic control group for specificity. ROC curves for each of the six proteins are shown in Figure 3. The ELISA OD cutoffs that maximized the accuracy of each of the six antigens are shown in Table 2 and the results indicated that a number of these proteins might be useful in determining new M. ulcerans endemic areas. In particular MUL_0513 and two of the Mls domains (AT-propionate, KR-B) all produced high area under curve (AUC, .0.8), and good sensitivity (.70%) and specificity (.80%). However the best antigen was Hsp65, with AUC of 0.932, 84.1% sensitivity and 93.3% specificity at an OD cut-off of 0.693. Hsp65 also had the highest likelihood ratio (12.6), indicating that an individual living in a BU endemic area is 12.6 times more likely to have a positive Hsp65 test than an individual residing in a non-endemic area. "
2491053,0.0,"Study population Of 34 enrolled patients, 12 were excluded from the study due to motion artifacts at PC-MRI (5/12), termination of the examination by the patient or MRI technician before completion (5/ 12), PC-MRI obtained at a suboptimal level (1/12) or image artifacts (1/12). Thus, 22 patients were included. Shunt surgery was performed in 17 of these, of which 16 (94%) were clinical responders. Other patient data are given in Table 1 and S1 File. Age and gender of four healthy controls are also presented in Table 1. "
2491053,1.0," ICP scores A summary of the ICP data from the iNPH patients are given in Table 2, and the full dataset from the patient cohort is presented in S1 Table. The coefficient of variation (CV = standard deviation/mean) illustrates the span of fluctuations in measured pulsatile and static ICP during overnight monitoring. Overnight monitoring of pulsatile and static (mean) ICP demonstrated large fluctuations, where CV was 26% (12, 41) and 128% (19, 5600), respectively (median and range). Fig 4 exemplifies recordings from a study patient demonstrating pulsatile ICP expressed by MWA (a), static ICP expressed by mean ICP (b) and heart rate (c) as a function of time. For patient specific measurements, MWA was to a very limited degree affected by HR, as the association between pulsatile ICP (MWA) and heart rate (HR) was low with median R = .02 (S1 Table). "
2491053,2.0," PC-MRI data from patients and healthy controls A summary of the PC-MRI data from patients and healthy controls is shown in Table 3, and an extended set of data from the PC-MRI studies of iNPH patients and healthy controls are presented in S2 and S3 Tables, respectively, and in S2 File. MRI-dP at level C2 was not different in iNPH patients and healthy subjects (P = .39). Only area of the subarachnoid space (ROI area and hence number of pixels) differed between groups (P = .016). "
2491053,3.0," Comparison of patient ICP scores and MRI-dP There were no associations between invasively measured pulsatile ICP and the non-invasive assessment of MRI-dP (R = -.18, P = .43) (Fig 5A) or mean ICP and MRI-dP (R = .10, P = .68) (Fig 5B). Moreover, the MRI-dP did not differ between individuals with MWA above or below established thresholds for shunting (P = .97), or healthy controls (P = .44) (Fig 6). "
2491053,4.0," Heart rate during PC-MRI and ICP monitoring There was a high correlation between heart rates (HR) from PC-MRI and invasive ICP moni- toring (R = .71, P = .001) (Fig 7A), and the Bland-Altman plot revealed no systematic differ- ences in HR registered during invasive ICP monitoring and PC-MRI (Fig 7B). "
1442658,0.0,"In the group 1 (MS patients with chronic plaques), average peak velocity was 5.5 ± 1.4 cm/sec (range, 3.4–8.4 cm/sec); average velocity, 0.36 ± 0.20 cm/sec (range, 0.04–0.70 cm/sec); average forward volume, 0.039 ± 0.016 mL (range, 0.010–0.080 mL); average reverse volume, 0.027 ± 0.016 mL (range, 0.010–0.080 mL); net forward volume, 0.012 ± 0.007 mL (range, 0.00–0.030 mL); average flow, 0.018 ± 0.010 mL/sec (range, 0.00–0.040 mL/sec); and average aqueductal area, 5.0 ± 1.3 mm2 (range, 2.7–9.1 mm2). "
1442658,1.0," In the group 2 (MS patients with active plaques), average peak velocity was 4.9 ± 1.0 cm/sec (range, 2.7–6.4 cm/sec); average velocity, 0.50 ± 0.30 cm/sec (range, 0.08–1.13 cm/sec); average forward volume, 0.031 ± 0.013 mL (range, 0.010–0.060 mL); average reverse volume, 0.018 ± 0.009 mL (range, 0.00–0.040 mL); net forward volume, 0.013 ± 0.008 mL (range, 0.00–0.040 mL); average flow, 0.019 ± 0.012 mL/sec (range, 0.00–0.040 mL/sec); and average aqueductal area, 4.1 ± 1.5 mm2 (range, 1.8–7.3 mm2). "
1442658,2.0," In the group 3 (controls), average peak velocity was 4.3 ± 1.3 cm/sec (range, 2.9–7.7 cm/sec); average velocity, 0.41 ± 0.27 cm/sec (range, 0.05–1.07 cm/sec); average forward volume, 0.021 ± 0.010 mL (range, 0.010–0.050 mL); average reverse volume, 0.012 ± 0.006 mL (range, 0.00–0.030 mL); net forward volume, 0.008 ± 0.006 mL (range, 0.00–0.020 mL); average flow, 0.013 ± 0.010 mL/sec (range, 0.00–0.040 mL/sec); and average aqueductal area, 3.1 ± 1.2 mm2 (range, 1.6–5.8 mm2). "
1442658,3.0," The average velocity, net forward volume, and average flow were not significantly different between the three groups regarding (p > 0.05). "
1442658,4.0," The MS patients with chronic plaques and active plaques, compared with the controls, showed a higher peak velocity, forward volume and reverse volume (Table 2). There were statistical significance between the MS patients with chronic plaques and the control group (p < 0.05). "
1442658,5.0," As shown in Table 2, the MS patients with active plaques and chronic plaques, compared with the controls, showed a higher aqueductal area, with statistical significance (p < 0.05). "
1442658,6.0," There were no statistical significance between the MS patients with chronic plaques and active plaques, except for reverse volume. The MS patients with chronic plaques showed a significantly higher reverse volume (p = 0.000). "
1442658,7.0," The peak velocity, forward volume, and aqueductal area were higher in MS patients with chronic plaques, without statistical significance (p > 0.05). "
1442658,8.0," Inter-observer reliability of CSF flow measurements was excellent for peak velocity and average velocity (κ = 1, 0.971, respectively). Inter-observer reliability of average flow, forward volume, reverse volume, net forward volume, and average aqueductal area measurements was good (κ = 0.786, 0.755, 0.759, 0.785, and 0.714, respectively). "
433520,0.0,"The inventory of water bug families in Centre Province of Cameroon was undertaken in Buruli ulcer endemic and non endemic areas, along the Nyong River. Among 7,407 collected specimens, seven aquatic Heteroptera families (Four true aquatic bugs and three semi-aquatic bugs) present in both areas were identified: Belostomatidae, Notonectidae, Nepidae, Corixidae, Gerridae, Mesoveliidae and Hydrometridae (Table 2 and Figure 2). The two most diversified families in our study were the families Notonectidae and Belostomatidae. Seven undeter- mined morphotypes were present in the Notonectidae family, two belonging to Anisopinae subfamily and five to Notonectinae subfamily. Appasus sp., Lethocerus and another unidentified mor- photype were present in the Belostomatidae family. Only one subfamily was identified in Nepidae and Corixidae families, respectively Micronectinae and Ranatrinae. All families identified in this study can be characterized as carnivorous predatory fluid- feeders, with the exception of the Corixidae family (plant feeders). Three families (Belostomatidae, Notonectidae, Nepidae), among the six carnivorous ones, are able to bite humans and to fly. "
433520,1.0," Cameroon has a tropical climate which varies from equatorial in the South to Sahelian in the North. The equatorial South, where the Buruli ulcer endemic area is located, has two wet seasons and two dry seasons. One wet season occurs between March and June and the main wet season occurs between August and November. One dry season occurs between June and August and the main dry season occurs between December and March. The population dynamics of water bugs was investigated in an endemic area for Buruli Ulcer (district of Akonolinga). In order to get comparable results, insects were captured at periodic intervals by the same operator (with standardized sampling methods), in the same water body each time. Large fluctuations of water bug density were observed among the samples (Figure 3A). The highest number of collected insects per sampling was recorded in January, during the long dry season (median = 369), whereas in other months, the median number of captured insects per sampling varied between 25 and 94 specimens (p,0.001, according to the negative binomial regression model estimating the count of insects per sampling). With respect to water bug families, the following variations in the sample composition were observed: out of seven families, four families (Belostomatidae, Notonectidae, Gerridae, Nepidae) were collected throughout the study period (Figure 3B), whereas the three other families (Corixidae, Mesoveliidae and Hydrometridae) were found only in January and/or April (Figure 3B). The most abundant family was Notonectidae (67% of total collected water bugs). The proportions for the other families were: 14.2% (Belostomatidae), 10.5% (Gerridae), 5.6% (Corixidae), 1% (Hy- drometridae) and 0.1% (Mesoveliidae). The relative abundance of families fluctuated over the year. For example, Belostomatidae and Notonectidae represented respectively 59.8% and 34.3% of total insects in October, and 10.1% and 88.4% in November (Figure 3B). Moreover it was observed that in January Corixidae reached the highest abundance (10.2% out of total water bugs), whereas in January and April the highest water bug diversity was noticed (Figure 3B). All these data suggest that the long dry season corresponds to the period during which highest water bug diversity and abundance occur. "
433520,2.0," Detection of M. ulcerans in samples collected in Buruli ulcer endemic and non endemic sites was performed by PCR targeting the IS2404 insertion and the KR domain which encodes a polyketide synthase. From 3647 water bugs collected in the endemic area, 68 pools out of 616 (11%) were positive for both markers, IS2404 and Ketoreductase (Figure 4A). In addition M. ulcerans DNA was detected in five out of seven analyzed insect families. The rate of colonization in these pools was around 10%, except for the Corixidae family (Micronectinae) captured only in January, for which the rate reached 43.7% (p = 0.008, Pearson Chi-square test) (Figure 4B). Of note, this result was confirmed for individual Corixidae specimens (n = 72). However, given the very low number of collected water bugs from Mesoveliidae and Hydro- metridae families (33 and 9 specimens, respectively), it is difficult to draw clear conclusions, in this case, about their possible subversion as hosts for M. ulcerans. The rate of insect colonization by M. ulcerans fluctuated between 1.4% and 33.9% according to the sampling period, with (p = 0.008, Pearson Chi-square test) a peak in July (33.9%) (Figure 4A). Moreover, in the present study, no correlation was established between abundance of water bugs and rate of colonization of water bugs by M. ulcerans. All families -notably Belostomatidae, Notonectinae and Gerridae- displayed very ulcerans similar (Figure 4C), with the exception of Nepidae (for which the sample size was limited). "
433520,3.0," From 422 water bugs caught in a Buruli ulcer non endemic area, no pool out of 80 was found positive (Table 3). Significantly, in these same April and July periods, 11.5% and 33.9%, respectively, pools were found positive in the endemic site situated 100 kms away. "
433520,4.0," Only living Belostomatidae insects of the genus Appasus sp. (Figure 5A and B) were allowed to salivate, for technical reasons. The saliva of these insects was first monitored for the presence of M. ulcerans DNA (Figure 5A and B). The individual saliva samples analysed by IS2404 and KR PCR were found positive in 51/293 of cases (17.4%), with a peak in July. Similar patterns were observed with homogenate tissue of Appasus (Figure 5C). Interestingly, few acid-fast bacilli were observed in saliva samples of three individual positive pools (November, April and July). Their viability was evaluated by inoculation of PCR positive saliva into the tails of 21 Balb/c mice. Using quantitative PCR, quantity of inoculated bacilli was determined to range between 16102 and 56103 bacilli per ml. Four months after the subcutaneous injection, three mice displayed lesions typical of M. ulcerans, in which acid-fast bacilli were detected. Quantity of bacilli was estimated by quantitative PCR to range between 66104 and 36105 bacilli per ml of grounded tissue. This result suggests growth of Mycobacterium ulcerans in mouse tail. It can be noticed, however, that conventional methods failed to isolate the bacilli by culture from mouse tissues presenting clinical lesions. "
1691937,0.0,"By simultaneously accounting for environmental and water bug transmission, we quantify the contribution of each mode of transmission to the temporal dynamics of BU cases in Akonolinga under a broad range of epidemi-ological and environmental parameters (Table 1). The best fit of mathematical models (AIC = 57.49) accurately predicted the monthly dynamics of observed BU cases (Fig. 2A) and suggested an exclusive role for environmental transmission (ratio λ MU/λ WB larger than 103). In addition, the mean force of infection in the set of 35 best fits that are considered equivalent (those with an AIC difference from best model lower than 2) was higher for the environmental transmission than for water bug transmission in 34 out of 35 fits. The ratio λ MU/λ WB, quantifying the importance of environmental transmission over water bug transmission, ranged from 0.86 to more than 106, with a median value of 276 (Fig. 2B). Environmental transmission thus contributed to almost the entire burden of BU infections in our temporal model. The predictions from this set of best parameters had a high and significant correlation with the observed number of BU cases (Fig. 2C), with an R2 of 0.60 and 0.69 for incubation periods of 3 and 5 months respectively (these are the incubation periods present in the best models). "
1691937,1.0," For the environmental transmission, the concentration of MU provided a better prediction of the temporal dynamics of the observed cases of BU than MU positivity. Indeed, fitted models based on MU concentration represented 100% of the total set of best 35 fits. A linear relationship between MU concentration and the force of infection, with a time of 6 months from infection to treatment, represented nearly two thirds of the fits. The mean AIC was lower in these fits than for fits with other times and functional links (Table 2). The mean value of this linear relationship is shown in Fig. 3A, along with the maximum and minimum values based on the parameters of the other best fits. "
1691937,2.0," Our statistical models of MU spatial associations with BU incidence in both Akonolinga and Bankim indi-cate similar drivers as the mathematical model of temporal dynamics (Table 2). In the univariate linear models, environmental transmission was the only statistically significant predictor of BU incidence in populations within a 5km buffer. MU positivity in a water body was the best spatial predictor (R2 = 0.15, p-value< 0.05), while MU concentration was only significant at the 90% level (R2 = 0.09, p-value< 0.1). None of the variables for the water bug transmission showed any association with BU cases (R2 = 0.03, p-value = 0.77 for water bug positivity and R2 = 0.02, p-value = 0.36 for number of infected water bugs). Bivariate analyses in which one variable for water bug transmission was added at a time did not improve the model with the environmental transmission only. "
1691937,3.0," We further explored whether a non-linear relationship between the MU environmental variables and BU incidence was more likely than a linear link by fitting GAMs of different spans. A GAM with a threshold effect and a saturation value significantly improved the results of the linear model for MU positivity (Table 2), but none of the nonlinear models improved the results for MU concentration. The predictions of the best statistical model are shown in Fig. 3B, along with their 95% confidence intervals (see Supplementary Materials, section S8 for a detailed description of all the statistical results). "
1691937,4.0," In order to understand whether the spatial and temporal models provided the same information on the link between environmental MU and BU, we explored the relationship between MU positivity and MU concentration (Fig. 3C). The two variables were highly correlated, suggesting that both positivity and concentration provide similar information about MU environmental load (Spearman’s correlation test, p-value < 0.01 for both datasets). Furthermore, there was a clear plateau in MU concentration at higher MU positivity levels for both the temporal and spatial datasets. This suggests that once a positivity level was reached, this did not result in higher concentra-tion in the samples. This would explain why we obtain a linear link with BU incidence for MU concentration but a saturation effect for MU positivity. We finally evaluated the strength of correlation between the temporal and spatial predictions for MU concentration only, and then for MU positivity. We found positive and significant cor-relations between the predictions of both models for each of these variables (Supplementary Materials, Section S6). "
1982497,0.0,"We performed MRV in 830 patients. The examination revealed a slower blood flow in IJVs. Only 17 patients (2%) showed no such flow patterns. The pathologies mentioned were seen: on the right side in 6% of scanned MS patients, on the left side – 15%, on both sides with right-side predominance – 22%, on both sides with left-side predominance – 34%, bilaterally with no side predominance – 19%. In 17 cases (2%), a more pronounced pathology was seen: slower blood flow in IJVs, vertebral, subclavian and also in the left brachiocephalic veins. Moreover, in 42 cases (5%), a decreased blood flow in the AV was detected (Table 1). "
429330,0.0,"Of the 195 probable Buruli ulcer cases recorded in Bankim district hospital since January 2007, 100 cases were contacted, 88 were questioned, and 77 retained for analysis. Only one BU patient refused to participate. Cases were not included or not considered for analysis if they reported having suffered from BU for ten years or longer (n = 11), if one relative (parent, child or sibling) was already included in the study (n = 5) or if their distant location did not allow us to investigate community controls (n = 6). Details of the inclusion process are provided in Figure 1. Community controls were randomly selected in the population census for 74 cases. For 3 cases living in villages for which census data were not available, controls were included from randomly selected houses. The main reasons for controls not participating were long- term or repeated absence (n = 30, 45%), refusal (n = 14, 21%), unable to be found (n = 8, 12%), or related to a case (n = 5, 7%). The main analysis was performed on 77 cases (72 probable and 5 laboratory confirmed cases) matched with 153 community controls. Out of 77 cases analyzed, 76 were matched with two controls and one case was matched with one control only. Familial controls were recruited when available, i.e. mainly for children. Case-familial control analysis was performed on 37 cases and 49 controls. These were distributed as follows: 12 groups of one case and two controls and 25 groups of one case and one control. Among controls, 42 were siblings, 5 were other relatives (half-brother or sister, cousin) and two were unrelated children living in the same household. "
429330,1.0," Most patients were healed, except for 16, who presented with lesions still not scarred (Table S1). Five cases could be confirmed, but laboratory confirmation could not be obtained for 11 who were already undergoing treatment. About as many cases were men (n = 40) as women (n = 37). Median age of analyzed cases was 14 years (Inter-quartile Range (IQR) = [10–36.5]). Lesions classically presented on lower (n = 39, 49%), and upper limbs (n = 29, 38%). Only 3 patients presented with multiple lesions, and 8 (10%) presented with head or trunk lesions. Median (IQR) time from onset of disease to day of interview was 17 (9–26) months, ranging from 15 days to 7 years. The majority of patients did not associate their disease with any particular circumstance, but 9 linked it to a wound and 17 to insect bites. The overall population of the study, presented in Table 1, showed an important heterogeneity of ethnic groups and origins. Tikari and Kwadja farmers are indigenous and represented 33% of controls, but Yamba and Mambila farmers originating from neighboring regions were also well represented, respectively 29% and 12% of the control population, respectively. Kotoko people, originating from the Extreme-North Cameroon, are also found in Bankim, where they settled on the banks of the Mappe´ Lake and currently handle the commercial fishing business. Fulani-related Mbororos live usually in settlements in the savanna where they traditionally raise cattle. Some of them practice transhumant pastoralism. Adults principally engaged in farming activities. Most children between 6 and 12 years old reported going to school (94%), and a majority of them participated in farming during weekends and holidays or during seasons when additional workforce was required (85%). Education level was low with few persons over 12 years of age having secondary education. "
429330,2.0," Univariate analysis. Neither ethnic group, activity nor education level was significantly associated with BU (Table 1). A history of BCG vaccination, assessed through the presence of a scar on the forearm, showed a nearly significant protection against BU. Compound environment was associated with an increased risk when small domestic animals such as poultry, ducks, goats or pigs, were present (Odds Ratio (OR) 95% Confidence Interval [95%CI] = 2.6 [1.2–5.7], p = 0.01) and when the compound was close to a water body (OR [95%CI] = 2.6 [1.1–5.8], p = 0.02). Use of specific light source (petrol lamp, electricity) and whether it burnt overnight or not, were not associated with the disease. Exposure to insects was assessed by questioning about specific insects bites (Table 2). Cases reported more frequently being bitten by hematophagous insects belonging to the Chrysops genus (Tabanidae), but the association was not significant. BU was significantly associated with reporting history of small skin lesions due to scratching after an insect bite (OR [95%CI] = 2.1 [1.2–3.7], p = 0.01). Mosquito coils were seldom used and no association with BU was found. When compared to never using a bed net, systematic bed net use was associated with protection from BU and occasional use was associated with an increased risk (systematic/none: OR [95%CI] = 0.6 [0.3–1.2], occasional/none: OR [95%CI] = 2.5 [1.0–6.4]; p = 0.01). Most bed nets had been bought from the local market and were not insecticide-treated. Net insecticide treatment did not appear associated with better protection, nor did the absence of holes. Exposure to water was assessed for various activities (Table 3). Fishing was a common secondary occupation among all categories of population but the study included few professional fishermen. Fishing activity, season, place or techniques used were not found to have statistically significant association with the disease. Bathing activities were separated into bathing for hygiene and for leisure. Bathing for hygiene was statistically associated with an increased risk of BU when baths were taken in the Mbam, a river flowing south from the district (OR [95%CI] = 4.4 [1.2–17], p = 0.02). Bathing in the barrage lake or other water bodies was not associated with a statistically significant change in the risk of disease. Bathing for leisure was a common activity for nearly all children and did not significantly increase risk. Domestic water supply and clothes washing activities were investigated, but no significant difference in exposure was found between cases and controls. Water sources were mainly rivers, streams or wells. Protected water sources were limited to urban compounds and not necessarily used for all activities. Whether unprotected water sources were running or stagnant was difficult to assess, but no statistically significant association was found between BU and declared characteristics of the water source. Not wearing shoes during domestic water supply or clothes washing was significantly associated with an increased risk of BU (OR [95%CI] = 6.7 [1.8–24.3], p = 0.002). Type of clothing or shoes worn during any other water-related activity was not associated with a significant risk of BU. Almost all cases and controls participated in farming activities (Table 4). Youngest children were considered participating when they accompanied their parents. Nearly all farmers planted corn. Growing other food crops was associated with a decreased risk of disease: growing cassava (OR [95%CI] = 0.4 [0.2–0.7], p = 0.001) or beans (OR [95%CI] = 0.5 [0.3–1.0], p = 0.05) presented a significantly decreased risk. Growing banana (sweet or plantain), groundnut and tubers like yam, sweet potato or taro was also associated with a small protection that did not reach significance level. In contrast, commercial crops like coffee and pepper were not associated with disease. Cases were more likely than controls to have a longer walking time to their fields and to sleep there. They more frequently reported cultivating areas that flooded during the rainy season. Cases also more often declared having a garden or a vegetable patch near their houses, and watering these plots was associated with a significantly increased risk. Clothing worn during farming activities was not associated with a risk of BU. Wounds were frequent in the population, and were usually acquired during farming activities (Table 3). Controls reported being wounded while clearing the field more often than cases. Several wound treatments were associated with a change in BU risk: using alcohol or soap to cleanse the wound were protective practices, while using no treatment led to an increased risk of disease. Rubbing leaves (usually the sap of a common Lamiaceae referred to as ‘‘benjamin’’) or applying ground tablets or ointment bought on the market was not significantly associated with the risk of BU disease. Dressing the wound was a protective practice when the bandage - either a piece of cloth or adhesive bandage - was regularly changed. "
429330,3.0," Multivariate analysis. For multivariate analysis, the main recoded in two categories, exposure ‘‘bed net use’’ was ‘‘Systematic bed net use Yes/No’’ by pooling the two categories ‘‘Never’’ and ‘‘Rare to often’’, which were both associated with an increased risk of disease in the univariate analysis (Table 5). Independent factors associated with an increased risk of BU were bathing for hygiene in the Mbam River (OR [95%CI] = 6.9 [1.4–35], p = 0.02) and reporting small scratch wounds after insect bites (OR [95%CI] = 3.8[1.0–14], p = 0.03). Factors independent- ly associated with a decreased risk were systematic use of a bed net (OR [95%CI] = 0.4 [0.2–0.9], p = 0.04), use of soap to cleanse wounds (OR [95%CI] = 0.1 [0.03–0.3], p,0.001) and growing cassava (OR [95%CI] = 0.3 [0.2–0.7], p = 0.005). No significant interaction was found in the final model between variables and a variable ‘‘interviewer’’. No significant interaction was found between these variables and age category or gender. Detailed results of variable selection process are provided in supplementary text S1. "
429330,4.0," Univariate analysis showed a few associations that did not reach significance level (table S2). Of note among those were: bed net use which was associated with a decreased risk (OR [95%CI] = 0.4 [0.1–1.4], p = 0.13); watering a garden, associated with an increased risk (OR [95%CI] = 3.1 [0.6–15], p = 0.13); and reporting scratch wounds after insect bites, associated with an increased risk of BU (OR [95%CI] = 2.3 [0.8–6.7], p = 0.10). No significant association with BU was revealed in multivariate analysis (table S2). "
429330,5.0," If we assume that the relationship between a protective factor and risk decrease is truly causal, we can calculate the proportion of cases in the general population (represented by the controls) prevented by this protective factor, based on the relative risk and the frequency of the factor in the general population (again, represented by controls). The preventive fraction for systematic bed net use was 32% (proportion of controls systematically using a bed net: 53%, OR = 0.4). Likewise, the fraction of cases prevented by adequate wound hygiene practices (using soap to cleanse wounds) was 34% (proportion of controls using soap: 38%, OR = 0.1). "
193334,0.0,"The demographic and clinical characteristics of all the 79 TGA patients, and the subset of 45 patients and 45 age- and sex-matched controls who underwent complete MRI, MRA, and MRV examinations are shown in Table 1. The patients and controls did not differ significantly in terms of their vascular risk factors. The TAMVs, FVs, and CSAs of the bilateral IJVs in the age- and sex-matched 45 patients and 45 controls are shown in Table 2. As compared to the controls, the TGA patients exhibited significantly lower TAMVS at the J2 and J3 segments of the bilateral IJVs. They also exhibited significantly lower FVs in the left IJV at the J2 and J3 segments and in the left VV. The FVs were not significantly lower in the right IJV; however, the patients still exhibited significantly lower total flow volumes in the bilateral IJVs and VVs. In both the patients and controls, the CSAs of the bilateral IJVs were not significantly different either at the J2 or J3 segment. The TGA patients exhibited a significantly higher prevalence of IJVVI (patients vs. controls: 82 vs. 44%); however, the side-specific prevalence was significantly greater on the left side (patients vs. controls: 53 vs. 20%), while the right-sided prevalence being comparable between the patients and controls (patients vs. controls: 29 vs. 24%). Furthermore, we detected a significant difference in the prevalence of left-sided IJVVI between the subjects with and without the presence of left BCV compression/stenosis [19 (61%) vs. 14 (24%), p = 0.0044]. "
193334,1.0," We have often observed that the IJV drainage flow usually appears ~4–8 s after initiating the VM, so we simply defined the complete absence of IJV drainage flow at the J2 or J3 segment within 10 s of initiating the VM as IJV “non-patency.” Table 3 displays the relationship between the ultrasound findings of IJV non-patency during the VM, and the MRI findings of venous compression/obstruction or TS hypoplasia in those 90 study subjects (45 patients and 45 controls). For the left IJV, the prevalence of ultrasound-detected IJV non-patency during the VM was significantly greater at the J2 segment in the study subjects with an upstream TS hypoplasia than that in the patients without such hypoplasia (56.9 vs. 44.3%, respectively; p = 0.0425). For the right IJV, the prevalence of IJV non-patency at the J2 segment was significantly higher in the patients with IJV compression at C1 or C4 than in the patients without such compression (62.07 vs. 28.57%, respectively; p = 0.0111). We found no significant difference in the prevalence of bilateral IJV non-patency during the VM between those age- and sex-matched patients and controls who underwent complete MRI examinations. However, since there are no statistical differences in all the flow profiles between two groups of TGA patients with and without venous MR imaging as shown in Table S1, thus we included the 34 patients who underwent complete ultrasound examinations but incomplete MRI examinations for analysis, we found a significant difference in the prevalence of IJV non-patency during the VM between the patients and controls (Table 4). Specifically, we found that the patients exhibited significantly higher IJV non-patency at the right J3 segment (patients: 32.1%; controls: 11.6%; p = 0.0128), but not significantly higher in the left J3 segment (patients: 49.35%; controls: 37.21%), and the right J2 segment (patients: 44.00%; controls: 32.56%). "
432326,0.0,"M. ulcerans phylogeny in Cameroon We sequenced the genomes of 82 M. ulcerans strains isolated from 45 IS2404 qPCR confirmed Cameroonian BU patients. Patients were identified between 2010 and 2012 and came from two geographically separated BU endemic regions of Cameroon, the Mapé and the Nyong river ba- sins. Prior to treatment, ulcerative lesions were sampled with a cotton swab for laboratory con- firmation of the clinical diagnosis, primary isolation of the disease causing organism and WGS of the isolated M. ulcerans strains. The mapping of the obtained Illumina sequencing reads against the reference strain resulted in an average coverage of 380 reads per position per genome. We reconstructed the phylogenet- ic relationship among 45 Cameroonian (one strain per patient), five Ghanaian and three Beni- nese M. ulcerans isolates based on 26,740 variable nucleotide positions, rooting the tree using a published M. marinum genome (Fig 1). The phylogenetic tree showed a very strong geographi- cal structure. The chromosome tree of the Cameroonian M. ulcerans isolates showed two dis- tinct lineages, the first one containing all the Nyong river basin isolates (Nyong lineage) and the second one all the isolates from the Mapé region (Mapé lineage). The Mapé river basin iso- lates were more closely related to a set of published genomes [13] of Ghanaian and Beninese isolates that we included in the analysis, than to the Nyong lineage. The two Cameroonian clonal complexes differed in altogether 828 SNPs shared by all members of the respective line- ages (Fig 1). The plasmid phylogeny reflected the topology of the M. ulcerans chromosome phylogenetic tree (Fig 1), supporting the hypothesis of a unique acquisition of the plasmid during the emer- gence of M. ulcerans [30] followed by parallel evolution between the chromosome and the plasmid. "
432326,1.0," Genetic diversity among the Cameroonian isolates We analysed the genetic diversity within the two Cameroonian geographical lineages separately (Fig 2). The genetic diversity observed for the Nyong river basin isolates (median pairwise SNP difference = 26.2 SNPs) was significantly higher (p-value < 0.0001) than for the Mapé basin isolates (median pairwise SNP difference = 7.6 SNPs). Furthermore, an analysis of the pairwise geographic distance of seven isolates from the Eastern Nyong river basin (approximately 1090 km2) and of four isolates from Western Nyong (approximately 625km2) still yielded values that were higher (median 24 and 36 pairwise SNP difference) than for the Mapé isolates (Fig 2). The higher genetic diversity thus does not seem to be related to the broader geographical distribution for the Nyong river basin isolates (approximately 8600 km2) compared to the Mapé river basin isolates (approximately 6400 km2) (Fig 3A2 and 3B2). These results were also reflected in the phylogenetic tree, where branch lengths were longer for the Nyong river basin strains than for the Mapé river basin isolates (Fig 1). The gene encoding for rpoB, which is known to harbour drug resistance mutations against rifampicin in M. tuberculosis [31], was not affected by SNPs in any of the M. ulcerans strains analysed here. When analysing the nucleotide diversity distribution along the chromosome by calculating the average nucleotide pairwise diversity per site (Pi) for both lineages, 99.9% of the genome was found to be highly conserved (S1 Fig). However, the average nucleotide diversity per site for the Nyong river basin lineage was 3.2 times higher than for the Mapé river basin lineage (4.10e-6 versus 1.3e-6). The regions of the genome with higher nucleotide diversity (0.375e-4 and 1.25e-4, respectively) seemed randomly distributed across the chromosome for both line- ages (S2 Fig) and the gene content of these regions varied between the two Cameroonian line- ages, comprising affected genes of diverse functionalities (S3 Table). "
432326,2.0," Phylogeographic analysis of the Cameroonian M. ulcerans isolates In order to analyse the distribution of genetic variants within the endemic areas, we recon- structed median joining networks for the sequenced strains and mapped the places of residence of the patients from which the strains originated (Fig 3). The network of the Mapé river basin isolates had a star structure with two isolates (BP130 and BP140) at the centre. All the other isolates were connected to this centre and separated by three to nine SNPs. While the SNP distance between the two central strains was zero, the geo- graphical distance between the corresponding residence places of the two corresponding pa- tients was 19.5 km. A total of four clusters were distinguished in the network: blue formed by two isolates, green and yellow formed by three isolates each and the red cluster as a complex structure formed by nine strains. The strains belonging to the red cluster shared two SNPs, the green ones also two SNPs, the yellow ones four and the blue ones shared three SNPs. All the grey strains were not forming clusters and differed by 1 to 11 SNPs from the central strains. In the network of the Nyong river basin isolates we observed only three clusters formed by three (green), seven (red) and one strain (blue). The isolates from the red cluster shared six SNPs, while the isolates from the green one shared only two SNPs. Overall, for both BU endemic areas in Cameroon we did not find a clear correlation between the genetic networks and the geographic distribution of the houses where the patients lived in the year prior to the onset of BU disease (Fig 3). Statistical analysis with the Mantel test for the smaller subset of Nyong sam- ples resulted in a positive and marginally significant correlation between the geographic and genetic distances (r = 0.2785, p-value = 0.054), whereas the test performed for the Mapé set of isolates resulted in a small non-significant negative correlation (r = -0.04774, p-value = 0.676). "
432326,3.0," Rate of acquisition of SNPs In the course of this genomic epidemiological study we obtained from three patients isolates from two or three different time points during the course of their disease (Table 1). When com- paring the SNP diversity between the isolates from the same patient, only one SNP difference was observed between two sequential isolates (Table 1). The affected gene (MUL_1383) en- coded for a hypothetical protein and the detected mutation was synonymous. No SNP differ- ence was observed between two strains isolated from two distant ulcers of one patient (Table 1). "
2547425,0.0,"CCSVI criteria I - Reflux in the IJV or VV in sitting and supine posture. We found no evidence of reflux using colour and duplex Doppler at any level bilaterally in either of the IJV or VV in any subject (Table 2). Reflux cannot be assessed in the transverse plane (Figure S3). Venous flow was spontaneous, phasic and caudal in both supine and upright positions (Figure S4). Reflux (>0.88 s) was never seen. In one control subject a vertebral vein was not visualized in the supine position. "
2547425,1.0, CCSVI criteria II - Reflux or no flow in the DCV. Flow in a DCV was assessed in the supine position. In one MS patient a DCV was not seen. There was no evidence of either reflux or cessation of flow in any of the study groups (Table 2). flow was mono-directional and did not change with either inspiration or expiration (Figure S5). 
2547425,2.0," CCSVI criteria III - High Resolution B-mode evidence of IJV anomalies or stenosis. Gray scale assessment of the IJV displayed anomalies in 3 out of 199 subjects (1.5%, see Table 2). The B-mode anomalies appeared as malformed or irregular valve movements. In all subjects, flow patterns were not altered and the anomalies did not represent vascular narrowing. There was no significant difference in maximum IJV velocities between matched cases and controls. After adjusting for the Bonferroni correction, none of these differences was statistically significant at any location (J1, J2, J3) or at either side (right or left). "
2547425,3.0," CCSVI criteria IV - Flow not detectable by Doppler in the IJVs and/or VVs despite numerous inspirations in sitting and supine posture. Flow was detected in all patients with the exception of one control patient in whom one VV was seen in the upright position but not in supine. was displayed in both planes at J1, J2 and J3 by optimizing PRF, angle of insonation and color gains (Figure S6). There was no evidence of blockage found in either study group or at any of the levels measured (Table 2). "
2547425,4.0, CCSVI criteria V - Reverted postural control of the main cerebral venous outflow pathways (IJV CSA supine-upright). ΔCSA was calculated as supine - upright. A negative ΔCSA would reflect abnormal venous drainage in accordance with the Zamboni hypothesis that the supine CSA would be diminished in patients with MS. Two MS patients and one control subject demonstrated a negative ΔCSA (Table 2). 
2547425,5.0," Zamboni criteria. The number of study participants who fulfilled each Zamboni criteria is shown in Table 2. No participants satisfied the first, second, or fourth criteria, three fulfilled the third criterion and three satisfied the fifth criterion. Exact conditional logistic regression analysis reveals no differences between cases and controls for any of the five criteria. Amongst all participants only one PPMS patient fulfilled the minimum two of five Zamboni ultrasound criteria for CCSVI and none filled more than two (Table 3). Analysis of the Zamboni rule with exact conditional logistic regression reveals no difference between cases and controls (p = 0.991; Table 4). Due to the sparse nature of the data (i.e., infrequent positive criteria) we could not obtain a point estimate of the odds ratio and its corresponding 95% confidence interval. "
2547425,6.0, Magnetic resonance imaging The between-reader reproducibility of MRI flow measurements was high—with ICC values varying from 0.81 to 0.94 for all segments. The comparison between absolute flow in the high neck and mid-neck IJVs as well as the straight sinus of all MS cases and control subjects is shown in Figure 1. There are no statistically significant differences between these flow values. A consistent finding was that flow in the right IJV was always higher than that in the left IJV. The differences in flow asymmetry (right IJV – left IJV) between MS cases and controls for the upper IJV and mid-neck IJV were not statistically significant (Table 5). Examination of the extra- and intra-cranial venous anatomy using contrast MRV revealed no evidence of stenoses or other venous abnormalities between cases and controls. 
232756,0.0,"Observation learning induces rapid auditory discrimination: \n During a pre-training phase, experimenters (EXP) were accustomed to air-puffs that followed one of two auditory stimuli of different duration. Then a training phase followed, during which we exposed EXP to the full training set of 10 auditory stimuli (Fig.�2a left panel and Supplementary methods). Gradually, EXP learned to escape from the perch more often in puffed trials; their escape probabilities (cumulated from trial onset to trial end) became larger on puffed trials than on unpuffed trials (Fig.�2b left and right). We quantified the birds� ability to discriminate stimulus class by the difference in (cumulative) escape probabilities (dPesc) between puffed and unpuffed trials (Fig.�2b, c, d, e). EXP attained a statistical performance criterion (based on the perching behavior in the most recent 800 trials,�see Methods and Supplementary Figure�1d) after 4700 [800, 10500] trials (median [range], n?=?10 birds). This criterion defined the end of the training phase, at which time EXP displayed a dPesc of 0.35 [0.27, 0.46] (median [range], dPesc averaged over the last 3 blocks of training, including the criterion block). After the training phase (or observation phase for observers), the experimenter was replaced by the observer (OBS) and a naive bird was placed in the observer�s cage. Then we began testing the OBS using the same pre-training and training paradigms it was previously allowed to observe. We refer to the training of observers as testing, Fig.�2a right panel. \n  At the beginning of the testing phase (first 3 testing blocks), OBS displayed a significantly higher discrimination performance than EXP at the beginning of their training phase (dPesc in first 300 trials: EXP (n?=?10) 0.2 [0 0.32], OBS (n?=?9) 0.4 [0.16 0.64]; EXP � OBS, median difference?=??0.22, p?=?0.013, test statistic?=?15; two-sided Wilcoxon rank sum test; 95% CI?=?[-Inf ?0.1]), Fig.�2d. Surprisingly, OBS� initial performance was no worse than that of EXP who had reached the learning criterion (average initial dPesc?=?0.40 in n?=?9 OBS vs average final dPesc?=?0.36 in n?=?10 EXP). OBS reached the performance criterion nearly instantaneously, in only 900 [800, 5600] trials (median [range], n?=?9 birds), less than a third of the trials required by EXP (two-sided Wilcoxon rank sum test with alternative hypothesis: EXP ? OBS, median difference?=?3100, p?=?0.015 (not exact), test statistic?=?75; 95% CI not computed because of ties), Fig.�2f. After reaching the criterion, OBS showed a significantly higher discrimination performance than EXP (dPesc at criterion in OBS?=?0.46 [0.29, 0.65]; EXP � OBS, median difference=??0.17, p?=?0.005, test statistic?=?12; two-sided Wilcoxon rank sum test; 95% CI?=?[?0.2 ?0.031]), Fig.�2e."
232756,1.0," Observers generalize poorly compared to experimenters \n  To compare generalization in experimenters and observers, first, we allowed generalization observers (GENOBS) to watch generalization experimenters (GENEXP) learn to discriminate the stimuli in the training set, after which we tested both groups of birds on the generalization set of stimuli, Fig.�3a. Contrary to our findings on the training set, GENOBS initially showed significantly poorer discrimination on the generalization set (average dPesc over the first 3 blocks (median [range]) in GENEXP: 0.41 [0.34, 0.6] and in GENOBS: 0.2 [?0.02, 0.54]; GENEXP � GENOBS, median difference?=?0.24, p?=?0.019, test statistic?=?67, two-sided Wilcoxon rank sum test, 95% CI?=?[0.016, 0.36]), Fig.�3b, c. GENOBS also took more time than GENEXP to reach criterion (3600 [800, 13300] trials in n?=?9 GENOBS versus 800 [800, 2200] trials in n?=?9 GENEXP; GENEXP�GENOBS median difference�?=??2800, p?=?0.006 (not exact), test statistic?=?10, two-sided Wilcoxon rank sum test; 95% CI not computed because of ties), Fig.�3d. \n  GENOBS needed more trials to reach the learning criterion than did OBS (GENOBS�OBS, median difference?=?2100 trials, p?=?0.044, test statistic?=?63.5, two-sided Wilcoxon rank sum test), demonstrating that observers reacted to small differences between stimuli from the training and generalization sets. Thus, overall, observers seemed to associate the perch-escape behaviors by experimenters much more exclusively with the presented auditory stimuli than did the experimenters themselves, who associated the air puffs inclusively with the stimuli (to include similar stimuli from the generalization set). \n  We inspected the escape behaviors of observers and experimenters. We found that after reaching the learning criterion, EXP and OBS displayed similar perch escape strategies. That is, they tended to abruptly increase their perch escape rates just before air-puff onsets (Supplementary Figure�2a, b), suggesting that birds responded by learning to escape the air puffs rather than by learning to stay when no puff was imminent."
232756,2.0," Observers do not learn through passive perceptual processes \n  We set out to characterize the requirements for observation learning. To test whether observers learned from experimenters� actions in response to the air-puffs, we allowed experimenter and observer pairs to experience several thousand (mean?�?standard deviation?=?7.5?�?3.6*103) stimulus playbacks including the sound of air-puffs, but not the tactile sensation of the puffs. We realized this perceptual paradigm by directing the air outlet away from the experimenters, Fig.�4a. Consequently, experimenters never experienced the air-puff as a force against their body. We refer to observers in such pairs as perceptual learners (PLs), because they could potentially learn from the pairing of stimuli with air-puff sounds. \n  Experimenters in this perceptual paradigm never produced dPesc values different from 0 (average dPesc after 5000 training trials in 3 experimenters: [?0.065, ?0.002, 0.007], p?=?0.81, p?=?0.25, p?=?0.64, respectively; z-test of individual proportions), hence they did not show the discriminative behavior that we suspected would drive learning in observers. When we tested PLs (n?=?7 birds) with air-puffs directed at them, they needed significantly more trials to reach criterion than OBS (4200 [1800, 20,300] trials in PLs versus 900 [800, 5600] in OBS; OBS � PL median difference?=??2400; two-sided Wilcoxon rank sum test of alternative hypothesis PL ? OBS, p?=?0.016 (not exact), test statistic?=?8.5; 95% CI not computed because of ties), Fig.�4e. PLs were slower than OBS even after removing an outlier bird (trials to criterion?=?20300) in the PL group (median difference?=???2389,�p?=?0.032 (not exact), test statistic = 8.5, 95% C.I not computed). PL performance at criterion was comparable to OBS performance (0.33 [0.064, 0.63] in PL versus 0.46 [0.29, 0.65] in OBS; OBS- PL; median difference?=?0.16, p?=?0.142, test statistic?=?46, two-sided Wilcoxon rank sum test, 95% CI?=?[?0.077 0.338]) and was not statistically different from performance in EXP (EXP � PL; median difference?=?0.06, p?=?0.41, test statistic?=?26, 95% C.I?=?[?0.2 0.2], two-sided Wilcoxon rank sum test). The absence of rapid learning in PLs suggests that learning in OBS required an experimenter engaged in the task and responding to air puffs."
232756,3.0," Observers do not learn from naive experimenters \n  We expected observation learning to be most effective when information is provided by an expert. To probe for sensitivity to experimenter performance, we tested a group of Valence Learners (VLs, n?=?5) that observed naïve experimenters who did not reach the performance criterion within (on average) 5600 [4360, 11436] trials. These naïve experimenters were hit by air puffs on average 539 times out of 1000 puffed trials, and escaped in unpuffed trials on average on 400/1000 trials. In addition, to give VLs direct experience of the reinforcer (its valence), 3/5 of these VL birds were initially exposed to air puffs (approximately 500 strong 1-s air puffs, see Methods). When tested, VLs were much slower than OBS to reach the learning criterion (trials to criterion in VL [n?=?5], median [range]: 6700 [6200, 12,100] versus OBS [n?=?9]:900 [800, 5600]; OBS�VL median difference?=??5500, two-sided Wilcoxon rank sum test of alternative hypothesis VL ? OBS, p?=?0.006 (not exact), test statistic?=?0, 95% CI not computed), Fig.�4e. The performance of VLs at criterion was lower than the performance of OBS (dPesc for VL [n?=?5]: 0.26 [0.13, 0.45] versus for OBS [n?=?9]:0.46 [0.29, 0.65], median difference =?0.21, p?=?0.007, test statistic?=?42, two-sided Wilcoxon rank sum test, 95% CI?=?[0.034 0.355]), and there was a trend of lower performance in VL compared to EXP (VL�EXP, median difference?=??0.11, p?=?0.07, test statistic?=?10, 95% C.I?=?[?0.21 0.05], two-sided Wilcoxon rank sum test). The poor testing results in VLs suggest that OBS did not learn by predicting the reward value experienced by EXP�and by converting this prediction into an optimal action during testing. Instead, VL behavior suggests that OBS focus on experimenters� discriminative actions, which must necessarily contain the information required for observation learning. In combination, PLs and VLs emphasize the importance of experimenters� discriminative actions for observation learning."
232756,4.0," Vocal exchanges are not required for observation learning \n  Given the importance of experimenter actions, we speculated that rapid learning in OBS could depend on vocal exchanges between EXP and OBS through calls occurring during and following stimulus presentation, Fig.�4c. Indeed, on the last day of the training phase, when EXP had reached the learning criterion, we found a difference in calling behavior between puffed and unpuffed trials. In six EXP-OBS pairs (on one day each), we inspected calling rates (defined as the probability of observing at least one call) during the stimulus period (from stimulus onset to stimulus offset) and during the delay period (defined from stimulus offset to air-puff onset), Fig.�4d. In puffed trials, the calling rate was lower in the delay period than in the stimulus period: stim call probability 0.44 [0.14, 0.88] vs delay call probability 0.27 [0.07, 0.45], median difference (Delay � Stim) ?0.15, p?=?3.8*10?6, test statistic?=?0, two-sided Wilcoxon sign rank test, n?=?6 EXP-OBS pairs. In unpuffed trials, there was merely a trend of reduced calling during the delay period: stim call probability 0.35 [0.08, 0.65] vs delay call probability 0.36 [0.16, 0.91], median difference 0.08 (Delay � Stim), p?=?0.052, test statistic?=?327, two-sided Wilcoxon sign rank test, n?=?6 EXP-OBS pair. In combination, the reduction in calling rate was much more pronounced during puffed trials: difference in median call probabilities for puffed (Delay � Stim) � unpuffed (Delay � Stim)?=??0.23, p?=?10?6, test statistic?=?592, two-sided Wilcoxon rank sum test, n?=?6 EXP-OBS pairs). Hence, the significant reduction in calling rates during puffed trials could signal the imminent arrival of an air puff. \n  To test whether observers used calls as a learning cue, we housed experimenters and observers (n?=?5 pairs) in separate soundproof boxes and gave them visual access to each other by virtue of two adjacent windows. Moreover, to trigger social interest, we allowed birds to vocally interact with each other using a custom digital communication system composed of two microphones and loudspeakers and an echo cancellation filter (Supplementary methods). We suppressed vocal exchanges during stimulus presentation by interrupting the communication system from stimulus onset to air-puff offset. We termed the observers in this paradigm no-trial-communication learners (-TCOM). Despite elimination of vocal interactions during the discrimination task, we found that -TCOM acquired stimulus-discriminative information in amounts comparable to OBS (trials to criterion: -TCOM (n?=?5): 800 [800, 4900]; OBS (n?=?9): 900 [800, 5600]; OBS � TCOM�median difference ?=?0.00001, p?=?0.77, test statistic?=?25, two-sided Wilcoxon rank sum test, 95% CI?=?[?1200 2300]), Fig.�4e. Hence, it follows that OBS did not require immediate vocal interactions. They could learn from visual displays only or from vocal exchanges following trials."
232756,5.0," Regularized logistic regression differentiates OBS from EXP \n  Observer behavior was reminiscent of a machine learning system that overfits the training data and generalizes poorly because it contains too many parameters and is trained on too few examples. In this sense, observers seemed to lack regularization, which is an umbrella term for all kinds of processes that prevent overfitting by introducing additional information, for example to use as few nonzero parameters as possible during fitting. Essentially, regularization methods improve generalization performance by dynamically regulating the use of parameters and of training data16,17. \n  In the context of our findings, these insights from statistical learning theory suggest that direct experience of the reinforcing learning cue is associated with regularization whereas observation is not. We tested the hypothesis that regularization could set the divide between experimenter and observer behaviors, by training a simple artificial neuron with a logistic activation function to discriminate between the two stimulus sets, Fig.�5a. The neuron received input from a group of at least 22 input neurons tuned to diverse sound features such as amplitude, pitch, duration, and Wiener Entropy, collectively defining the feature set used in Sound Analysis Pro (SAP), a popular birdsong analysis software18 (Supplementary Figure�4 and Supplementary Table�1). To model observers, we trained the neuron to fire during puffed stimuli and to remain silent during unpuffed stimuli. We used a gradient descent learning rule that maximizes the likelihood of correct discrimination (Methods). We found that the discriminative performance of the �observer� neuron increased rapidly to the theoretical limit on the training set, but when we interrupted the training at any time and evaluated the neuron�s performance on the testing set, we found poor generalization, Fig.�5b. The reason for poor generalization was that the neuron based its classification on exceedingly many sound features that by chance were slightly informative about the reinforcing air-puff, Fig.�5e and Supplementary Figure�4. \n  We then modeled experimenters by endowing the learning rule with L1 regularization. L1 regularization implements a conjunctive minimization of summed absolute synaptic weights17 that we implemented at each synaptic weight update as a small reduction of synaptic weights by an amount ?19. We used L1 regularization because it is very simple (subtractive) and because it allowed us to formulate a mechanism that dynamically regulates the regularization parameter ? in proportion to reward prediction error (Methods), known to be signaled in the vertebrate brain by a class of dopaminergic neurons20�22. According to our proposal, regularization (weight reduction) increases when the bird suddenly receives less reward than expected, as in experimenters that get hit by an air puff for the first time. Our proposed mechanism is such that when experimenters reach a high rate of success, the reward prediction error reaches zero in expectation, which settles the value of ?, Fig.�5c. The observer brain would not modulate ? because observers do not directly experience rewards and punishments during the experimenter training phase. \n  We found that interrupting the training process of the regularized neuron at any time resulted in roughly equal performances on both training and testing stimulus sets, Fig.�5d, similar to experimenters� behavior. However, the excellent generalization performance came at a cost: Because of the repeated reductions of synaptic weights in modeled experimenters, their synaptic weights and performance on the training set grew only slowly. The main effect of regularization was to concentrate the final synaptic weights on the duration feature, corresponding with our design of stimulus class, Fig.�5e. \n  We tested other explanations for the differences between experimenters and observers, such as assuming that observers learned from noisy experimenter actions, but found regularization to be the only mechanism that achieved satisfactory simulations results�(Supplementary Figure 5)."
1789181,0.0,"In this section, we first present the classification results of the proposed SOM-SNN framework for the two benchmark datasets and then compare them with other baseline models. Next, we discuss its early decision-making capability, the effectiveness of using the SOM for feature representation and its underlying hyperparameters, as well as the key differences between the feedforward SNN-based and RNN-based systems for a temporal classification task. Finally, we demonstrate the improved classification capability of the modified Maximum-Margin Tempotron learning rule and the robustness of the framework against environmental and neuronal noises."
1789181,1.0," 3.1. Classification results \n 3.1.1. RWCP dataset \n  As shown in Table ?Table1,1, the SOM-SNN model achieved a test accuracy of 99.60%, which is competitive compared with other deep learning and SNN-based models. As described in the experimental set-up, the MLP and CNN models are trained using spectrogram images of fixed dimensions, instead of explicitly modeling the temporal transition of frames. Despite their high accuracy on this dataset, it may be challenging to use them for classifying sound samples of long duration; the temporal structures will be affected inconsistently due to the necessary rescaling of the spectrogram images (Gütig and Sompolinsky, 2009). On the other hand, the RNN and LSTM models capture the temporal transition explicitly. These models are however hard to train for long sound samples due to the vanishing and exploding gradient problem (Greff et al., 2017). \n  LSF-SNN (Dennis et al., 2013) and LTF-SNN (Xiao et al., 2017) classify the sound samples by first detecting the spectral features in the power spectrogram, and then encoding these features into a spatiotemporal spike pattern for classification by a SNN classifier. In our framework, the SOM is used to learn the key features embedded in the acoustic signals in an unsupervised manner, which is more biologically plausible. Neurons in the SOM become selective to specific spectral features after training, and these features learned by the SOM are more discriminative as shown by the superior SOM-SNN classification accuracy compared with the LSF-SNN and LTF-SNN models."
1789181,2.0," 3.1.2. Tidigits dataset \n  As shown in Table ?Table2,2, it is encouraging to note that the SOM-SNN framework achieves an accuracy of 97.40%, outperforming all other bio-inspired systems on the TIDIGITS dataset. In Anumula et al. (2018), Abdollahi and Liu (2011), and Neil and Liu (2016), novel systems are designed to work with spike streams generated directly from the AER silicon cochlea sensor. This event-driven auditory front-end generates spike streams asynchronously from 64 bandpass filters spanning over the audible range of the human cochlea. Anumula et al. (Abdollahi and Liu, 2011) provide a comprehensive overview of the asynchronous and synchronous features generated from these raw spike streams, once again highlighting the significant role of discriminative feature representation in speech recognition tasks. \n  Tavanaei et al. (Tavanaei and Maida, 2017a,b) proposes two biologically plausible feature extractors constructed from SNNs trained using the unsupervised spike-timing-dependent plasticity (STDP) learning rule. The neuronal activations in the feature extraction layer are then transformed into a real-valued feature vector and used to train a traditional classifier, such as the HMM or SVM models. In our work, the features are extracted using the SOM and then used to train a biologically plausible SNN classifier. These different biologically inspired systems represent an important step toward an end-to-end SNN-based automatic speech recognition system. \n  We note that the traditional RNN based system offers a competitive accuracy of 97.90% (Anumula et al., 2018); our proposed framework, however, is fundamentally different from traditional deep learning approaches. It is worth noting that the network capacity and classification accuracy of our framework can be further improved using multi-layer SNNs."
1789181,3.0," 3.2. Early decision making capability \n  We note that the SNN-based classifier can identify temporal features within the spatiotemporal spike pattern and generate an output spike as soon as enough discriminative evidence is accumulated. This cumulative decision-making process is more biologically plausible, as it mimics how human makes decisions. A key benefit of such a decision-making process is low latency. As shown in Figure ?Figure3A,3A, the SNN classifier makes a decision before the whole pattern has been presented. On average, the decision is made when only 50% of the input is presented. \n  Additionally, we conduct experiments on the SOM-SNN, RNN, and LSTM models, whereby they are trained on the full input patterns but tested with only a partial presentation of the input. The training label is provided to the RNN and LSTM models at the end of each training sequence by default as it is not clear beforehand when enough discriminative features have been accumulated. Likewise, the training labels are provided at the end of input patterns for the SNN classifier. For testing, we increase the duration of the test input pattern presented from 10 to 100% of the actual duration, starting from the beginning of each pattern. As shown in Figure ?Figure6B,6B, the classification accuracy as a function of the input pattern percentage increases more rapidly for the SNN model. It achieves a satisfactory accuracy of 95.1% when only 50% of the input pattern is presented, much higher than the 25.7 and 69.2% accuracy achieved by the RNN and LSTM models respectively. For the RNN and LSTM models to achieve early decision-making capability, one may require that the models be trained with partial inputs or output labels provided at every time-step. Therefore, SNN-based classifiers demonstrate great potential for real-time temporal pattern classification, compared with state-of-the-art deep learning models such as the RNN and LSTM."
1789181,4.0," 3.3. Feature representation of the SOM \n  To visualize the features extracted by the SOM, we plot the BMU activation sequences and their corresponding trajectories on the SOM for a set of randomly selected samples from class �bell5,� �bottle1,� and �buzzer� in Figure ?Figure4.4. We observe low intra-class variability and high inter-class variability in both the BMU activation trajectories and sequences, which are highly desirable for pattern classification. Furthermore, we perform tSNE clustering on the concatenated input vectors entering the SOM and the BMU trajectories generated by the SOM. In Figure ?Figure5A5A (input vectors entering the SOM), it can be seen that samples from the same class are distributed over several clusters in 2D space (e.g., class 7, 10). The corresponding BMU vectors, however, merge into a single cluster as shown in Figure ?Figure5B,5B, suggesting lower intra-class variability achieved by the SOM. The class boundaries for the BMU trajectories may now be drawn as shown in Figure ?Figure5B,5B, suggesting high inter-class variability. The outliers in Figure ?Figure5B5B maybe an artifact due to the uniform rescaling performed on BMU trajectories, a necessary step for tSNE clustering. \n  We note that the time-warping problem exists in the BMU activation sequences, whereby the duration of sensory stimuli fluctuates from sample to sample within the same class. However, the SNN-based classifier is robust to such fluctuations as shown in the classification results. The decision to fire for a classifying neuron is made based on a time snippet of the spiking pattern; such is the nature of the single spike-based temporal classifier. As long as the BMU activation sequence stays similar, duration fluctuations of input sample will not affect the general trajectory of the membrane potential in each output neuron; the right classification decision, therefore, can be guaranteed. Hence, those outliers in Figure ?Figure5B5B underlying the time-warping problem may not necessarily lead to poor classification. \n  To investigate whether the feature dimension reduction of the SOM is necessary for the SNN classifier to learn different sound categories, we performed experiments that directly input the spike trains of the latency-encoded (20 neurons) (Yu et al., 2013b) or population-encoded (144 neurons) (Bohte et al., 2002) mel-scaled filter bank outputs into the SNN for classification. We find that the SNN classifier is unable to classify such low-level spatiotemporal spike patterns, and only achieve 10.2 and 46.5% classification accuracy for latency- and population-encoded spike patterns, respectively. For both latency- and population-encoded spike patterns, as all encoding neurons spike in every sound frame, albeit with different timing, the synaptic weights therefore either all strengthen or all weaken in the event of misclassification as defined in the Tempotron learning rule. Such synchronized weight updates make it challenging for the SNN classifier to find discriminative features embedded within the spike pattern. \n  As summarized in the section 1, the learning rules for the SNN can be categorized into either membrane-potential based or spike-time based; the Maximum-Margin Tempotron learning rule belongs to the former. To study the synergy between the SOM-based feature representation and spike-time based learning rule, we conducted an experiment using the ReSuMe (Ponulak and Kasi?ski, 2010) learning rule to train the SNN classifier. For a fair comparison with the Maximum-Margin Tempotron learning rule, we use one output neuron to represent each sound class and each neuron has a single desired output spike. To determine the desired spike timing for each output neuron, we first present all training spiking patterns from the corresponding sound class to the randomly initialized SNN; and monitor the membrane potential trace of the desired output neuron during the simulation. We note the time instant when the membrane potential trace reaches its maximum (denoted as Tmax) for each sound sample, revealing the most discriminative local temporal feature. We then use the mean of Tmax across all 20 training samples as the desired output spike time. As shown in Table ?Table1,1, the SNN trained with ReSuMe rule achieves a classification accuracy of 97.0%, which is competitive with other models. This, therefore, demonstrates the compatibility of features extracted by the SOM and spike-time based learning rules, whereby the intra-class variability of sound samples is circumvented by SOM feature extraction such that a single desired spike time for each class suffices. \n  We note that the SOM functions as an unsupervised sparse feature extractor that provides useful, discriminative input to downstream ANN classifiers. As shown in Table ?Table1,1, the classification accuracy of the SOM-RNN model is better than that of the RNN model alone, and the accuracy of the SOM-LSTM model is also comparable to that of the LSTM model. Additionally, we also notice faster training convergence for both the SOM-RNN and SOM-LSTM models compared to those without the SOM, requiring approximately 25% less number of epochs. This observation may be best explained by the observations made in Figure ?Figure4,4, whereby only a subset of the SOM neurons are involved in the spiking patterns of any sound sample (with low intra-class variability and high inter-class variability) which in itself is highly discriminative. \n  To analyze the effect of different hyperparameters in the SOM on classification accuracy, we perform the following experiments: \n  Neural Map Size. We sweep the SOM neural map size from 2 × 2 to 16 × 16. As shown in Figure ?Figure6,6, we notice improved SNN classification accuracy with larger neural map, which suggests that a larger SOM captures more discriminative features and therefore generates more discriminative spiking patterns for different sound classes. However, the accuracy plateaus once the number of neurons exceeds 120. We suspect that with more neurons the effect of the time-warping problem starts to dominate, leading to more misclassification. Hence, the optimum neural map size has to be empirically determined. \n  Number of Training Epochs. We sweep the number of training epochs used for the SOM from 100 to 1,000 with an interval of 100. We observe improvements in classification accuracy of the SNN classifier, with more training epochs of the SOM, which plateaus at 400 for the RWCP dataset. \n  Number of Activated Neurons. We perform experiments with different number of activated output neurons K = [1, 2, 3] for each sound frame. Specifically, the distances between the SOM output neurons' synaptic weight vectors and the input vector are computed, and the top K neurons with the closest weight vectors will emit a spike. The neural map sizes are swept from 2 × 2 to 16 × 16, with number of training epochs fixed at 400. As shown in Figure ?Figure6,6, with more activated output neurons in the SOM, the SNN achieves lower classification accuracy for neural map size below 100, while achieving higher accuracy for neural map size larger than that. It can be explained by the fact that for smaller neural maps, given the same number of feature clusters, fewer neurons are allocated to each cluster. Now, with more activated neurons per frame, either fewer clusters can be represented, or the clusters are now less distinguishable from each other. Either way, inter-class variability is reduced, and classification accuracy is adversely affected. This capacity constraint is alleviated with a larger neural map, whereby neighboring neurons are usually grouped into a single feature cluster. As shown in the inset of Figure ?Figure6,6, for neural map size larger than 100, more activated neurons per frame improves the feature representation with some redundancy and lead to better classification accuracy. However, it should be noted that with more activated neurons per frame, there are more output spikes generated in the SOM, hence increasing energy consumption. Therefore, a trade-off between classification accuracy and energy consumption has to be made for practical applications."
1789181,5.0," 3.4. Tempotron learning rule with hard maximum-margin \n  As described in section 2, we modify the original Tempotron learning rule by adding a hard margin ? to the firing threshold Vthr. With this modification, we note that the classification accuracy of the SNN increases by 2% consistently with the same SOM dimensions. \n  To demonstrate how the hard margin ? improves classification, we show two samples which have been misclassified by the SNN classifier trained with the original Tempotron rule (Figures 7A,B), but correctly classified by the Maximum-Margin Tempotron rule (Figures 7C,D). In Figure ?Figure7A,7A, both output neurons (i.e., �ring� and �bottle1�) are selective to the discriminative local feature occurring between 2 and 10 ms. While in Figure ?Figure7B,7B, the discriminative local feature is overlooked by the desired output neuron, possibly due to the time-warping, and the output neuron representing another class fires erroneously afterward. \n  When trained with the additional hard margin ?, the negative output neuron representing the �bottle1� class is suppressed and prevented from firing (Figure ?(Figure7C).7C). Similarly, the negative output neuron representing the �metal15� class is also slightly suppressed, while the positive output neuron representing the �kara� class undergoes LTP and correctly crosses the Vthr (Figure ?(Figure7D).7D). Therefore, the additional hard margin ? ensures a better separation between the positive and negative classes and improves classification accuracy. \n  Since the relative ratio between the hard margin ? and the firing threshold Vthr is an important hyper-parameter, we investigate its effect on the classification accuracy using the RWCP dataset by sweeping it from 0 to 1.2 with an interval of 0.1. The experiments are repeated 20 times for each ratio value with random weight initialization. For simplicity, we only study the symmetric cases whereby the hard margin has the same absolute value for both positive and negative neurons. For the case when the ratio is 0, the learning rule is reduced to the standard Tempotron rule. As shown in Figure ?Figure8,8, the hard margin ? improves the classification accuracy consistently for ratios below 1.0, and the best accuracy is achieved with a ratio of 0.5. The accuracy drops significantly for ratio above 0.9, suggesting a high level of margin may interfere with learning and lead to brittle models."
1789181,6.0," 3.5. Robustness to noise \n 3.5.1. Environmental noise \n  We report the classification accuracies over 10 runs with random weight initialization in Tables ?Tables3,3, ?,44 for mismatched and multi-condition training respectively. \n  We note that under the mismatched condition, the classification accuracy for all models degrades dramatically with an increasing amount of noise and falls below 50% with SNR at 10 dB. The LSF-SNN and LTF-SNN models use local key points on the spectrogram as features to represent the sound sample, and are therefore robust to noise under such conditions. However, the biological evidence for such spectrogram features is currently lacking."
1789181,7.0," 3.5.2. Spike jittering As shown in Table ?Table4,4, multi-condition training effectively addresses the problem of performance degradation under noisy conditions, whereby MLP, CNN, LSTM, and SOM-SNN models have achieved classification accuracies above 95% even at the challenging 0 dB SNR. Similar to observations made in McLoughlin et al. (2015), we note that the improved robustness to noise comes with a trade-off in terms of accuracy for clean sounds, as demonstrated in the results for the ANN models. However, the classification accuracies improve across the board for the SOM-SNN model under all acoustic conditions using the multi-condition training, achieving an accuracy of 98.7% even for the challenging case of -5 dB SNR. The SOM-SNN model hence offers an attractive alternative to other models especially when a single trained model has to operate under varying noise levels. \n  3.5.2. Spike jittering \n  As shown in Figure ?Figure9A,9A, the SOM-SNN model is shown to be highly robust to spike jittering and maintains a high accuracy independent of the number of neurons activated per sound frame in the SOM. We suspect that given only a small subset of neurons in the SOM are involved for each sound class, the requirement of the SNN for precise spike timing is relaxed."
1789181,8.0," 3.5.3. Spike deletion \n  As shown in Figure ?Figure9B,9B, the SOM-SNN model maintains a high classification accuracy when spike deletion is performed on the input to the SNN. As only a small subset of pre-synaptic neurons in the SOM deliver input spikes to the SNN for each sound class, with high inter-class variability, the SNN classifier is still able to classify correctly even with some input spike deletion. The peak membrane potential value is used in some cases to make the correct classification."
271920,0.0,"Sound-to-symbol mapping learning outcomes \n When learning outcomes were examined in all bilinguals and monolinguals, including individuals who performed below 65% accuracy, statistically equivalent performance was found between bilinguals' post-training accuracy (M = 71.5%, SD = 16.3) and monolinguals' post-training accuracy (M = 76.1%, SD = 13.1), t(65) = 1.2, p > 0.1. However, a chi-squared test examining the distribution of low-accuracy performers (<65%) across bilinguals and monolinguals was marginally significant, Chi-Squared (df = 1) = 3.8, p = 0.051, suggesting different distributions of lower learning outcomes in the bilinguals vs. monolinguals (see Participants Section). Nonparametric independent samples Mann�Whitney U tests suggested that the bilingual learners and non-learners differed on post-training and overall processing accuracies (ps < 0.001), showed a marginal difference on numbers reversed performance (p = 0.076, learners: M = 16.9, SE = 0.7; non-learners: M = 14.5, SE = 1.2), but did not differ on the remaining language history, cognitive, and linguistic measures listed in Table ?Table11. \n  When participants with overall accuracy below 65% were excluded, bilinguals (n = 27) and monolinguals (n = 27) reached similar post-training accuracies (monolinguals: M = 77.6%, SE = 2.2; bilinguals: M = 77.1%, SE = 2.1), t(52) = 0.16, p > 0.5, and response times (monolinguals: M = 3900.7 ms, SE = 215.4; bilinguals: M = 4417.8 ms, SE = 215.4), t(52) = 1.7, p = 0.1. Examination of post-training accuracies showed that monolinguals and bilinguals had equivalent mastery of the timbre dimension [main effect of group: F(1, 52) = 1.8, p > 0.1; group × timbre interaction: F(1, 52) = 0.089, p > 0.5], the pitch dimension [main effect of group: F(1, 52) = 1.8, p > 0.1; group × pitch interaction: F(1, 52) = 0.05, p > 0.5], and the duration dimension [main effect of group: F(1, 52) = 1.9, p > 0.1; group × duration interaction: F(1, 52) = 1.4, p > 0.1]. These findings suggested equivalent mastery of the learned symbolic system. Further, more efficient performance on tone-to-symbol mappings (response times divided by proportion correct) was associated with higher scores on the receptive vocabulary tasks in both monolinguals (PPVT: r = ?0.46, p < 0.05) and bilinguals (PPVT: r = ?0.36, p = 0.063; TVIP: r = ?0.22, p > 0.1; combined PPVT/TVIP: r = ?0.34, p = 0.087), suggesting that previous vocabulary knowledge is positively associated with learning success in the novel symbol system in terms of both higher accuracy rates and faster retrieval times. No associations were found between learning outcomes and performance on the matrix reasoning subtest of the WASI (ps > 0.5), numbers reversed (ps > 0.1), or on the Test of Auditory Discrimination (ps > 0.5)."
271920,1.0," Processing and competition resolution during sound-to symbol mapping \n Sound-to-symbol mapping, competition resolution and previous vocabulary knowledge \n  To examine target identification during processing of similar tone-to-symbol mappings, a mixed linear model was employed with fixed effects including trials with and without competitor symbols (competitor, filler; baseline: filler) and language group (bilingual, monolingual; baseline: monolingual). In addition, z-transformed PPVT scores were entered as a continuous predictor variable. Finally, participants and items (target type) were entered as random effects on the slope. Findings yielded a main effect of competitor, with longer and less accurate responses to competitor trials (M = 3663.0 ms/proportion correct, SE = 118.6) than to filler trials (M = 3388.8 ms/proportion correct, SE = 105.1), b = ?608.7, SE = 295.5, p < 0.05. In addition, a main effect of vocabulary skill was found, with higher PPVT skills associated with quicker and more accurate responses (b = ?44.6, SE = 295.8, p < 0.05). Finally, an interaction emerged between language group and PPVT, with a stronger association between target identification efficiency and PPVT performance in monolinguals (R2 = 0.209) relative to bilinguals (R2 = 0.025, see Figure ?Figure5),5), b = ?980.8, SE = 533.8, p = 0.05. No other effects were significant. \n  To examine the possibility that receptive vocabulary in Spanish, or in Spanish and English combined, would be a better predictor of performance in bilinguals, mixed linear models were created with performance on the Spanish TVIP and with combined performance on the PPVT and TVIP. No significant effects emerged for bilinguals involving either the TVIP or the combined PPVT and TVIP (all ps > 0.1). Together, findings suggest that (1) competition resolution during processing of novel symbolic information was comparable across bilinguals and monolinguals, (2) previous vocabulary knowledge did not influence competition resolution, and (3) previous vocabulary knowledge did influence overall response efficiency on the novel processing task, but more so in monolinguals than bilinguals. \n   Sound-to-symbol mapping, competition resolution and previous success in learning symbolic information \n  To examine the influence of learning success on target identification efficiency and competition resolution, previous symbolic learning success (z-transformed post-training accuracy) was entered into the previously-described mixed linear model instead of vocabulary skill. In addition to the previously-described main effect of competitor (b = ?600.9, SE = 286.6, p < 0.05), a main effect of training success was identified: Greater learning success was associated with greater tone-to-symbol retrieval efficiency, b = ?820.3, SE = 307.4, p < 0.01. This pattern was of statistically equivalent magnitude in bilinguals (R2 = 0.203) and monolinguals (R2 = 0.304), see Figure ?Figure6.6. No other effects were significant. Thus, (1) previous learning success did not influence competition resolution, yet (2) previous learning success did influence overall response efficiency on the novel processing task, an effect that did not differ across monolinguals and bilinguals. \n   Priming: residual activation of sound-to-symbol targets and competitors"
271920,2.0,"Residual inhibition of competitor symbols \n  To examine residual inhibition of competitor symbols after target identification, a mixed linear model was employed with fixed effects including priming probes placed in previous baseline and competitor locations (baseline, competitor; baseline: baseline) and inter-stimulus interval (200, 500, 800; baseline: 200), as well as language group (bilingual, monolingual; baseline: monolingual). In addition, z-transformed PPVT scores and post-training accuracies were separately entered as continuous variables. Finally, participants were entered as random effects on the slopes of both competitor and inter-stimulus interval effects. Results yielded an interaction between competitor location and inter-stimulus interval: At 200 ms post-target identification, response efficiency was significantly longer and less accurate to competitor probes (M = 722 ms/proportion correct, SE = 16.9) than to baseline probes (M = 698.7, SE = 16.9), b = ?38.6, SE = 15.9, p < 0.05. This finding suggested residual inhibition of the competitor at 200 ms post-target identification. While the three-way interaction between language group, inter-stimulus interval, and priming probe did not reach significance, p > 0.1, planned follow-up contrasts suggested that the difference between competitor and baseline probes was significant for bilinguals, t(26) = ?2.6, p < 0.05, but not monolinguals, t(26) = ?1.9, p = 0.07. This finding suggests that, while both bilinguals and monolinguals showed patterns of residual inhibition at 200 ms post-target identification, this effect was somewhat more robust in bilinguals, see Figure ?Figure77. \n  In addition, an interaction between language group and PPVT performance was again present, b = ?114.6, SE = 35.4, p < 0.01: Monolinguals with higher PPVT scores responded to priming probes with greater efficiency (R2 = 0.227), while no such effect was present in the bilinguals (R2 < 0.001). Consideration of Spanish vocabulary in bilinguals did not change this pattern (combined PPVT and TVIP: R2 for bilinguals = 0.004; TVIP only: R2 for bilinguals = 0.016). Finally, when learning success was entered into the model instead of vocabulary knowledge, no effect involving learning success reached significance. Together, these findings suggest that (1) a pattern of residual inhibition was identified at 200 ms post-target identification but not at 500 or 800 ms, (2), these inhibition effects were particularly robust in bilinguals, and (3) neither receptive vocabulary knowledge nor symbol learning success modulated these inhibition effects."
271920,3.0," Residual facilitation of target symbols \n  To examine residual facilitation of target symbols after target identification, a mixed linear model was employed with fixed effects including priming probes placed in previous baseline and target locations (baseline, target; baseline: baseline) and inter-stimulus interval (200, 500, 800; baseline: 200), as well as language group (bilingual, monolingual; baseline: monolingual). In addition, z-transformed PPVT scores and post-training accuracies were separately entered as continuous variables. Finally, participants were entered as random effects on the slopes of both competitor and inter-stimulus interval effects. Findings yielded a main effect of priming probe location, with shorter and more accurate responses on target (M = 642.4 ms/proportion correct, SE = 14.2) than baseline probes (M = 700.2 ms/proportion correct, SE = 14.2), b = ?54.4, SE = 15.0, p < 0.001. When PPVT performance was entered into the model, we again found the previously described interaction between language group and PPVT, b = ?104.8, SE = 33.6, p < 0.01, R2bilinguals < 0.001; R2monolinguals = 0.226. In bilinguals, inclusion of the combined PPVT/TVIP score (R2 = 0.002) or the TVIP score (R2 = 0.014) did not alter this pattern. Finally, when learning success was entered into the model, no significant effects emerged involving training success. Together, these findings suggest robust residual target activation across language groups and inter-stimulus intervals."
271920,4.0," Associations between residual and Stroop inhibition \n  Finally, we examined the relation between residual competitor inhibition after tone-to-symbol identification and performance on a nonlinguistic Stroop task. Stroop performance was analyzed with a mixed linear model with fixed factors including condition (center, congruent, incongruent; baseline: center) and language group (bilingual, monolingual; baseline: monolingual), and with participants entered as a random effect on the slope. Results yielded a main effect of condition, with responses on congruent trials (M = 458.0 ms/proportion correct, SE = 8.1) significantly faster and more accurate than responses on center trials (M = 482.9 ms/proportion correct, SE = 8.2), b = ?24.7, SE = 9.0, p < 0.01, and with incongruent trials (M = 585.9 ms/proportion correct, SE = 8.1) significantly slower and less accurate than center trials, b = 111.0, SE = 9.0, p < 0.001. No other effects were significant, suggesting equivalent Stroop inhibition performance across the bilingual and monolingual groups. \n  Consistent with Blumenfeld and Marian (2011), negative priming effects were compared with the difference score between congruent and incongruent Stroop reaction times, with smaller effects reflecting better abilities to ignore location information. The z-transformed Stroop effect was entered as a continuous variable into the previously-presented mixed linear model examining priming probes. Since relations between residual inhibition and Stroop performance were of interest, the dependent variable in this model was the negative priming effect (baseline probes minus competitor probes). A three-way interaction emerged between language group, inter-stimulus interval, and Stroop performance: at 500 ms post-target identification, in bilinguals, a smaller Stroop effect was associated with less residual competitor inhibition, relative to monolinguals, b = 38.9, SE = 18.8, p < 0.05, R2bilinguals = 0.14, R2monolinguals = 0.02."
2617564,0.0,"1. Listener performance \n Behavioral results from all experiments are presented in the right column of Figure 2, with discrimination accuracy (proportion correct) on the ordinate and testing block number on the abscissa. Given that Orthogonal discriminability is predicted to recover by the end of the experiment, omnibus analysis of variance (ANOVA) tests are likely to result in Type II error. Consequently, to retain sensitivity to differences in discriminability across conditions at different phases of the experiment, results are analyzed using planned-comparison paired-sample t-tests."
2617564,1.0," a. Experiment 1 \n  Discrimination of Consistent pairs in the first block of testing (mean?=?0.67, s.e.?=?.01) was significantly better than discrimination of Orthogonal pairs (mean?=?0.60, s.e.?=?.03) (t 39?=?2.36, p<.025, Cohen's d?=?0.44; Figure 2B). While discrimination accuracy of Consistent pairs was numerically greater than that of Orthogonal pairs in the second (mean of 0.68 versus 0.63) and third testing blocks (0.69 versus 0.65), t-tests did not reach statistical significance (second block: t 39?=?1.58, p?=?.12; third block: t 39?=?1.27, p?=?.21). This pattern of results replicates Experiment 2 of Stilp et al. [22]; discrimination of Orthogonal test pairs is initially inferior to that of Consistent test pairs supporting a robust correlation, and performance recovers through further testing so that discrimination across conditions is comparable by the final testing block. It bears mention that in their Expt. 2 (r?=?0.97), Stilp et al. [22] report superior discrimination of Consistent sound pairs relative to Orthogonal sound pairs in the first as well as second testing block. Relative to that experimental design, Expt. 1 in the present report removes Single-cue stimuli while maintaining 18 Consistent sounds and 2 Orthogonal sounds yielding nearly the same correlation (r?=?0.98). In the present experiment, Consistent discrimination was significantly more accurate than Orthogonal discrimination in the first testing block (p<.025) with only a trend toward significance in the second testing block (p?=?0.12). It is unclear why the full pattern of significance was not fully replicated despite highly similar stimuli and correlation coefficients. Independent-samples t-test indicates that the difference in Consistent and Orthogonal discrimination in the second testing block did not significantly differ across experiments (t 78?=?0.73, p?=?0.47), suggesting patterns of results are not fundamentally different from one another. Results indicate that both the correlated and orthogonal dimensions appear to become weighted proportional to the amount of variance accounted for by each dimension."
2617564,2.0," b. Experiment 2 \n Discrimination of Consistent pairs in the first block of testing (mean?=?0.66, s.e.?=?.02) was again significantly better than discrimination of Orthogonal pairs (mean?=?0.60, s.e.?=?.03) (t 39?=?2.71, p<.01, Cohen's d?=?0.43; Figure 2D). Despite restricting the range of acoustic evidence supporting the correlation, this early difference in discrimination persisted. Experiment 2 also reveals that correlation among stimulus attributes need not be nearly perfect (r?0.97) for efficient coding to occur. Discrimination did not significantly differ in either the second (Consistent mean?=?0.71, s.e.?=?.02, Orthogonal mean?=?0.69, s.e.?=?.03; t 39?=?0.67, n.s.) or third block (Consistent mean?=?0.74, s.e.?=?.02, Orthogonal mean?=?0.77, s.e.?=?.02; t 39?=?1.27, n.s.). \n Unlike previous experiments, discrimination in both conditions improved markedly across testing blocks. Owing to the inability to separate learning (improvement throughout the experiment) from effects of the correlation between AD and SS on Orthogonal discriminability (initially inferior but later comparable to that of Consistent sound pairs), performance was assessed through paired-sample t-tests contrasting early versus late (i.e., first versus third testing block) discrimination of Consistent pairs, which are predicted to remain equally discriminable throughout the experiment. Consistent discrimination significantly improved from the first to third block of Experiment 2 (t 39?=?4.39, p<.0001, Cohen's d?=?0.60), but this learning effect was not consistent across experiments. Participants in Experiment 3 exhibited a significant but more modest learning effect for Consistent trials (t 39?=?3.23, p<.01, Cohen's d?=?0.35), but no significant differences were observed in Experiments 1, 4, or 5 (all t?1.21, n.s., Cohen's d<0.18). The magnitude of the learning effect in Experiment 2 may be due to one or both of the following factors. First, reducing variability in AD and SS cues by truncating the correlation may facilitate discrimination over time. Second, listeners in Experiment 2 were presented more repetitions of stimulus pairs in a given block (12) than in other experiments (8) in the effort to make overall number of trials comparable. Nevertheless, the principal finding is superior discrimination of Consistent pairs relative to Orthogonal pairs early in testing."
2617564,3.0,"c. Experiment 3 \n Unlike previous experiments, discrimination was comparable across Consistent (mean?=?0.63, s.e.?=?.01) and Orthogonal conditions (mean?=?0.61, s.e.?=?.02) in the first testing block (t 39?=?0.75, n.s., Cohen's d?=?0.12; Figure 2F). By testing more extreme Orthogonal test pairs (i.e., less similar to Consistent pairs), differences in discrimination observed in previous experiments were extinguished. Roughly equivalent discrimination persisted throughout the experiment (Block 2: Consistent mean?=?0.66, s.e.?=?.02, Orthogonal mean?=?0.64, s.e.?=?.02 [t 39?=?0.86, n.s.]; Block 3: Consistent mean?=?0.66, s.e.?=?.02, Orthogonal mean?=?0.64, s.e.?=?.02 [t 39?=?1.54, n.s.]). This demonstrates that efficient coding of correlated acoustic attributes is sensitive to the range of physical acoustic/psychoacoustic evidence inconsistent with the primary correlation and consistent with a second orthogonal dimension. Results also demonstrate that simple strength of the primary correlation is insufficient to attenuate discriminability of orthogonal stimulus differences, as all stimulus pairs presented in Experiment 3 (r?=?�0.83) were relatively equally discriminable, but pairs presented in Experiment 2 (r?=?�0.81) produced significant differences in early performance. The explanatory power of simple strength of correlation between acoustic attributes, absent consideration of both the quantity and quality (range) of evidence that is inconsistent with the correlation, is challenged by these results."
2617564,4.0,"d. Experiment 4 \n Despite a three-fold increase in presentations, discrimination of the Orthogonal pair (mean?=?0.59, s.e.?=?.02) was still significantly worse than that of Consistent pairs (mean?=?0.63, s.e.?=?.01) in the first testing block (t 39?=?2.06, p<.05, Cohen's d?=?0.37; Figure 2H). This negligible effect of probability sheds light on the results of Experiment 3, that efficient coding was likely extinguished due to increased range of acoustic evidence supporting orthogonal variability and not the concurrent increase in Orthogonal test trials. Similar to previous experiments, performance across conditions was equivalent in the second (Consistent mean?=?0.64, s.e.?=?.02, Orthogonal mean?=?0.64, s.e.?=?.02 [t 39?=?0.36, n.s.]) and third testing blocks (Consistent mean?=?0.64, s.e.?=?.01, Orthogonal mean?=?0.61, s.e.?=?.02 [t 39?=?1.58, n.s.])."
2617564,5.0," e. Experiment 5 \n Even with ten-fold oversampling, discrimination of the Orthogonal pair (mean?=?0.60, s.e.?=?.02) was modestly worse than that of Consistent pairs (mean?=?0.63, s.e.?=?.01) in the first testing block (t 39?=?1.87, p?=?.07, Cohen's d?=?0.36; Figure 2J). It bears note that paired-sample t-tests used in all analyses are two-tailed. One could use a one-tailed t-test based on the prediction that discrimination of Consistent pairs will be greater than that of Orthogonal pairs, in which case the difference would be statistically significant (one-tailed p<.05). However, performance in the first block does not significantly differ in Experiment 5 versus Experiment 3 as indicated by independent samples t-tests on orthogonal discrimination performance (t 78?=?0.63, n.s.) and differences between Consistent and Orthogonal discrimination (t 78?=?0.71, n.s.). Perhaps surprisingly, testing the Orthogonal sound pair ten times as often as any Consistent sound pair failed to produce practice effects sufficient to promote Orthogonal discrimination exceeding Consistent discrimination (second block: Consistent mean?=?0.64, s.e.?=?.02, Orthogonal mean?=?0.62, s.e.?=?.02 [t 39?=?0.69, n.s.]; third block: Consistent mean?=?0.64, s.e.?=?.01, Orthogonal mean?=?0.62, s.e.?=?.02 [t 39?=?0.54, n.s.]). Thus, the conservative conclusion one can draw from this marginal effect is that manipulation of Orthogonal stimulus probability has little effect on listener discrimination."
2617564,6.0,"2. Model predictions \n a. Experiment 1 \n Predictions from the PCA models are presented in the first column of Figure 4, with Euclidean distance between Consistent (black) versus Orthogonal (grey) stimulus pairs on the ordinate and training epoch on the abscissa. Simulation timecourses for correlation-matrix-based (solid lines) and covariance-matrix-based (dashed lines) models are scaled to share comparable abscissas. Similar to [22], the PCA model quickly discovered the principal component (the Consistent dimension) and distances between Orthogonal pairs initially decreased considerably (Figure 4A). With further exposure to the stimulus set, the PCA model gradually captured the modest variance not explained by the first component, progressively increasing distances between Orthogonal pairs until reaching original relative values by the end of the simulation. Thus, the PCA model initially captures only variability along the principal component in the two-dimensional stimulus space at the expense of the orthogonal component, incrementally coming to capture remaining variance, matching the pattern observed in listener performance. Predictions from the correlation-based (solid lines) and covariance-based (dashed lines) versions of the PCA model were nearly identical, with a slightly larger initial decrease in Orthogonal distances predicted by the covariance model. \n Simulation results using the choice model are depicted in the middle (correlation) and right (covariance) columns of Figure 4, with percent correct discrimination along the ordinate and testing block number along the abscissa. Predictions across 40 simulations exhibited markedly less variability than listener data, but patterns of results remain excellent fits to human performance. Both correlation and covariance models predicted significantly poorer discrimination of Orthogonal stimuli in the first block of testing (correlation model [Figure 4B]: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.58, s.e.?=?.006, t 39?=?14.92, p<1e-17, Cohen's d?=?3.15; covariance model [Figure 4C]: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.57, s.e.?=?.004, t 39?=?21.50, p<4e-23, Cohen's d?=?5.09). Marked improvement in Orthogonal discrimination was evident in the second block, but this was still inferior to Consistent discrimination (correlation model: Consistent: mean?=?0.69, s.e.?=?.007; Orthogonal: mean?=?0.65, s.e.?=?.005, t 39?=?5.23, p<6e-6, Cohen's d?=?1.19; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.63, s.e.?=?.004, t 39?=?10.12, p<2e-12, Cohen's d?=?2.38). Finally, Consistent and Orthogonal stimuli were relatively equally discriminable in the third block (correlation model: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.68, s.e.?=?.006, t 39?=?0.62, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.68, s.e.?=?.004, t 39?=?0.39, n.s.)."
2617564,7.0,"b. Experiment 2 \n The initial decrease in distance between Orthogonal stimuli is smaller and recovery to baseline distances sooner than that observed for Experiment 1 (Figure 4D). These outcomes are anticipated given simulation of a more weakly correlated stimulus set (r?=?�0.81). Simulations by Stilp et al. [22] and Experiment 1 suggest that principal and second components become weighted in proportion to the amount of covariance captured by each dimension, and model predictions for Experiment 2 reveal more weight being attributed to the second (Orthogonal) dimension as it captures relatively more unshared covariance here than in other, more highly-correlated stimulus sets. Both correlation-based and covariance-based models predict significantly poorer Orthogonal discrimination in the first testing block, but models make different predictions regarding the rate of recovery to baseline distances between stimuli. The correlation-based model predicts a more extended recovery, which contributes to a larger predicted effect size in the first block (Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.64, s.e.?=?.006, t 39?=?5.65, p<2e-6, Cohen's d?=?1.40; Figure 4E) than that predicted by the covariance-based model (Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.65, s.e.?=?.005, t 39?=?4.95, p<2e-5, Cohen's d?=?1.12; Figure 4F), which predicts more rapid recovery to baseline distances. Nevertheless, both models correctly predict significantly poorer Orthogonal discrimination in the first testing block, and comparable discrimination in the second (correlation model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.68, s.e.?=?.007, t 39?=?1.12, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.62, n.s.) and third testing blocks (correlation model: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.69, s.e.?=?.005, t 39?=?0.38, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.48, n.s.), matching listener performance. Finally, neither version of the PCA model predicts overall improved performance later in the simulation (i.e., Euclidean distances in both conditions increasing over time) as observed in listener performance, suggesting insensitivity to some practice effects."
2617564,8.0,"c. Experiment 3 \n Both versions of the PCA model predict a shallow and very short-lived decrease in Orthogonal distances, with the vast majority of the simulation predicting equal discriminability across conditions (Figure 4G). Virtually identical simulation results both predict comparable performance across conditions in the first (correlation model [Figure 4H]: Consistent: mean?=?0.68, s.e.?=?.006; Orthogonal: mean?=?0.68, s.e.?=?.005, t 39?=?0.26, n.s.; covariance model [Figure 4I]: Consistent: mean?=?0.68, s.e.?=?.004; Orthogonal: mean?=?0.68, s.e.?=?.004, t 39?=?0.75, n.s.), second (correlation model: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.006, t 39?=?0.08, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.003; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.60, n.s.), and third testing blocks (correlation model: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.006, t 39?=?0.25, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.26, n.s.). These predictions mirror listener performance, and support the idea that both listeners and the model quickly exploited covariance in more extreme Orthogonal stimuli to discover the second component and facilitate Orthogonal discrimination."
2617564,9.0,"d. Experiment 4 \n Both versions of the PCA model predict a sizable initial decrease in Orthogonal distances before later recovery to original relative distances (Figure 4J). These predictions resemble those of Experiment 1, where the early difference in discrimination was both predicted and behaviorally observed, in contrast to those of Experiment 3, where largely equal discrimination throughout was both predicted and observed. Recovery to original relative distances for Orthogonal stimuli occurred much more quickly in Experiment 4 than Experiment 1, revealing some sensitivity to the fact that Orthogonal stimuli were sampled more frequently. Further, the covariance model predictions displayed a slightly larger magnitude of initial decrease in Orthogonal distances and slightly longer recovery to baseline distances than that observed for the correlation model, resulting in a slightly larger effect size in the first testing block (correlation model (Figure 4K): Consistent: mean?=?0.70, s.e.?=?.005; Orthogonal: mean?=?0.64, s.e.?=?.005, t 39?=?6.94, p<3e-8, Cohen's d?=?1.65; covariance model (Figure 4L): Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.63, s.e.?=?.005, t 39?=?7.85, p<2e-9, Cohen's d?=?1.89). Both versions of the model predicted equal discriminability in the second (correlation model: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.69, s.e.?=?.005, t 39?=?0.14, n.s.; covariance model: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.68, s.e.?=?.005, t 39?=?1.20, n.s.) and third testing blocks (correlation model: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.69, s.e.?=?.005, t 39?=?0.12, n.s.; covariance model: Consistent: mean?=?0.70, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.62, n.s.)."
2617564,10.0,"e. Experiment 5 \n The correlation-based PCA model predicts a shallow and very short-lived decrease in Orthogonal distances, with all but the first few epochs of the simulation predicting equal discriminability across conditions (Figure 4M). These predictions are identical to those made for Experiment 3, such that equal discriminability of Consistent and Orthogonal stimuli is predicted in all blocks of testing (Block 1: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.006, t 39?=?0.13, n.s.; Block 2: Consistent: mean?=?0.69, s.e.?=?.005; Orthogonal: mean?=?0.69, s.e.?=?.007, t 39?=?0.06, n.s.; Block 3: Consistent: mean?=?0.69, s.e.?=?.006; Orthogonal: mean?=?0.69, s.e.?=?.006, t 39?=?0.09, n.s.; Figure 4N). \n Similar to Experiment 4, the covariance-based PCA model predicts a slightly larger magnitude of initial decrease in Orthogonal distances and slightly longer recovery to baseline distances than that observed for the correlation model (Figure 4M). These differ from other model predictions in two significant ways. First, similar to listeners and unlike the correlation model, the covariance model predicts inferior discrimination of Orthogonal stimuli in the first testing block of Experiment 5 (Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.67, s.e.?=?.004, t 39?=?4.02, p<.0005, Cohen's d?=?0.87; Figure 4O). Second, the covariance model displays sensitivity to (and thus makes different predictions for) stimuli with the same correlation matrix but different covariance matrices (i.e., stimuli presented in Experiments 3 and 5). An independent-samples t-test confirms that the predicted difference in Consistent and Orthogonal discrimination in the first testing block of Experiment 5 (mean difference?=?.023) is significantly larger than the difference observed in the first block of Experiment 3 (mean difference?=?.005; t 78?=?2.11, p<.05). Predictions made by the correlation model for the first block of Experiment 3 versus Experiment 5 did not differ (independent-samples t-test on mean differences: t 78?=?0.28, n.s.). These results demonstrate that while the PCA model based on the correlation matrix of the inputs [26] is useful for predicting discriminability of some stimulus sets, the covariance-based PCA model is a better predictor of listener performance overall. Finally, the covariance model predicted comparable performance across conditions for remaining test blocks (Block 2: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.08, n.s.; Block 3: Consistent: mean?=?0.69, s.e.?=?.004; Orthogonal: mean?=?0.69, s.e.?=?.004, t 39?=?0.42, n.s.)."
2617564,11.0,"f. Across all experiments \n The predictive power of covariance-based PCA is further demonstrated through closed-form linear algebraic solutions in Table 1. Table 1 orders stimulus sets from Experiments 1�5 to reflect performance differences in discriminability of Consistent versus Orthogonal sound pairs in the first testing block as measured by effect size (rightmost column). Eigenvalues calculated from the correlation matrix versus covariance matrix of stimulus set before the simulation are also provided. The success with which listeners discriminate Orthogonal pairs is well predicted by the second Eigenvalue calculated from the covariance matrix reflecting true psychoacoustic distances: as the second Eigenvalue increases, greater perceptual weighting is reflected in improved listener performance on Orthogonal trials and subsequently decreased effect sizes early in the experiment (r?=??0.95, p<.025). This relationship with performance is not observed for the second Eigenvalue of correlation matrices, the first Eigenvalue of correlation or covariance matrices, or simple strength of the principal correlation. The relationship between the second Eigenvalue of the covariance matrix and effect size is similarly robust if calculated on model representations of the inputs after the first one-third of the simulation (akin to the first testing block for listeners; r?=??0.94, p<.025). No other metric calculated after one-third of the simulation reliably predicts effect sizes for the first block of testing. While some caution is warranted in generalizing this relationship given that the second Eigenvalue can be increased by multiple manipulations (removal of Consistent sounds, addition of more extreme Orthogonal sounds, oversampling of Orthogonal sounds), it does provide promising extensions of the present work in optimal weighting of statistically derived dimensions in complex sounds."
1911559,0.0,"3.1. Auditory working memory \n Digit Span Backwards (DSB) raw ability scores were converted to standardized T?Scores and compared across groups using a one?way analysis of variance (ANOVA). No significant difference was found between groups; 6?years: Mean (SD) = 56.60 (9.89); 8?years = 54.03 (9.37); 10?years = 55.07 (9.92), (F(2, 180) = 1.07, p = .345), showing that participants in each group were performing at a cognitive level expected for their age."
1911559,1.0,"3.2. Multisensory Attention Learning Task (MALT) \n To examine performance across groups on aspects of sustained attention on the learning element of the MALT, trials to criterion and number of errors were calculated."
1911559,2.0,"3.2.1. Trials to criterion \n The mean number of learning trials on the MALT in order to reach the criterion of 50 correct target responses was calculated for each group. Results of a univariate ANOVA with two between?subjects factors of Age Group (3 levels: 6, 8, and 10) and Condition (3 levels: V, A, and AV) found a significant main effect of Age Group, F(2, 172) = 4.44, p = .013, partial ?2 = .05, but not of Condition (F < 1), with 6?year?olds requiring a significantly greater number of trials (Mean = 146.98, SD = 8.05) to reach criterion than 8?year?olds (Mean = 143.18, SD = 7.92), p = .025, and trend for more trials than 10?year?olds (Mean = 143.67, SD = 6.73), p = .055. No differences were seen between 8? and 10?year?olds (p > .05)."
1911559,3.0,"3.2.2. Errors on MALT \n A univariate ANOVA to analyse mean number of commission errors (i.e., incorrectly responding to a non?target item) across Age groups and Conditions (see Table 1) found a significant main effect of Age Group, F(2, 172) = 5.05, p = .007, partial ?2 = .06, but not Condition (F < 1), driven by 6?year?olds making significantly more commission errors than 10?year?olds, p = .009 (Bonferroni?corrected pairwise comparisons). \n  Mean number of omission errors (i.e., failing to respond to the correct target) across Age groups and Conditions (Table 1), analysed as above, found a significant main effect of Age, F(2, 172) = 4.59, p = .011, partial ?2 = .05, but not Condition (F < 1). Pairwise comparisons (Bonferroni?corrected) found 6?year?olds made significantly more omission errors than 8?year?olds (p = .015) and there was a trend for 6?year?olds to make more errors than 10?year?olds (p = .061)."
1911559,4.0,"3.2.3. Category identification test \n As a measure of incidental category learning, mean number correct on the category identification task was calculated for each age group and compared across learning condition (Figure 3). Results of a univariate ANOVA with two between?subjects factors of Age Group (3 levels: 6, 8, and 10) and Condition (3 levels: V, A, and AV) found no significant Age Group by Condition interaction (F < 1). However, significant main effects of Age Group, F(2, 168) = 5.23, p = .006, partial ?2 = .06, and Condition, F(2, 168) = 17.42, p < .001, partial ?2 = .17, were identified. Pairwise comparisons (Bonferroni?corrected) for Age Group found that 6?year?olds performed reliably below 10?year?olds (p = .007), with no differences between 6 and 8 years, or 8 and 10 years (p > .05, for all). For Condition, pairwise comparisons indicated that participants scored significantly higher following the Audiovisual learning condition (Mean = 14.07) than either the Auditory (Mean = 10.32) or Visual?only (Mean = 10.97) conditions (p < .001 for both). No difference was found between Auditory and Visual groups (p = .996). \n  To examine whether incidental categorization performance differed from chance, data were analysed for each Age group and Condition using one?sample t?tests with a test value of 8. Six?year?olds were found to score significantly above chance on the Visual?only (t(19)�=�2.73, p�=�.013) and Audiovisual (t(19)�=�4.23, p�<�.001) conditions, but not in the Auditory?only condition (p�=�.095). The 8? and 10?year?olds scored significantly above chance on all learning conditions (p�>�.05, for all), indicative of a high level of categorization performance in these groups across conditions. \n  An examination of the relationship (Pearson's r) between age (collapsed across groups) and performance on the category identification task for each condition indicated a significant positive correlation in the Audiovisual learning condition, r�=�.334, p�=�.011, and a trend for a positive correlation in the Auditory?only learning condition, r�=�.249, p�=�.055, but not in the Visual?only learning condition (p�=�.319). Data are presented in Figure�4. \n  An investigation of the relationships (Pearson's r) between incidental learning (total correct on category task) and auditory working memory (DSB), sustained attention skills (omission errors) and inhibitory control skills (commission errors) found no significant correlations across any age groups or conditions (p�>�.05, for all)."
1911559,5.0," 3.2.4. Explicit categorization knowledge test \n  As well as an examination of incidental knowledge, following the category identification task, each participant was asked to state verbally what they judged the differences between the two families of frogs to be and how they reached their categorization choices. Verbal responses were scored as follows; don't know/none given�=�0 points, related categorical description given but inaccurate (e.g., �they had different coloured spots�)�=�1 point, partially correct family description (i.e. citing 1 feature but not both in AV condition, e.g., number of spots, but no mention of auditory features)�=�2 points, fully correct family description (i.e. �different number of spots and different croak sounds� in AV condition or �croaks to log were deeper than croaks to lily pad� for A condition)�=�3 points. A mean explicit categorization score was calculated for each group and condition (Figure�5). Although a high correlation was found between incidental and explicit scores (r�=�.455, p�<�.001), results of a univariate ANOVA with two between?subjects factors of Age and Condition for explicit knowledge data indicate a different pattern of performance than seen in the incidental knowledge test. That is, although results found a main effect of Age Group, F(2, 172)�=�7.86, p�=�.001, partial ?2�=�.08, with 6?year?olds significantly less able to express the correct reason for categorizing than the older two groups (p�=�.002 and p�=�.003), no main effect of Condition, F(2, 172)�=�2.22, p�=�.112, partial ?2�=�.03, was found. This suggests that there is an age?related difference in the ability to verbally express categorization knowledge compared to the incidental learning element of the task."
1911559,6.0," 3.2.5. Discrimination task \n  To examine the saliency and discriminability level of the visual and auditory features of target exemplars, the same discrimination task as used in the initial pilot study (see above description in Stimuli discrimination) was conducted with 15 participants randomly selected from each age group (including five participants from each condition). Mean accuracy score for visual and auditory discriminators was calculated for each age group. Results of a one?way ANOVA found a significant difference across groups between visual and auditory score; F(2, 42)�=�4.17, p�=�.023, driven by 6?year?olds scoring significantly below 10?year?olds in visual discrimination. Paired samples t?tests to examine differences in visual and auditory accuracy scores for each age group separately revealed significantly lower visual than auditory discrimination ability only in 6?year?olds; Mean (SD) visual�=�11.33 (2.35), auditory�=�12.47 (1.46), t(14)�=�?2.20, p�=�.045. No significant difference between visual and auditory discrimination ability was found for 8?year?olds; Mean (SD) visual�=�13.07 (1.39), auditory�=�13.27 (.88), p�=�.647, or for 10?year?olds; Mean (SD) visual�=�13.33 (2.02), auditory�=�12.80 (2.51), p�=�.217."
271124,0.0,"The results are presented in three parts: (a) a comparison of total raw accuracy in pre-training vs. post-training tests, irrespective of Training Mode (AO/AV) and test mode (ao/av) in an Age (6 vs. 8 years) × Language Background (Bilingual vs. Monolingual) × Tone Language Experience (Tonal vs. Non-tonal) × (Mean Test Score � Pre-/Post-Training) design with repeated measures on Pre- vs. Post-Training scores; (b) an analysis of a percentage gain due to training dependent variable derived from the Pre- and Post-Test scores (see formula below) in an Age × Language Background × Tone Language Experience × Training Mode (AO/AV) × (ao vs. av Tests) design, with repeated measures on ao vs. av tests; and (c) a set of correlations between the phoneme deletion and word and non-word reading ability tests and with the pre- and post-tests and gain due to training for the three English-speaking groups (Mono-Eng, Bi-Eng/Arabic, Bi-Eng/Thai) for whom data on the phonological awareness and reading tests was collected."
271124,1.0,"Raw accuracy \n  Raw percentage correct data were first analyzed to show the absolute level of performance Post-Training compared to Pre-Training as a product of the group factors. A 2 × 2 × 2 × (2) Analysis of Variance (ANOVA) was conducted with Age, Language Background and Tone Experience as between-subject factors and Phase (Pre- vs. Post-training test), as the within-subject factor. All factors have two levels so no planned contrasts were required. Alpha was set at 0.05 and the effect sizes are given for significant differences (critical F = 3.898). \n  The results are graphically presented in Figure ?Figure2.2. As can be seen there was a general improvement from pre-training to post-training and this Phase main effect was significant, F(1,65) = 7.61, p < 0.01, ?p2 = 0.077, with Post-Training Mean = 28.43, and SD = 0.09, and Pre-Training Mean = 25.76, and SD = 0.06. \n  As can be seen in Figure ?Figure2,2, there was Pre- to Post-Training improvement for three of the four 6-year-old groups, and all of the four 8-year-old groups, with other interactions also apparent. Accordingly, while the Phase main effect was unaffected by Language Background, Monolingual vs. Bilingual, it was qualified by Age and Tone Experience: there was a Phase × Age, F(1,65) = 9.90, p < 0.005, ?p2 = 0.395, and a Phase × Age × Tone Experience, F(1,65) = 15.40, p < 0.001, ?p2 = 0.505, interaction. As can be seen in Figure ?Figure2,2, these interactions are due to (i) greater improvement from pre- to post-training by 8-year-olds than by 6-year-olds, and (ii) especially greater improvement for 8-year-olds with Tone Language experience, irrespective of whether the tonal experience is in a monolingual or bilingual context. \n  The decrease in performance from pre- to post-training by the monolingual tone language (Thai) 6-year-olds is puzzling. These children had just begun instruction in reading and writing at school, including learning the orthographic representation of Thai tones (a regular but complicated 4-way interaction of initial consonant class, final consonant manner, vowel length, and tone diacritics (Kasisopa et al., 2013, 2016; see Davis et al., 2015). It is possible that these, as yet non-automatic controlled, processes involved in learning the orthographic representation of Thai tones coupled with intensive training on foreign (Mandarin) tones, resulted in overload and confusion at the perceptual level interference from L1 phoneme-to-grapheme/grapheme-to-phoneme levels. This explanation is clearly speculative and requires further research."
271124,2.0," Performance gain \n  While the above analysis shows effects of training on tone perception, it may be noted that many of Pre- and some of the Post-test scores hover around chance level (25%, given there are 4 Mandarin tones). This raises the issue of the degree of improvement given the initial level of performance and the equivalence of improvements from an initial level of chance responding vs. a higher level of initial responding. To accommodate such differences a dependent variable was derived as follows: \n  Thus if a child had 20% correct on Pre-Training and 30% on Post-Training�the Performance Gain would be 50%; or if there was the same absolute increase of 10% from 50% on Pre-training to 60% on Post-training, the percentage improvement would be 20%. Thus this measure takes into account the initial level of performance in the pre-training test and represents the percent improvement in relation to that level. Mean and Standard Error Performance Gain for each of the four Language Background × Bilingual Status groups are shown for AO/AV training groups in ao and av tests in Figure ?Figure33 as well as in Table ?Table11 alongside the number and percentage of participants who showed pre- to post-training improvement in each group (see also Table B in the Supplementary Material for individual Performance Gain scores for each participant). \n  Performance Gain scores were analyzed in an Age × Language Background x Tone Experience × Training Mode between-subject factor × Test Type (ao or av) within-subject factor ANOVA. The only significant main effect was for Age, F(1,65) = 8.09, p < 0.01, ?p2 = 0.111. Age also interacted with two other factors: there was an interaction of Age × Tone, F(1,65) = 15.19, p < 0.001, ?p2 = 0.189, and of Age × Tone × ao/av test, F(1,65) = 9.54, p < 0.01, ?p2 = 0.128. This set of results is represented in Figure ?Figure4.4. As can be seen, 8-year-olds showed more Performance Gain than 6 year-olds. There was more Performance Gain for Tone language than Non-Tone language background children, but this was only evident in the 8-year-olds. Finally, while the Tone > Non-Tone advantage for 8-year-olds was evident in both ao and av tests, Performance Gain was greater when indexed in ao tests. \n  The above Age and Tone Language background results are independent of whether the children were monolingual or bilingual and whether they were trained with AO or with AV stimuli. Turning to Training Mode and Monolingual/Bilingual, the Training Mode and Monolingual/Bilingual interaction, and the Training Mode × Monolingual/Bilingual × ao/av interaction were both very close to significance Training Mode × Monolingual/Bilingual, F(1, 65) = 3.91, p > 0.05, ?p2 = 0.057; Training Mode × Monolingual/Bilingual × ao/av tests, F = 3.76, p>0.05, ?p2 = 0.055 (critical F = 3.98). Given these close to significant interactions and the significant interaction of ao vs. av tests with Age and Tone Language results above, and in order to avoid a Type II error in this first test of the effect of training mode on lexical tone perception, these two approaching significance results were followed up in simple effect tests of Training Mode × Monolingual/Bilingual at each level of the test type, ao tests and av tests. These revealed a non-significant Training Mode × Monolingual/Bilingual interaction for av tests, F(1, 65) = 0.70, p > 0.1, ?p2 = 0.011, but a significant Monolingual/Bilingual interaction for ao tests, F(1, 65) = 5.19, p < 0.03, ?p2 = 0.074. This set of results is represented in Figure ?Figure5.5. As can be seen Bilingual participants show greater Performance Gain after training with AO stimuli, whereas Monolingual participants show greater Performance Gain after training with AV stimuli, and this is especially the case when indexed by ao test trials."
271124,3.0," Correlations with phonological awareness and reading \n  Correlations, with age partialed out, between the phoneme deletion, word and non-word reading tests with the pre-training, post-training, and performance gain due to training were conducted for the three groups with English as one of their languages (Mono-Eng, Bi-Eng/Arabic, Bi-Eng/Thai). \n  There were, not surprisingly, correlations between the three language measures �phoneme deletion and word reading r(62) = 0.50, p < 0.001, phoneme deletion and non-word reading r(62) = 0.59, p < 0.001, and word and non-word reading, r(62) = 0.75, p < 0.001. \n  More important are correlations between any of the three language measures and the tone training scores. The only significant correlation of this nature was between phoneme deletion and the pre-training av-test, r(62) = 0.26, p < 0.05. This indicates that children's phonological awareness, in this case their proficiency on a phoneme deletion task, is positively related to their initial identification of the four Mandarin tones presented in auditory-visual mode."
1303382,0.0,"2.1. Assessment of Task Specific Variations in Frequency Discrimination Abilities \n Figure 1 and Table 1 summarise performance of the three groups of participants on the two psychophysical tasks (2I_6A_X versus 3I_2AFC). \n  First, regardless of group, there is considerable individual variation in discrimination thresholds for both task designs and for each ISI in the 2I_6A_X task. Though contrary to prediction, individual variations in JND are less marked for the 3I_2AFC compared to any ISI condition in the 2I_6A_X task. \n  To explore the differences among the two tasks, the data from the 2I_6A_X task for the ISI = 200 ms condition were entered into a repeated-measures ANOVA with the data from the 3I_2AFC task. This ISI condition was most similar to that of the 3I_2AFC task. Confirming the impression that participants obtained better overall JNDs with the 3I_2AFC than the 2I_6A_X task, a significant effect was observed for Task (F(1, 73) = 57.88, p < 0.001, ?2 = 0.442). There was also a significant main effect for Group (F(2, 74) = 7.65, p < 0.001, ?2 = 0.173, ? = 0.879) reflecting both lower JNDs and reduced individual variation in performance in the student group for both tasks. \n  The mean thresholds for the 2I_6A_X task increase with increasing ISI in all three groups. To investigate this last effect further, the data from this task were entered into a repeated-measures ANOVA with ISI (10, 200, 1000 ms) as the within-subjects measure and Group (Par-TD, Par-LI, Student) as the between-subjects measure. Mauchly�s test of sphericity was significant (p = 0.007) and degrees of freedom were adjusted using Greenhouse-Geisser correction factors. A significant effect was observed for ISI reflecting the progressive increase in discrimination threshold with increasing ISI (F(1.78, 131.32) = 58.89, p < 0.001, ?2 = 0.443, ? = 0.887). Post hoc Bonferroni tests indicated that mean thresholds for all three ISIs differed significantly from each other. There was also a significant main effect for Group (F(2, 74) = 3.486, p < 0.05, ?2 = 0.086, ? = 0.635), reflecting the lower thresholds observed among the student group. The two parent groups had comparable JNDs. There was no significant Group x ISI interaction (i.e., JNDs for all three groups were similarly affected by increasing ISI). "
1303382,1.0," 2.2. Training Effects on JND Estimation in the 2I_6A_X Task \n  Neither the large variability in JNDs measured using the 2I_6A_X task, nor the lower JNDs for the 3I_2AFC task, were predicted at the outset of the study. Initial piloting with students suggested that the 2I_6A_X task was procedurally more difficult than the 3I_2AFC task. The study protocol was consequently set so that the 3I_2AFC task was always presented first. Then the ISI = 400 ms condition was used as a training session for the 2I_6A_X task and each condition started with four condition specific training trials. This testing protocol was expected to minimise any training effects on performance for the 2I_6A_X task. However, varying degrees of experience with the 2I_6A_X task may still have contributed to the individual variation observed, since the order of presentation of the remaining ISI conditions in the task was randomised. The data were therefore entered into a repeated-measures ANOVA, ISI (3) × Group (3) × Order (6) to test for such effects. A significant effect for ISI was found (p < 0.001), but there was no effect (or indeed any trend) for order of presentation of ISI condition. There was also no significant interaction between Order × Group. Thus individual differences in experience with the task did not significantly contribute to the broad individual variation observed in performance on it."
1303382,2.0," 2.3. Task-Specific Susceptibility to Individual Differences \n  To investigate susceptibility of the two different task designs to individual differences in musical experience (listening and training), nonverbal IQ (NVIQ) and SES, these variables were entered as predictors (forced entry) into a series of multiple linear regression analyses with ln(JND) for each task/ISI condition as outcome measure. Initial models were optimised to retain only those predictors that significantly contributed to each outcome measure. \n  The data were first checked for evidence of significant multicollinearity between predictors (correlations greater than 0.8), or correlation between errors (Durbin-Watson statistic, values less than 1 or greater than 3). The effect of influential cases was assessed by checking for data points where Cook�s distances were greater than 1, Mahalanobis distances were greater than 15, or leverage values were greater than twice the average leverage value (i.e., for the 2I_6A_X task > 0.08; for the 3I_2AFC task > 0.05). One participant was excluded from the 2I_6A_X dataset because of a marked bias for responding �different� (d? = 2.15, criterion c = ?0.84) resulting in very low JND estimates which contrasted with the JND observed for the 3I_2AFC task (172.5 Hz versus, for example, 3 Hz (ISI = 1000 ms)). \n  The regression weights for each analysis are summarised in Table 2. Predictors making nonsignificant contributions are shown to the right of the table. The inputs into the final models are bolded together with the amount of variance (R2) explained by each model. \n  SES and musical training were the only factors to significantly contribute to variance in JND estimates in the 2I_6A_X task. The amount of variance explained by these predictors increased with increasing ISI to a maximum of 43% for the longest ISI (1000 ms), as compared with an initial 27% for the shortest ISI (10 ms). The regression weights for musical training across the 200 and 1000 ms ISI conditions are equivalent. Musical training predicts more individual variation in JND in these two ISI conditions, than it does for the 10 ms ISI condition. SES explains more variation in JND for the 10 and 1000 ms ISI conditions, than it does for the 200 ms condition. \n  By contrast with the 2I_6A_X task, only musical training explained significant variance in JNDs for the 3I_2AFC task and the amount explained by it was considerably less than that explained by SES or musical training for any condition in the 2I_6A_X task. Overall, the 3I_2AFC task is less susceptible to individual differences in the factors assessed here than the 2I_6A_X task."
1303382,3.0," Effect of Different Task Requirements on Observed Threshold \n  If the higher thresholds and more variable performance in the 2I_6A_X task reflect the fact that it is more demanding than the 3I_2AFC task, then the participants who are least able to cope with the extra demands of the task will have the highest thresholds for it. They would therefore be expected to show the greatest amount of improvement in the easier task [21] which stresses their weaker cognitive skills less. To test this prediction, correlations were performed between threshold estimates obtained on the 2I task versus amount of improvement observed for the 3I task. Significant positive correlations (p < 0.001) were observed for all ISI conditions (ISI 10: r = 0.715; ISI 200: r = 0.724; ISI 1000: r = 0.731), confirming this prediction and suggesting that the 2I_6A_X task was inherently more difficult to do than the 3I_2AFC."
1303382,4.0," 2.4. Contribution of Frequency Discrimination to Nonword Repetition \n  To assess contributions of frequency discrimination to verbal short-term memory, discrimination thresholds in the 3I_2AFC task and the three ISI conditions of the 2I_6A_X task were entered into a multiple linear regression analysis (forced entry), with �schooling� (proxy for vocabulary knowledge), and �music training�. This latter factor was included in the model because of the relationship to frequency discrimination performance observed in this study, and also because musical training is thought to enhance efficiency of auditory processing and hence support language learning [33]. \n  Only two predictors explained significant variance in nonword repetition: schooling, and JNDs measured using the 3I_2AFC task. The three ISI conditions of the 2I_6A_X task demonstrated high multicollinearity (r ? 0.8) with each other which contrasted with the low correlations (<0.38) of each measure with the JNDs observed for the 3I task. None of the JNDs for any ISI condition explained significant variance in nonword repetition and they were deleted from the final model, together with musical training which also explained little or no variance in nonword repetition. Table 3 summarises the final regression model together with observations from the initial exploratory analyses. \n"
2521573,0.0," The ERP responses at FZ to the standard and deviant stimuli, together with the resultant difference waves are plotted in Figure 1 for each participant group."
2521573,1.0," Analysis of MMN amplitude and latency \n  As a first analysis, we compared the amplitudes of the MMN for the two groups of nonword-repeaters across the four deviants (Electrode × Deviant × Group). A significant main effect was found for Electrode [F(5, 53)?=?4.807, p?=?.001, ?2?=?0.312], but there was no main effect for Group nor did any interaction with Group approach significance. Thus the two groups did not differ in early consonant change detection. \n  In a similar analysis, peak latencies for the MMN responses were also compared between the groups. No significant main effects or interactions were obtained, i.e., the two groups did not differ in rate of processing during early consonant change discrimination."
2521573,2.0," Analysis of LDN amplitude and latency \n Figure 2 compares mean LDN and MMN amplitudes collapsed across the six electrodes for the two groups as a function of deviant. As illustrated, strong LDN responses were obtained to all four deviants in the good nonword-repeaters. By contrast, an attenuated LDN response to D3 was observed in the poor nonword-repeaters. \n  Statistical analyses showed that, in addition to a significant main effect for Electrode [F(5, 53)?=?5.725, p<.001; ?2?=?0.351], there was a significant main effect for Deviant [F(3, 53) 3.629, p<.01; ?2?=?0.165] and importantly, a significant Group × Deviant interaction [F(3, 55) 6.9, p<.01, ?2?=?0.273]. The analysis was repeated with the good nonword-repeaters subdivided into three groups of 14�15 participants each, and the interaction with deviant position was replicated, F (9, 165)?=?2.67, p?=?.006. The interaction was further explored by repeating the within-subjects analysis for good and poor nonword-repeaters separately. For the poor nonword-repeaters, there was a significant effect of deviant position, F (3,12)?=?7.7, p?=?.004, ?2?=?0.657, and specific contrasts revealed this reflected a significant quadratic term, F (1, 14)?=?8.2, p?=?.013, ?2?=?0.368, reflecting the bow-shaped function seen in the LDN. For the good nonword-repeaters, there was also a significant effect of deviant position, F (3, 41)?=?3.6, p?=?.022, ?2?=?0.207, but neither linear nor quadratic terms were significant (F-ratios<1). \n  This analysis was followed up with one sample t-tests on average mismatch responses across the six fronto-central electrodes to determine whether the LDN differed significantly from zero. For the good nonword-repeaters, a significant LDN was found at all syllable positions (i.e., for positions 1, 3, and 4, p<.001; for position 2, p<.01). By contrast, for the poor nonword-repeaters, LDN responses significantly greater than zero were recorded at positions 1, 2, and 4 (with p values of <.001), but not at position 3. In sum, there is a significant difference in magnitude of LDN response to consonant change between the two groups at the third syllable and this difference associates with differences in overall nonword repetition score. \n  To further test this association, we performed a correlation between nonword repetition score and mean LDN amplitude in response to the four deviants. A strong correlation was observed between nonword repetition score and mean LDN amplitude at syllable 3 only (r?=??0.407, p<.001), i.e., smaller LDN amplitudes at this position were associated with lower nonword repetition scores. \n  As with the MMN response, peak latencies were submitted to analysis to test for differences in rate of processing deviance detection between the two groups. Though a significant effect for Electrode was obtained [F(3, 55) 3.404, p?=?.01, ?2?=?0.243], there was no main effect for Group nor any interaction with Group suggesting similar rates of processing among the two groups during this stage of consonant change detection. \n  \n  \n  \n  \n "
2521573,3.0," Relationship of MMN to LDN \n  The LDN and the MMN are both elicited in response to a change in stimulus, yet only differences in LDN were associated with nonword repetition ability. A question thus arises regarding the extent to which these two negative deflections provide different information about the process of change discrimination in this paradigm. To assess this, mean MMN and LDN amplitudes across the six electrodes were calculated and a series of one-tailed Pearson product moment correlations were performed between the amplitudes of the two components for each deviant. We predicted a direct relationship between the two components if they reflected common processes. \n  Correlations between the LDN and the MMN amplitudes in response to deviant syllables 1, 2 and 3 fell far short of significance (r?=??.18, ?21, .00 respectively) when all participants were included in the analysis. The correlation between MMN and LDN for deviant syllable 4 when both groups were included was .34 (p?=?.009), which was significantly different from zero, even after Bonferroni correction (critical p-value of .012). \n  Correlations between the LDN and MMN amplitudes were also tested for each group separately applying the Bonferroni corrected critical p-value of 0.012. No evidence was found for significant correlations between LDN and MMN in the poor nonword-repeaters. In the good nonword-repeaters, weak correlations were observed between LDN and MMN at syllables 1 and 4 (r?=?.37, .32 respectively) which did not survive correction for multiple testing. \n  Overall, with the possible exception of the final syllable, the evidence for common processes being involved in the generation of the MMN and LDN responses was not compelling."
2521573,4.0," Family history and nonword repetition ability \n  There were more parents of children with SLI in the poor nonword-repeater group. This raises a question regarding the role of family history for SLI in our findings. To test this, LDN amplitude × Deviant was entered into a repeated measures analysis with Group × Family history (+FH, ?FH). The numbers are not sufficient for a powerful analysis, but no significant interaction was observed between family history and deviant position. A plot of the mean LDN amplitudes for each of the four groups (Figure 3) clearly demonstrates a reduction in LDN amplitude in response to the consonant change which, regardless of family history, occurs on the third syllable in the poor nonword-repeaters."
2562735,0.0, 1. Descriptives
2562735,1.0,"Grand average waveforms \n Figure 2 shows the grand average standard, deviant and MMR waveforms of the adults in the current study (right) and, for comparison, of the infants in [4] (left), at eight electrodes, for each Distribution Type (unimodal vs. bimodal) pooled over Standard Vowel. The figure confirms the negative polarity and the expected latency and fronto(central) scalp distribution of the adult MMN (Method section 6): the red curve, which is the MMR waveform, deviates in the negative direction (notice that negative polarities are plotted upwards) from the baseline between 150 and 250 ms, and seems to do so more at frontocentral sites then elsewhere. The figure also confirms that the infant MMR contains less pronounced peaks [55] and that its scalp distribution is less defined than in adults (e.g., [54], see also [4]). Also, in accordance with several previous studies (e.g., [25], [48]�[50]), the polarity of the infant MMR is positive."
2562735,2.0," Scalp distributions  \n Figure 3 depicts the scalp distributions, which were made in Praat [43], for the unimodally (top) and bimodally (bottom) trained adults in the current study (right) and, for comparison, for the infants in [4] (left). The adult distributions were measured between 167 and 217 ms after stimulus onset, i.e., in a 50-ms window around the average MMR latency (i.e., the time of the most negative voltage occurring in the grand average waveform at Fz between 150 and 250 ms), which was at 192 ms. The infant distributions were measured between 100 and 500 ms after stimulus onset (Method section 6). Just as the grand average waveforms in Figure 2, the topographies of the MMR in Figure 3 illustrate the adult negative polarity (always blue, never red) and frontocentral distribution (darkest blue at frontocentral sites). For the infants, the positive polarity (red) and less specified distribution (darkest colors are spread over the scalp) are clearest for the bimodally trained infants. The MMR was not significantly different from zero for the unimodally trained infants (details are provided in Results section 2)."
2562735,3.0," MMR amplitudes \n  The MMR amplitude in the overall window where the response was expected (i.e., between 150 and 250 ms after stimulus onset; see Method 6) was significantly negative for both the bimodally trained adults (mean?=??0.45 �V, 95% confidence interval [henceforth CI]?=??0.95??0.05 �V, t[19]?=??1.89, p?=?0.037) and the unimodally trained adults (?0.80 �V, 95% CI?=??1.39??0.20 �V, t[18]?=??2.82, p?=?0.006), thus suggesting that both groups discriminated the two test vowels to some extent. \n  Subsequently, for each adult participant the MMR amplitude was calculated at Fz in a 50-ms window around the MMR latency for the participant�s group (see Method 6). This group latency was 193 ms for Unimodal [æ], 196 ms for Bimodal [æ], and 189 ms for Unimodal [?] and Bimodal [?]. The MMR amplitudes, averaged over the participants per Distribution Type and Standard Vowel, are presented in Table 2, together with their standard deviations and confidence intervals. For comparison, the corresponding numbers of the infant MMR amplitudes (see Method 6) are also shown. \n  In [4], no significant difference had been observed between the infant MMR amplitudes at frontal, central and temporal electrodes (Fz, F3, F4, Cz, C3, C4, T7, T8). To further explore the frontocentral scalp distribution observed in the adult grand average waveforms and scalp topographies, we performed an analysis of variance (ANOVA) with Electrode (the same eight electrodes as for the infants) as a within-subject factor. The effect of Electrode was significant (F [7?, 266?, ??=?0.504]?=?9.94, Greenhouse�Geisser corrected p<0.001). The amplitude at T7 (mean?=??0.19 �V) was significantly less negative (�smaller�) than the amplitudes at all frontal and central electrodes (mean at Fz?=??0.91 �V, mean at Cz?=??0.90 �V, mean at F3?=??0.77 �V, mean at F4?=??0.93 �V, mean at C3?=??0.85 �V, mean at C4?=??0.84 �V; all ps?0.002), and not significantly different from the amplitude at T8 (mean?=??0.50 �V, p?=?0.80). These results are in line with a predominantly frontocentral distribution of the adult MMN."
2562735,4.0," 2. No significant effect of distributional vowel training in Dutch adults \n  Recall (Method section 1) that in order to test whether there was a difference between the unimodally and bimodally trained participants, while controlling for differences in the presented standard, we performed an ANOVA with the MMR amplitude at Fz as the dependent variable, and with Distribution Type (unimodal vs. bimodal) and Standard Vowel ([æ] vs. [?]) as between-subject factors. The main and interaction effects were not significant (for Distribution Type: mean difference bimodal � unimodal?=?+0.30 �V, 95% CI?=??0.50?+1.10 �V, F<1, p?=?0.45; for Standard Vowel: mean difference [æ]�[?]?=??0.40 �V, 95% CI?=??1.19?+0.40 �V, F[1, 35]?=?1.02, p?=?0.32; for the interaction: F[1, 35]?=?1.41, p?=?0.24). Because the effects involving Standard Vowel were not significant, the amplitude data do not show proof of any perceptual asymmetry (Method section 1). The insignificance of all effects involving Distribution Type implies that the amplitude data do not provide sound evidence that bimodally trained Dutch adult learners have a different amplitude (mean?=??0.78 �V, 95% CI?=??1.34??0.23 �V) and thus benefit differently from distributional training than unimodally trained learners (mean?=??1.08 �V, 95% CI?=??1.65??0.51 �V). For comparison, the corresponding ANOVA for the infants in [4], which also included Time Bin and Electrode as within-subject factors (see Method 6), had yielded a significant effect of Distribution Type (mean difference bimodal � unimodal?=?+1.06 �V, 95% CI?=?+0.08?+2.04 �V, F[1, 18]?=?7.03, p?=?0.016), with a larger positive MMR, and thus a larger effect of distributional training, for the bimodally trained infants (mean?=?+1.37 �V, 95% CI?=?+0.68?+2.05 �V) than for the unimodally trained infants (mean?=?+0.31 �V, 95% CI?=??0.38?+1.00 �V)."
2562735,5.0, 3. Smaller effectiveness of distributional training in adults than in infants
2562735,6.0," From the statistical significance of the distributional effect in infants [4] and the statistical non-significance of the effect in adults (the present paper) we cannot yet conclude that the effect is greater in infants than in adults. A valid test requires a direct comparison of the two age groups. The difference in MMR amplitude between the Bimodal and Unimodal groups (i.e., Bimodal MMR � Unimodal MMR) for the adults was +0.30 �V (?=??0.78 �V�?1.08 �V; i.e., in the unexpected direction, though non-significant), whereas that for the infants [4] was +1.06 �V (?=?+1.37 �V�+0.31 �V). This age difference does not appear to be due to adults having a smaller MMR amplitude in general than infants, because the literature review in the Method section (section 7) suggested that this amplitude is probably greater in adults than in infants. The age difference could therefore be due to a truly smaller effect of distributional training in adults than in infants. To verify this, the current section presents a numerical comparison of the infant and adult MMR amplitudes. As determined by the literature review in the Method section (section 7), the comparison requires a normalization of the MMR amplitudes, which should include a correction for the opposite polarity of adult and infant MMRs and a scaling of the size of the MMR. To implement the normalization (or something equivalent to normalization), we multiplied each adult�s MMR amplitude by ?1 to correct for the negative polarity, and we multiplied each infant�s MMR amplitude by a scaling factor to correct for the smaller size. Before applying the scaling factors estimated from the literature, which were 1.18 and 1.41 (Method section 7), we present the results for a more conservative scaling factor of 1.00 (i.e. no scaling), which is smaller than the estimates; this scaling turns the mean MMR for adults into ?0.30 �V, and that for the infants into +1.06 �V, giving a difference of 1.36 �V."
2562735,7.0," Scaling factor of 1 \n  Using a conservative scaling factor of 1, we performed an ANOVA with the normalized MMR amplitude as the dependent variable, and Age Group (infant vs. adult), Distribution Type (unimodal vs. bimodal) and Standard Vowel ([æ] vs. [?]) as between-subject factors (given that in [4] a strong interaction was observed between Distribution Type and Standard Vowel, Standard Vowel was included to be able to extract possible interactions with this variable). The ANOVA yielded the following normalized MMR amplitudes per Age Group and Distribution Type (as visible in Figure 4): infant unimodal 0.31 �V (CI?=??0.38?+1.00 �V), infant bimodal 1.37 �V (CI?=?+0.68?+2.05 �V), adult unimodal 1.08 �V (CI?=?+0.56?+1.60 �V) and adult bimodal 0.78 �V (CI?=?+0.27?+1.29 �V). \n  Crucially, the interaction between Age Group and Distribution Type was significant (F[1, 53]?=?5.05, p?=?0.029). Thus, the effect of distributional training differed between infants and adults (see below). Further, the interaction between Distribution Type and Standard Vowel was significant (F[1, 53]?=?4.85, p?=?0.032), as well as the triple interaction between Age Group, Distribution Type and Standard Vowel (F[1, 53]?=?13.99, p?=?0.0005). The other interaction effect (between Age Group and Standard Vowel) and the main effects were not significant (all p-values >0.21). \n  As the number of participants was not the same in all groups, it is relevant to note that the crucial interaction between Age Group and Distribution Type did not depend much on the way the terms for the ANOVA were entered in the linear model. With �Type-III sums of squares�, the p-value for each main or interaction effect is calculated from a comparison between the full model (i.e. the model with all main and interaction terms) and the full model from which only this one term was dropped. This led to the above-mentioned p-value of 0.029 for the interaction between Age Group and Distribution Type. With �Type-I sums of squares�, the terms are entered into the linear model one by one and the p-value for each term depends on when the term is added. Under the constraint that the three two-way interaction terms are added after the three main terms and before the three-way interaction term, the p-value for the interaction between Age Group and Distribution Type depended only slightly on the order in which the two-way interactions entered into the model: it was 0.027 if this term was entered first, 0.024 if it was entered after Distribution Type × Standard Vowel but before Standard Vowel × Age Group; 0.025 if it was entered after Standard Vowel × Age Group but before Distribution Type × Standard Vowel; and 0.023 if it was entered last. By contrast, the interaction between Distribution Type and Standard Vowel was not robust to such variation. With Type-III sums of squares, the p-value of the interaction was as shown above (i.e., p?=?0.032), while with Type-I sums of squares the effect was non-significant, irrespective of the chosen order of factors (i.e., the p-value ranged from 0.23 to 0.27). This difference in significance is due to the strong effect of the three-way interaction term: only if this triple term is present and has taken away much of the variance does the interaction between Distribution Type and Standard Vowel provide a significant improvement to the model. The robustness of the interaction of Age Group and Distribution Type, together with the lack of robustness of the interaction of Distribution Type and Standard Vowel, means that the former effect has been shown more credibly than the latter. \n  The observed interaction between Age Group and Distribution Type is pictured in Figure 4. The figure suggests that the difference in the normalized MMR amplitude between unimodally and bimodally trained participants was larger (i.e., more positive after normalization) for the infants than for the adults. When controlling for a possible effect of Standard Vowel, this difference is significant for the infants (mean difference normalized bimodal � unimodal?=?+1.06 �V, 95% CI?=?+0.09?+2.03 �V), thus indicating an effect of distributional training, and not significant for the adults (mean difference normalized bimodal � unimodal?=??0.30 �V, 95% CI?=??1.03?+0.43 �V). In view of the significance of the interaction between Age Group and Distribution Type, it is now possible to interpret the significant effect of distributional training for the infants as indeed being larger (i.e., +1.06�?0.30 �V?=?+1.36 �V, 95% CI?=?+0.15?+2.57 �V) than the non-significant effect for the adults (if that effect exists at all)."
2562735,8.0," Other scaling factors \n  The statistical significance of the result depended on the size of the scaling factor by which the infant MMR amplitude was multiplied. With the conservative value of 1.00 used above, the p-value for the interaction between Age Group and Distribution Type was 0.029 (Type-III sums of squares). With the scaling factors estimated above (Method section 7), namely 1.18 and 1.41, which express the idea that adult MMRs are bigger than infant MMRs, the p-value would be lowered to 0.018 and 0.010, respectively. With a scaling factor of 0.8172, which expresses the opposite assumption from that derived from the literature, namely that infants have a somewhat larger MMR amplitude than adults, the p-value would become exactly 0.05. We can conclude that for a large range of plausible scaling factors, the effect of distributional training is reliably smaller for adults than for infants."
1695972,0.0,"Psychometric and behavioral data \n The two groups did not differ in terms of general cognitive capability (KAI t(22)?=?0.423, p?=?0.676; MWT t(22)?=?0.642, p?=?0.528) or alertness (t(19)?=?0.617, p?=?0.545). Otherwise, the generalized linear mixed model (i.e., 2 groups?×?2 time points) revealed a main effect of time point (z?=??2.391, p?=?0.0403) as well as group?×?time point interaction effect (z?=?2.016, p?=?0.0438). As visible in Fig.�1A, the main effect of time point originated from a better discrimination at T1 (mean correct responses?=?63.04%) compared to T0 (mean correct responses?=?48%), whereas the group?×?time point interaction was related to a higher performance of the TG compared to the PG at T1 (mean correct responses, TG T0?=?45.09%, PG T0?=?50.46%, TG T1?=?74.09%, PG T1?=?53.69%)."
1695972,1.0," FFRs responses \n  A one-sample t-test computed against zero (i.e., no lag) across all participants in order to exclude electromagnetic interference induced by the headphones (Bonferroni corrected p value for two tests?=?0.025) yielded significant results at both T0 (t(23)?=?7.825, p?<?0.001) and T1 (t(23)?=?8.475, p?<?0.001). These results are in line with previous literature13 and indicate the presence of genuine FFRs (Fig.�2) characterized by a mean delay of about 8?ms (i.e., T0, mean?=?7.825?ms, sd?=?1.917?ms; T1, mean?=?8.475?ms, sd?=?1.468?ms) reflecting signal transfer time from the ear to rostral brainstem structures13. \n  The evaluation of between-group f1 peak amplitudes (Fig.�3) by means of a t-test (i.e., percent signal change) yielded a significant group difference (t(22)?=??2.147, p?=?0.043). Post-hoc t-tests against zero calculated separately for the two groups (i.e., Bonferroni corrected p value for two tests?=?0.025) revealed that the TG was characterized by a significant signal reduction (t(10)?=??2.704, p?=?0.022; mean % signal change?=??21.36, neural adaptation, Fig.�4), whereas brain activity did not change within the PG (t(12)?=?0.349, p?=?0.733, mean % signal change?=?2.74). Finally, even though we did not have any a priori-hypotheses, for reasons of completeness, we also evaluated percent signal change in f0 (i.e., added responses) and higher harmonics (i.e., subtracted responses, f2, f3, and f4) between the two groups. Since we did not reveal group differences in these additional parameters (f0, t(22)?=??0.193, p?=?0.849; f2, t(22)?=??0.881, p?=?0.388; f3, t(22)?=??0.586, p?=?0.564; f4, t(22)?=??0.035, p?=?0.972), results indicate a specificity of brainstem responses to the trained stimulus attribute (i.e., f1)."
1695972,2.0,"FFR: stimulus-response correlations \n  Potential group differences in stimulus-response correlations (i.e., stimulus tracking and lag) as a function of treatment were evaluated by contrasting the percent signal change between the two groups by means of t-tests (Bonferroni corrected p value for two tests?=?0.025). These analyses did not reveal significant group differences in signal tracking (t(22)?=?0.508, p?=?0.617) nor in lag (t(22)?=??0.182, p?=?0.857)."
1695972,3.0," FFR: brain-behavior relationships \n  In order to provide further evidence for the specificity of the functional changes observed within the TG at the processing level of the brainstem, we correlated percent f1 signal change with the learning performance during the training session (i.e., ? percent correct responses between run 6 and run 1 of the training session). Results revealed a significant negative correlation (i.e., see Fig.�4D) between the two variables (r?=??0.607, p?=?0.024, one-tailed)."
1695972,4.0," MMN responses \n  Between-group differences in MMN area and latency in response to spectral (i.e., early MMN) and temporal (i.e., late MMN) manipulations were evaluated by means of separate t-tests (i.e., percent signal change; Bonferroni corrected p value for 4 tests?=?0.0125). These statistical analyses did not reveal significant group differences (spectral area t(22)?=??1.167, p?=?0.256; temporal area t(22)?=?1.656, p?=?0.112; spectral latency t(22)?=?1.085, p?=?0.29; temporal latency t(22)?=??0.514, p?=?0.613). Furthermore, in order to rule out the possibility that a general adaptation of the auditory cortex (i.e., see Fig.�5) as a consequence of repeated auditory stimulation between the two measurements points (i.e., T0 and T1) may have accounted for the lack of group differences, we performed additional post-hoc analyses within the two groups (one sample t-test against zero, two-tailed, Bonferroni corrected p value for 4 tests?=?0.0125). These supplementary analyses did not reach significance (TG MMN area early, t(10)?=??1.536, p?=?0.155; TG MMN area late, t(10)?=??1.493, p?=?0.166; PG MMN area early, t(12)?=?1.173, p?=?0.264; PG MMN area late, t(12)?=??2.466, p?=?0.030)."
1695972,5.0," MMN sources \n  LORETA source estimation (Table ?(Table1)1) consistently revealed MMN maxima originating from posterior superior temporal areas, irrespective of group affiliation (i.e., TG and PG), time point (i.e., T0 and T1), and condition (i.e., spectral and temporal). These findings point to a main contribution of the auditory cortex to MMN responses."
1695972,6.0," Training-related cortical-subcortical relationships \n  Putative changes in cortical-subcortical interactions within the TG were evaluated by correlating (according to Pearson�s r, two-tailed) the percent signal change of early MMN area and latency with f1 signal change (Bonferroni corrected p value for two tests?=?0.025). These correlative analyses did not reach significance (rMMN area_f1 amplitude?=?0.155, p?=?0.65; rMMN latency_f1 amplitude?=?0.355, p?=?0.285)."
2004704,0.0,"Daily monitoring revealed that two of the six cattle had slightly elevated temperatures of 39.1 °C and 39.4 °C on day 1 post-inoculation. Both the animals had no appetite on that specific day but returned to normal by day 2 post-inoculation. No further signs of distress were noted for any of the animals throughout the remainder of the trial. Blood samples were collected daily from the animals from day 1 to day 39 post-inoculation and viraemia was detected between day 2 and day 32 in four of the animals and in the two other animals viraemia could be detected until 39 days post-inoculation using virus isolation. Seroconversion was confirmed using a commercially available competitive ELISA (Veterinary Medical Research and Development, Centurion, SA); all cattle tested negative on day 0 and seropositive on days 13, 15, 17, 19 and 21."
2004704,1.0,Parental strains from the vaccine bottle and the BTV 4 field strain each demonstrated unique electrophoretic profiles and it was possible to distinguish between genome segments based on their PAGE migration profiles as illustrated in Figure 2. Eleven samples were identified as possible reassortant viruses. Full-length sequences of all these samples were submitted to GenBank (Bioproject number: PRJNA287219) and sequence data (with accession numbers) were published by Van den Bergh et al. (2016).
2004704,2.0,"Comparison of genomic sequences of each of the suspected reassortant isolates (n = 11) with the vaccine strains and the BTV 4 wild-type revealed that nine of the 11 samples analysed clustered with the wild-type BTV 4 strain in which all 10 segments were identical to the 10 segments of BTV 4. Two of the viral isolates obtained from blood samples (samples 2b and 6b, Figure 3), however, grouped with the BTV 9 vaccine strain. Nine of the segments of these isolates clustered with BTV MLV 9 with segment 8 as an exception that clustered with another vaccine strain from Bottle B, BTV 8 (Figure 4)."
342394,0.0,"The serological evidence of BTV infection was observed in 58 out of 299 cows accounting for a 19.4% prevalence rate among cattle in North Kordufan State. The highest and the lowest rate of infections were recorded in Shiekan and Elnnuhud, (15%) and (27.5%), respectively. Initially, univariate analysis using Chi-square test was conducted for the association between the potential risk factors and BTV infection. The results of the univariate analysis are presented in (Table ​(Table1).1). The results obtained from the univariable model were re-entered into a final multivariate model using logistic regression analysis. In the final models, a variable with a P-value <0.05 was considered statistically significant. The individual risk factors attributes indicated that older cattle (>2 years of age) were four times more likely to be infected with BTV (OR = 4.30, CI = 1.941-9.467, p-value = 0.01). Weak and emaciated cattle were almost 3 times more likely to be at risk for contracting BTV infection (OR = 2.925, CI = 1.146-7.606, p-value = 0.025). The management risk factor attributes showed that the preventive measures, such as routine application of insecticide in the selected herds and spraying or dipping decreased the odds for bluetongue seropositivity by 7 times compared to non sprayed cattle (OR = 7.408, CI = 3-111-17.637, p-value = 0.01). In contrast, there was no significant difference between BTV seropositive cattle and other individual or management risk factors included in the study such as, animal sex, animal source, grazing system, other animals in the herd, herd size, farm yard, milk production, history of diseases and localities. The results are shown in (Table ​(Table22)."
2087253,0.0,"Safety of test series of the bivalent live cultural vaccine against BTV Other than a relatively mild fever (40.3–40.8 °C) for 2–4 days and swelling at the site of vaccination which resolved within 2–3 days, the animals developed no clinical signs after vaccination (Table ​(Table2).2). These results indicate that this vaccine is generally safe for sheep."
2087253,1.0,"Reversion to virulence Both strains induced viremia in susceptible animals (Fig. ​(Fig.1).1). During the passages in sheep, the BTV titer was 1.16 ± 0.16 log10 TCID50/mL at the first passage, decreasing to 0.83 ± 0.08 and 0.92 ± 0.08 log10 TCID50/mL with subsequent passages (P ≤ 0.001) (10 total)."
2087253,2.0,"The attenuated virus showed no pathogenic properties after its intravenous administration to sheep, and all the animals remained healthy during the observation period (30 days)."
2087253,3.0,"Neutralizing antibody titers One week after vaccination, all the sheep had detectable levels of neutralizing antibodies, measured with a SNT, with mean titers (log10) ranging from 1.1 (for BTV-4) to 1.25 (for BTV-16) at 7 days after-vaccination (Fig. ​(Fig.2).2). Four weeks after vaccination, all the vaccinated animals had even higher levels of neutralizing antibodies: 4.0–4.8 log2 at 28 days and 1.8–2.0 log2 at 360 days (Fig. ​(Fig.22)."
2087253,4.0,The levels of NA in the sera of the immunized sheep differed significantly for both serotypes from day 7 to day 360 (P ≤ 0.0001).
2087253,5.0,"Group-specific antibody titers A graphical summary of the percentage inhibition (IP) results are given for each group in Fig. ​Fig.3.3. All sheep were seronegative before vaccination and the control sheep remained seronegative in all assays until challenge. After vaccination, the percentage inhibition decreased dramatically. The optical densities of specific antibodies decreased throughout the duration of the study, from IP < 8 ± 3.07 at day 28, to IP < 16.5 ± 4.95 at day 90, and IP < 46.25 ± 6.40 at day 360."
2087253,6.0,"Clinical protection following challenge Seven days after immunization, the animals developed protective immunity against BTV (Fig. ​(Fig.4a).4a). However, the vaccinated animals were insufficiently protected from challenge because they developed clinical signs of bluetongue, with an average score of 10 points. The unvaccinated control animals also developed clinical signs, with an average score of 20.8 points, so the difference in the mean scores was 10.8 points. At 14, 90, and 270 days after immunization, strong protective responses developed against BTV-4 and BTV-16 (Fig. 4b, c). The vaccinated animals showed a slight increase in body temperature after challenge, whereas the unvaccinated animals developed typical clinical signs of the disease. At 360 days after immunization, one vaccinated sheep showed an increase in body temperature of 41.5 °C for 2 days after challenge, which then returned to normal (Fig. ​(Fig.4d).4d). The vaccinated animals had an average clinical score of one point after challenge, whereas the unvaccinated animals had an average score of 27 points, indicating the high protective activity of the test vaccine."
761719,0.0,"Seroprevalence of bluetongue in west and northwest was shown in Table 1. The results showed that the seropositive rate in sheep over the whole study area was 40.87%. Presence of anti-bluetongue antibodies was found highest in west. The highest prevalence of antibodies was in West Azerbaijan (64.86%), and lower (23.77%) was in Ardabil (Table 1)."
921211,0.0,"BTV8ΔNS4 is attenuated in experimentally infected sheep. In a previous study, we showed that a BTV8 NS4 deletion mutant (BTV8ΔNS4) is as virulent as BTV8wt in experimental mouse models of infection (8). Here, we wanted to determine whether NS4 influenced virulence in sheep, the natural host of BTV infection. Therefore, we experimentally infected sheep with BTV8wt or BTV8ΔNS4. Sheep infected with BTV8wt showed an elevation of body temperature from day 6 to day 8 p.i. (Fig. 1, top). BTV RNA was detectable at day 4 p.i. and reached a plateau from days 6 to 10 p.i., followed by a slow decrease. Viremia remained detectable until the end of the experiment. In contrast, animals infected by BTV8ΔNS4 did not develop pyrexia and displayed a delayed onset and lower levels of viremia. BTV RNA was below the detection level in 4 of the 5 inoculated sheep at 4 weeks p.i., when the experiment was stopped (Fig. 1, middle). Between days 4 and 28 p.i., the average levels of BTV RNA were between 102- and 105-fold higher in sheep infected with BTV8wt than in those infected with BTV8ΔNS4. As expected, all BTV-infected animals developed neutralizing antibodies from day 7 p.i. (Fig. 1, bottom). Altogether, these data show that BTV8ΔNS4 is attenuated in sheep and suggest that NS4 is a virulence factor in vivo."
921211,1.0,"Replication kinetics of BTV8wt and BTV8ΔNS4 in primary ovine endothelial cells and human A549 cells. We showed previously that BTV8ΔNS4 replicates as efficiently as BTV8wt in immortalized cell lines, such as hamster BSR and sheep CPT-Tert cells (8), but these cell lines do not possess an intact IFN response to viral infections (44, 45). Hence, we compared the replication kinetics of BTV8wt and BTV8ΔNS4 in primary ovEC. BTV8wt reached titers approximately 20-fold higher than those of BTV8ΔNS4 at 72 h p.i. (Fig. 2A). Similarly, BTV8wt reached titers nearly 60-fold higher than those of BTV8ΔNS4 in the IFN-competent human cell line A549 (Fig. 2A). These data demonstrate that the presence of NS4 confers a replication advantage on BTV8 in cells that are capable of mounting an antiviral response."
921211,2.0,"NS4 inhibits IFN release, but not virus sensing, in infected cells. Given the data obtained as described above and the previously published observation that NS4 confers a replication advantage on BTV in cells pretreated with IFN (8), we next sought to determine whether NS4 impacted the level of IFN released into the supernatant of infected cells. Primary ovEC were infected at an MOI of 4 with either BTV8wt or BTV8ΔNS4. At 16 h p.i., the level of IFN in the cell culture medium was measured using an IFN protection assay. BTV8ΔNS4-infected cells had, on average, 13 times more IFN (P < 0.001) in their supernatants than BTV8wt-infected cells (Fig. 2B)."
921211,3.0,"These results could potentially be explained by NS4 affecting either the sensing of viral infection or transcription and/or the synthesis/secretion of IFN into the supernatant. The first step in IFN-β expression is the recognition of pathogen-associated molecular patterns (PAMPs) by various host pattern recognition receptors, which results in the translocation of the transcription factors IRF-3 and NF-κB into the nucleus (37). In order to determine whether NS4 impacted supernatant levels of IFN by interfering with this process, we infected A549 cells at an MOI of 4 for 16 h and assessed the nuclear translocation of IRF-3 and NF-κB by confocal microscopy. The cellular localization of IRF-3 and NF-κB in mock-infected cells was exclusively cytoplasmic (Fig. 3), while stimulation with tumor necrosis factor alfa (TNF-α) used as a positive control resulted in nuclear translocation of NF-κB in essentially 100% of the cells (not shown). In contrast, between 25 and 35% of cells infected by BTV8wt showed translocation of IRF-3 and NF-κB into the nucleus. BTV8ΔNS4 was found to induce levels of translocation similar to those of BTV8wt, suggesting that NS4 does not prevent either PAMP recognition by the host cells or translocation of IRF-3 and NF-κB. NS2 immunolabeling confirmed similar levels of infection in cells infected with BTV8wt or BTV8ΔNS4 (Fig. 3)."
921211,4.0,"NS4 downregulates IFN-β and ISG mRNA levels. Next, we carried out RNA-seq analysis of IFN-competent A549 cells infected with either BTV8wt or BTV8ΔNS4 in order to further characterize the activity of NS4. Mock-infected A549 cells were used as negative controls. Libraries were prepared from nascent RNA metabolically labeled with a uracil analogue for 90 min at 12 h p.i. (Fig. 4A) and sequenced on an Ion Proton sequencer (Life Technologies, Thermo Fisher). On average, 64.58 million reads per sample were generated (Phred quality > 20). We found 2,863 differentially expressed genes in cells infected by BTV8wt compared to mock-infected cells, of which 1,055 were downregulated and 1,808 were upregulated (Fig. 4B). In comparison, fewer genes (n = 2,292) were found to be differentially expressed in cells infected by BTV8ΔNS4 than in mock-infected cells, with 752 of them being downregulated and 1,540 upregulated. The entire list of differentially expressed genes in BTV8wt and BTV8ΔNS4-infected cells is presented in Tables S1 to S3 in the supplemental material. The CH25H gene (encoding cholesterol 25-hydroxylase; a known interferon-stimulated gene [ISG]) was found to be the most upregulated gene in BTV8ΔNS4-infected cells. A total of 117 genes were upregulated in BTV8ΔNS4-infected cells compared to BTV8wt-infected cells (see Table S3 in the supplemental material). Of these 117 genes, 102 were either IFN genes or ISGs, according to the Interferome database (63). IFN-β, IFN-λ1, IFN-λ2, and IFN-λ3 genes were among the top 6 upregulated genes in BTV8ΔNS4-infected cells (87- to 136-fold more than in mock-infected cells) (Table 1). Interestingly, more genes were strongly upregulated (fold change > 32) in BTV8ΔNS4 (n = 33) than in BTV8wt-infected cells (n = 7). These genes included MX1 and -2; interferon-induced protein with tetratricopeptide repeats 1 (IFIT1), -2, and -3; and OASL genes and other well-characterized ISGs. However, all 33 of the genes highly upregulated in BTV8ΔNS4-infected cells were also upregulated (albeit at a lower level) in BTV8wt-infected cells (Table 1). The IFN-β gene, for example, was also upregulated (17-fold) in BTV8wt-infected cells. No major differences in the levels of expression in BTV8wt- and BTV8ΔNS4-infected cells were observed for the genes with the highest levels of downregulation (Table 2). We validated the RNA-seq analysis by qRT-PCR on selected genes found to be equally or differentially expressed in mock-infected and infected cells. Relative mRNA levels of IFNB1, IFIT1, beta-2 microglobulin (B2M), β-actin (ACTB), annexin A1 (ANXA1), and TATA-binding protein (TBP) determined by RT-qPCR reflected the patterns of expression observed in the RNA-seq analyses (Fig. 4C). The Ingenuity Pathway Analysis software (Qiagen) was used to compare the representation of canonical pathways between infected and uninfected cells (Fig. 5A and ​andB)B) and cells infected with either BTV-8wt or BTV8ΔNS4 (Fig. 5C). Most of the pathways were involved in the cellular immune response, cytokine signaling, the inflammatory response, apoptosis, and pathogen-related signaling. Consistent with the RNA-seq data set, pathways relating to the innate immune response were particularly evident when comparing BTV8ΔNS4 with BTV8wt (Fig. 5C)."
921211,5.0,"The availability of the transcriptome of cells infected by BTV8wt and BTV8ΔNS4 also provided additional information regarding the possible influence of NS4 on mRNA maturation. Comparable proportions of reads containing intron sequences were found in mock-infected cells and in cells infected with BTV8wt or BTV8ΔNS4 (data not shown). In addition, we also quantified how many reads finished with 8 or more adenines, assuming these reads to be representative of polyadenylated mRNAs. Comparable percentages of poly(A) reads were obtained under the three conditions tested, suggesting that NS4 was not associated with a global defect in mRNA polyadenylation (data not shown)."
921211,6.0,"NS4 modulates the activities of a wide range of promoters. We next assessed the ability of BTV-8 NS4 to reduce the activities of basal promoters, such as the cytomegalovirus (CMV) immediate-early promoter and the promoters of genes involved in the host innate immune response (IFN-β and ISRE-containing promoters). 293T cells were cotransfected with a plasmid expressing either BTV NS4 or NS2 and an FLuc reporter plasmid driven by either the CMV promoter, the IFN-β promoter, or a promoter containing ISRE elements (Fig. 5). At 4 h posttransfection, cells transfected with the IFN-β promoter were stimulated with Sendai virus, while cells transfected with the ISRE-containing promoter were stimulated with universal IFN (200 U/ml). NS4, unlike NS2, was able to reduce by between 40 and 60% the activities of CMV, IFN-β, and ISRE promoters (Fig. 6)."
921211,7.0,"To further investigate the ability of NS4 to block host gene expression, sheep cells were cotransfected with an expression plasmid for FLuc, under the control of the CMV immediate-early promoter, along with a variety of expression plasmids expressing BTV NS4 or an empty plasmid (also containing a CMV promoter) as a control (Fig. 7). NS4 is well conserved among the BTV serotypes/strains identified to date (8). The only exceptions were a strain of BTV-1 (GenBank accession number D10905, submitted in 1992) and the more divergent BTV-25 and BTV-26 strains (GenBank accession numbers EU839845 and JN255161), which showed only 77.9%, 76.6%, and 75.3% identity to BTV-8 NS4, respectively (Fig. 7A). All of the NS4 proteins tested were able to reduce FLuc expression, with the notable exception of NS4 from BTV-1 (D10905) (Fig. 7B). Interestingly, the NS4 protein of BTV-1 (D10905) displayed a mobility different from those of other NS4 proteins by SDS-PAGE that could be explained by the presence of considerable differences in the basic residues in the N terminus. In addition, using BTV-8 NS4, we showed that gene expression inhibition by NS4 was dose dependent (Fig. 7C)."
921211,8.0,"In a previous study, we showed that NS4 localizes in the nucleoli of infected or transfected cells (8). Interestingly, BTV-1 (D10905) NS4 was the only variant that failed to localize to the nucleoli of sheep CPT-Tert cells (Fig. 7D), suggesting that nucleolar localization may be critical for the activity of this nonstructural protein."
921211,9.0,"NS4 is not the only viral protein involved in host cell protein shutoff. It is well established that BTV induces protein synthesis shutoff in infected cells (64,–66). Conceivably, a reduced level of IFN (both mRNA and proteins) observed in cells infected with BTV8wt could reflect the general virus-induced shutoff of protein synthesis. In order to test this hypothesis, we metabolically radiolabeled nascent proteins in ovEC mock infected or infected with either BTV8wt or BTV8ΔNS4. As expected, we observed decreased levels of 35S-labeled methionine/cysteine proteins in BTV8wt-infected cells compared to mock-infected cells (particularly evident at 18 and 26 h p.i.), confirming previously published data (Fig. 8) (65, 66). Protein synthesis shutoff was also evident in BTV8ΔNS4-infected cells, although at somewhat reduced levels compared to BTV8wt-infected cells. In order to quantify the reduction in protein synthesis during viral infection we used phosphorimaging and measured the signal intensity of a prominent band present in all samples (Fig. 8A, black arrow). The signal intensity of actin in BTV8wt-infected cells relative to mock-infected cells (taken as 100%) decreased progressively to 69% at 10 h p.i., 37% at 18 h p.i., and 2% at 24 h p.i., by which point cytopathic effect was apparent. On the other hand, the signal intensity of actin decreased to 82%, 56%, and 12%. Hence, these data suggest that host protein shutoff induced by BTV occurs largely independently of NS4, although the protein may contribute to the phenomenon."
921211,10.0,"BTV-8 NS4 does not influence mRNA splicing or translation. We also assessed the impact of NS4 on RNA transcript splicing. CPT-Tert cells were transfected with the pRL-CMV vector, which is driven by the CMV immediate-early promoter and contains the RLuc gene downstream of an intron. In this assay, NS4 retained the ability to inhibit the expression of the reporter gene in a dose-dependent manner (Fig. 8B), indicating that NS4 does not affect mRNA splicing and confirming the data obtained by RNA-seq as described above. Cells were also cotransfected with in vitro-transcribed RNA encoding FLuc and an expression plasmid for BTV8 NS4, in order to determine whether NS4-induced inhibition of protein expression could also occur at the translational level (Fig. 8C). Increasing levels of NS4 did not interfere with the level of FLuc activity driven by RNA, as opposed to the activity driven by plasmid DNA, used as a control, suggesting that the inhibition mediated by NS4 most likely occurs at the transcriptional and not at the translational level."
1200121,0.0,"In the present study, 422 serum samples from sheep (246) and goats (176) were collected and screened for the presence of BTV specific antibodies by c-ELISA. Out of 422 sera tested, 129 (30.6%) (95% CI 26.2–35) were found to be positive for BTV-specific antibodies (Table 1)."
1200121,1.0,"On the basis of univariate and multivariate logistic regression analysis, it was concluded that risk factors like sex, and body condition had no significant (P > 0.05) impact (Table 2) whereas species, age, districts and agro-ecology had significant (P < 0.05) influence on the seroprevalence of bluetongue. It was found that goats were 2.3 times more likely to be positive to group specific BT virus antibody than sheep. Adults were three times compared to young animals and animals of lowland compared to highland areas were three times more likely to be seropositive to BTV respectively. Among the districts, small ruminants in Bedelle district were 2.3 times more likely to be seropositive to BTV than Jimma district (Table 2)."
921401,0.0,"Replication kinetics in vitro and virulence in mice of BTV-2IT2000, BTV-8NET2006, and BTV-8IT2008. In order to investigate virus and host factors affecting the clinical outcome of BTV infection, we initially focused on three different strains of bluetongue: a BTV-2 strain isolated from Italy in 2000 (BTV-2IT2000), a BTV-8 strain isolated from the Netherlands in 2006 (BTV-8NET2006), and a BTV-8 strain isolated in Italy in 2008 (BTV-8IT2008)."
921401,1.0,"First, we assessed the ability of all viruses to replicate in sheep CPT-Tert cells. No major differences were observed in the replication kinetics of the viruses regardless of the serotype and strain used in the assay (Fig. 1A). We next assessed the virulence of each strain in IFNAR−/− mice, as these mice succumb to wild-type BTV infection (57, 72). Mice were inoculated intraperitoneally with 300 PFU of the BTV strains described above. All of the mice inoculated with the various BTV strains showed clinical signs around 3 days p.i., characterized by ocular discharge, apathy, and lethargy. All BTV-infected mice died between 6 and 8 days postinfection, while no signs of disease were observed in the control mock-infected mice (Fig. 1B)."
921401,2.0,"Influence of species, breed, and age of the mammalian host on the clinical outcome of BTV infection. Several studies investigating the factors that affect the clinical outcome to BTV infection have already been published (1, 20, 21, 73). Here, we aimed to assess the variables affecting the pathogenesis of bluetongue in a single experimental framework. First, we assessed the outcome to BTV infection in 2-year-old goats and sheep of three different breeds (the Northern European Dorset poll, the Italian Sardinian sheep, and a mixed breed from Central Italy). An additional group of Dorset poll sheep, 8 months old in age, were also used in the study. We deliberately used viruses isolated in KC cells and subsequently passaged twice in BHK-21 for all the experimental infections carried out in this study. This strategy allowed us to use viruses minimally passaged in vitro and with the same history in cell culture."
921401,3.0,"Sheep infected with BTV-8NET2006 developed classic clinical signs of bluetongue, including fever (defined here as body temperature of >40°C), which started 4 to 5 days p.i., depression, anorexia, respiratory distress, increase in salivation, facial edema, and hyperemia of nasal and buccal mucosa (Fig. 2; see also Fig. S1 in the supplemental material, showing data for each individual animal). Overall, no major differences in clinical signs were observed between the three sheep breeds used in this study or between 8-month-old and 2-year-old Dorset poll sheep. In addition, no significant differences (P > 0.05) were observed in the levels of fever or the cumulative number of days with fever between all the sheep groups. However, one sheep in the mixed-breed infected group had to be euthanized because of onset of severe clinical signs. Consequently, the general and total clinical score of the infected mixed-breed group was higher than that of the other groups (Fig. 2A). In all the infected groups, BTV RNA in the blood peaked at about 5 days p.i. and then slowly decreased, although it remained detectable up to 4 weeks p.i., at which point the experiment was concluded (Fig. 2C; see also Fig. S1 in the supplemental material). Neutralizing antibodies were detected at day 7 p.i., peaked by day 14 p.i., and then remained essentially constant for the duration of the experiment (Fig. 2D)."
921401,4.0,"On the other hand, goats after BTV-8NET2006 infection showed no clinical signs or fever throughout the duration of the experiment (28 days) (Fig. 2A and ​andB).B). Differences in the body temperature between day 3 and 10 postinfection were statistically significant between goats and each of the groups of sheep described above (P < 0.0001). The onset of viremia in goats was delayed compared to that in infected sheep, peaking at 10 days postinfection. Average levels of BTV RNA in the blood were at least 10-fold higher in goats than in infected sheep between day 9 and 16 p.i., but overall the differences observed were not statistically significant due to individual variations (ANOVA P = 0.45) (Fig. 2C; see also Fig. S1 in the supplemental material). All mock-infected sheep and goat controls used in this study showed no clinical signs and remained negative for the presence of both viral RNA in the blood and neutralizing antibodies toward BTV (see Fig. S2 in the supplemental material)."
921401,5.0,"Influence of BTV strain and serotype on the clinical outcome of BTV infection. We also assessed the pathogenicity of different BTV serotypes, as well as different virus strains within a single serotype. The severity of disease observed in sheep inoculated with either BTV-2IT2000 or BTV-8NET2006 was largely equivalent, with both viruses inducing typical clinical signs observed in bluetongue (Fig. 3A). In contrast, animals infected with BTV-8IT2008 showed only a mild transitory fever but no other clinical signs (Fig. 3B; see also Fig. S3 in the supplemental material showing data for each individual animal). Excluding the temporary pyrexia displayed by some animals at day 1 p.i., BTV-8NET2006 and BTV-2IT2000 induced cumulatively 17 and 18 days of fever in their respective groups of infected sheep. In contrast, BTV-8IT2008 induced only 8 cumulative days of fever. Overall, we also observed that on average sheep infected with BTV-8NET2006 or BTV-2IT2000 displayed higher levels of fever than sheep infected with BTV-8IT2008, although differences were not statistically significant (ANOVA P = 0.17). BTV-8IT2008, BTV-8NET2006, and BTV-2IT2000 all induced similar levels of viremia (ANOVA P = 0.54) and neutralizing antibodies in infected sheep (Fig. 3C and ​and D)."
921401,6.0,"We next sequenced the complete genomes of BTV-8NET2006 and BTV-8IT2008 in order to determine the genetic basis for the different phenotypes of these two viruses. We detected a total of 24 nucleotide mutations between BTV-8NET2006 and BTV-8IT2008, including 16 silent mutations and 8 nonsynonymous mutations, leading to differences in the viral VP1, VP2, VP4, NS1, NS2, and VP6 proteins (Fig. 4)."
921401,7.0,"Effect of cell culture adaptation on BTV virulence. Published reports suggest that, in some cases, infection of target species using blood directly from a naturally BTV-infected animal induces more severe clinical signs than tissue culture-adapted virus (20, 61). In the context of the experimental framework used in this study, we inoculated two groups of Sardinian sheep with either blood from a BTV-infected animal [BTV-8NET2007(blood)] or the same virus isolated in cell culture after a single passage in KC cells and two passages in BHK21 [BTV-8NET2007(1KC-2BHK)]. As assessed by qRT-PCR, the infected blood contained approximately 100-fold less viral RNA than the inoculum of BTV-8NET2007(1KC-2BHK) (data not shown). Sheep infected with BTV-8NET2007(blood) displayed a higher clinical score and reached statistically significant higher levels of fever (P = 0.01) than sheep inoculated with BTV-8NET2007(1KC-2BHK) (Fig. 5A and ​andB;B; see also Fig. S4 in the supplemental material). Sheep infected with BTV-8NET2007(blood) displayed 27 cumulative days of fever as opposed to 16 shown by sheep infected with BTV-8NET2007(1KC-2BHK). In addition, the levels of viral RNA in the blood were also consistently and considerably higher (10- to 1,000-fold; P = 0.018) in sheep infected with BTV-8NET2007(blood) than those found in BTV-8NET2007(1KC-2BHK)-infected sheep (Fig. 5C; see also Fig. S4 in the supplemental material). Interestingly, viremia was delayed by 2 days in BTV-8NET2007(blood)-infected animals. In addition, we did not find neutralizing antibodies at 7 days postinfection in any of the sheep infected with BTV-8NET2007(blood) (Fig. 5D). In contrast, all sheep infected with BTV-8NET2007(1KC-2BHK) had BTV-neutralizing antibodies by day 7 p.i. No differences in the levels of neutralizing antibodies were found at later time points between sheep infected with BTV-8NET2007(blood) and BTV-8NET2007(1KC-2BHK). Thus, as proposed in other studies (20, 61), infection of sheep with BTV collected directly from infected animals and never passaged in tissue culture induced more severe clinical signs than the homologous virus passaged even minimally in tissue culture."
921401,8.0,"BTV population diversity influences virulence. Next, we aimed to link the phenotypic differences described above between sheep inoculated with BTV-8NET2007(blood) and BTV-8NET2007(1KC-2BHK) to genetic changes that might occur in the virus following cell culture adaptation. We analyzed the genomes of BTV-8NET2007(blood) and BTV-8NET2007(1KC-2BHK) by deep sequencing, using the same stocks utilized in the experimental infections described above. We also analyzed the intermediate viruses BTV-8NET2007(1KC) and BTV-8NET2007(1KC-1BHK). Furthermore, in order to test the reproducibility of the results obtained, we repeated in parallel the adaptation in KC and BHK21 cells of BTV-8NET2007(blood) in an independent set of experiments. All together, we analyzed the full genome of 7 viral samples: BTV-8NET2007(blood) and two independent isolates of BTV-8NET2007(1KC), BTV-8NET2007(1KC-1BHK), and BTV-8NET2007(1KC-2BHK)."
921401,9.0,"We found that the consensus sequences of BTV-8NET2007(blood) and BTV-8NET2007(1KC-2BHK) were identical, with the exception of two silent mutations in segments 1 (nucleotide 2756) and segment 4 (nucleotide 1431) (Fig. 6). Both point mutations were selected after the initial passage in KC cells and in both independent experiments."
921401,10.0,"RNA viruses, due to their high mutation rates, do not exist as a single genotype but as a complex of variants (also referred to as quasispecies), each possessing unique random mutations (74, 75). Consequently, we analyzed BTV-8NET2007(blood) and the effect on its population diversity after passaging in vitro in KC and BHK21 cells."
921401,11.0,"In Fig. 7, we have plotted the degree of variability at each nucleotide position of each genomic segment before and after passaging in cell culture. A nucleotide is plotted and is referred to as a “variant” if it represents at least 0.1% of the viral population. In general, the number of variants was higher in the virus before cell passaging, or after one passage in KC cells, than what observed even after a single passage in BHK21 cells. Interestingly, for 9 of the 10 segments in the first set of experiments, and for 8 of the 10 segments in the second set of experiments, the number of variable nucleotides was higher in the virus passaged once in KC cells than in the virus from blood before passage in cell culture. There was a larger number of variants with a frequency between 0.1 and 0.29% in BTV-8NET2007(1KC), while the number of variants with a frequency of >0.4% was severalfold higher in BTV-8NET2007(blood) (Fig. 8). The two silent mutations selected in the consensus sequence of BTV-8NET2007(1KC-2BHK) were already present as high-prevalence variants in BTV-8NET2007(blood) (14.9% for nucleotide 2756 of segment 1 and 10.4% for nucleotide 1431 of segment 4) (dots circled in red in Fig. 7). On the other hand, other variants present with a frequency of about 10% in segment 3 and segment 6 were not selected after passage in vitro. Essentially, the same results were obtained in the two independent sets of experiments."
2299383,0.0,"Bluetongue virus and epizootic haemorrhagic disease virus sero-prevalence and sero-incidence. The results generated by c-ELISA for the 137 cattle samples showed that the small per-farm sample size (12; IQR: 10–21) resulted in a large between-farm variation in the BTV and EHDV sero-prevalence (Table 1). The highest BTV and EHDV sero-prevalence was recorded for samples collected during the 2000/2001 season. However, there was only a significant difference recorded between the sero-prevalence of antibodies to EHDV in cattle over the three seasons (p = 0.043). The median sero-prevalence of BTV and EHDV in the cattle sampled across the three rainy seasons studied was 62% (IQR: 30–89) and 56% (IQR: 5–77), respectively."
2299383,1.0,"The results from the 72 sheep also showed that the small per-farm sample size (12; IQR: 11–13) resulted in a large between-farm variation in the BTV and EHDV sero-prevalence (Table 2). The sero-prevalence of BTV antibodies in sheep was highest in the third season (2001/2002), but the difference between years was not significant (p = 0.513). The median sero-prevalence of BTV and EHDV over the three seasons was 41% (IQR: 19–63) and 0% (IQR: 0–21), respectively."
2299383,2.0,"The nine sentinel cattle herds, established over the three rainy seasons, comprised a total of 65 cattle with a median of 9 (IQR: 5–14) cattle per farm (Table 3). The small sentinel herd sample size resulted in a large between-sentinel herd variation in the sero-incidence of BTV and EHDV. Median sero-incidences for BTV and EHDV in cattle of 43% (IQR: 22–67) and 27% (IQR: 9–57), respectively, were recorded."
2299383,3.0,"The six sentinel sheep herds, established over the three rainy seasons, comprised a total of 44 sheep, with a median of 9 (IQR: 7–11) sheep per farm. Only one sheep seroconverted against EHDV and seven sheep converted against BTV across all three seasons. The median sero-incidence of BTV over the three seasons was 14% (IQR: 6–23)."
2299383,4.0,"Viral serotyping. Virus isolations were made from three individual cows from two of the farms where the sentinel cattle were located during the 2001/2002 season. The virus type, determined by neutralisation assays for each isolate, was BTV serotype 3. No EHDV isolations were made."
2549955,0.0,"Two BTV-1 clinical cases occurred in November 2007 in France. As in the BTV-8 study, we did not include these two first cases because they could induce bias in the estimation of the velocity of BTV-1 spread. These two cases occurred at the end of the vector activity period and were followed by the vector-free period during which BTV transmission was effectively inactive. In 2008, 4,195 BTV-1 clinical cases were reported. From this, we identified the date of the first clinical case in 1,595 municipalities (Fig. 1). These dates ranged from July 11th 2008 to January 5th 2009."
2549955,1.0,"1 Velocity of BTV-1 spread estimation. We selected the smallest subset of fourth-order TSA-SARerr models for which the sum of the AICc weights was ≥0.9. The resulting subset contained 66 models (Table S2). Model-averaged parameters obtained from these 66 models were used to estimate a velocity for each of the 1,595 municipalities. These velocity estimates ranged from 0.98 to 126.34 km/day with a mean value of 5.35 km/day (median value  = 2.64 km/day). However, 90% (1,439) of the municipalities had velocity ≤10 km/day, indicating that BTV-1 spread was mostly local. High values for the velocity of BTV-1 spread were marginal, potentially linked with farm animal movements. Model residuals, i.e., the difference between the fitted and observed date of first clinical case, had a mean non-significantly different from zero (0.2, 95% Confidence Interval (CI): −0.43−0.93) and a bell-shaped distribution. No spatial structure was detected in these residuals. The difference between the fitted and observed date of first clinical case was less than 16 days for 1,337 municipalities (84%) and environmental covariates were available for 1,314 of these municipalities (82%). For this sub-dataset of 1,314 municipalities the minimum and maximum velocities were identical to those of the full dataset, and the mean and median values of the velocity of BTV-1 spread were 5.72 and 2.74 km/day, respectively. The estimated velocities at these 1,314 municipalities were subsequently included in the analysis of the effect of vaccination (see section 3.2). Velocity vectors of the 1,314 municipalities are presented in Figure 2: from the initial introduction zone (indicated by a red arrow on the map), the virus spread rapidly from west to east along the Pyrenees Mountains, then, from this initial incursion, the virus spread sideways to the south and north. The departments with few infected municipalities, in red on the map, were departments with an early vaccination scheme."
2549955,2.0,"2 Effect of vaccination on velocity of BTV-1 spread. Figure 3 displays vaccine coverage for the 1,314 municipalities used to analyse the effect of vaccination. Of these municipalities, 78% (1,028) had no vaccine coverage at the date of first clinical case. For the 286 municipalities with vaccine coverage, the percentage of immunized animals ranged from 0.4% to 100% (n = 15 municipalities) with a median value of 55%. The 1,314 municipality data subset was split randomly into “training” (986 municipalities) and “testing” subsets (328 municipalities). The first was used to fit linear regression models via OLS (Table S3). The best OLS model included elevation, edge density between arable land and forest, temperature at one and two month lags, rainfall at a two month lag, small ruminant and beef cattle densities, and vaccination coverage. This OLS model performed poorly in predicting the velocity of BTV-1 spread from environmental covariates (squared Pearson's r = 0.27, RMSE  = 7.33 km/day) in the training dataset and spatial autocorrelation at short distance was detected in the residuals (Fig. S2A). We thus fitted a RAC model to account for spatial autocorrelation. The RAC model contained the environmental covariates from the above OLS model plus an autocovariate that represented spatial autocorrelation in the residuals of the OLS model at a neighborhood size of 3.6 km. The fit of the RAC model was satisfactory (squared Pearson's r = 0.81, RMSE  = 3.69 km/day). In contrast to the OLS model, analysis of the residuals showed no spatial autocorrelation (Fig. S2). Parameter estimates of the RAC model are presented in Table 2. The RAC model was tested on the 328 municipality testing dataset and predictive performance was good (squared Pearson's r = 0.86, RMSE  = 3.14 km/day)."
2549955,3.0,"Estimated coefficients and p-values of environmental covariates are reported in Table 2. The intercept indicates an average velocity of BTV-1 spread of approximately 3.5 km/day (Table 2). As expected, vaccination was negatively associated with velocity of BTV-1 spread, which was, on average, 1.7 km/day lower in municipalities with immunized animals at the date of first clinical case, than in municipalities with no immunized animals."
2549955,4.0,"Meteorological variables, landscape factors and host availability were also correlated to velocity of BTV-1 spread. The contribution of covariates to model fit was assessed via D-values of each covariate (Fig. S3). Weather at a two-month lag had the greatest effect on the velocity of BTV-1 spread, followed by edge density between arable land and forest, temperature at one-month lag and density of beef cattle. Weather at a two-month lag greatly influenced velocity, the latter being negatively correlated to the monthly average of maximum daily temperature such that a 4 km/day decrease in velocity was observed when monthly average of maximum daily temperature was higher than 25°C. Velocity was also positively associated with rainfall: heavy rainfall (>70 mm per month) increased the velocity by 4 km/day. Considering the effect of weather at a one-month lag, a monthly average of maximum daily temperature around 24°C was associated with a velocity increase of 1.9 km/day. Overall, the effect of weather on the velocity of BTV-1 spread was greater at a two-month lag than at a one-month lag. Regarding landscape-related variables, elevation and edge density between arable land and forest were positively correlated with velocity. Finally, velocity of BTV-1 spread was associated with beef cattle and small ruminant densities in different ways, while the density of dairy cattle had negligible effect. Velocity was positively associated with beef cattle density. On the other hand, the highest small ruminant densities (>20 small ruminants/km2) were negatively correlated with velocity."
2549955,5.0,"Finally, the range of velocities obtained by varying a single covariate across its observed range whilst holding all other covariates constant at their observed mean is presented in Figure 4. The graph provides a visual indication of the independent effect-size of each covariate on the average value of 3.5 km/day."
341358,0.0,"Between 2012 and 2013, at the national level, 37 of 171 dairy cattle herds (21.6, 95% confidence interval: 16.1–28.4%) analyzed and 85 of 466 dairy cattle heads (18.2, 95% confidence interval: 15.0–22.0%) analyzed showed antibodies against BTV using cELISA as shown in Table 1. The agreement of the serologic status between dairy cattle sampled within the same herd in our prevalence study, as measured by the intra-class correlation coefficient, was 0.21. Our results identified the population sizes of herds to be a protective factor. An increased number of animals inside the farm led to a decreased risk of being positive. In the univariable analysis (Table 2), no significant risk differences in land use, adult/calf ratios, and experience of reproductive problems were found. Our results identified herd size as a protective factor. An increased number of animals inside the farm led to risk of being positive (OR = 2.762, p = 0.003 in a herd of ≤5 animals; OR = 4.174, p = < 0.001 in a herd of 6–30), while older age was shown to be a significant risk factor (OR = 0.294, p = < 0.001 in juveniles; OR = 0.443, p = 0.004 in a herd of subadults). The cattle density for the class of 11–20 animals was another significant risk factor (OR = 1.737, p = 0.070), while cattle densities for the classes of ≤10 or ≥ 21 were not significantly associated. We observed a significant difference in the individual likelihood of being positive in southern provinces with respect to northern provinces (OR = 1.757, p = 0.019). A significant difference was also observed in the individual likelihood of being positive in western provinces with respect to eastern provinces (OR = 0.531, p = 0.026). The risk factors identified in the multivariable logistic model (p < 0.001) were as follows: older animals (adults), southern, and northern provinces. The herd size was confirmed to be a protective factor (Table 3). Of the positive dairy cattle herds, 82.4% (28/34) were clustered in either < 30% or > 81%, suggesting a bimodal frequency distribution (Fig. 2). Additionally, there were substantial regional differences in the seroprevalence within South Korea (Fig. 1). Of the 85 ELISA-positive samples, only 59 were positive by SNT (Table 1) and neutralized one or more BTV serotypes: 1 (26 serum samples), 2 (11 serum samples), 3 (15 serum samples), 4 (13 serum samples), 7 (6 serum samples), 15 (9 serum samples), and 16 (13 serum samples). These findings support the notion that BTV-1 is the most prevalent serotype in South Korea. By contrast, 26 dairy cattle serum samples failed to neutralize any known BTV serotype. Additionally, the RNA of the BTV-1, − 2, − 3, − 15, and − 16 serotypes was detected in 13 serologically positive blood samples by RT-PCR, indicating that several BTV serotypes were actively circulating in the dairy cattle populations in the studied area. Further phylogenetic analysis and virus isolation for these blood samples could not be performed using these samples because of an insufficient blood volume and quality of the positive samples."
822569,0.0,"3.1. Demographic features. Since the first report in 2003, 11 cases of imported melioidosis have been reported in South Korea. The mean age of the patients was 52.3 years, ranging from 32 years to 66 years. Ten patients (90.9%) were older than 45 years, and all patients were male. With regard to their occupations, the patients included businessmen (36.3%), construction workers (18.2%), welders (18.2%), engineers (9.1%), drivers (9.1%), and actors (9.1%). The demographic, epidemiologic, and clinical features of the patients are summarized in Table 1."
822569,1.0,"3.2. Epidemiologic features. All the patients had visited Southeast Asia, which is a traditional endemic region for melioidosis. The countries from which melioidosis were imported included Malaysia (27.3%), Thailand (27.3%), Cambodia (18.2%), Philippines (9.1%), Indonesia (9.1%), and Vietnam (9.1%). Domestic cases of melioidosis have never been reported in South Korea, based on previous epidemiological investigations, and so all cases are thought to be imported. Nine patients had stayed in the endemic region for >1 month. However, two patients developed melioidosis after a few days of travel to the endemic region. Four patients developed symptoms during their stay in the endemic region and were diagnosed with melioidosis after returning to South Korea. The remaining seven patients developed initial symptoms after returning to South Korea. Of these patients, the interval between returning to South Korea and symptom onset ranged from 1 day to 3 years. Seven patients had at least one risk factor for melioidosis. Diabetes mellitus was the most frequent risk factor (63.6%), followed by lung cancer (9.1%) and chronic kidney disease (9.1%)."
822569,2.0,"3.3. Clinical manifestations. Eight patients had acute infections (symptom duration of <2 months) and three had chronic infection (symptoms for > 2 months). Of these 11 patients seven (63.6%) presented with pneumonia, three (27.3%) with genitourinary infection, and one (9.1%) with soft tissue infection. Abscess formation was observed in the prostate in three patients, and in the spleen and liver in one patient. Three patients had septic shock on admission with evidence of organ dysfunction, all of whom underwent rapid progression of the disease and died. Nine patients were bacteremic. In the remaining two patients, B. pseudomallei grew in bronchoscopic washing and surgical specimen obtained by pulmonary lobectomy. Four patients died and seven patients survived without relapse."
822569,3.0,"Of the five patients reported since 2011, two patients showed unusual clinical manifestation. Case 1 had a coinfection with pulmonary tuberculosis and melioidosis. The patient initially presented with chronic cough, and Mycobacterium tuberculosis was cultured in a lung biopsy. The patient underwent antitubercular therapy. However, the cough persisted, and the patient underwent a left upper lobectomy more than a year after returning from the endemic region. The surgical specimen grew B. pseudomallei. Case 5 was the first melioidosis patient in South Korea presented with a mycotic aneurysm of the aorta. The patient initially developed dysuria and was diagnosed with a prostate abscess. Although fever subsided after the treatment, fever recurred about 50 days after its onset. The subsequent diagnostic workup revealed a mycotic aneurysm of the aorta. The patient underwent surgical treatment of the aneurysm, and blood and the surgical specimen grew B. pseudomallei."
435540,0.0,"The demographic sub-model was able to reproduce the past population structure of Thailand from 1980 to the present (see S2 Figure A). The parameters that characterized seasonal movement were estimated by fitting the model to the population movement data (see S2 Figure B). The model showed that majority of movements were made by Northeast individuals who moved to non-Northeast areas, approximately 13,600 persons per 100,000 population per month, or 34% of all movements within a month (see S1 Table A). Moreover, the majority of movements were among those aged between 15 and 60 years old, about 19,000 persons per 100,000 population per month, or 51% of all movements within a month (see S2 Figure C)."
435540,1.0,"The fitting performance is shown in Fig 2. Melioidosis cases occurred seasonally, with a peak in the wet season that lasted from May to October. The infection parameters that minimized the fit statistic, using the Bayesian method, are shown in Table 1. The highest infection rate was estimated to be 6 cases per 100,000 population per month among males aged 45–59 years old in the Northeast. The lowest rate was 0.4 cases per 100,000 population per month among females aged 15–44 years old in the non-Northeast region. Surprisingly, we found that the infection rate among the transient male population aged 15–44 years was higher than the non-Northeast population (0.8 compared with 0.08 per 100,000 persons per month). Overall 46% of melioidosis cases were symptomatic. Recovery rates for untreated symptomatic cases and asymptomatic patients were estimated by the model, with the average period of infection estimated at around 9 and 5 months, respectively. The susceptibility to melioidosis among DM population is 10.84 [95% CI 8.42–12.23] times greater than the non-DM population. If patients’ treatment failed and they developed severe melioidosis, they could die within two weeks. We estimated 80% and 50% under-reporting of cases in 2008–2009 and 2010–2015, respectively."
435540,2.0,"Projections of the numbers of melioidosis cases between 2015 and 2035 are given in Fig 3. Total melioidosis incidence per year was projected to increase by 70%, from 6,569 (4,834–8,701) in 2015 to 11,173 (8,207–14,773) in 2035. The largest increase of melioidosis was projected to occur among the population aged 45–59 years old. The predicted incidence among males was two-fold greater than that of females. The majority of melioidosis cases were seen to occur in the population from the Northeast region of Thailand. The predicted incidence among non-diabetic was two-fold greater than that of diabetic population."
435540,3.0,"In Fig 4, total melioidosis incidence rates were projected to increase by approximately 10% by 2035, from 11.42 (8.5–13.4) in 2015 to 12.78 (9.6–14.9) per 100,000 population in 2035 (see Table 2). The highest incidence rates were predicted to be among those aged between 45–59 years old, followed by those age 60 years old and above. The incidence was almost double among males compared with females in both Northeast and other regions. The incidence rate among the Northeast population was more than double compared with the transient population, and almost ten times higher when compared with the other regions. This study also highlighted the importance of melioidosis among the transient population who temporally live in the risk area but had almost six times higher incidence compared with other regional populations. From diabetes prospective, the incidence of melioidosis among diabetes was predicted to be as high as 60 per 100,000 population. To summary, the risk of melioidosis among the aging population with some chronic diseases such as diabetes is presenting an increasing trend. The risk of infection among transient population, who temporary get some disease exposure during the agricultural seasons, cannot be ignored."
2515873,0.0,"The melioidosis cohort consisted of 30 patients and 30 controls. Baseline characteristics are in Table 1. In the melioidosis cohort, 6,755 probes were differentially expressed (that is, either up or downregulated) representing 4632 unique genes. Annotation was available for 1,658 of these genes, of which 651 were upregulated and 1,007 were downregulated. The tuberculosis cohort consisted of 20 patients and 24 controls. In the tuberculosis cohort, 6911 probes differentially expressed (5045 unique genes). Annotation was available for 1985 of these genes, of which 847 were upregulated and 1138 were downregulated. In both the melioidosis and the tuberculosis cohorts, the signature seen was dominated by neutrophils, which formed the bulk of the circulating leukocytes. Multiple lymphocyte-related pathways were downregulated, but this reflects the fact that lymphocyte counts were low in both melioidosis and tuberculosis. Pathways associated with transcription and translation were also prominent, in keeping with the large number of genes differentially regulated in both melioidosis and tuberculosis."
2515873,1.0,"Pathway Analysis. Interferon-mediated responses were the dominant pathway seen in both melioidosis and in tuberculosis (p<0.0001 for both, Tables 2 & 3). Class 1 and class 2 interferons were prominent in both (Table 4). Of the immune-related pathways, TRAIL (TNF superfamily member 10), tumour necrosis factor α (TNFα), transforming growth factor β (TGF-β), interleukin (IL)-1, IL-2, IL-12, chemokine and Toll-like receptor (TLR) pathways were all differentially regulated (Tables 2 & 3). There was no gene signature that distinguished melioidosis from tuberculosis, and for each of the pathways differentially expressed in melioidosis, we were able to find a counterpart in tuberculosis (Tables 2 & 3). Berry et al. reported an 86-gene signature that was specific for tuberculosis [7]. This 86-gene signature was also present in melioidosis (Figure 1)."
2515873,2.0,"Modular Analysis. In a modular analysis of the upregulated genes (Figure 2A), interferon and cytokine signalling clustered together in the centre of the network, causing the complement (cluster 1), NOD-like receptor (cluster 2) and TLR (cluster 3) pathways to gain prominence. In the downregulated genes (Figure 2B), the most prominent clusters were the ribosomal proteins (cluster 1) and zinc finger proteins (cluster 2)."
2515873,3.0,"PAMP-specific Responses. B. pseudomallei expresses lipopolysaccharide on its outer membrane, while M. tuberculosis does not and has a lipid-rich cell wall. Lipopolysaccharide is recognized by TLR4 and CD14, and both are upregulated in melioidosis (P = 0.0016 and 1.5 × 10–6, respectively); however, TLR4 and CD14 are also upregulated in tuberculosis (P = 1.5 × 10–6 and 9.4 × 10–4). B. pseudomallei is a flagellated, motile bacterium, while M. tuberculosis is immotile with no flagellum. Flagellin is a ligand for TLR5 [25] and NLRC4 [26]. Both TLR5 and NLRC4 were upregulated in melioidosis (P = 5.4 × 10–13 and 4.2 × 10–10, respectively), but both were upregulated in tuberculosis also (P = 8.1 × 10–10 and 2.4 × 10–11)."
1477397,0.0,"Incidence of melioidosis. A total of 2,243 patients were admitted to Sappasithiprasong Hospital between 1997 and 2006 with their first episode of culture-confirmed melioidosis. Overall, 24% of cases were diagnosed as a result of active case finding on the medical and intensive-care wards. The average annual incidence rate for the province during the 10-year study period was 12.7 cases per 100,000 people per year, but the rate showed considerable variability over time (Table 1). A year-on-year increase was observed between 2000 and 2006, and an annual incidence (100,000 people) of 8.0 (95% CI = 7.2–10.0) in 2000 rose to 21.3 (95% CI = 19.2–23.6) in 2006 (P < 0.001; χ2 test for trend). There was a negative association between the total annual rainfall and the number of melioidosis cases in each year (Spearman's ρ = −0.89; P < 0.001) (Table 1)."
1477397,1.0,"Incidence of melioidosis by age, gender, and diabetes. Twenty-seven patients were excluded from this analysis, because the history of underlying diseases was not recorded. Of the 2,217 patients remaining, 1,296 (58.5%) were male, and 921 (41.5%) were female. Median age was 49 years (interquartile range [IQR] = 37–60 years), and 199 patients (9.0%) were younger than 15 years of age. A total of 662 patients (29.9%) were patients with known diabetes, and an additional 370 patients (16.7%) were defined as having previously undiagnosed diabetes at presentation with melioidosis. The previously undiagnosed diabetes group was made up of 222 patients (60%) who survived their episode of melioidosis and had confirmed diabetes and 148 patients (40%) who were hyperglycemic at presentation but died of melioidosis before the presence of diabetes could be investigated. Table 2 shows the average annual incidence rate of melioidosis by age, sex, and presence of diabetes. Melioidosis was more common in males, and incidence was highest in the 55- to 64-year age group. Crude and adjusted rate ratios (RR) were calculated for gender, age, and diabetes (Table 3). Male sex, age ≥ 45 years, and both known and undiagnosed diabetes were independent risk factors for melioidosis. Known and undiagnosed diabetes were associated with an adjusted RR of 12.4 and 7.8, respectively, compared with no diabetes (P < 0.001)."
1477397,2.0,"Deaths from melioidosis. Death occurred in 956 of 2,243 patients, and the average mortality rate over the study period was 42.6% (Table 1). There was a decrease in mortality rate over time from 49% in 1997 to 40.5% in 2006 (P = 0.006; χ2 test for trend). The average mortality rate from melioidosis was calculated for the province as 5.41 per 100,000 people per year. Figure 1 shows a comparison between these data and national population mortality rates attributed to other infectious diseases. If national data for deaths from infectious diseases are representative for Ubon Ratchathani province, melioidosis was the third most common cause of death from an infectious disease over the study period after human immunodeficiency virus (HIV)/acquired immunodeficiency syndrome (AIDS) and tuberculosis. In 2006, the population mortality rate attributed to melioidosis was comparable with the mortality rate attributed to tuberculosis (8.64 [95% CI = 7.33–10.11] versus 8.30 per 100,000 people per year, respectively)."
1477242,0.0,"A total of 44,426 blood culture samples were collected from patients during January 2009 to December 2013 in Nakhon Phanom province. Of these, 2,528 (5.7%) cultures from 2,031 patients had a presumed pathogen isolated. A total of 631 B. pseudomallei isolates from 575 patients were identified; after excluding 11 outpatients and 56 patients with multiple positive cultures, 564 hospitalized bacteremic melioidosis patients were included in the analysis. Among these 564 patients with bacteremic melioidosis, 313 (56%) had ALRI and were also captured by the pneumonia surveillance system (Figure 1)."
1477242,1.0,"Incidence of hospitalized bacteremic melioidosis. The overall incidence rate of bacteremic melioidosis hospitalizations in Nakhon Phanom, Thailand, during 2009–2013 was 14.9 per 100,000 persons per year. Annual incidence ranged from 13.7 per 100,000 persons in 2009 to 17.2 per 100,000 persons in 2010 (Table 1). Males comprised 60% of hospitalized bacteremic melioidosis patients and the overall incidence rate was higher in males than females (Table 1). During the investigation period, bacteremic melioidosis occurred in patients aged 1 to 93 years old; median age was 53 years (interquartile range 43–62 years), and 22 (4%) bacteremic melioidosis patients were younger than 15 years old. The highest incidence was observed among patients aged 55–64 years at 46.9 per 100,000 persons per year (95% CI; 39.9–54.8) (Table 1). Age-specific incidence rate by year is shown in Figure 2. The number of bacteremic melioidosis cases was significantly higher in the rainy season, 304 cases in July–October with a peak in August (19%) compared with the dry season, 121 cases in March–June (P-value = 0.037)."
1477242,2.0,"Of 313 bacteremic melioidosis patients with ALRI, 202 (65%) had a CXR performed within 48 hours after admission, and 92 (29%) had radiographic evidence of pneumonia. Therefore, among all 564 bacteremic melioidosis case patients, 92 (16%) had pneumonia. The incidence rate of hospitalized bacteremic melioidosis with pneumonia was 2.4 per 100,000 persons per year (95% CI; 1.9–2.9). Among bacteremic melioidosis patients with pneumonia, the most common clinical characteristics were rales or crepitation (84%), fever > 38°C (74%), cough (66%), and dyspnea (66%); 74% required oxygen supplementation."
1477242,3.0,"Among the 564 hospitalized bacteremic melioidosis patients, 52% (294) were admitted in community hospitals and 48% (270) in a provincial hospital. Patients admitted in the provincial hospital were more likely to have severe respiratory illness as demonstrated by 40% requiring intubation (54/138) compared with 11% (20/175) of patients admitted to community hospitals, P-value < 0.001. We observed differences in the prevalence of the following clinical measures between bacteremic melioidosis patients with ALRI admitted to the provincial hospital compared with those admitted to community hospitals: dyspnea (62% versus 28%), tachypnea (43% versus 21%), wheezing (24% versus 43%), confusion (21% versus 9%), oxygen therapy (64% versus 49%), intubation (39% versus 10%), abnormal white blood cell count (60% versus 43%), and comorbidity of renal disease (41% versus 26%) and liver disease (19% versus 3%); P-value < 0.05."
1477242,4.0,"Deaths among hospitalized bacteremic melioidosis. In-hospital death occurred in 79 (14%) of 564 bacteremic melioidosis patients. Most (50/79) deaths occurred within 2 days after admission. Median duration of hospital stay before death was 2 days with a range of 1–21 days. The in-hospital fatality rate declined from 15% in 2009 to 13% in 2013 (slope of regression; −0.5%, 95% CI; −1.1–0.03%, Figure 3A). The in-hospital fatality rate among bacteremic melioidosis patients was highest in November at 19% (8/43) compared with the month with the highest number of cases in August 13% (14/106). The overall population mortality rate was 2.1 per 100,000 persons per year (95% CI; 1.7–2.6) and slightly decreased from 2.7 per 100,000 persons per year (95% CI; 1.6–4.1) in 2010 to 2.0 per 100,000 persons per year (95% CI; 1.1–3.3) in 2013. The observed in-hospital fatality rate among bacteremic melioidosis pneumonia patients significantly decreased from 33% (6/18) in 2009–5% (1/20) in 2013 (P-value = 0.006) (Figure 3B). Thirty-nine (42%) melioidosis pneumonia patients were intubated and mechanically ventilated, of whom 51% (20/39) died in the hospital and 41% (16/39) were discharged in poor condition. In-hospital mortality rate among patients admitted to the provincial hospital was higher than that among cases admitted to community hospitals (33% [67/206] versus 7% [12/173], P-value < 0.001)."
1477242,5.0,"Potentially poor clinical outcome at the time of discharge was observed at 32% (178/564) of bacteremic melioidosis patients, including 139 (25%) who transferred to another hospital, 22 (4%) discharged against advice, and 17 (3%) escaped (Table 2). Outcome status was listed as poor condition in 47% (34/72) of bacteremic melioidosis patients with pneumonia compared with 35% (144/413) of non-pneumonia cases (P-value = 0.045). Given the high percentage of patients with potentially poor clinical outcome at the time of discharge, we performed a sensitivity analysis to account for a range of overall death rate among patients discharged in poor condition. The overall death rate ranged from 14% to 46%; 22% to 59% among patients with pneumonia; and 13% to 43% among non-pneumonia patients. Patients who had poor clinical outcome at discharge were more likely to have dyspnea (48% versus 31%), abnormal breath (40% versus 24%), tachypnea (36% versus 23%), oxygen therapy (71% versus 37%), intubation (30% versus 4%), and confusion (19% versus 8%) compared with survivors; P-value < 0.05."
1477242,6.0,"Drug susceptibility. Among 513 B. pseudomallei isolates tested since 2010, 99.8% were susceptible to ceftazidime and 95.8% were susceptible to trimethoprim/sulfamethoxazole. No clear trend in resistance patterns during the study period was observed."
429616,0.0,"A total of 30 patient samples classified as cases of melioidosis were analyzed of which 23 were confirmed cases (culture positive) and 7 were probable cases (high antibody titre positive). Among the 23 confirmed cases of melioidosis, 18 were classified as septicaemic or bacteriaemic. A total of 27 identified positive cases had comorbidities such as diabetes, alcoholism, kidney disease etc. Healthy volunteers and cases of sepsis (negative for B. pseudomallei) of 10 each, were also profiled as negative controls for the study."
429616,1.0,"We analyzed our data based on duration of clinical symptoms, duration of antibiotics and associated comorbidities as these listed factors play a confounding role in host gene expression during infection. Such an analysis was needed to understand host gene expression during early and late acute phases of infection and disease severity in susceptible groups."
429616,2.0,"Interestingly, we did not find significant differential expression of immune response genes and epigenetic modifiers in melioidosis patients compared to healthy controls. Cases of sepsis due to other infections, on the other hand, showed statistically significant differential gene expression from the melioidosis patients for most of the genes investigated."
429616,3.0,"Gene expression profile of cytokines. mRNA expression levels of IL18, CCL5 and IL12 in PBMC’s were low in all the samples. IL8, IL15 and HMGB1 were significantly up regulated in other sepsis cases compared to healthy controls (Table 2, Fig 1)."
429616,4.0,"IL6, IL8, IFNγ, TNFα, IL1β and IL15 did not show any statistically significant differential gene expression in melioidosis samples compared to sepsis cases. IL4 showed significant up regulation in melioidosis cases compared to other sepsis cases (Table 2, Fig 1) while HMGB1, an inflammatory mediator was consistently down regulated in melioidosis cases compared to other sepsis cases, irrespective of all other factors like comorbidities, duration of fever/clinical symptoms and antibiotic treatment (Tables ​(Tables22–5, Figs ​Figs11–3)."
429616,5.0,"Septicaemic melioidosis patients showed a similar expression pattern as above, in addition to IL8 being down regulated compared to other sepsis cases (Table 3, Fig 1). IL8 down regulation was also seen in early acute melioidosis cases with less than 15 days of fever/clinical symptoms and antibiotic treatment. (Table 3, Fig 2). Melioidosis patients with regular alcohol consumption habits also expressed significant down regulation of IL8 compared to other sepsis cases (Table 5, Fig 3)."
429616,6.0,"Gene expression profile of Toll-like receptors (TLR’s). TLR2 and TLR4 were significantly up regulated in sepsis caused by other pathogens compared to healthy controls. Melioidosis patients showed significantly down regulated expression of TLR4 while both TLR2 and TLR4 was down regulated in septicaemic melioidosis cases compared to sepsis caused by other pathogens (Table 2, Fig 1)."
429616,7.0,"Gene expression profile of genes associated with the antigen presentation pathway and cell-mediated immunity. MICB, PSMB2, PSMB8 and PSME2 were significantly up regulated in other sepsis cases compared to healthy controls while these target genes showed no significant differential expression in patients suffering from melioidosis compared to healthy controls. Therefore, the expression of these genes can be considered as down regulated in the melioidosis cohort including septicaemic melioidosis cases compared to other sepsis cases (Tables ​(Tables22 and ​and3,3, Fig 1). This differential expression between melioidosis cases compared to sepsis controls was seen consistently, irrespective of other factors like duration of fever/clinical symptoms, antibiotic treatment and associated comorbidities (Tables ​(Tables22–5, Figs ​Figs11–3)."
429616,8.0,"Gene expression profile of epigenetic modification factors. DNMT3B, HDAC1 and HDAC2 were significantly up regulated in other sepsis cases compared to healthy controls (Table 2, Fig 1). These epigenetic markers were significantly down regulated in melioidosis including septicaemic melioidosis cases compared to other sepsis cases (Tables ​(Tables22 and ​and3,3, Fig 1). Our results also showed a consistent differential expression pattern of these epigenetic factors irrespective of other factors like duration of fever/clinical symptoms, antibiotic treatment and associated comorbidities (risk factors) (Tables ​(Tables22–5, Figs ​Figs11–3). Melioidosis patients with a regular alcohol consumption habit also expressed significant down regulation of DNMT3A, apart from a similar differential expression of other markers compared to other sepsis cases (Table 5, Fig 3)."
1807783,0.0,"Figure 1 shows the configuration of parameter estimates for reduction in CFR and percentage of melioidosis-confirmed cases in which each strategy is cost-effective. In a scenario where 20% of empirically treated patients are culture-confirmed melioidosis, meropenem would be cost-effective as an empirical treatment for patients with suspected severe melioidosis (Plan B) and for all suspected melioidosis patients (Plan C) if meropenem reduced mortality by at least 9% (absolute reduction from 70% to at least 64%) and at least 30% (absolute reduction from 40% to at least 28%), respectively (Figure 1, Scenario 1). This proportion of culture-confirmation is a reasonable estimate for routine practice in northeast Thailand."
1807783,1.0,"In a scenario where over 50% of empirically treated patients are culture-confirmed melioidosis, (Plan B) would be cost-effective with a reduction in CFR of 5% and (Plan C) with a reduction of at least 14%, respectively (Figure 1, Scenario 2). Such a high proportion of culture-confirmation has been reported in the context of clinical trials, however, this is unlikely to be representative of routine care."
428872,0.0,"Patient characteristics. We recruited 52 controls and 34 culture-confirmed melioidosis patients at Sappasithiprasong Hospital in Ubon Ratchathani, Thailand. All patients were septic (see inclusion criteria) and had diabetes. Controls were, therefore, otherwise healthy diabetics attending a routine out-patient diabetes clinic. Their baseline characteristics are presented in Table 1 and their laboratory findings are depicted in S1 Table. This cohort has been previously described elsewhere [9]. In the melioidosis group, 12 patients died (35%) before the first follow up (≥28 days after enrolment)."
428872,1.0,"Melioidosis is associated with thrombocytopenia. An important function of VWF is to mediate platelet-platelet interactions and platelet adhesion to sub-endothelial collagen and is associated with platelet consumption and thrombocytopenia [13–15]. The median platelet count in patients with melioidosis was 189 × 109/l compared to 299 × 109/l in controls (p = 0.0001, Fig 1A). There were 14 melioidosis patients (41%) with thrombocytopenia (defined as a platelet count <150 × 109/l) and no cases of thrombocytopenia among controls (p<0.0001). Among patients, the lowest admission platelet count observed was 13 × 109/l. Platelet counts were lower in non-survivors (median 138 × 109/l) compared to survivors (247 × 109/l, p = 0.02, Fig 1B). Of the 12 patients who died, eight (67%) had thrombocytopenia compared to six of the survivors (27%, p = 0.04)."
428872,2.0,"VWF levels are elevated in melioidosis. Having seen thrombocytopenia in acute melioidosis, we predicted that this would be driven by high levels of circulating VWF. We observed that VWF antigen levels were higher in patients (geometric mean, 478 U/dl) compared to controls (166 U/dL, p<0.0001, Fig 2A). However, the level of VWF antigen at recruitment was not associated with mortality (geometric mean 445 U/dL in survivors versus 540 U/dL in non-survivors, p = 0.08, Fig 2B)."
428872,3.0,"Excess circulating VWF in melioidosis is driven by excess secretion. Next, we looked at whether the excess VWF antigen might be explained by increased secretion. VWF propeptide is a marker for recent secretion of VWF from the Weibel-Palade bodies (WBD) of endothelial cells and the dense granules of platelets [29]. We found VWF propeptide concentrations were higher in patients (460 U/dL) compared to controls (159 U/dL, p<0.0001, Fig 3A). Furthermore, VWF propeptide levels correlated well with VWF antigen levels (Pearson’s r = 0.54, p = 0.003, Fig 3B), supporting our hypothesis that the excess in circulating VWF was due to excess secretion of VWF. VWF propeptide concentration and survival were not correlated, and the range of values obtained in non-survivors fell within the range obtained for survivors (p = 0.21, Fig 3C)."
428872,4.0,"Excess circulating VWF antigen is also driven by reduced ADAMTS13. ADAMTS13 is a metalloprotease secreted by the liver known as VWF cleaving protease [14, 17]. Deficiencies of ADAMTS13 results in the accumulation of VWF in the circulation and, consequently, thrombocytopenia [13, 14]. Previous studies have found an association between sepsis and reduced levels of ADAMTS13 [30, 31]. The mean ADAMTS13 concentration was 31 U/dL in patients and 90 U/dL in controls (p<0.0001, Fig 4A). ADAMTS13 levels and VWF antigen were negatively correlated (r = 0.53, p = 0.002, Fig 4B), which supports our hypothesis that decreased levels of ADAMTS13 contribute to high concentrations of VWF in melioidosis. However, there was only weak evidence for an inverse correlation between ADAMTS13 deficiency and mortality in melioidosis (p = 0.05, Fig 4C). Although the mean ADAMTS13 level in non-survivors (26 U/dL) was lower than that in survivors (34 U/dL), the range of values obtained in non-survivors (14 to 43 U/dL) fell entirely within the range of values obtained in survivors (11 to 57 U/dL)."
428872,5.0,"VWF is not the main driver of thrombocytopenia in melioidosis. Thrombocytopenia was a feature of acute melioidosis and correlates with mortality. We also found high levels of VWF in melioidosis, which were both explained by increased secretion of pre-formed VWF and by reduced clearance of VWF. However, if VWF were the main driver of thrombocytopenia in melioidosis, then it is surprising that VWF antigen, VWF propeptide and ADAMTS13 levels do not correlate with mortality. We therefore re-examined the relationship between VWF antigen levels and platelet count, and found that although both were deranged in melioidosis, their levels were not correlated (r = 0.28, p = 0.12, S1 Fig)."
428872,6.0,"Platelet counts, VWF antigen and ADAMTS13 return to normal following recovery from melioidosis. In those patients who survived, a follow-up sample was taken seven days following enrollment and at the first follow-up clinic (≥28 days after discharge). In all patients, perturbations of platelet counts as well as abnormalities in levels of VWF antigen, VWF propeptide and ADAMTS13 all resolved completely following recovery from melioidosis (S2A–S2D Fig)."
432177,0.0,"We identified 1170 articles from the bibliographic databases search (PubMed, Web of Science and Thai-Journal Citation Index) including Google Scholar, as well as 82 articles from the grey literature sources. After removal of duplicates, the remaining 1091 records were then assessed for the eligibility through abstracts and full texts. We excluded 1021 studies for particular reasons, and the rest of the 70 studies were sought for the individual participant data. We found 69 studies with 159 subjects for which individual participant data were provided. However, nine individual patients were excluded because the participants duplicate others."
432177,1.0,"Moreover, we excluded the additional 42 cases because the diagnosis was not CNS melioidosis. Finally, we recruited 69 reports including 108 subjects for which individual participant data were provided. For another study that individual participant data were not provided, the aggregate data of 12 participants were available. In total, we recruited 70 studies with 120 patients for the analysis (Fig 1). The first report of a CNS melioidosis patient was presented in 1977. The number of patients per publication ranged from 1 to 12 cases."
432177,2.0,"The characteristics of the included studies and individual patients are summarized in the S1 Table. Most cases (93%) were reported from the endemic area of melioidosis in which Australia, Thailand, India, and Malaysia accounted for a majority of patients (Fig 2). Ninety-three percent of Australian patients were reported from the northern part, while 65% of Thai cases were from the northeastern region. Eight cases (7%) were reported from the non-endemic countries including the USA, Belgium, Japan, Norway, and UAE. These patients traveled, lived or served as a soldier in the endemic region at some points of time before the disease development. Fifteen cases worked as rice farmers. Three patients reported the histories of preceding cranial injuries."
432177,3.0,"The median age of the CNS melioidosis patients was 40 years (IQR 18–53). The 10-day newborn was the youngest reported case, while the oldest was 75 years of age. Most patients (77%) were adults (≥19 years), and 70% of patients were men. Risk factors for melioidosis were shown in Table 1. Most patients (60%) had one or more risk factors. Diabetes mellitus was the most common (43%), but in Australia, excessive alcohol use is the most prominent risk factor (39%). Five cases from Australia were reportedly heavy drinkers of kava, a drink prepared from the powder of the root plant Piper methysticum. Contrary to adult patients, most pediatric cases (67%) did not have any risk factors for melioidosis. However, diabetes mellitus remained the only risk factor among children."
432177,4.0,"The median duration from clinical onset to diagnosis was ten days (IQR 5–25), and it ranged from 1 to 150 days. Majority of CNS melioidosis patients (91%) was classified as acute melioidosis (less than two months of onset). Encephalomyelitis (37%) and brain abscess (35%) were the two most common disease types. Regarding the age group, encephalomyelitis was most observed in the adult (39%), while brain abscess was the most common type in the children (44%). The cases of encephalomyelitis were reported mainly from Australia (63%). Other types of CNS melioidosis included isolated meningitis and isolated extra-axial collection, which accounted for 16 and 12 percent of cases, respectively. Clinical manifestations of all CNS melioidosis and its types are described in Table 2. Fever was the top presentation for all CNS melioidosis, while other features included headache, altered consciousness, neck stiffness, seizures, unilateral weakness, paraplegia, quadriplegia, and cranial nerve palsies. The facial nerve was the most common cranial nerve affected. In encephalomyelitis patients, the fever and cranial nerve deficits were the prominent manifestations. In brain abscess cases, the most common presentations were the fever and unilateral weakness. Fifteen cases were reported to present with craniofacial swelling. Sixty-seven percent of patients had one or more extraneurological involvement. More than half of those had a pulmonary infection, while one-fourth had localized skin infection (Table 3)."
432177,5.0,"Fifty-eight cases underwent lumbar puncture. The CSF profile showed pleocytosis in 91% of the cases, and 64% of patients had CSF mononuclear cell predominance. The CSF WBC count had a median of 190 cells/μL (IQR 54–413), while no CSF RBC was detected in 78% of patients. CSF protein was high (>0.45 g/L) in 93% of cases, and the median protein value was 1.16 g/L (IQR 0.82–1.64). CSF glucose was low (<2.2 mmol/L) in 34% of patients, and the mean glucose level was 2.8 mmol/L (SD 1.5)."
432177,6.0,"Both CT and MRI of the brain were equally done (60% vs. 58% of cases). However, 33% of patients who did the brain CT initially had a normal imaging result, while the brain MRI findings were abnormal in all cases. The imaging findings included hyperintensity on T2W in all MRI cases and also brain edema in 97% of CT and MRI results. There were 49 patients of encephalomyelitis and brain abscess reported having the abnormal contrast enhancement in neuroimaging which the rim-enhancing pattern was the most common characteristic (78%). Other features included nodular (14%), irregular (14%), leptomeningeal (14%) and linear enhancement (2%). Brainstem (34%), frontal lobe (34%) and parietal lobe (33%) were among the most common locations affected in the encephalomyelitis and brain abscess patients (Table 1). Lesions involving contiguous parts of the CNS, which included supra- and infratentorial brain as well as spinal cord, occurs in 29 percent of encephalomyelitis cases. Skull and scalp lesions were present in 19% and 16% of cases, respectively. Twenty-two percent of patients having brain parenchymal diseases also had concurrent involvement of adjacent parts encompassing extra-axial spaces, skull or extracranial structures."
432177,7.0,"The diagnosis of melioidosis was confirmed with the positive culture in 110 CNS melioidosis patients (92%). Blood was the most common specimen (41%) that grew the organism. Positive cultures of the CNS specimens, which includes brain tissue or pus, CSF and extra-axial collection, were present in 32, 21 and 10 cases, respectively (Table 4). Nine patients (8%) depended on only the serology for diagnosis, which the antibody titer ranged from 1:16 to 1:1,280. There was one case that was diagnosed by only polymerase chain reaction test of blood buffy coat."
432177,8.0,"Ceftazidime (54% of cases), meropenem (36%) and trimethoprim/sulfamethoxazole (TMP/SMX, 41%) were the primary drugs used for intensive-phase therapy. Others included chloramphenicol (13%), imipenem (7%) and doxycycline (5%) (Table 1). Eight or more weeks of recommended treatment duration was reported in 30 percent of non-death cases. For eradication phase, TMP/SMX was the most common prescription (73%) among others that encompassed doxycycline (27%) and amoxicillin/clavulanic acid (12%). The treatment duration of at least six months was given in 24 percent of non-death patients. Adjunctive abscess drainage was performed in 58 percent of cases. After treatment, 37 percent of the CNS melioidosis patients recovered completely or nearly completely. Thirty-one percent had moderate neurological improvement, while 13 percent did not recover and suffered neurological disability. Overall mortality was 20 percent of patients."
1974798,0.0,"Our synthesis of evidence from 12 observational studies indicates that diabetes is the risk factor for melioidosis with the highest relative risk, followed by age over 45 years and chronic renal disease (Table 1). In the regional analysis, vaccinating diabetics aged over 45 years living in environmentally suitable areas for melioidosis (Vac 2) would be cost-effective in EAP, SAF and SOA (Fig. 2; see Additional file 1: Table S4 and Figure S2 for detailed results). However, those vaccination strategies would not be cost-effective in LAC and MENA. In the country/territory-level analysis, vaccinating diabetics aged over 45 years (Vac 2) is a cost-effective strategy in 45 geographies. Of these, vaccinating individuals aged over 45 years with either diabetes or chronic renal diseases (Vac 3) is the optimum strategy in six geographies, while vaccinating everyone aged over 45 years with or without diabetes/chronic renal disease (Vac 4) is optimal in ten geographies (Additional file 1: Table S5). However, in 22 geographies, none of the strategies tested (Vac 1-Vac 4) are cost-effective (Fig. 3). Figure 4 shows the cost-effectiveness of vaccinating the diabetic population aged over 45 years (Vac 2) in each geography, as a ratio of GDP per capita."
1974798,1.0,"Of 5.47 billion people across the 83 evaluated geographies, 1.55 billion are predicted to live in environmentally suitable areas for melioidosis transmission [3]. Of these, 457 million are > 45 years old. If the optimal cost-effective strategy in Additional file 1: Table S5 was applied in each of the 61 geographies where one of the vaccine strategies was found to be cost-effective, 5.26 million people would be vaccinated per year, averting on average 69,000 lost QALYs, 8400 cases and 4500 deaths (i.e. 5.09% reduction in total burden) per vaccinated age cohort. Vaccination would cost USD62.1 million per year but save USD2.47 million in treatment costs. The regions in order of the magnitude of projected reductions in cases are EAP, SOA, SAF, LAC and MENA (with reductions in total burden of 6.72%, 5.30%, 3.87%, 3.58% and 1.99% respectively)."
1974798,2.0,"Alternatively, if everyone aged 46 living in an environmentally suitability area was vaccinated (Vac 4), then 15.18 million people would be vaccinated per year. This could potentially prevent 13,628 cases of melioidosis and 7386 deaths (9.4% reduction) with a gain of 113,407 QALYs per vaccinated age cohort. If the cost of vaccination was not fixed, then under this scenario the threshold cost of vaccination (averaged across all countries) would be USD18.54, giving a potential market size of USD281.32 million per year (ignoring vaccine distribution costs)."
1974798,3.0,"A sensitivity analysis showed that with only 50% vaccine protection, vaccinating diabetics aged over 45 years (Vac 2) is a cost-effective strategy in 43 geographies. In addition, vaccinating individuals aged over 45 years with diabetes and/or chronic renal disease (Vac 3) is the optimum strategy in three geographies, while vaccinating everyone aged over 45 years with or without diabetes/chronic renal disease (Vac 4) is optimal in five geographies. In 32 geopraphies, none of the strategies tested (Vac 1-Vac 4) are cost-effective (Additional file 1: Figure S3(a-g) and Table S6). If the optimal cost-effective strategy was applied in each of the 51 geographies, 3.55 million people would be vaccinated per year, averting on average 35,370 lost QALYs, 4311 cases and 2332 deaths (2.61% reduction) per vaccinated age cohort."
639480,0.0,Behavioural analyses
639480,1.0,"Experiment 1 \n The experiment was designed to compare the learning and retention of visuomotor rotations under error-based feedback and two types of reinforcement feedback. Figure 2 A shows the time series of reach angles for the different groups. All groups could reach within the target zone during the baseline phase. During the perturbation phase all groups learned and on average were within the final target zone centred on 15�. The open- and closed-loop groups were able to match the desired duration time window for most trials and did not have a significantly different proportion of trials outside the range (invalid trials, 5.7% and 3.7%, respectively, P = 0.18). During retention, when both the cursor and outcome feedback were removed, each group initially maintained their learned reach angle, though the error-based group showed some decay over this period. \n A mixed model ANOVA of reach angle showed no group effect, but a significant effect of experimental phase [ F (4,228) = 79.176, P <  0.001; Greenhouse-Geisser corrected, F (2.267,129.198) = 79.176, P <  \n 0.001] and a significant group � phase interaction [ F (2,228) = 6.849, P <  0.001]. Thus, the three groups responded differently across phase. We used post hoc comparisons to examine the key features of learning and retention. We found differences at baseline with the open-loop group having a significantly more negative reach angle compared to the error-based group ( P <  0.05). In addition the closed-loop group showed significantly more learning in the early perturbation phase compared to the error-based and open-loop groups (both P <  0.001). All groups showed significant learning from baseline to the late perturbation phase (all P <  0.001) and similar reach angles early in retention, but in late retention the error-based group showed significant decay from late perturbation compared to the other groups ( P <  0.001). This suggests that learning with error feedback yielded reduced retention of the learned movement relative to reinforcement feedback. \n Figure 2 B shows total learning (difference between Baseline and End Perturbation) and the per cent early and late retention (measured as the ratio of Early and Late Retention angle to End Perturbation). One-way ANOVA on total learning revealed a significant main effect of group [ F (2,57) = 5.446, P <  0.01], driven by a significant difference between the error-based and open-loop group. This effect was preserved in Brown-Forsythe testing of mean differences, which accounts for unequal variances within groups [ F (2,38.439) = 5.446, P <  0.01]. \n One-way ANOVA showed similar early retention (mean of first 40 retention trials) for all groups [F(2,57) = 2.833,P = 0.067] but a significant difference in late retention [mean of last 40 retention trials F (2,57) = 5.056, P <  0.05] and post hoc test showed this was driven by the decay in the error-based group compared to the open-loop group ( P <  0.05). To examine differences in retention between groups when equated for total learning (and therefore discounting potential effects of the number of valid trials), we selected 10 subjects (of 20) from each of the open-loop and closed-loop groups so as to match their total learning mean and variance to the error-based group. To do this we computed the mean and variance of all possible subgroups of 10 subjects in the open-loop and closed-loop groups, respectively. We chose the subgroup that minimized the Jensen-Shannon divergence between that subgroup and the error-based group�s total learning distributions. Figure 2 C shows the time series of reach angles for these matched subgroups and the error-based group. Group means for total learning were not significantly different following matching, [ F (2,37) = 3.215, P = 0.052; Brown-Forsythe, F (2,17.182) = 2.645, P =  0.10; Fig. 2 D]. Analysis of both early and late retention in the matched subgroups revealed a significant main effect of group [early retention, F(2,37) = 6.573, P <  0.01; late retention,F (2,37) = 8.916, P <  0.01;Fig. 2 D]. The main effect for late retention was preserved following Brown-Forsythe tests [ F (2,19.406) = 9.097, P <  0.01] indicating that the result was robust to unequal variance across groups. In both early and late retention, main effects were driven by significantly reduced retention in the error-based group compared with the two reinforcement-learning groups. Thus, learning with reinforcement feedback yielded enhanced retention of the learned reach angle compared with online error feedback. \n To examine variability in performance we analysed within subject standard deviations in the reach angles of the overall groups over the 40 baseline trials. One-way ANOVA revealed a significant main effect of group [ F (2,57) = 7.251, P <  0.01], which was repeated following Brown-Forsythe testing [ F (2,42.044) = 7.251, P <  0.05]. Post hoc comparisons revealed that the effect resulted from significantly greater within subject reach angle variability in the two reinforcement groups compared to the error-based group (both P <  0.01). The main effect of group was replicated when within subject reach angle standard deviation was analysed in the resampled reinforcement groups matched to the performance of the error-based group [ F (2,37) = 7.496, P < 0.01; Brown-Forsythe, F (2,20.587) = 5.695, P <  0.05]. Overall, these findings suggest that online error feedback reduces behavioural variability compared with binary reinforcement feedback."
639480,2.0," Experiment 2 \n This experiment was designed to compare reinforcement learning and error-based learning in individuals with cerebellar damage and age-matched, healthy controls (older controls). Both groups could, on average, reach within the target zone during the baseline phase of both tasks ( Fig. 3 A and B). By the late perturbation phase, control subjects were on average within the final target zone (centred on 15�) in both tasks. However, the cerebellar group on average only reached the final target in the error-based task. Both groups maintained their learned reach angle throughout retention in the closed-loop task. In the error-based learning task, older control subjects initially maintained their learned reach angle, but their performance decayed over the retention period. In contrast, the cerebellar subjects showed no retention as their performance immediately returned to close to baseline. \n We used a mixed-model ANOVA to examine differences in reach angle between the groups, tasks and phases. We found significant main effects of group [ F (1,21) = 8.6, P <  0.01], task [ F (1,21) = 6.3,P <  .05] and phase [ F (4,84) = 50.1,P < 0.001; Greenhouse-Geisser corrected,F(2.4,49.8) = 50.1,P < 0.001]. The interaction among these factors was also significant [F(4,84) = 4.73,P < 0.01].Post hocanalysis showed that both groups learned from baseline to the late perturbation phase in both tasks (for the cerebellar group in the closed-loop task,P < 0.05, all others, P < 0.001). Total learning was greater for the error-based task compared to the reinforcement task [F(1,21) = 24.7,P < 0.001,Fig. 3C]. Although there were differences in the mean learned reach angle between older control group and cerebellar group in the closed-loop task (P < 0.01), total learning was not significantly different across the groups in either task (P = 0.235). \n In the closed-loop condition, the cerebellar and older control group did not have a significantly different proportion of invalid trials (10.9 and 11.5%, respectively, P = 0.90) whereas the young controls had only 1.7% invalid trials. We used a bootstrap analysis to compare reach angles at the end of the perturbation phase as well total learning, both adjusted for the number of valid trials (see �Materials and methods� section). This showed that the cerebellar group had a significantly smaller reach angle at the end of the perturbation phase compared to the older and younger groups (P < 0.001), but the older group was not significantly different from the younger group (P = 0.24). However, for total learning all groups showed significantly different amounts of learning with the older learning more than the cerebellar group (P = 0.026) and the younger learning more than the older group (P < 0.001). \n In the error-based task, both groups showed a significant decay from late perturbation to early and late retention (older control:  P <  0.001, P < 0.05, respectively; cerebellar: bothP < 0.001). However, the decay in early retention was much greater for the cerebellar group as they returned to near baseline performance ( P < 0.001). \n To take into account the final learning level, we examined the per cent early and late retention ( Fig. 3 D and E). Mixed model ANOVA of per cent early retention revealed a significant main effect of task [ \n F (1,21) = 54.8, P <  0.001] and a significant interaction among factors group and task [ F (1,21) = 15.2,P < 0.01, Fig. 3 D]. Post hoc analysis showed that the cerebellar group had reduced retention in the error-based task relative to the closed-loop task ( P <  0.001) and reduced retention in the error-based task compared to controls ( P < 0.01). ANOVA of per cent late retention revealed a significant main effect of task [ F (1,21) = 11.3, P < 0.01, Fig. 3 E], which was driven by reduced retention in both groups the error-based task compared to the closed-loop task. Together these results suggest that cerebellar patients retained their learning in the closed-loop task similarly to age-matched controls. Conversely, while control participants showed some early retention of the adaptation in the error-based task, the cerebellar group showed no such retention. \n We were surprised that the cerebellar group showed almost complete adaptation in the error-based task, despite no retention. This discrepancy could arise if the cerebellar group relied on online visual feedback to control their reaches. In support of this, examination of the initial portion of the trajectory in the error-based group appears more directed toward the visual location of the target late in learning ( Fig. 4 , middle) and only curves towards the target zone as the movement progresses. In contrast the initial trajectory in the closed-loop task (in which visual feedback cannot be used) is aimed towards the target zone. In early retention ( Fig. 4 , right) the error-based group make movements almost straight to the target suggesting that the curvature seen in the later perturbation movements are driven by visual feedback. In the closed-loop task, however, the cerebellar group maintains some of their initial trajectory deviation in the early retention period. This suggests that the cerebellar group used online feedback to correct their movements in the error-based task resulting in the appearance of complete adaptation, but without any true updating of feedforward models of the correct movement. \n To examine movement variability we analysed baseline within subject reach angle standard deviation for each subject in the two tasks. Mixed model ANOVA revealed a significant main effect of group that was the result of greater reach angle variability in the cerebellar group compared to controls [ F (1,21) = 14.0, P <  0.01]. The group � task interaction was also significant [ F (1,21) = 8.3, P < 0.01]. Within the older control group, reach angle variability was greater in the closed-loop task compared to the error-based task ( P <  0.01). Baseline reach angle standard deviation in the cerebellar group was related to their clinical impairment. The kinetic function sub-score of the International Cooperative Ataxia Rating Scale (ICARS), which is the component of the scale directly related to arm ataxia, was correlated with baseline variability in both the error-based ( r = 0.8, P <  0.01, Fig. 5 A) and closed-loop tasks ( r = 0.6, P <  0.05, Fig. 5 B). No other significant correlations were found between dependent variables and ataxia rating scores."
639480,3.0,"Modelling \n  Many of the cerebellar subjects showed significant learning and retention in the reinforcement condition. Further, we saw individual differences in reinforcement learning within the cerebellar and control groups with some subjects showing substantial learning and others showing little learning. In an attempt to understand these differences, we developed a simple mechanistic model of the reinforcement learning task and fit each subject�s closed-loop data. The model considered the reach angle executed on a given trial to be the result of an internal estimate of the ideal reach angle (i.e. to counter the current rotation applied) with the addition of two sources of variability: motor noise and exploration variability. The important difference between these two sources of variability is that we assume participants are unaware of their motor noise, but have full awareness of their exploration variability. When an action is rewarded, the subject updates their internal estimate of reach angle based solely on the contribution of exploration variability. When an action is unrewarded, the reach angle is not updated. The model has two parameters, the standard deviations of the Gaussian distributions that generate the motor noise and exploration variability. We fit the model to each individual subject�s data using maximum likelihood estimation. \n Three typical subject�s data (a cerebellar, old and young control) are shown along with a typical simulation for each ( \n Fig. 6 \n A�C and parameter estimates, see �Materials and methods� section). The cerebellar subject had the largest motor noise, followed by the older control with the young control having the smallest amount of motor noise. In contrast, the younger control had the largest exploration variability. These parameters led to slower learning for the cerebellar and older control and faster learning for the younger control. Figure 6 D shows that group means match reasonably well to the mean of the simulations (averages of 10 000 simulations with each subjects fitted parameter). \n The model predicts that the amount of learning and reward depends on both the motor noise and exploration variability. Figure 7 A shows the proportion of rewarded trials in late learning from the model for different settings of the motor noise and exploration variability. This shows that performance tends to decrease with motor noise and intermediate values of exploration variability lead to the greatest reward. Therefore for a given level of motor noise there is an optimal level of exploration variability that will lead to maximal adaptation. Achieving a good level of adaptation thus requires a balance between exploration and motor noise. \n Examining the fits across the subjects (Fig. 7 B parameters with 95% confidence intervals) shows that there is wide variation of the parameters but that they tend to cluster by group. In addition there is variability in the per cent learning in the late perturbation period across subjects (percentage learning is shown as fill of the circular symbols in Fig. 7 B). The reason for this is that the model is probabilistic in nature and therefore even with identical parameters for exploration variability and motor noise the actual time series of reaches and adaptation will vary each time the model is run. For example, sometimes the model will be lucky and draw random samples of motor noise with less variability and sometimes the model will be unlucky and draw samples with more variability. We examined this by looking at the distribution of adaptation expected from the model when we performed many thousands of simulations and then determined where a participant�s actual adaptation lies within this distribution. Across all 34 participants we find on average that participants� adaptation was ranked at 58 (where 1 is the model�s best and 100 the model�s worst performance) and that this rank was not significantly different from the expected value of 50 (P =  0.11). Importantly, even though there was variation in performance predicted by the model, the way in which a participant changed their reach angle as a function of current reach angle and reward (or lack thereof) allowed us to extract model parameters with reasonably narrow confidence limits. \n Analysis of mean parameter values yielded significant differences between groups. One-way ANOVA of motor noise revealed a main effect of group [? \n m \n ; \n F(2,31) = 7.6,P < 0.01; Brown-Forsythe,F(2,19.9) = 7.2,P < 0.01;Fig. 7C] that resulted from significantly greater motor noise in the cerebellar group compared to both young (P < 0.05) and age-matched controls (P < 0.01). One-way ANOVA of exploration variability also revealed an effect of group [?e;F(2,31) = 6.4,P < 0.01; Brown-Forsythe,F(2,15.2) = 5.7,P < 0.05,Fig. 7C], which resulted from significantly greater exploration in young controls compared to both the cerebellar group (P < 0.05) and older controls (P < 0.01). Importantly, one-way ANOVA of the proportion of rewarded trials over the perturbation phase of the experiment revealed a main effect of group [ F (2,31) = 8.232, P <  0.01] where the reward rate was significantly lower for the cerebellar group (0.57 � 0.04) than both the older (0.73 � 0.04) and young control (0.76 � 0.03) groups (both P < .01). \n Although we have phrased the model as motor noise and exploration variability, a mathematically similar way of expressing this is that there is a total variability in a participant�s reach direction and that he or she is only aware of a proportion of this variability and corrects for this proportion when rewarded (see �Materials and methods� section). We replot the parameter estimates as total variance and the proportion corrected for in Fig. 7D. One-way ANOVA of total variance revealed a main effect of group [F(2,31) = 9.9,P < 0.001; Brown-Forsythe,F(2,21.1724) = 10.0,P < 0.01] where both cerebellar (P < 0.001) and young control (P < 0.05) groups showed significantly greater variability than the older control group, but were not different from each other. Analysis of rho showed a significant main effect of group [F(2,31) = 4.8,P < 0.05; Brown-Forsythe,F(2,11.2) = 4.1,P < 0.05] where the cerebellar group was aware of a smaller proportion of their total variability compared with both older and young controls. This comparison was significant between the cerebellar and young control group (P < 0.05)."
2436073,0.0,"Effects of type of reinforcement and exposure to stressors unrelated to the learning task \n In the absence of stressors unrelated to the learning task, the learning performance (number of trials to reach stage 1 and number of stages reached) did not differ between the two types of reinforcement (Kruskal-Wallis trials to reach stage 1: K = 7.07, P = 0.07, Kruskal-Wallis trials to reach stage 1: K = 8.68, P = 0.03, Dunn test PR vs. NR, Ptrials to reach stage 1 = 0.80, Pstages reached = 0.78, Fig 3A and 3B). However, when stressors unrelated to the learning task were added, learning performance significantly decreased with positive reinforcement and tended to decrease with negative reinforcement (Dunn test PR vs. PR+ES: Ptrials to reach stage 1 = 0.03, Pstages reached = 0.04; Dunn test NR vs. NR+ES: Ptrials to reach stage 1 = 0.06, Pstages reached = NS; Fig 3A and 3B). \n  In the absence of stressors unrelated to the learning task, the observed behaviours did not differ between reinforcement types (Table 2, comparison between PR and NR). However, when stressors unrelated to the task were added, horses exhibited significantly more alert postures, startle reactions and glancing at the audience horse under both reinforcements contingencies; in the NR group, they also showed more ears pointing backward and blowing (Table 2, comparison between PR vs. PR+ES or NR vs. NR+ES). No significant differences were observed between the four groups in the number of times the horses sniffed or nibbled the experimenter, explored the environment, defecated or crossed the wooden bar. \n  In the absence of stressors unrelated to the task, the increase in salivary cortisol concentrations did not differ between groups, neither in session 1 nor 3. When stressors unrelated to the task were added, the increase in concentration was significantly higher but only in the case of positive reinforcement (Dunn test PR vs. PR+ES: PSession 1 < 0.05, PSession 3 < 0.01; Table 3)."
2436073,1.0," Relationships between personality and learning performance \n  Horses learning with negative reinforcement without stressors unrelated to the task (NR) that required the shortest time to reach the stage 1 criterion (i.e. the best performers among the NR horses) were the most fearful and active (correlation between the number of trials to reach stage 1 and a) intensity of the startle response during the surprise test: rs = -0.57, P = 0.03; and b) number of areas crossed: rs = -0.61, P = 0.02). \n  Horses learning with negative reinforcement and exposure to extrinsic stress (NR+ES) that reached the highest number of stages (i.e. the best performers among the NR+ES horses) were the least fearful and active (correlations between the number of stages reached and a) number of glancing at the novel area: rs = 0.54, P = 0.04; b) total number of blowing: rs = 0.55, P = 0.03; c) latency before eating during the novel area test: rs = 0.48, P = 0.07 (tendency); d) number of contacts with the novel object: rs = -0.45, P = 0.09 (tendency); and e) number of areas crossed: rs = -0.54, P = 0.04). In addition, the fastest horses to reach the stage 1 criterion in the NR+ES group (the best performers) were also the least fearful, the closest to humans and the most active (correlations between the number of trials to reach the stage 1 criterion and a) number of contacts with the novel object: rs = -0.52, P = 0.04; b) number of contacts with the passive human: rs = -0.57, P = 0.03; and c) number of areas crossed: rs = -0.51, P = 0.05). \n  By contrast, only one negative correlation between a variable related to fearfulness and the level of learning performance was found in each group of horses with positive reinforcement (PR and PR+ES). This correlation indicated that horses reaching the highest number of stages (i.e. the best performers among PR and PR+ES horses respectively) were the least fearful in both groups (correlations between the number of stages reached and a) the number of glancing at the novel area in PR group: rs = -0.51, P = 0.05; and b) the number of glancing at the novel object in PR+ES group: rs = -0.57, P = 0.03)."
1649970,0.0,"Suppression of gene expression by dsRNA injections of OA1, Dop1 and Dop2 in the cricket \n We first studied the effects of double-stranded RNA (dsRNA) injection of the OA1, Dop1 or Dop2 gene on the expression levels of target gene mRNA in the cricket head. As a control, the amount of OA1, Dop1 or Dop2 mRNA in the brains of DsRed2 RNAi crickets was also studied. Groups of crickets were injected with 20?pmol OA1, Dop1, Dop2 or DsRed2 dsRNA into the head hemolymph. Target sequences of RNAi for OA1, Dop1 and Dop2 are shown in Methods and in Fig. 1. The amounts of mRNA in the heads of dsRNA-injected crickets were measured by quantitative real-time PCR (qPCR) at 48?hr after injection, and the relative amount of mRNA transcribed from the target gene was compared to that in intact crickets. The levels of OA1, Dop1 and Dop2 mRNA in DsRed2 RNAi crickets were similar to those in intact crickets (Fig. 2). In contrast, expression levels of OA1, Dop1 and Dop2 mRNA in the heads of OA1, Dop1 and Dop2 RNAi crickets were, on average, 31%, 29% and 25% of those in intact crickets. Statistical comparisons showed that the levels of OA1, Dop1 and Dop2 mRNA in OA1, Dop1 and Dop2 RNAi crickets were significantly lower than those in DsRed2 RNAi crickets (OA1: t?=?3.68, df?=?4.60, p?=?0.017; Dop1: t?=?3.09, df?=?8.26, p?=?0.014; Dop2: t?=?2.31, df?=?15.28, p?=?0.035, two sample t-test with Welch�s correction). All RNAi crickets exhibited normal viability, and their locomotor activities and feeding behaviors were not distinguishable from those of intact animals. Evidence suggesting intact sensory and motor functions of those RNAi crickets is described below. \n Effects of the suppression of OA1, Dop1 and Dop2 genes on acquisition and retention in appetitive conditioning \n  We then studied the effects of gene silencing by RNAi on acquisition and retention performances in appetitive olfactory conditioning. We used conditioning of maxillary palpi extension response (MER) for evaluation of the conditioning effect8. We have reported that presentation of peppermint or apple odor to the antennae of crickets rarely (in less than 20% of crickets) induces MER and that pairing of each odor with water leads to an increase in the probability of MER8. \n  We first studied acquisition performance in appetitive conditioning in groups of crickets injected with dsRNA. Four groups of crickets were injected with 20?pmol dsRNA of OA1, Dop1, Dop2 or DsRed2. Two days after the injection, they were subjected to 4-trial conditioning to associate an odor with water reward with inter-trial intervals of 5?min. The absence or presence of MER to 3-sec odor (CS) presentation prior to presentation of water (US) was recorded (Fig. 3a). \n  All groups exhibited significant increases in the percentages of MER to the CS with increasing the number of conditioning trials (Fig. 4a, Cochran�s Q test: OA1: ?2?=?9.8, p?=?0.02; Dop1: ?2?=?32.3, p?=?0.00000046; Dop2: ?2?=?32.2, p?=?0.00000048; DsRed2: ?2?=?31.9, df ?=?3, p?=?0.00000056). Between-group comparison, however, showed that the percentage of MER to the CS in the OA1 RNAi group was significantly lower than that in the control (DsRed2 RNAi) group in the 4th trial (i.e., after the third training, see Fig. 3) (Fisher�s exact test, adjusted by Holm�s method: p?=?0.012, sample numbers shown in the figure). In contrast, the percentages of MER to the CS in the Dop1 and Dop2 RNAi groups did not significantly differ from that in the DsRed2 RNAi group (Fisher�s exact test, adjusted by Holm�s method: Dop1: p?=?0.781, Dop2: p?=?0.189). The results indicate that silencing of OA1 significantly reduces acquisition in appetitive learning, but that of Dop1 or Dop2 does not. Impairment of appetitive learning by silencing of OA1 is not due to impairment of the perception of water US, because the crickets exhibited MER to a drop of water applied to the mouth or palpi. Moreover, perception of CS and behavioral responses to the CS are intact in the OA1 RNAi crickets, as evidenced by their intact aversive learning described below. \n  Next, retention performance was tested at 30?min after 4-trial appetitive conditioning. The Dop1, Dop2 and DsRed2 RNAi groups exhibited high percentages (more than 70%) of MER to the odor paired with the US (paired odor or CS), and the percentages were significantly greater than those of MER to the odor not used in training (novel odor) (Fig. 4b, McNemar�s test: Dop1: ?2?=?11.1, df?=?1, p?=?0.0000013; Dop2: ?2?=?9.09, p?=?0.0026; DsRed2: ?2?=?19, p?=?0.0000013). In the OA1 RNAi group, on the other hand, percentage of MER to the CS did not significantly differ from that to the novel odor (?2?=?0, p?=?1). Thus, the Dop1 and Dop2 RNAi groups exhibited normal retention of CS-specific appetitive memory, but the OA1 RNAi group did not."
1649970,1.0," Effects of the suppression of OA1, Dop1 and Dop2 genes on acquisition and retention in aversive conditioning \n  In aversive conditioning experiment, we used vanilla or maple odor, to which crickets exhibited high percentages (more than 70%) of MER8. We observed that repeated presentation of these odors alone led to a decrease of MER percentages8, obviously due to habituation. In order to discriminate pairing-specific decrement in percentages of MER due to aversive conditioning from this non-associative effect, we used a differential conditioning procedure in which one of the two odors was paired with 20% sodium chloride solution (paired odor) and the other was presented alone (unpaired control odor) (Fig. 3b)8, and the percentages of MER to the paired and unpaired odors were statistically compared. \n  Four groups of crickets were injected with dsRNA of OA1, Dop1, Dop2 or DsRed2, and two days later they received 4-trial differential aversive conditioning training with 5-min inter-trial intervals (Fig. 3). The percentages of MER to the unpaired odor significantly decreased with the increase of the trial number in the OA1, Dop1 and Dop2 RNAi groups (Cochran�s Q test: OA1: ?2?=?22.6, p?=?0.000050; Dop1: ?2?=?11.6, p?=?0.0088; Dop2: ?2?=?26.6, p?=?0.0000071). DsRed2 RNAi group also showed a decrease of percentages of MER to the unpaired control odor, but the decrease was not statistically significant (?2?=?3.5, df?=?3, p?=?0.317). This was obviously due to a slightly lower percentage of MER in the first trial, which appeared to reflect incidental data variation due to small sample size. \n  Percentages of MER to the paired odor significantly decreased with progress of training in all groups (Fig. 5, Cochran�s Q test: OA1: ?2?=?59.9, p?=?0.00000000000062; Dop1; ?2?=?13.7, p?=?0.0034; Dop2: ?2?=?57.5, p?=?0.0000000000020; DsRed2: ?2?=?24.1, df?=?3, p?=?0.000023). In OA1, Dop2 and DsRed RNAi groups, percentages of MER to the paired odor were significantly lower than those to the unpaired odor in the 3rd trial (McNemar�s test: OA1: ?2?=?4.57, p?=?0.033; Dop2: ?2?=?9.31, p?=?0.0023, DsRed2: ?2?=?4.5, df?=?1, p?=?0.033) and 4th trial (OA1: ?2?=?5.4, p?=?0.020; Dop2: ?2?=?12, p?=?0.00053; DsRed2: ?2?=?6.4, p?=?0.011), indicating that aversive conditioning is successful. In the Dop1 RNAi group, on the other hand, the percentages of MER to the paired odor did not significantly differ from those to the unpaired odor in the 3rd trial (McNemar�s test: ?2?=?0.29, p?=?0.59) and 4th trial (?2?=?0.25, p?=?0.62). The results suggest that silencing of Dop1, but not that of OA1 or Dop2, impairs acquisition in aversive conditioning. \n  Retention performance was tested at 30?min after 4-trial differential aversive conditioning. The OA1, Dop2 and DsRed2 RNAi groups exhibited significantly lower percentages of MER to the CS (paired odor) than to the unpaired odor (Fig. 5, McNemar�s test: OA1: ?2?=?4.5, p?=?0.034; Dop2: ?2?=?7,14, p?=?0.0075; DsRed2: ?2?=?9, df?=?1, p?=?0.0027). In the Dop1 RNAi group, on the other hand, the percentages of MER to the paired odor did not significantly differ from those to the unpaired odor (McNemar�s test, ?2?=?0.29, p?=?0.59). Thus, the OA1 and Dop2 RNAi groups exhibited normal retention of CS-specific aversive memory, but the Dop1 RNAi group did not."
1962556,0.0,"Experiment 1 \n The first experiment examined how adding noise affects reinforcement motor learning in healthy subjects. Figure 3a shows the group mean time series for all three experimental conditions in which no noise, or low or high levels of noise were added (green, yellow, and red curves, respectively). Participants� average reaches during the baseline phase of each condition, both before and after the addition of noise, were very similar (Fig 3b). This suggests that simply adding noise did not impair their baseline ability to perform the task. \n  When subjects performed the control condition (i.e., with no noise added), they showed strong learning to the initial rotation, followed by a return to baseline, and finally strong learning of the second opposite rotation. In this condition, subjects hit a mean reach angle of 12� (in the direction countering the rotation) across the final 40 trials of each rotation phase (Fig 3b, green). Similar levels of adaptation (?10�) were seen when subjects had a low noise level added (Fig 3b, yellow), although they had a significantly lower reward rate (61% vs 77%). However, in the high-noise condition (Fig. 3b, red), subjects showed significantly reduced adaptation (?5�) and a lower reward rate (46%). \n  We performed a repeated-measures ANOVA for average hand reach angle in the final 40 trials of each block (Fig 3a, BL1, BL2, R1, and R2) and condition. This showed a significant main effect of block (F(2,20) = 47.950, p < 0.001; Greenhouse�Geisser corrected, F(1.248,12.480) = 47.950, p < 0.001) and condition (F(2,20) = 10.402, p = 0.001) as well as a significant block by condition interaction (F(4,40) = 12.349, p < 0.001; Fig. 3b). Post hoc analysis showed no significant differences between the first and second baseline blocks in any of the experimental conditions (all p > 0.05). However, in all three conditions, there was significant adaptation during both the first rotation block (all p < 0.001) and the second rotation block (control and low noise, p < 0.001; high noise, p = 0.028) compared with their respective baselines. In the rotation block, reach angle adaptation in the high-noise condition was significantly reduced compared with both the control (p = 0.002) and low-noise (p = 0.006) conditions. No significant difference was found in learning between the control and low-noise conditions (p = 1.00). Overall, these results suggest that participants were able to use reinforcement feedback to significantly alter their reach angle in all three experimental conditions, but this was reduced in the high-noise condition. \n Figure 3c shows that the reinforcement rate was highest in the control condition and dropped in the low-noise and high-noise conditions (72%, 61%, and 46%, respectively; F(2,30) = 37.405, p < 0.001). Note that the reinforcement rate showed a statistically significant decrease with each level of added noise (all post hoc tests, p < 0.001). \n  To parse the influence of reinforcement feedback on subjects� behavior in the noise conditions, we computed the absolute change in reach angle as a function of whether a trial was rewarded or not (Pekny et al., 2015) and whether the true reach was in or out of the reward zone. Figure 4 shows that subjects changed their reach angle more following unrewarded trials compared with rewarded trials, regardless of whether they were in or out of zone. The main effect of reward for the low-noise and high-noise conditions were F(1,10) = 29.179, p < 0.001 and F(1,10) = 29.179, p < 0.001, respectively. In the low-noise condition, there was also a main effect of reach accuracy (F(1,10) = 9.299, p = 0.012). Finally, there were significant reward by accuracy interactions in both the low-noise condition (F(1,10) = 7.006, p = 0.024; Fig. 4a) and the high-noise condition (F(1,10) = 14.270, p = 0.004; Fig. 4b)."
1962556,1.0," Experiment 2 \n  The second experiment examined whether slower learning in the high-noise condition of experiment 1 resulted from reinforcing errors by clamping the reinforcement rate at 33.8% (clamp) in a new group of participants. This was done to match the proportion of the trials reinforced in the high-noise task when the hand reach angle was correct. The high-noise and clamp tasks were now similar, except that the latter was not reinforced on any error trial (12% of trials in the high-noise task). To ensure that the reinforcement rate was indeed held at a fixed value throughout the clamp condition, we analyzed the group mean reinforcement rate at the following four phases of the task: the final 40 trials of the second baseline phase; the final 40 trials of the first rotation; the final 40 trials of the return to baseline; and the final 40 trials of the second rotation. Repeated-measures ANOVA showed no significant differences across the phases (F(3,27) = 1.637, p = 0.204). \n  A paired-samples t test showed that the difference in reinforcement rate between the control and clamp conditions was significant (t(9) = 14.1524, p < 0.001; Fig. 5b). Figure 5a shows the group mean time series for the two conditions. The average reach angle during the baseline phase of the clamp condition was similar to that during the control condition, indicating that the reduction in reinforcement rate did not impair participants� baseline ability to perform the task. We also found that the lower reinforcement rate of the clamp condition did not affect the learning of the initial rotation, return to baseline, or the learning of the second opposite rotation. Repeated-measures ANOVA showed only a significant main effect of block (F(2,18) = 30.734, p < 0.001; Greenhouse�Geisser corrected: F(1.286,11.572) = 30.734, p < 0.001; Fig. 5c). Post hoc analysis showed that the main effect was driven by significant differences between the two baseline blocks and the rotation block (both p < 0.001). There was no significant difference between the first and second baseline block (p = 1.00). Within both the control and clamp conditions, there was significant adaptation in both the first and second rotations (all p < 0.001) compared with both baseline blocks. This suggests that the reduced learning rate in the high-noise group from experiment 1 was due to the 12% of erroneous reaches that were rewarded when ?hand was outside the reward zone. \n  As in experiment 1, we analyzed the absolute change in reach angle as a function of reinforcement feedback. Repeated-measures ANOVA showed only a significant main effect of reward (F(1,9) = 12.490, p = 0.006; Fig. 5d). That is, participants showed a greater change in reach angle following unrewarded trials compared with rewarded trials. There was no effect of condition (F(1,9) = 0.416, p = 0.535) or reward by condition interaction (F(1,9) = 0.469, p = 0.511). This suggests that although participants altered their behavior following unrewarded trials more than following rewarded trials, they did not change their behavior from the control and clamp conditions."
1962556,2.0," Comparison with patients with cerebellar damage \n  We compared subjects� learning of the first rotation in experiment 1 to the performance of a group of individuals with cerebellar degeneration who learned a single 15� rotation using the same closed-loop reinforcement feedback as part of a previous study (published in Therrien et al., 2016). Figure 6 shows the time series data comparing the performance of the group with cerebellar damage to the groups in control (Fig. 6a), low-noise (Fig. 6b), and high-noise (Fig. 6c) conditions of experiment 1. The group of patients with cerebellar damage was able to reach within the target zone at baseline, but were unable to reach to the new target zone in the rotation block. This differed from the control and low-noise conditions of experiment 1, where participants were able to learn to rotate their reach angles to the new target zone. Similar to the patient group, participants were unable to reach the final target zone in the high-noise condition of experiment 1. However, participants in the high-noise condition still showed a faster learning rate than patients with cerebellar damage. \n  Using independent-samples t tests, we compared the mean values of the group with cerebellar damage for early learning rate, total learning, and reinforcement rate for each condition of experiment 1 (Fig. 6d�f). Participants in the control condition showed significantly greater total learning (t(21) = ?3.2648, p = 0.004), early learning rate (t(21) = 4.3910, p < 0.001), and reinforcement rate (t(21) = ?3.8324, p < 0.001) compared with the group of patients with cerebellar damage. Participants also showed significantly greater total learning (t(21) = ?3.9907, p < 0.001) and early learning rate (t(21) = 5.3784, p < 0.001) in the low-noise condition compared with the patients with cerebellar damage. The difference in reinforcement rate between the low-noise condition and the group of patients with cerebellar damage was not significant (t(21) = ?1.1919, p = 0.247). \n  Finally, comparing the high-noise condition to the patients with cerebellar damage, we found that total learning was not significantly different between groups (t(21) = ?1.861, p = 0.249). However, there were significant differences in early learning rate (t(21) = 3.6563, p = 0.002) and reinforcement rate (t(21) = 2.4292, p = 0.024). The early learning rate was greater for participants in the high-noise condition compared with patients with cerebellar damage. However, patients with cerebellar damage showed a greater reinforcement rate than participants in the high-noise condition. Overall, these results suggest that adding noise to the reaches of neurologically healthy participants� impaired reinforcement learning in our task, but did not completely replicate the behavior of the patient group."
1962556,3.0," Modeling results \n  The objective of experiment 1 was to test the hypothesis that increased variability from motor noise would impair reinforcement learning in a similar way to patients with cerebellar degeneration. While behavioral data showed similar total learning between the high-noise and patient groups, the high-noise group showed a faster early learning rate. To determine the source of this discrepancy, we modeled subjects learning in the three conditions of experiment 1 using a simple mechanistic model of the reinforcement learning task. The reach angle executed on each trial is modeled as the sum of an internal estimate of the correct reach angle and two sources of behavioral variability, as follows: exploration variability and motor noise. The model assumes that participants have access to the variability from exploration, but do not have access to motor noise. As a result, if a reach is reinforced, the model only updates the internal estimate of the correct movement by the draw of exploration variability on that trial. When a reach is not reinforced, the internal estimate is not updated. The model has three parameters: the SDs of the Gaussian distributions that generate motor noise and exploration variability following rewarded and unrewarded trials. We fit the model to each subject�s data in each condition of experiment 1 as well as each subject�s data in each condition of experiment 2. We also fit the data for each patient with cerebellar damage. The model was fit using maximum-likelihood estimation. \n  Comparing mean parameter values between subjects in experiment 1 and the group of patients with cerebellar damage revealed significant differences in motor noise (Fig. 7a). Patients with cerebellar damage had significantly greater motor noise than participants in the control (t(21) = 3.5707, p = 0.002) and low-noise (t(21) = 3.1929, p = 0.004) conditions of experiment 1. The difference between patients with cerebellar damage and participants in the high-noise condition was not significant (t(21) = 1.3225, p = 0.200), suggesting that this condition effectively matched the motor noise of patients with cerebellar damage. There were no differences between groups across the conditions of experiment 1 for exploration variability following rewarded trials (control condition: t(21) = ?0.6409, p = 0.529; low-noise condition: t(21) = 1.0964, p = 0.285; high-noise condition: t(21) = 1.2381, p = 0.229; Fig. 7b). However, patients with cerebellar damage showed significantly smaller exploration following unrewarded trials compared with participants in all three conditions of experiment 1 (control condition: t(21) = ?2.5702, p = 0.018; low-noise condition: t(21) = ?4.5549, p < 0.001; high-noise condition: t(21) = ?2.8990, p = 0.009; Fig. 7c). Thus, adding noise in experiment 1 did not reduce participants� exploration following errors relative to the control condition. This left them greater variability from which to learn compared with patients with cerebellar damage. \n  There were no differences in fitted parameter values between the control and clamp conditions of experiment 2 (Fig. 7d: ?m, t(9) = ?1.7678, p = 0.111; Fig. 7e: ?e after rewarded trial, t(9) = ?0.2686, p = 0.794; Fig. 7f: ?e after unrewarded trial, t(9) = ?0.4655, p = 0.653). This suggests that withholding reinforcement of correct movements did not change participants� motor noise or exploration variability relative to the control condition. \n  To determine the goodness of fit of our model, we compared the mean reaching behavior over subjects in each condition of experiments 1 and 2 to the mean of the model simulations. This resulted in R 2 values of 0.95, 0.91, and 0.66 for the control, low-noise, and high-noise conditions of experiment 1. For experiment 2, R 2 values were 0.87 and 0.76 for the control and clamp conditions, respectively. \n  Finally, to examine the importance of each model parameter we compared the full three-parameter model to two reduced models (one with no motor noise and one with exploration variability) that did not depend on whether the previous trial was rewarded or not (Therrien et al., 2016). We did not examine a model with motor noise only because some exploration variability is needed to show learning. Model comparisons using the BIC showed that the three-parameter model best fit the data for experiments 1 and 2, while the reduced model with exploration that was independent of reward on the previous trial best fit the data for patients with cerebellar damage (Table 1)."
440047,0.0,"We describe our results in three parts. We start with using our network to model a classical reversal learning task. We take advantage of the simplicity of the task to explain the principal ideas behind the network model and why we think the network resembles the OFC. Then we show such a network may be applied to a more complex scenario, both in the task structure and in the temporal dynamics, in which the OFC has been shown to play important roles. Finally, to further illustrate the similarities between our network model and the OFC, we demonstrate how the selectivity of the neurons in the network may resemble experimental findings in the OFC during value-based decision making."
440047,1.0,"Reversal learning \n  In a classical reversal learning task, the animals have to keep track of the reward contingency of two choice options that may be reversed during a test session [9, 28]. Normal animals were found to learn reversals faster and faster, which has been used as an indication of their ability of learning the structure of the task [7]. Such behavior was however found to be impaired in animals with OFC lesions and/or with lesions that contained fibers passing near the OFC [9, 29]. These animals were not able to learn reversals faster and faster when they were repeatedly tested. The learning impairments could be explained by a deficit in acquiring and representing the task structure [7]. \n  Our neural network model consists of a state encoding layer (SEL), which is a reservoir network. It receives three inputs and generates two outputs (Fig 1A). The three inputs from the input layer (IL) to the SEL are the two choice options A and B, together with a reward input that indicates whether the choice yields a reward or not in the current trial. The outputs units in the decision-making output layer (DML) represent choice actions A and B for the next trial. The inputs are provided concurrently and the neural activity of the SEL at the end of the trial is used to determine the SEL�s output (Fig 1B). The connections from the IL to the SEL and the connections within the SEL are fixed. Only the connection weights from the SEL to the DML are modified during the training with a reward dependent Hebbian rule, in which the weight changes are proportional to the reward prediction error and the pre- and post-synaptic neuronal activities. \n  The network is able to reproduce animals� behavior. The number of the error trials that takes for the network to achieve the performance threshold, which is set at 93% in the initial learning and at 80% in the subsequent reversals, decreases as the network goes through more and more reversals (Fig 1C). Interestingly, a learning deficit similar to that found in OFC-lesion animals is observed if we remove the reward input to the SEL (Fig 1C). As the OFC and its neighboring brain areas such as the ventromedial prefrontal cortex (vmPFC) are known to receive both the sensory inputs and reward inputs from sensory and reward circuitry in the brain [30�32], removing the reward input from our model mimics the situation where the brain has to learn without functional structures in or near the OFC. \n  Neurons in the SEL, as expected from a typical reservoir network, show highly heterogeneous response patterns. Some neurons are found to encode the stimulus identity, some neurons encode reward, and others show mixed tuning (Fig 2A). A principal component analysis (PCA) based on the population activity shows that the network can distinguish all four possible task states: choice A rewarded, choice A not rewarded, choice B rewarded, and choice B not rewarded (Fig 2B and S1 Fig). The first three principal components capture 92.0% variance of the population activity. \n  The ability to distinguish these states is essential for learning. To understand the task acquisition behavior exhibited by our model, we study how neurons with different selectivity contribute to the learning (Fig 2C and S2 Fig). We find that readout weights of the SEL neurons that are selective to the combination of stimulus and reward inputs (e.g. AR and BR) are mostly affected by the learning. The difference between the weights of their connections to the outputs A and B keeps evolving despite repeated reversals. In contrast, the weights of the output connections of pure stimulus-selective neurons (e.g. A and B) only wiggle around the baseline between reversals. Once the network is trained, the expected rewards from AR/BN and BR/AN inputs are exactly the opposite (S3 Fig). \n  The difference between these two groups of neurons explains why our network achieves flexible learning behavior only when the reward input is available. Let us first consider the AR neurons, which are selective for the situation when choice A leads to reward. In these A-rewarded blocks, the connections between the AR neurons and the DML neuron of choice A are strengthened. When the reward contingency is reversed and now choice A leads to no reward, the connections between the AR neurons and choice A are not affected very much. That is because the group of AN and then BR neurons instead of the AR neurons are activated in the blocks when choice A is not rewarded. As the result, the connections between the AN neurons and the DML neuron of choice B are strengthened and the connections between the AN neurons and the DML neuron of choice A are weakened. When the reward contingency is flipped again, the connections between the AR neurons and the DML neuron of choice A are strengthened further. This way, the learning is never erased by the reversals, and the network learns faster and faster. In comparison, let us now consider the A neurons, which encode only the sensory inputs and are activated whenever input A is present. In the A-rewarded blocks, the connections between the A neurons and the DML neuron of choice A are strengthened. In B-rewarded blocks, the connections between the A neurons and the DML neuron of choice A are however weakened when the network chooses A and gets no reward, and the learning in the previous block is reversed. Thus, the output connections of A neurons only fluctuate around the baseline with the reversals. They do not contribute much to the learning, and the overall behavior of the network is mostly driven by neurons that are activated by the combination of reward input and sensory inputs. Removing R deactivates these neurons and leads to the structure agnostic behavior. \n  The importance of the neurons that are selective for the combination of stimulus and reward inputs can be further illustrated by a simulated lesion experiment. After the network is well-trained, we stop the training and test the network�s performance with a proportion of neurons randomly removed at the time of decision (Fig 2D). The neurons that are removed are either 50 randomly chosen neurons, 50 A neurons, or 50 AR neurons. This inactivation happens only at the time of decision making, therefore the state encoding in the reservoir is not affected. The inactivation of AR neurons produces the largest impairment in the network�s performance. Compared to the network with random inactivation, the network with AR-specific inactivation cannot reach the criterion we set previously within a block in more than 50% of the blocks and makes significantly more errors to reach the criterion in the blocks that it does. Inactivation of A-selective neurons produces much smaller performance deficits. \n  It is important to note that although the reinforcement learning algorithm employs the same small learning rate for both the intact network and the �OFC-lesion� network, the former only requires a few number of trials to acquire a reversal in the later stage of training, indicating the reversal behavior may not have to be slow with a small learning rate. In fact, once the network is trained, learning is no longer necessary for the reversal behavior. The network takes very few trials to adapt to reversals without learning (Fig 2E). That is because the association between input AR/BN and decision A and the association between input BR/AN and decision B have been established in the network."
440047,2.0," Two-stage Markov decision task \n  We further test our network with a two-stage decision making task. The task is similar to the Markov decision task used previously in several human fMRI studies and used to study the model-based reinforcement learning behavior in humans [6, 33�36]. In this task, the subjects have to choose between two options A1 and A2. Their choices then lead to two intermediate outcomes B1 and B2 at different but fixed probabilities. The choice of A1 more likely leads to B1, and the choice of A2 is more likely followed by B2. Importantly, the final reward is contingent only on these intermediate outcomes, and the contingency is reversed across blocks (Fig 3A). Thus, the probability of getting a reward is higher for B1 in one block and becomes lower in the next block. The probabilistic association between the initial choices and the intermediate outcomes never changes. The subjects are not informed of the structure of the task, and they have to figure out the best option by tracking not only the reward outcomes but also the intermediate outcomes. \n  We keep our network model mostly the same as in the previous task. Here, we have two additional input units that reflect the intermediate outcomes (Fig 3B). To demonstrate our network model�s capability of encoding sequential events, the input units are activated sequentially in our simulations as they are in the real experiment (Fig 3C). We also add a non-reward input unit whose activity is set to 1 when a reward is not obtained at the end of a trial. The additional non-reward input facilitates learning but does not change the results qualitatively. \n  For a simple temporal difference learning strategy without using any knowledge of task structure, the probability of repeating the previous choice only depends on its reward outcome. The probability of repeating the previous choice is higher when a reward is obtained than when no reward is obtained. The intermediate outcome is ignored. However, this is no longer the case when the task structure is taken into account. For example, consider the situation when the subject initially chooses A1, the intermediate outcome happens to be B2, and a reward is obtained. If the subject understands B2 is an unlikely outcome of choice A1 (rare), but a likely outcome of choice A2 (common), a reward obtained after the rare event B2 should actually motivate the subject to switch from the previous choice A1 and choose A2 the next time. The subject should always choose the option that is more likely to lead to the intermediate outcome that is currently associated with the better reward. \n  To quantify the learning behavior, we first evaluate the impact of the previous trial�s outcome on the current trial. We classify all trial outcomes into four categories: common-rewarded (CR), common-unrewarded (CN), rare-rewarded (RR) and rare-unrewarded (RN). Here, common and rare indicate whether the intermediate outcome is the more likely outcome of the chosen option or not. Glascher et al [6] showed that the model based learning led to a higher probability of repeating the previous choice in the CR and RN conditions. This is also what we observe in our network model�s behavior (Fig 4A). \n  To illustrate how the network acquires the task structure, we define the task-structure index, which represents the tendency of employing task structure information (see the Method). The task-structure index grows larger as the training goes on (Fig 4B). It indicates that the network learns the structure of the task gradually and transits to a more efficient behavior from an initially task-agnostic behavior. \n  Similar to our findings in the first task, the network without the reward input in the SEL behaves in a task-agnostic manner. It does not show the transition that indicates the learning of the task structure (Fig 4B). We further quantify the contribution of task structure information to the network behavior using a model fitting procedure previously described by Glascher et al. [6], and the network without the reward input shows a significantly smaller weight for the usage of task structure, suggesting it is worse at picking up the task structure (Fig 4C and S4 Fig). When the network time constant is sufficiently long, the task-structure dependent behavior is not because the intermediate outcomes occur after the first stage outcomes so that the former having a stronger representation in the network at the time of decision (S5 Fig). \n  Again, a PCA on the SEL population activity shows that the SEL distinguishes different task states (Fig 4D). The first three principal components explain 83.97% variance of the population activity. Because the structure of the task in which the contingency between the first stage options and the intermediate outcomes is fixed, the network only needs to find out the current reward contingency of the intermediate outcomes. We found that the learning picks out the most relevant neurons that encode the contingency between the intermediate outcomes and the reward outcomes (B1R, B2R, etc.). Their connection weights to the DML neurons show better and better differentiation of the two choices throughout the training (Fig 4E). In contrast, the connection weights of the neurons that encode the association between the first stage options and the reward outcomes (A1R, A2R, etc.) are less differentiated. \n  These results suggest that the network acquires the task structure. It understands that the contingency between intermediate outcomes and reward outcomes is the key to the performance. Thus, its choice only depends on the interaction between the intermediate outcome and the reward outcome of the last trial, but not on the other factors (Fig 4F and 4G). The network behavior is similar to the Reward-as-cue agent described by Akam et al. [37]."
440047,3.0," Value representation by the OFC \n  Previous electrophysiology studies have shown that OFC neurons encode value during economic choices [11, 13]. In a series of studies carried out by Padoa-Schioppa and his colleagues, monkeys were required to make choices between two types of juice in different amounts. The monkeys� choices depended on both their juice preference and the reward magnitude. Recordings in the OFC revealed multiple classes of neurons encoding a variety of information, including the value of individual offers (offer value), the value of the chosen option (chosen value), and the identity of the chosen option (chosen identity) [38, 39]. \n  Here we show that our network model may explain this apparent heterogeneous value encoding in the OFC. We model the two-alternative economic choice task by providing two inputs to the SEL, representing the reward magnitude of each option with range adaption (Fig 5A). The input dynamics are similar to that of the sensory neurons [40]. The network model reproduces the choice behavior of monkeys (Fig 5C)[11]. \n  Then we study the selectivity of the SEL neurons. Just as in the previous experimental findings in the OFC, we find not only neurons that encode the value of each option (offer value neurons, middle panel in Fig 6A), but also neurons that encode the value of the chosen option (chosen value neurons, left panel in Fig 6A). Furthermore, a proportion of neurons show the selectivity for the choice as previously reported (chosen identity neurons, right panel in Fig 6A). We classify the neurons in the reservoir network into 10 categories as described in Padoa-Schioppa and Assad [11]. Interestingly, we are able to find neurons in the reservoir in 9 of the 10 previous described categories (Fig 6B and 6C). The only missing category (neurons encoding other/chosen value) was also rarely found in the experimental data. Although the proportions of neurons encoding each category are not an exact copy of the experimental data, but the similarity is apparent. This is surprising given that we do not tune the internal connections of the SEL to the task. The results are robust across different input connection gains, noise levels in the SEL, and dynamics of the input profiles (S6 Fig). The heterogeneity that is naturally expected from a reservoir network takes much more effort to explain with recurrent network models that have a well-defined structure [40, 41]."
2347850,0.0,"Group demographics and diagnostic information: \n The psychosis group and the control group were matched on age, gender, and NARTestimated verbal IQ (Table 1). When all available information was utilized to apply diagnostic categories after 12months, 81 patients were classified as schizophrenia-spectrum psychosis and 31 as affective psychosis, with missing information on 6 cases. PANSS scores from initial assessment were available on 78 patients."
2347850,1.0,"Learning analysis: stages passed and failed \n  In the control group, 1 participant failed at the IDS stage, 2 failed at the IDR stage, 5 failed at the EDS stage, and 1 failed at the final reversal stage (see figure 2). In patients, 2 failed at \n the compound discrimination stage, 1 at the compound reversal stage, 27 failed at the EDS stage, and 11 failed at the final reversal stage. Thus, in terms of stage failures, significantly more patients failed the EDS stage (? = 16.5, P < .001), and the final reversal \n stage (? = 9.6, P < .01), than controls."
2347850,2.0," Learning analysis: error analysis \n  For a more sensitive analysis, we examined error scores at each stage. We compared all patients (n = 119) vs all controls (n = 107) \n on initial discrimination learning (figure 3). By examining the number of errors using the Mann-Whitney U test, we confirmed that psychosis patients made more errors than controls during initial discrimination learning (z = 2.5, P = .01); in contrast, there were \n no differences between patients and controls on initial reversal learning, compound discrimination learning, ID set shifting, compound reversal, or IDR. However, there were deficits in ED set shifting (z = \n ?5.1, P < .001) and final reversal stages (z = ?3.7, P < .001). Next, we examined the total number of reversal errors over the course of the experiment in participants who attempted all stages of the IDED test: ie, those who completed at least the EDS stage and so could attempt the final reversal stage (99 controls and 89 patients, see table 2 and figure 4). Although some psychosis patients showed good performance, as a group patients made more total reversal errors than controls (z = ?2.4, P = .02). \n  We next examined whether, within the patient group, total reversal errors could be explained, at least in part, by SD errors. Utilizing Poisson regression, we found that SD errors did not predict total reversal errors (z = 0.7, P = .5). In contrast, SD errors were a significant predictor of EDS errors (z = 5.4, P < .001). \n  Having established the differences between first-episode psychosis patients and controls, we proceeded to examine whether patients with schizophrenia-spectrum psychoses differed from patients with affective psychosis. Patients with affective psychosis made fewer ID shifting errors than patients with schizophrenia-spectrum psychosis (z = ?2.3, P = .026), but there were no differences in any other stages of the ID/ED or in total reversal errors (z = ?0.539, P = .6; table 3). \n  Finally, we examined whether symptom scores correlated with performance on simple and reversal trials in the 56 first-episode psychosis patients who completed at least the ED stage of the ID/ED test and for whom PANSS scores were available. Poisson regression revealed that total reversal errors were predicted by negative symptoms (z = 3.72, P < .001), but not positive symptoms (z = ?0.6, P = .6), which is consistent with results from a correlational analysis: total reversal errors correlated significantly with negative symptoms (Spearman ? = 0.3, P = .02) but not with positive symptoms (Spearman ? = 0.2, P = .20). There was no association between SD errors and psychopathology either on correlational analysis (positive symptoms Spearman ? = 0.06, P = .6; negative symptoms Spearman ? = 0.02, P = .98) or on Poisson regression (positive symptoms z = 0.52, P = .6, negative symptoms z = 0.35, P = .7)."
1816166,0.0,"Comparative experiment between rigid criterion and flexible criterion \n According to two different reward settings of rigid and flexible criteria, six paper dataset sequences and ten sequences in the classic Uniref50 database are selected as experimental objects. The known information and test energy information were shown in Table�2. The parameters were set as follows: step-size parameter ??=?0.01, exploration probability ??=?0.5, and learning parameter ??=?0.9. \n  In Table�3, the first four sequences were chosen to compare the performance of reinforcement learning with rigid and flexible criteria. In order to avoid contingency, the rigid and flexible criteria experiments were repeated five times. The number of training iterations per round was set to 5 million, and the test was performed once every 10,000 times. In training process, the number of episodes required to converge to the lowest energy was counted as shown in Table ?Table33. \n  Combination of Tables�2 and ?and33 showed that reinforcement learning with rigid criterion can stably find the lowest energy conformation faster than reinforcement learning with flexible criterion. For the shorter sequences (1 and 2), the number of training episodes required for agent to achieve convergence conformation by flexible criterion was greater than rigid criterion. Reinforcement learning with rigid criterion sampled an average 30,000 and 210,000 episodes to achieve the robust lowest energy conformation, which was 50 and 63% less than 60,000 and 570,000 episodes required by reinforcement learning with rigid criterion. For the longer sequences (3 and 4), reinforcement learning with flexible criterion could not find the lowest energy conformation. One possible reason was that, although flexibility criterion gave a negative reward (or penalty) for states that caused repetition, the states still had some positive Q values, and the Q values of these repeated states in rigid criterion still had an initial value of 0. Therefore, the probability of the repeated states in flexibility criterion being selected was greater than rigid criterion. And as the length of the sequence increased, the number of states that caused repetition in the full state space was also greater, and it was more difficult to find the lowest energy structure."
1816166,1.0," Comparative experiment with greedy algorithm \n  Reinforcement learning with full states using rigid criterion was compared with greedy algorithm. The experimental objects were the twelve sequences in the Uniref50 data set. Similarly, in order to avoid accidentality, two methods were trained for five rounds, and the number of training iterations per round was set to 5 million, and the samples were performed once every 10,000 times. We counted the number of times the lowest energy was obtained in the last 100 samples (Table�4). \n  It can be seen from Table ?Table22 that reinforcement learning with full states using rigid criterion can find the lowest energy for all 16 sequences, but the greedy algorithm can only find 13 of them. From Table ?Table4,4, the training process with 10 sequences was far superior to the greedy algorithm for the above 12 sequences. And the total number of times that the lowest energy was found was 300, which was greater than 205 for the greedy algorithm."
1816166,2.0," Comparative experiment with the reinforcement learning with partial states \n  Reinforcement learning with full states using the rigid criterion was compared with reinforcement learning with partial states. The experimental objects and experimental settings were the same for greedy algorithm above. \n  In the reinforcement learning with partial states, for an HP sequence of length n, its state space S consists of 1?+?4 (n-1) states. Apart from the first amino acid that had only one state, each of the other amino acids had four different actions (up, down, left, and right) to transfer to four different states, so the number of the entire state set was expressed as 1?+?4 (n-1), so S?=?{s1,?s2,?�,?s1?+?4(n???1)}. For example, the state of the first amino acid is s1. In this state, the four actions of up, down, left, and right were respectively transferred to states s2,�s3,�s4,�s5, which were all possible states of the second amino acid. On the same basis, the four actions of up, down, left and right respectively transferred to the states s6,�s7,�s8 and�s9, which were all possible states of the third amino acid, and so on, to find all the states of the subsequent amino acids. \n  In Table ?Table2,2, there were 8 sequences that cannot converge to the lowest energy conformations by the reinforcement learning with partial states, while reinforcement learning with full states successfully folded all sequences to the lowest energy conformations. Table ?Table44 showed that in the last 100 episodes, reinforcement learning with full states hits the lowest energy an average five times, which was 40 and 100% higher than the three and zero times hit by the greedy algorithm and reinforcement learning with partial states, respectively. Reinforcement learning with full states achieved lower energy structures on ten out of twelve sequences than the greedy algorithm."
1786347,0.0,"2.1. Human behavior \n In this task, participants were repeatedly shown a series of colored triangles, red or blue, on a screen, and they were required to press one of two buttons in response to each triangle. They received monetary reward or punishment according to whether this response was correct or wrong. To analyze the behavior, we encoded each response according to underlying behavioral types, where type 1 behavior was to press button one when a red triangle was shown, and button two for blue; type 2 was the opposite of type 1. Over groups of consecutive trials, one response type was rewarded on the majority of trials, controlled by two levels of probability (73% and 83%) known as feedback validity (FV), giving expected uncertainty in the environment. For a set of trials in which response type 1 was rewarded the most, we say that the underlying experimental rule was rule 1, likewise for type 2 responses and rule 2. Stimuli were presented in blocks of 120 trials having constant FV and one of two levels of volatility. High volatility blocks had a rule switch every 30 trials, stable blocks had the same underlying rule for all 120 trials. The participants were not given any information about the generation of rewards or the split of the task into blocks. This data has been examined previously, without considering the fit of different learning models to the behavior (Bland and Schaefer, 2011). Further details of the study can be found in the Materials and Methods section or Bland and Schaefer (2011). \n  Figure ?Figure11 illustrates the study by showing responses made and feedback given for the first 120 trials of the study for four individual participants. Participants were most likely to switch from one response type to the other after negative feedback, that is a loss of points. \n  If the underlying rule can be identified from the pattern of rewards, but the result on individual trials cannot be predicted due to the randomness in reward generation, then to achieve the greatest rewards one should always respond according to the underlying rule, we call this maximizing. So if one knows that type 1 responses are rewarded mostly, then one should make a type 1 response every trial and ignore occasional losses. This does not consider how to identify which response is being rewarded most, or how to identify a rule switch. We quantify participants' behavior by calculating the percentage of trials in which each participant's response is of the type which is associated with the underlying experimental rule. Individual differences in responding to the task gave a range of maximizing behavior from 62% to 89% (mean 74.5%, SD 6%). The overall average feedback validity used in the experiment was 78%, so the average maximizing was just below that. This is in line with many other studies which find that in probabilistic tasks, the average frequency of each response matches the frequency of reward allocation, known as probability matching (see e.g., Vulkan, 2000; Shanks et al., 2002)."
1786347,1.0," 2.2. Computational modeling \n  Reinforcement learning models are based on standard reinforcement learning techniques of making trial by trial adjustments to the predicted value of a particular action, which is a prediction of how much reward is expected from that action. This predicted value is adjusted according to the outcome and a learning rate which controls how much influence the latest outcome has in changing the predicted value of an action. We considered three alternative reinforcement learning models, two of these, standard reinforcement learning model (RL) and win loss modified reinforcement learning model (WL), assume that the environment is fully coupled. This assumes that responses can be viewed in terms of the two response types described above, with the red triangle requiring the opposite response from blue, allowing us to ignore the actual color presented on each trial, and also that exactly one of the responses will be rewarded on each trial. This means that, if feedback shows that one response type is incorrect, then the other response type would have been correct on that trial and vice versa, so regardless of which response is made, feedback lets you know how each response type would have fared. \n  The assumption that the participants expected the environment to be coupled was motivated by the instructions given to participants, but to validate this assumption, we tested an uncoupled reinforcement learning model (UNC) which considers the colors seen and the button presses to be independent of each other and a separate predicted value is maintained for each combination of button and color. Given the assumption of independence, feedback after making a response does not give you any information about the result of pressing the other button or seeing the other color. \n  In our UNC and RL models, one learning rate is assumed for each participant. Our win loss modified reinforcement learning model (WL) allows wins and losses to have different influences on learning by allocating two learning rates to each participant, treating trials following a loss or a win separately. \n  Our Bayesian models are based on hidden Markov models which assume that rewards are governed by a hidden environmental state which cannot be directly observed but can be inferred. In our simple hidden Markov model (HMM), as with Hampton et al. (2006), the hidden state has two possible values, which are equivalent to the two experimental rules. Given the structure of the HMM and the outcomes, combination of response type made and feedback received, Bayesian reasoning is used to determine a probability of reward for each response type. Two sets of probabilities define the structure of the HMM, these are taken to be constant parameters for each participant. These probabilities control the chance of a rule switch and the relation between the hidden state and the reward. \n  Following the work of Behrens et al. (2007), we created a Bayesian model (VOL) which assumes an additional level of structure to the environment, volatility, or how quickly the environment is changing. As with Behrens et al. (2007), a hidden state relates directly to the probability of reward for a particular response, in our case representing the probability of response type 2 being rewarded, without the assumption in the HMM of only two states. This gives a flexible model which can respond to any change in state including changes in feedback validity. Like Behrens et al. (2007) we have assumed that the process for determining the current state and volatility does not vary between participants. \n  In all models, following the calculation of a belief or probability, we apply softmax action selection to determine the probability of making each action on each trial. Softmax action selection assumes that the chosen action depends on the difference between the values associated with each action and on a temperature parameter controlling the amount of randomization of responses on top of underlying beliefs. A low temperature increases the probability of choosing the higher valued action and a high temperature makes the probability of each action more similar. For the RL and UNC models we fit one temperature parameter to each participant's behavior, for the other models we fit two temperature parameters, differentiating trials following wins and losses. \n  Given a set of parameters and a model, we calculate a probability for each action on each trial for the outcomes received by the participant. The natural logarithms of the probabilities for the actions actually taken are summed for each participant. For each model, parameters are fit to each participant's behavior by searching possible values to maximize the likelihood of the parameters over all trials, for more details see Materials and Methods."
1786347,2.0," 2.3. Comparing model fit \n  Models with more parameters should be able to show a closer fit to the data so it is customary to penalize models with more free parameters which have been fit to participants' behavior (Mars et al., 2012). To do this, we compare the five models described above by calculating the commonly used Bayesian Information Criterion (BIC) for each model (Lewandowsky and Farrell, 2011). \n  As a better model has a lower BIC value, Table ?Table11 shows that the WL model gave the best overall fit to the data. We also examined the BIC for each model calculated separately for each participant. The UNC model was the worst fit to behavior compared to the other models for all participants. The best fit model was the WL model for 24 of the 30 participants, for four participants the best fit was the RL model and for two the HMM. Of the 24 participants for whom the WL model was the best fit, 23 had HMM as the next best fit. The differences in the BIC between the WL model and each other model were statistically significant, p < 0.001 in each case, t(29) = 5.05, 4.25, and 7.48 for comparison of WL to RL, HMM, and VOL models, respectively. \n  As described by Lewandowsky and Farrell (2011), we calculated Bayes factors for the difference between the HMM and WL models, we did this using the calculated BIC for each participant. Bayes factors can give an indication of the size of an effect, Lewandowsky and Farrell (2011) report previously proposed guidelines that a Bayes factor above 10 implies strong evidence for one model over the other, and between 3 and 10 implies moderate evidence. Figure ?Figure22 shows the Bayes factors for the WL compared to HMM for all participants. \n  The HMM and WL models fit the participants' behavior better than the other models so we now focus on these two models. Having used all trials to determine the best fit parameters for each participant and model, we could now calculate a trial by trial probability of making a type 2 response. Figure ?Figure33 shows these probabilities for the HMM and WL models for three participants for the first 240 trials of the study. In general, the probabilities match closely, but where there is a difference, the WL model is usually closer to the actual response made by the participant. This follows from the use of log likelihood to find the best model, Figure ?Figure33 is an illustration. \n  As the WL model was the best fit to behavior, we look at the values of the fit parameters. Figure ?Figure44 shows the fit parameters for the WL model, the temperature was significantly higher after a loss than a win, t(29) = 5.61, p < 0.0001 with means of 0.87 and 0.35 after a loss and a win, respectively. According to this model, participants were more likely to randomize their responses after a loss. The fit learning rates were significantly higher after a win than after a loss, means of 0.77 and 0.52, respectively, t(29) = 4.52, p < 0.0001. A lower learning rate after a loss implies that losses are treated less strongly, which allows behavior to respond more slowly to occasional negative feedback and so take advantage of stable periods by not switching to the opposite response type when occasionally losing points when using the most likely response. Finally, we broke down the BIC scores for the WL model between a win and a loss. We find some indications that the WL model fits best after a loss, but this is at the edge of significance (p = 0.054)."
1786347,3.0," 2.4. Parameter recovery \n  If the fit parameters are reliable, we should be able to take simulated data, with known parameters, and accurately estimate those parameters (Lewandowsky and Farrell, 2011). For each model, we chose parameters to represent �typical participants� and used the model's learning rules to generate two sets of simulated responses to each participant's observed outcomes. We used the same process as for the original participant responses to estimate parameters for the simulated responses. \n  Figure ?Figure55 shows that the fit parameters for the WL model are clustered around the parameters used for data generation which are shown by crosses suggesting that the parameters are reliable. \n  The left of Figure ?Figure66 shows the parameters representing probabilities in the structure of the HMM fit to participant behavior and on the right the parameters fit to data generated using the HMM with parameter values shown by crosses. If the participants had understood the experimental generation of outcomes and were applying that knowledge, we would expect the fit parameters to be close to those approximating the generation of data, shown in the left of Figure ?Figure66 by a cross. \n  For the HMM, the spread of fit parameters away from the data generation parameters shows that the parameters are not well recovered. In particular, for several participants the fit value for the error probability was 0.49, that is the probability of losing when using the response type associated with the current rule. Fitting parameters to data generated with this parameter value, the estimated parameter values covered the whole range of feasible values. For the data generated with parameters closer to the actual experimental data, the fit parameters are not so widely spread."
1786347,4.0,"2.5. Model recovery \n  We found that the WL model was the best fit to participant data of the models tested. If model fitting is carried out on simulated data, the best fit model should be that which generated the data. Using the simulated data from the parameter recovery testing described above, we compared the fit of each model as in the analysis of participant data. Table ?Table22 shows the percentage of simulations using each model which were best fit by each model. The correct model has been identified in most cases for all of the models. \n  The largest incorrect identification was the finding that the RL model was the best fit for 18.8% of the simulations by the HMM. The wrongly identified simulations were those which had the parameter for the error probability set to 0.49, and the probability of a switch set to 0.35. This was also the set of parameters which could not be reliably recovered from the simulated data as described above. A simulation using these parameters always gives probabilities close to 0.5 for each response with slight preference in line with the most recent outcome. Reinforcement learning produces responses in line with the most recent outcome by setting the learning rate to one, and the probabilities remain close to 0.5 by setting a high value for temperature. In this way the same behavior can be achieved by the HMM and RL models. Using BIC to compare models, RL will be preferred as the RL model has two parameters compared to four for the HMM."
1786347,5.0," 2.6. How well can these learning methods do? \n  Human behavior was best fit by the WL model, we now consider how the models compare when carried out by an ideal agent. By ideal agent, we mean an agent which always selects the action which the model suggests is most likely to give a reward, and the model parameters are chosen to give the highest number of rewards for the task. We used the sequence of outcomes received by each participant in the task and then considered the performance of each model on each participant's trials. \n  For the RL and WL models, these parameters were found by a grid search over all possible values of the learning rates at intervals of 0.01. For the WL model, a learning rate after a win of 0.48 and after a loss of 0.24 maximized rewards. A learning rate of 0.2 gave maximum rewards for the RL model. The WL model won significantly more rewards than the RL model t(30) = 3.53, p = 0.0014. \n  For the HMM, we searched the parameter space in the region of those parameters approximating the generative environment to find the best performance. The generative environment had equal blocks with FV of 83% and 73%, giving an average probability of 22% of losing when using the response associated with the rule, the error probability. For the probability of a rule switch we used a probability of 0.021 based on 5 switches in 240 trials, having switches after 120 or 30 trials. The parameters which maximized rewards were 0.021 for the switch probability and 0.2 for the error probability. There was no significant difference between the performance of the WL and HMM models t(30) = 1, p = 0.33. The HMM was significantly better than the VOL model, t(30) = 4.98, p < 0.0001. \n  Figure ?Figure77 shows the maximizing behavior, aligned with the experimental rule, of the ideal WL model in comparison to that of the participants. The percentage of responses in line with the underlying experimental rule were averaged over all participants and the ideal WL model for trials following rule switches, with each of the levels of feedback validity (FV) shown separately. The ideal WL has parameter values which optimize behavior over all trials, not just volatile blocks. The ideal WL model far outperforms the participants and reaches a steady level of maximizing at 100% in the high FV condition. \n  As well as being able to outperform humans, the WL model can also closely simulate human behavior. Ten sets of simulated responses were generated using the WL models with the fit parameters and the sequence of outcomes for each individual participant. Figure ?Figure77 shows that the simulations closely replicate the aggregate performance of the participants. Although only volatile blocks are shown, the parameters used in the simulations were those fit to participant behavior across all trials regardless of the experimental conditions. Maximizing behavior of participants and simulations quickly adapts to a rule switch and reaches a plateau which is approximately equal to the level of feedback validity (probability matching). For trials 21�30 following a switch in the high feedback validity (FV = 83%) condition, participants showed maximizing of 82% and the WL simulation 81%. In the low feedback validity condition (FV = 73%), maximizing by participants and the WL model was 73%."
2183937,0.0,"In Experiment 1, rats received excitotoxic lesions of the AcbC or sham lesions, and were then tested on an instrumental free-operant acquisition task with delayed reinforcement (Experiment 1A; see Methods) and subsequently a reinforcer magnitude discrimination task (Experiment 1B). In Experiment 2, na�ve rats were trained on the free-operant task for delayed reinforcement; AcbC lesions were then made and the rats were retested."
2183937,1.0,"Histology \n  In Experiment 1, there were two postoperative deaths. Histological analysis revealed that the lesions were incomplete or encroached significantly on neighbouring structures in four subjects. These subjects were excluded; final group numbers were therefore 8 (sham, 0 s delay), 6 (AcbC, 0 s delay), 8 (sham, 10 s delay), 7 (AcbC, 10 s delay), 8 (sham, 20 s delay), and 7 (AcbC, 20 s delay). In Experiment 2, one rat spontaneously fell ill with a colonic volvulus during preoperative training and was killed, and there were three postoperative deaths. Lesions were incomplete or too extensive in seven subjects; final group numbers were therefore 7 (sham, 0 s delay), 5 (AcbC, 0 s delay), 8 (sham, 10 s delay), 4 (AcbC, 10 s delay), 8 (sham, 20 s delay), and 5 (AcbC, 20 s delay). \n  Lesions of the AcbC encompassed most of the core subregion; neuronal loss and associated gliosis extended in an anteroposterior direction from approximately 2.7 mm to 0.5 mm anterior to bregma, and did not extend ventrally or caudally into the ventral pallidum or olfactory tubercle. Damage to the ventromedial caudate-putamen was occasionally seen; damage to AcbSh was restricted to the lateral edge of the dorsal shell. Schematics of the lesions are shown in Figure ?Figure2.2. Photomicrographs of one lesion are shown in Figure ?Figure3,3, and are similar to lesions with identical parameters that have been presented before [29,30]."
2183937,2.0," Acquisition of instrumental responding (Experiment 1A) \n  The imposition of response-reinforcer delays retarded the acquisition of free-operant lever pressing, in sham-operated rats and in AcbC-lesioned rats (Figure ?(Figure4).4). AcbC-lesioned rats responded slightly more than shams on both the active and inactive levers in the absence of response-reinforcers delays, but when such delays were present, AcbC lesions retarded acquisition relative to sham-operated controls (Figure ?(Figure55). \n  An overall ANOVA using the model lesion2 � delay3 � (session14 � lever2 � S) revealed multiple significant interactions, including lever � delay � lesion (F2,38 = 5.17, p = .01) and session � lever � delay (F6.0,229.1 = 5.47,  = .464, p < .001), justifying sub-analysis. All six groups learned to respond more on the active lever than the inactive lever (p ? .002, main effect of lever or session � lever interaction for each group alone). \n  For sham-operated rats, delays reduced the rate of acquisition of the active lever response and reduced the asymptotic level of responding attained (Figure ?(Figure4a;4a; delay: F2,21 = 11.7, p < .001;  = .276, p < .001; session � delay: F7.2,75.3 = 2.46,  = .276, p = .024). The presence of a delay also increased responding on the inactive lever slightly (delay: F2,21 = 4.06, p = .032), though not systematically (the 10 s group differed from the 0 s group, p = .036, but no other groups differed, p ? .153). \n  There was a further, delay-dependent impairment in AcbC-lesioned rats, who responded more than shams at 0 s delay but substantially less than shams at 10 s and 20 s delay. As in the case of sham-operated controls, delays reduced the rate of acquisition and the maximum level of responding attained in AcbC-lesioned rats (Figure ?(Figure4b;4b; delay: F2,17 = 54.6, p < .001; delay � session: F6.9,58.7 = 2.64,  = .266, p = .02). Responding on the inactive lever was not significantly affected by the delays (maximum F15.8,134.2 = 1.65,  = .607, p = .066). At 0 s delay, AcbC-lesioned subjects responded more than shams on the active lever (Figure ?(Figure5a;5a; lesion: F1,12 = 5.30, p = .04) and the inactive lever (lesion: F1,12 = 9.12, p = .011). However, at 10 s delay, AcbC-lesioned rats responded significantly less than shams on the active lever (Figure ?(Figure5b;5b; lesion: F1,13 = 9.04, p = .01); there was no difference in responding on the inactive lever (F < 1, NS). At 20 s delay, again, AcbC-lesioned rats responded significantly less than shams on the active lever (Figure ?(Figure5c;5c; lesion: F1,13 = 9.87, p = .008) and there was no difference in responding on the inactive lever (F < 1, NS)."
2183937,3.0," Experienced response-delivery and response-collection delays (Experiment 1A) \n  For every reinforcer delivered, the active lever response most closely preceding it in time was identified, and the time between that response and delivery of the reinforcer (the 'response-delivery delay') was calculated. This time can therefore be equal to or less than the programmed delay, and is only relevant for subjects experiencing non-zero programmed response-reinforcer delays. The response-to-reinforcer-collection ('response-collection') delays were also calculated: for every reinforcer delivered, the response most closely preceding it and the nosepoke most closely following it were identified, and the time between these two events calculated. This time can be shorter or longer than the programmed delay, and is relevant for all subjects. \n  AcbC-lesioned rats experienced the same response-delivery delays as shams when the programmed delay was 10 s, but experienced longer response-delivery delays when the programmed delay was 20 s (Figure ?(Figure6a).6a). Similarly, AcbC-lesioned rats experienced the same response-collection delays as shams when the programmed delay was 0 s, slightly but not significantly longer response-collection delays when the programmed delay was 10 s, and significantly longer response-collection delays when the programmed delay was 20 s (Figure ?(Figure6b).6b). These differences in the mean delay experienced by each rat were reflected in differences in the distribution of response-delivery and response-collection delays when the programmed delay was non-zero (Figure 6c,d). Since AcbC-lesioned rats experienced slightly longer delays than sham-operated rats, it was necessary to take this into account when establishing the effect of delays on learning, as follows."
2183937,4.0," Effect of delays on learning (Experiment 1A) \n  There was a systematic relationship between the acquisition rate and the programmed delay of reinforcement, and this was altered in AcbC-lesioned rats. Figure ?Figure7a7a replots the rates of responding on the active lever on session 10 of acquisition [1]. Despite the comparatively low power of such an analysis, lever-pressing was analysed for this session only using the model lesion2 � delay3. This revealed a significant lesion � delay interaction (F2,38 = 12.6, p < .001), which was analysed further. Increasing delays significantly reduced the rate of responding in this session for shams (F2,21 = 17.3, p < .001) and AcbC-lesioned rats (F2,17 = 54.4, p < .001). AcbC-lesioned rats responded more than shams at zero delay (F1,12 = 8.52, p = .013) but less than shams at 10 s delay (F1,13 = 4.71, p = .049) and at 20 s delay (F1,13 = 17.3, p = .001). \n  Since the AcbC group experienced slightly longer response-delivery and response-collection delays than shams when the programmed delay was non-zero (Figure ?(Figure6),6), it was important to establish whether this effect alone was responsible for the retardation of learning, or whether delays retarded learning in AcbC-lesioned rats over and above any effect to increase the experienced delay. The mean experienced response-collection delay was calculated for each subject, up to and including session 10. The square-root-transformed number of responses on the active lever in session 10 was then analysed using a general linear model of the form lesion2 � experienced delaycov. Unlike a standard analysis of covariance, the factor � covariate interaction term was included in the model. This confirmed that the lesion retarded the acquisition of responding in AcbC-lesioned rats, compared to controls, in a delay-dependent manner, over and above the differences in experienced delay (Figure ?(Figure7b;7b; lesion � experienced delay: F1,40 = 12.4, p = .001)."
2183937,5.0," Experienced delays and learning on the inactive lever (Experiment 1A) \n  No such delay-dependent effects were observed for the inactive lever. Experienced inactive-response-delivery delays (calculated across all sessions in the same manner as for the active lever) were much longer and more variable than corresponding delays for the active lever, because subjects responded on the inactive lever so little. Means � SEMs were 250 � 19 s (sham, 0 s), 214 � 29 s (AcbC, 0 s), 167 � 23 s (sham, 10 s), 176 � 33 s (AcbC, 10 s), 229 � 65 s (sham, 20 s), and 131 � 37 s (AcbC, 20 s). ANOVA of these data revealed no effects of lesion or programmed delay and no interaction (maximum F1,38 = 1.69, NS). Experienced inactive-response-collection delays were 252 � 19 s (sham, 0 s), 217 � 29 s (AcbC, 0 s), 169 � 23 s (sham, 10 s), 179 � 33 s (AcbC, 10 s), 231 � 65 s (sham, 20 s), and 136 � 37 s (AcbC, 20 s). Again, ANOVA revealed no effects of lesion or programmed delay and no interaction (maximum F1,38 = 1.61, NS). When the square-root-transformed number of responses on the inactive lever in session 10 was analysed with the experienced delays up to that point as a predictor, using the model lesion2 � experienced inactive-response-collection delaycov just as for the active lever analysis, there was no lesion � experienced delay interaction (F < 1, NS)."
2183937,6.0," Discrimination of relative reinforcer magnitude (Experiment 1B) \n  Relative preference for two reinforcers may be inferred from the distribution of responses on concurrent variable interval schedules of reinforcement [31-33]. According to Herrnstein's matching law [31], if subjects respond on two concurrent schedules A and B delivering reinforcement at rates rA and rB respectively, they should allocate their response rates RA and RB such that RA/(RA+RB) = rA/(rA+rB). Overmatching is said to occur if subjects prefer the schedule with the higher reinforcement rate more than predicted by the matching law; undermatching is the opposite. Both sham-operated and AcbC-lesioned rats were sensitive to the distribution of reinforcement that they received on two concurrent random interval (RI) schedules, altering their response allocation accordingly. Subjects preferred the lever on which they received a greater proportion of reinforcement. In general, subjects did not conform to the matching law, but exhibited substantial undermatching; this is common [33]. AcbC-lesioned rats exhibited better matching (less undermatching) than shams (Figure ?(Figure8),8), suggesting that their sensitivity to the relative magnitudes of the two reinforcers was as good as, or better than, shams'. \n  To analyse these data, the proportion of pellets delivered by lever A (see Methods), and the proportion of responses allocated to lever A, were calculated for each subject for the last session in each of the three programmed reinforcement distribution contingencies (session 11, programmed reinforcement proportion 0.5; session 19, programmed proportion 0.8; session 27, programmed proportion 0.2; see Table ?Table1).1). The analysis used a model of the form response proportion = lesion2 � (experienced reinforcer distributioncov � S); the factor � covariate term was included in the model. Analysis of sham and AcbC groups separately demonstrated that both groups altered their response allocation according to the distribution of reinforcement, i.e. that both groups discriminated the two reinforcers on the basis of their magnitude (effects of reinforcer distribution; sham: F1,47 = 16.6, p < .001; AcbC: F1,39 = 97.2, p < .001). There was also a significant lesion � reinforcer distribution interaction (F1,86 = 5.5, p = .021), indicating that the two groups' matching behaviour differed, with the AcbC-lesioned rats showing better sensitivity to the relative reinforcer magnitude than the shams (Figure ?(Figure8).8). These statistical conclusions were not altered by including counterbalancing terms accounting for whether lever A was the left or right lever (the left having been the active lever previously in Experiment 1A), or whether a given rat had been trained with 0, 10, or 20 s delays in Experiment 1A."
2183937,7.0," Switching behaviour during concurrent schedule performance (Experiment 1B) \n  Because switching behaviour has the potential to influence behaviour on concurrent schedules e.g. [34], we also analysed switching probabilities. AcbC-lesioned rats were less likely than shams to switch between levers when responding on two identical concurrent RI schedules with a changeover delay (COD) of 2 s. Responses on the left and right levers were sequenced for sessions 8�11 (concurrent RI-60s schedules, each delivering a one-pellet reinforcer; see Methods and Table ?Table1),1), and the probabilities of switching from one type of response to another, or repeating the same type of response, were calculated. The switch probabilities were analysed by one-way ANOVA; this revealed an effect of lesion (F1,42 = 8.88, p = .005). Mean switch probabilities (� SEMs) were 0.41 � 0.02 (AcbC) and 0.49 � 0.01 (sham)."
2183937,8.0," Effects of AcbC lesions on performance of a previously-learned instrumental response for delayed reinforcement (Experiment 2) \n  Due to mechanical faults, data from four subjects in session 10 (preoperative) and data from one subject in session 22 (postoperative) were not collected. Both sessions were removed from analysis completely, and data points for those sessions are plotted using the mean and SEM of the remaining unaffected subjects (but not analysed). \n  Preoperatively, the groups remained matched following later histological selection. Analysis of the last 3 preoperative sessions, using the model lesion intent2 � delay3 � (session3 � lever2 � S), indicated that responding was affected by the delays to reinforcement (delay: F2,31 = 5.46, p = .009; delay � lever: F2,31 = 19.5, p < .001), but there were no differences between the groups due to receive AcbC and sham lesions (terms involving lesion intent: maximum F was for session � lever � lesion intent, F2,62 = 1.844, NS). As expected, delays reduced the rate of responding on the active lever (F2,31 = 15.6, p < .001) and increased responding on the inactive lever (F2,31 = 8.12, p = .001) preoperatively. \n  AcbC lesions selectively impaired performance of instrumental responding only when there was a response-reinforcer delay. There was no effect of the lesion on responding under the 0 s delay condition, but in the presence of delays, AcbC lesions impaired performance on the active lever (Figure ?(Figure9;9; Figure ?Figure10).10). These conclusions were reached statistically as follows. \n  Subjects' responding on the relevant lever in the last preoperative session (session 14) was used as a covariate to increase the power of the analysis [35]. As expected, there were no significant differences in the covariates themselves between groups due to receive AcbC or sham surgery (terms involving lesion intent for the active lever: Fs < 1, NS; for the inactive lever, lesion intent: F1,31 = 2.99, p = .094; lesion intent � delay: F < 1, NS). Analysis of the postoperative sessions, using the model lesion2 � delay3 � (session17 � lever2 � session-14-active-lever-responsescov � S), revealed a near-significant lesion � delay � session � lever interaction (F22.4,335.5 = 1.555,  = .699, p = .054). Furthermore, analysis of postoperative responding on the active lever, using the model lesion2 � delay3 � (session17 � session-14-active-lever-responsescov � S), revealed a session � delay � lesion interaction (F17.3,259.5 = 1.98,  = .541, p = .013) and a delay � lesion interaction (F2,30 = 3.739, p = .036), indicating that the lesion affected responding on the active lever in a delay-dependent manner. In an identical analysis of responding on the inactive lever (using inactive lever responding on session 14 as the covariate), no terms involving lesion were significant (maximum F: lesion, F1,30 = 1.96, p = .172), indicating that the lesion did not affect responding on the inactive lever. \n  Postoperatively, response-reinforcer delays continued systematically to decrease responding on the active lever, both in shams (Figure ?(Figure9a;9a; delay: F2,20 = 11.78, p < .001; session � delay: F12.4,124.1 = 2.36,  = .388, p = .008) and in AcbC-lesioned rats (Figure ?(Figure9b;9b; delay: F2,11 = 13.9, p = .001). Shams continued to discriminate between the active and inactive lever at all delays (lever: all groups p ? .002; lever � session: all groups p ? .003). AcbC-lesioned rats continued to discriminate at 0 s and 10 s (lever: p ? .011; lever � session: p ? .036), but AcbC-lesioned subjects in the 20 s condition failed to discriminate between the active and inactive levers postoperatively (lever: F1,4 = 1.866, p = .244; lever � session: F < 1, NS). \n  Lesioned subjects responded as much as shams at 0 s delay, but substantially less than shams at 10 s and 20 s delay (Figure ?(Figure10).10). Again, analysis was conducted using responding on the relevant lever in session 14 (the last preoperative session) as a covariate. At 0 s, the lesion did not affect responding on the active lever (lesion: F < 1, NS; lesion � session: F16,144 = 1.34, NS). However, at 10 s, AcbC-lesioned rats responded significantly less than shams on the active lever (lesion: F1,9 = 7.08, p = .026; lesion � session: F15.0,135.3 = 3.04,  = .94, p < .001). Similarly, at 20 s, AcbC-lesioned rats responded less than shams on the active lever (lesion: F1,10 = 6.282, p = .031). There were no differences on responding on the inactive lever at any delay (Fs ? 1.31, NS). \n  As in Experiment 1, AcbC-lesioned rats experienced the same response-delivery delays as shams when the programmed delay was 10 s, but experienced longer response-delivery delays when the programmed delay was 20 s (Figure 11a). Similarly, AcbC-lesioned rats experienced the same response-collection delays as shams when the programmed delay was 0 s, slightly but not significantly longer response-collection delays when the programmed delay was 10 s, and significantly longer response-collection delays when the programmed delay was 20 s (Figure 11b)."
2183937,9.0," Relationship between experienced delays and performance (Experiment 2) \n  There was a systematic relationship between the postoperative response rate and the programmed delay of reinforcement, and this was altered in AcbC-lesioned rats. Figure 12a replots the rates of lever-pressing on session 24, the 10th postoperative session (compare Figure ?Figure7).7). An analysis using the model lesion2 � programmed delay3 revealed a significant lesion � delay interaction (F2,31 = 5.09, p = .012). In this session, there was no significant effect of delays on shams' performance (F2,20 = 2.15, p = .143), though there was for AcbC-lesioned rats (F2,11 = 9.01, p = .005). There were no significant differences in responding on this session between shams and AcbC-lesioned rats in the 0 s condition (F1,10 = 3.10, p = .109) or the 10 s condition (F < 1, NS), but AcbC-lesioned rats responded less at 20 s delay (F1,11 = 6.74, p = .025). \n  Since the AcbC group experienced slightly longer response-delivery and response-collection delays than shams when the programmed delay was non-zero (Figure ?(Figure11),11), as before, the rate of responding in session 24 was analysed as a function of the delays experienced postoperatively. The mean experienced response-collection delay was calculated for postoperative sessions up to and including session 24; the square-root-transformed number of lever presses in session 24 was then analysed using a general linear model of the form lesion2 � experienced delaycov, with the factor � covariate interaction term included in the model. This confirmed that the lesion affected responding in AcbC-lesioned rats, compared to controls, in a delay-dependent manner, over and above the postoperative differences in experienced delay (Figure 12b; lesion � experienced delay: F1,33 = 6.53, p = .015)."
2183937,10.0," Locomotor activity and body mass \n  AcbC-lesioned animals were hyperactive compared to sham-operated controls, and gained less mass then shams across the experiments (Figure ?(Figure13),13), consistent with previous results [22,29,36]."
908754,0.0,"We applied intra-operative microstimulation in the SN of eleven patients undergoing DBS for the treatment of PD as they performed a reinforcement learning task (Table ?(Table1).1). Subjects selected between a red and blue card deck by pressing buttons on hand-held controllers and subsequently received positive or negative feedback (Figure ?(Figure1A).1A). The reward probabilities associated with each card deck stochastically fluctuated throughout the intra-operative session to encourage learning (Figure ?(Figure1B,1B, see Section 2)."
908754,1.0," Subjects demonstrated clear evidence of learning on the task. Both during stage 1 and stage 2, subjects showed an increased probability of repeating the same action after receiving positive feedback [�win-stay,� 0.5 expected by chance; t(10) > 5.8, p's < 0.001, Figure ?Figure1C].1C]. Subjects also showed an increased probability of making a high reward probability choice (�accuracy�) during the last 10 trials of a particular reward probability regime, as compared to the first 10 trials after a regime switch [t(10) = 4.35, p = 0.001, Figure ?Figure1D1D]."
908754,2.0," To assess the importance of SN neuronal activity for learning, we applied SN microstimulation following approximately half the reward trials during stage 2 of each subject's intra-operative session. To assess whether SN stimulation had an effect on learning, we compared subjects' win-stay probabilities following reward trials that were accompanied by stimulation (�stim trials�) and stage 2 reward trials during which stimulation was not applied (�control trials�). Across 11 subjects, we observed a trend toward decreased win-stay following stimulation trials compared to control trials [t(10) = 2.03, p = 0.068, Figure ?Figure22]."
908754,3.0," Our main hypothesis was that stimulation-related changes in learning would vary based on the functional properties of neurons near the electrode tip. To assess whether this was the case, we extracted various physiological parameters from neural activity recorded during stage 1 of each subject's intra-operative session (see Section 2). We assessed whether there was a correlation between stimulation-related changes in learning and mean spike rate of units recorded on each channel, and observed a significant negative correlation such that the greatest impairments in learning were observed when the electrode was positioned near neurons with relatively high spike rates (r = ?0.64, p = 0.045, Figure ?Figure3A).3A). Based on the the established finding that high spike rates and narrow waveforms are properties of GABAergic neurons (Ungless and Grace, 2012), we also assessed for a correlation between stimulation-related changes in learning and mean waveform duration. We observed a positive correlation between stimulation-related changes in learning and waveform duration, such that the strongest impairments occurred near neurons with narrow waveforms (r = 0.64, p = 0.044, Figure ?Figure3B).3B). We did not observe a significant relation between stimulation-related changes in learning and phasic post-reward changes in activity (p > 0.5), and generally did not observe post-reward phasic changes in activity (z-score range: ?0.1:0.36). Two example neurons are shown in Figure ?Figure3C3C."
1904820,1.0,"Microscopic examination was performed for diagnosis in all of the malaria cases. A total of 153 cases of malaria were observed between January 2004 and June 2013, 113 of which were found among Japanese travellers. Of the latter, there were 78 cases of P. falciparum malaria (including 1 case of co-infection with P. malariae malaria and 1 case of co-infection with P. vivax malaria confirmed by PCR), 22 cases of P. vivax malaria (including 1 case of co-infected with P. falciparum malaria confirmed by PCR), 11 cases of P. ovale malaria, 3 cases of P. malariae malaria, and 1 case of P. knowlesi malaria. RDTs were performed in 67, 21, 10, 2, 1 and 2 cases among the mono-infection cases of P. falciparum malaria, P. vivax malaria, P. ovale malaria, P. malariae malaria, P. knowlesi malaria and co-infection cases, respectively. The cases confirmed by PCR were 11, 19, 10, 3 and 1 cases in P. falciparum malaria, P. vivax malaria, P. ovale malaria, P. malariae malaria and P. knowlesi malaria, respectively (Table ?(Table11)."
1904820,2.0,"We focused on a comparison of P. ovale malaria mono-infection cases and P. vivax malaria mono-infection cases. There were 10 cases of P. ovale malaria (mean age, 27.8 years; male-to-female ratio, 2.3:1) and 18 cases of P. vivax (mean age, 29.8 years; male-to-female ratio, 2.6:1). These patients constituted the final study population. The results of RDTs were evaluated for 9 patients with P. ovale malaria and 17 patients with P. vivax malaria (excluding 1 co-infected case). Among the 18 cases of P. vivax malaria, 13 (72.2%) had been infected in Asia, 4 (22.2%) in South America, and 1 (5.6%) in Africa (Republic of Rwanda) (Table ?(Table2).2). All of the 10 cases of P. ovale malaria had been infected in Africa (Table ?(Table3).3). The average parasitemia in the cases of P. ovale malaria was significantly lower than that in P. vivax malaria (P = 0.002). The sensitivity of RDTs for P. ovale malaria was also significantly lower than that for P. vivax malaria (P < 0.001). The sensitivity of SDMA for P. vivax malaria and P. ovale malaria was 100% (7/7) and 50% (2/4), respectively. The sensitivity of BN for P. vivax malaria was 90.0% (9/10), but it was ineffective in detecting the cases of P. ovale malaria (0/5; Table ?Table4).4). There were only 3 cases of P. malariae malaria, one of which showed co-infection with P. falciparum. The other 2 cases of P. malariae malaria were mono-infection of P. malariae. In the mono-infection cases, one case of P. malariae malaria showed a positive line detecting pLDH of SDMA while the other case showed a positive line detecting aldolase of BN."
359836,1.0,"Figure 2 shows the incidence of clinical malaria over the 18-month follow-up period observed in the control arm of the Phase III trial and estimated by the model, for each age group and each transmission level. The modelled results matched the trial results closely, although some differences appeared mainly in the infant age group for the low transmission category and in the older age group for moderate and high transmission. The model mostly underestimates the malaria incidence observed in the trial for the 5 to 17-month group. Table 4 shows the number of clinical malaria cases and the percentage of severe malaria cases observed in the control and vaccine arms of the Phase III trial and predicted by the model. The modelled results matched well with the data (error in acceptable 10 % area) in the age group vaccinated at age 6 12 weeks although in the vaccine arm the model provided more severe cases than the trial (+23 %). In the age group vaccinated at 5 17 months the data were more difficult to reproduce because of the lower number of cases estimated in moderate and high transmission settings. The model tended to underestimate the burden of malaria compared with the observed data from the trial in the 5 17 months as pointed out in Table 4. The age distribution of malaria cases predicted by the model matched well with the age distribution published by Carneiro et al. [14] for clinical cases (Fig. 3a) and severe cases (Fig. 3b)."
359836,2.0,"Table 5 shows the estimated impact of adding RTS,S vaccination with doses administered at age 6, 10 and 14 weeks or 6, 7-and-a-half and 9 months in 42 African countries and eight specific countries (see Additional file 3: Table S1 for results in each country). The estimates were based on vaccinating the birth cohort in 2017 and following them for 10 years, assuming no change in malaria transmission. Vaccination at age 6, 10 and 14 weeks would be expected to avert almost five million cases of clinical malaria, 119,000 severe malaria cases, 98,600 malaria hospitalizations and 31,000 malaria deaths. Vaccination at age 6, 7-and-a-half and 9 months would be expected to avert almost 12.5 million cases of clinical malaria, 250,400 severe malaria cases, 208,000 malaria hospitalizations and 65,400 malaria deaths. Therefore the higher efficacy obtained in five to 17-months age group would overcome the lower coverage with vaccination starting at 6 months (75 % of DTP3). Table 6 shows these estimated impact data expressed per 100,000 vaccinees. Countries with high malaria transmission, such as Nigeria and Burkina Faso, generally had higher values than countries with lower malaria transmission, such as Kenya. In Kenya more than 75 % of the population is not exposed or exposed to low levels of malaria transmission (i.e., with parasite prevalence below 5 % in children of 2 10 years old) while 7 % would experience high malaria transmission (i.e., with parasite prevalence above 40 % in children of 2 10 years old). Exposure levels are also variable in Tanzania with about 45 % of the population in low transmission areas versus 12 % experiencing high levels of transmission. This suggests that the projected impact of vaccination increases with transmission even if the relative percentage of events averted is predicted to decrease with transmission. Vaccination at age 6, 7-and-a-half and 9 months generally resulted in higher values than vaccination at age 6, 10 and 14 weeks, reflecting the higher vaccine efficacy in the older age group. Over the 42 African countries it is estimated that 2019 (?3652; 6341) cases of neurological sequelae would be averted with vaccination at the age of 6, 10 and 14 weeks and 4258 (?7; 8191) cases of neurological sequelae with vaccination at the age of 6, 7-and-a-half and 9 months."
359836,3.0,"Figure 4 shows the estimated percentage of clinical malaria cases averted when adding RTS,S vaccination at age 6, 10 and 14 weeks and at age 6, 7-and-a-half and 9 months in low, moderate and high transmission categories. Addition of RTS,S would be expected to reduce the incidence of clinical malaria in a higher proportion for low transmission than higher transmission settings. The benefit would be expected to occur in the first 1 4 years, and the model predicted a small increase in later years in high transmission areas, reflecting delayed development of natural immunity. This appears in the reduction of proportion of events averted in children less than 10 years of age compared with children under 5 years of age."
2052982,1.0,"A total of 1099 children were included in the study. During the analysis it became apparent that information on one malaria RDT result and two malaria slide readings were missing and these were considered as missing data for the analysis. Malaria was the most frequently infection diagnosed by nurses by malaria RDT in 72.68% (798/1098) of febrile children, but only 53.69% (589/1097) of febrile children could be confirmed by expert microscopy. The second commonest cause of fever diagnosed by heath facilities nurses were respiratory tract infections (RTI) [bronchiolitis 9.2%(101/1099), pneumonia 14.47% (159/1099), other RTI 14.10% (155/1099)]. The characteristics of study population are presented in Table 1. A small percentage of the febrile children who received antimalarial prescription got first an injectable antimalarial (artesunate or artemether) followed by artemisinin-based combination therapy (artemether lumefantrine or artesunate amodiaquine) for subsequent home treatment 2.11% (17/805). The majority of malaria treatment 97.88% (788/805) was artemisinin-based combination therapy as previously mentioned. For the antibiotic prescriptions, 14.58% (125/857) and 1.17% (10/857) have received respectively 2 and 3 antibiotic prescriptions, and 84.24% (722/857) received a single prescription. All antiparasitics were single prescriptions (Table 2)."
2052982,2.0,"Table 3 presents the risk of antimicrobial prescriptions according to malaria RDT results during the study period. It is evident that rural health facilities as well as the referral hospital were likely to prescribe an antimalarial in case of a positive malaria RDT, as recommended by WHO, compared to negative tested cases. Antibiotics were likely to be prescribed to negative malaria RDT. The adherence rate of the health care workers to the result of the malaria RDT-PfHRP2 was 92.89% (1020/1098: 762 malaria RDT positive patients received an antimalarial treatment and 258 malaria RDT negative cases did not receive an antimalarial treatment). However, if malaria expert microscopy is considered as gold standard, the risk for febrile children tested with RDT-PfHRP2 to have their initial antimalarial prescription affected (modified) was statistically significant (RR?=?7.74, p?=?0.00001). Moreover, the likelihood of antibiotic prescription in case of a negative malaria RDTs was 3 times higher compared to positive malaria RDTs and statistically significant (RR?=?3.57, p?<?0.0001). It is apparent from Table 4 that the health care workers at the rural health facilities were more likely to prescribe antimicrobials to children who tested positive for malaria by RDT (antimalarial?=?96.11%; antibiotics?=?75.20%; antiparasitics?=?18.63%) than at the level of the referral hospital (antimalarial?=?93.37%; antibiotics?=?62.98%; antiparasitics?=?1.65%). Furthermore, the nurses in the rural health facilities were more likely to prescribe antibiotics (97.86%) and antiparasitics (26.73%) to children who tested negative by malaria RDT than attending health staff at the referral hospital (antimalarial?=?84.07%; antiparasitics?=?2.65%), except for malaria treatments (rural health facilities?=?7.48%; referral hospital?=?24.77%). As an overall trend it was found that the risk of prescribing antimalarial as well as antibiotic and antiparasitic to children with a positive malaria RDT compared to children with negative malaria RDT was higher in health facility compared to referral hospital. The risk of prescribing antimalarial in positive tested patients compared to negative malaria RDTs was 8.01 (95% CI 5.51 11.66, p?=?0.00001) and 6.93 (95% CI 4.07 11.81, p?=?0.00001) for the rural health facility and referral hospital, respectively. The risk of prescribing antibiotic in case of negative malaria RDT compared to RDT positive was 11.10 (95% CI 4.18 29.43, p?=?0.00001) in health facility and 2.14 (95% CI 1.38 3.32, p?=?0.00001) in referral hospital."
2052982,3.0,"By cross-checking the laboratory findings (actual cause of disease) with the antimicrobials prescribed by health care workers based on the routine practice (based on the national guideline for the treatment of childhood diseases), it is evident that a large part of the febrile children who received an antibiotic prescription did actually not need such a treatment. It was that at the rural health facilities all children with a positive bacterial bloodstream infection (bBSI) (25/25) or urinary tract infection (UTI) (8/8) and 80.39% (41/51) with bacterial gastro-intestinal infection (bGII) based to laboratory results did actually receive antibiotic prescriptions. But also 93.98% of the febrile children without any infection (confirmed by laboratory testing) in the present study too actually received antibiotic prescriptions. In contrast, at the referral hospital only 75% (30/40) of children with positive bBSI, 64.28% (9/14) with bGII and 100% (3/3) with UTI did actually receive antibiotic prescription. Moreover, 86.04% (74/86) of febrile children without (laboratory confirmed) infection did also got antibiotic prescriptions (Table 5)."
1904879,1.0,"The baseline characteristics of the study population are shown in Table 1. A total of 491 children aged between 6?months and 14?years participated in the study. There were more females (55.6%) than males (44.6%), and most of the participants were less than 5?years (43.6%) old. A greater proportion of parents/caregivers of the children had a primary level of education (51.8%) followed by those with secondary school education (31.6%). The proportion of children who slept under a long-lasting mosquito net the previous night before the survey was 62.3%. On microscopic examination, P. falciparum infection was present in 27.7% of the children, while using RDT, malaria was diagnosed in 39.7% of participants. Fever and anaemia were observed in 3.7% and 72.7% of the children, respectively. The prevalence of falciparum malaria among the 491 children varied with sex as shown in Table 2. By microscopy, malaria parasite prevalence was higher in females (31.9%) than males (22.5%) and the difference was significant at P?=?0.021, whereas by RDT, the difference in prevalence of malaria parasite between males (35.8%) and females (42.9%) was not statistically significant (P?=?0.111). Conversely, the geometric mean parasite density (GMPD) was significantly higher (P?=?0.025) in males (218 parasites/?L of blood) than females (172 parasites/?L of blood). A significant difference in P. falciparum infection by microscopy (P?=?0.002) and RDT (P?=?0.001) was observed with age, with the ??4?years age group having the highest malaria prevalence (31.9% by microscopy and 47.4% by RDT), followed by the 5 8?years age group (29.9% by microscopy and 38.1% by RDT) and least by the ??9?years age group (11.9% by microscopy and 23.8% by RDT). In addition, children ??4?years of age had the highest GMPD (224/?L of blood), followed by the 5 8?years age group (159/?L of blood) and lastly the 9?years age group (141/?L of blood). In both microscopy and by RDT, the prevalence of P. falciparum infection was highest in children whose parents had no formal level of education (63.2% by microscopy and 57.4% by RDT), while children whose parents had tertiary level of education had the least prevalence (9.0% by microscopy and 14.1% by RDT), and the difference was significant at P?<?0.001 and P?<?0.001 respectively (Table 2). Children who used mosquito bed net had a significantly lower P. falciparum infection prevalence (15.4% by microscopy and 35.6% by RDT) when compared with children who did not use a bed net (48.4% by microscopy and 46.7% by RDT). P. falciparum infection prevalence was significantly higher by microscopy (P?=?0.039) and RDT (P?<?0.001) in children with anaemia (30.3% by microscopy and 44.5% by RDT) than those non-anaemic (20.9% by microscopy and 26.9% by RDT) as shown in Table 2."
1904879,2.0,"The CareStart  Malaria HRP2 pf Ag RDT had a sensitivity of 82.4% (95% CI:74.9 88.4%) and specificity of 76.6% (95% CI 71.9 80.9%). The PPV, NPV and Acc were 57.4% (95% CI 52.4 62.3%), 91.9% (95% CI 88.7 94.2%) and 78.2% (95% CI 74.3 81.8), respectively. False positive results were observed in 42.6% (83) of children with microscopy negative results for P. falciparum, while the false negative rate was 8.1% (24) among the children as shown in Table 3. The measure of agreement kappa (?) between microscopy and CareStart  Malaria HRP2 pf Ag RDT (G0141) was 0.52. There was a statistically significant dependence of the positivity of the RDT on clinical malaria parasitaemia (P?<?0.001), fever (P?<?0.004) and parasite density (P?<?0.001). The positivity of the RDT was 100% for clinical malaria parasitaemia (presence of Plasmodium, with an axillary temperature of ??37.5? C) and 72.2% among febrile children (temperature of ??37.5? C, regardless of the presence of Plasmodium). The RDT demonstrated a sensitivity of 96.1% for parasite densities above 200 parasites/?L of blood (Table 4). A multivariate analysis demonstrated that children who were febrile (P?<?0.001), less than 5 years old (P?<?0.02), those who had fever within a month (P?<?0.001), and those anaemic were more likely to have a positive RDT result. Febrile children were 6.8 times more likely to have a positive RDT for P. falciparum than non-febrile children while those under 5 years of age were 2 times at odds of having a positive RDT than their contemporaries. In addition, children with a history of fever within a month at the time of the survey were 4.57 times more likely to be positive for P. falciparum infection by RDT when compared with children without fever. Moreover, those with anaemia were 2 times at higher odds of having a positive outcome with RDT than non-anaemic children as shown in Table 5. The accuracy of malaria parasitaemia as assessed by the area under the ROC curve to predict malaria by RDT was 75.4% (95% CI, 70.6 80.1). The optimal cutoff for the diagnosis of malaria by RDT was 77 parasites/?L of blood."
544861,1.0,"Seventy-four facilities correctly filled out and returned their questionnaires given a response rate of 90.2%. More than half 50 (67.6%) of the functional facilities were in the urban area. As shown in table 1, among the doctors and nurses, a majority 22 (95.6%) and 10 (83.3%) respectively were in the urban area, while among the community health extension workers (CHEWs)/community health officers (CHO), a majority 20 (90.9%) were in the rural areas. Respondents were asked to state the various methods they used in diagnosing malaria. If they used more than one method, they were asked to say so. As shown in table 2, the most common method for diagnosing malaria in the study area by health workers was syndromic approach, followed by microscopy and then RDT examination. Doctors and laboratory technicians were significantly more likely to use RDTs than CHEWs/CHOs and nurses while the laboratory technicians and nurses were more likely to use microscopy than doctors and CHEWs/CHOs. Also, nurses, CHEW/CHO and doctors were significantly more likely to use syndromic approach than laboratory technicians. Within the groups, all the other health workers were significantly more likely to use syndromic approach except for the laboratory technicians who used microscopy more. As shown in table 3, majority of the respondents 45/74 (61.1%) knew about RDTs and most of them learnt it through their co-workers 18 (40%) and conferences 13 (28.9%). Awareness was higher among doctors 18/23 (78.3%) and laboratory technicians 14/17 (82.4%). There was statistically significant differences in awareness among the different cadres of health workers. Also, the proportion of workers aware was higher in the urban area (34/50, 68.0%) than in the rural area (11/24, 45.8%). Health workers in the public facilities were more aware than those in the private facilities and this was statistically significant."
544861,2.0,"As shown in table 3, majority of the respondents 45/74 (61.1%) knew about RDTs and most of them learnt it through their co-workers 18 (40%) and conferences 13 (28.9%). Awareness was higher among doctors 18/23 (78.3%) and laboratory technicians 14/17 (82.4%). There was statistically significant differences in awareness among the different cadres of health workers. Also, the proportion of workers aware was higher in the urban area (34/50, 68.0%) than in the rural area (11/24, 45.8%). Health workers in the public facilities were more aware than those in the private facilities and this was statistically significant. As shown in table 4, a total of 24 (32.4%) had RDT kits in their health facilities of work at the time of the survey. In the urban area, 13/50 (26.0%) of them and 11/24 (45.8%) of the rural facilities had RDTs, but there was no statistical significant difference (p > 0.05). Among the public health facilities, 14/36 (38.9%) of them and 10/38 (26.3%) of the private facilities had RDTs, but the difference was not significant (p > 0.05). Most of these RDTs were either bought from a pharmacy store 10 (41.7%) or were donated to them by nongovernmental organizations 10 (41.7%). Only 3 (12.5%) of the facilities got their RDTs from the government. However 26 (35.1%) of the respondents knew where to purchase or get RDTs."
544861,3.0,"Table 5 shows that of the 45 that were aware of RDTs, only 23 (51.1%) facilities had actually used it. Most of the users were in urban area 16/34 (47.1%) and were mostly from the public facilities 16/26 (61.5%). Doctors 11/18 (61.1%), laboratory technologists 7/14 (50.0%) and CHEWs/CHOs 5/10 (50.0%) were the main users with no nurse using them. Out of the 23 facilities that had used RDTs only 10 (43.5%) were still using it at the time of the survey. The non users were mainly from the private clinics 8/19 (42.1%) and the reasons given for non use included: unreliability of RDTs, supply issues, cost of the RDTs and preference for other methods of diagnosis. Table 6 shows that out of the 23 respondents that had used RDTs, most of them 17 (74%) said RDTs saved time and was better than other diagnostic methods 11 (47.8%), while 4 (17.4%) and 2 (8.7%) of them said RDTs were the same with other diagnostics and were worse than other diagnostic methods respectively. However, 6 (26.1%) were not sure. From the table, supply issues, charge to patients, and ignorance, were the most important limitations of the use of RDTs being 20 (86.9%), 15 (65.2%) and 6 (26.1%) respectively. More than 90% of the respondents rated RDTs to be either good, very good or excellent. A majority of them 16 (69.6%) were satisfied with the benefits of RDT while a few 3 (13%) and 4 (17.4%) were not and indifferent respectively. As shown in table 7, of the 23 respondents that had used RDT, 10/16 (62.5%) in public facilities and 6/7 (85.7%) in private facilities said they knew RDT could be affected by temperature. While 6/16 (37.5%) and 2/7 (28.6%) of public and private facilities respondents respectively preserved their RDTs in cold boxes, 4/16 (25.0%) and 2/7 (28.6%) of them in public and private facilities respectively had no special arrangement. There was no statistical significant differences between the private and public facilities in all the variables."
544861,4.0,"Table 8 shows that more of the public health facilities (32, 88.8%) and fewer (13, 34.2%) of the private health facilities reported using ACTs for the treatment of malaria. Private health facilities reported using SP, chloroquine and Artemisinin Monotherapy more than the public health facilities, being SP (12, 31.6%), chloroquine (10, 26.3%) and Artemisinin Monotherapy (3, 7.9%) for private health facilities and SP (2, 5.%6),and chloroquine (2, 5.6%) for public health facilities respectively.. ACTs were available in 32 (88.8%) and 17 (44.7%) of the public and private facilities respectively at the time of this survey (p < 0.05). Most of the public facilities 30 (83.3%) and 14 (36.8%) of the private facilities had Artemether-Lumefantrine (AL). However, Artesunate+Amodiaquine (AA) were found in 13 (36.1%) of the public and 5 (13.2%) of the private health facilities respectively, while Dihydroartemisinin-Piperaquine (DP) were found in 16 (44.4%) of the public and 8 (21.1%) of the private facilities respectively. "
361983,1.0,"A total of 78,454 patients with a clinical diagnosis of malaria were tested using RDTs over a period of approximately four years at four study health centres; 25,473 (32.5%) tested positive for P. falciparum malaria. Bufundi and Kilibwoni, both located at relatively high altitude, had lower RDT positivity rates compared to Kebisoni and Sengera (Table 1). Positivity rate increased with decreasing altitude. Sites located at high altitudes showed similar positivity rates among all age groups (Figure 1) except for increased rates in males aged 15 years and above at Bufundi, which probably reflects high levels of mobility in this group due to seasonal labour in neighbouring (and more endemic) districts. Some variations in morbidity levels between age groups were observed in Sengera and Kebisoni, areas located at lower altitudes. Sengera, which is a non-governmental health centre, showed an age pattern compatible with moderately high endemicity in which relatively few adults are affected compared with younger age groups. RDT positivity rates varied by season and year at each site, indicating temporal changes in accuracy of clinical diagnosis of malaria (Figure 2). The absolute number of suspected cases of malaria who tested positive varied between sites depending on altitude and type of health facility. As an example, Sengera, the non-governmental facility, charged fees for consultation and drugs whereas the other government facilities provided free treatment, resulting in relatively low observed attendance at the facility. RDT positivity rates increased as the number of RDT-positive cases increased, especially in sites located at lower altitudes. There was a strong correlation between monthly RDT positivity rates and number testing positive with RDTs in all sites, with correlation coefficients varying between 0.64 (Kebisoni) and 0.87 (Sengera). At Kebisoni, both clinical malaria cases and RDT-positive cases increased during the study period, but there was no similar trend in the RDT positivity rate (Figure 2)."
361983,2.0,"At the hypoendemic site (Kilibwoni), only 10/1,000 (1.0%) of cases examined microscopically were positive for P. falciparum by RDT, whereas at the mesoendemic site (Kebisoni), 609/1,237 (49.2%) were positive. The sensitivity, specificity, PPV and NPV of the RDTs at Kilibwoni were 90.0%, 99.9%, 90.0% and 99.9%, respectively, whereas the corresponding figures at Kebisoni were 91.0%, 65.0%, 71.6% and 88.1%, respectively. A significantly higher specificity was observed at Kilibwoni compared to that of the more endemic Kebisoni (p < 0.0001) (Figure 3). This resulted in a significantly higher NPV for RDTs in the former (p < 0.0001), but there was no significant difference between the two sites in terms of PPV (p = 0.198). At Kebisoni, 220/628 patients (35%) who tested negative by microscopy tested positive by RDT. At Kilibwoni, only one of the 990 patients who tested negative by microscopy tested positive by RDT. Fifty-five of the 609 patients (9%) confirmed to be positive with microscopy at Kebisoni were declared negative with RDTs. Most of these patients had low mean parasite densities (below 1,000/?l in 34/55). However, six of the 55 false negative patients at Kebisoni (11%) had parasite densities exceeding 8,000/?l. At Kilibwoni, one patient was false negative by RDT out of a total of 10 who were confirmed positive by microscopy. At Kebisoni, true parasite rates (as determined by microscopy) declined during the four months (December 2005   March 2006) of concurrent collection of blood samples for comparison of RDTs with microscopy. During this period, the specificity of RDTs increased steadily from 56% in December 2005 to 79% in March 2006 (Figure 4a). There was no substantial change in the sensitivity of RDTs. During the same period, the NPV of RDTs increased from 67% to 92% whereas there was little change in PPV (76% in December 2005 and 77% in March 2006). The true parasite rate varied between age groups. The peak parasite rate was observed in children 2 4 years of age and the rate decreased in the older age groups (Figure 4b). Specificity of RDTs increased as parasite rates decreased, but sensitivity was more or less uniform among the various age groups. Sensitivity of RDTs was significantly higher in patients with fever (body temperature of 37.5 C and above) on presentation compared to non-febrile patients (97% versus 89%, p = 0.006) but specificity was significantly lower in febrile patients (33% versus 69%, p < 0.0001). No significant differences were detected between the two groups in terms of PPV and NPV (p = 0.827 and p = 0.742, respectively). At Kebisoni, microscopically confirmed P. falciparum patients with high parasite densities were significantly more likely to be true positive with RDTs than patients with a low parasite density (Figure 5). The mean parasite densities of false negatives and true positives were 898/?l and 5,215/?l and this difference was statistically highly significant (p < 0.0001). A logistic regression model showed that age, presence of fever, area and month of presentation were significantly and independently associated with probability of a negative RDT test result being a true negative (Table 2). False positive error rates declined in older age groups. Patients with fever at the time of presentation were more likely to test false positive with RDTs compared to those without. The site at higher altitude and with low malaria transmission intensity was associated with higher specificity. Specificity increased towards the end of the transmission season. Previous intake of antimalarials, revisit in the previous two weeks, travel outside the district in the previous two weeks and sex were not significantly associated with the probability of a negative RDT test result being true negative."
451939,1.0,"One thousand seven hundred forty studies were identified from electronic databases. After screening the titles, abstracts, and keywords, 1595 studies were removed based on inclusion and exclusion criteria, 85 studies were removed due to the duplicates and 60 full-text potentially eligible articles were retrieved for the consideration. Finally, 15 studies were included in the analysis [27,28,29,30,31,32,33,34,35,36,37,38,39,40,41]. The flow diagram of our study selection is shown in Fig. 1. We included fifteen studies that compared the economic value of RDT with other malaria diagnostic methods. Fourteen studies were full health economic evaluations that made a comparison in terms of costs and effectiveness between RDT and its comparators. All of them were cost-effectiveness analyses, nine of which used decision tree models. Besides, one study, although did not say that it was a cost-effectiveness analysis, assessed both the costs and the specificity of RDT, thus we also considered it as full economic evaluations and included it [28] (Table 1). Most of the studies were conducted in Africa, except three: one in Afghanistan [29], and two in Brazil [36, 37]. The Africa-based studies were all performed in Sub-Saharan Africa (Ethiopia [32], Congo [35], Ghana [38, 40], Kenya [28], Nigeria [41], Senegal [34], Tanzania [33], Uganda [27, 30, 31]). One study targeted at all endemic countries in Sub-Saharan Africa using a simulated cohort with fever in the rural areas [39]. Eleven studies focused on suspected malaria and fever patients. Among the other four studies, two targeted at children [38, 40], one focused on the application of RDT in school students [28], and one assessed the effectiveness of RDT among healthy pregnant women [35]. According to the CHEERS checklist, huge gaps existed in the quality of evidence reported. Scores ranged from 7 to 23. Two studies provided a high quality of evidence with the highest score of 23 [29, 40], five had evidence of moderate quality [27, 30, 35, 36, 38], and eight had low quality with the lowest score of 7 [28, 31,32,33,34, 37, 39, 41]. The overall quality of all studies included could be seen in Fig. 2 and Additional file 1."
451939,2.0,"The economic value of RDT was assessed in the fifteen economic evaluations and summarized in Table 2. Three malaria diagnostic techniques were reported and compared in all papers: RDT, microscopy, and presumptive diagnosis, and the majority took microscopy and/or presumptive diagnosis method as the comparison for RDT."
451939,3.0,"Microscopy is a conventional diagnostic method to detect malaria infection. Six out of fifteen studies found that introducing RDT to substitute microscopy was likely to be cost-effective [27, 29, 35, 37, 39, 41]. Four of them made that conclusion as RDT could lead to either lower costs and improved outcomes, or a cost-saving when compared to microscopy [29, 35, 37, 41]. A cost-effectiveness analysis based on decision tree compared RDT and microscopy to presumptive diagnosis simultaneously [27]. It found that overall, RDT had lower positive ICER than microscopy and was most cost-effective in both high and low transmission settings. A decision-analytical study presented evidence of the cost-effectiveness of RDT compared to both microscopy and presumptive diagnosis [39]. With a threshold of USD 150 for the incremental cost per addition averted disability-adjusted life years (DALYs), RDT was highly likely to be cost-effective. The cost-effectiveness of RDT in comparison to the presumptive diagnostic method was reported in ten studies, and all of them used presumptive diagnosis as a base case with RDT as the intervention to compare [27, 29,30,31,32, 34, 38,39,40,41]. Eight studies provided supportive evidence that RDT was highly likely to be cost-effective: three studies observed that the use of RDT could be less costly while more effective [27, 32, 41], three studies found that RDT could result in an increase in both costs and effectiveness but it had the potential to be cost-effective at a low willingness to pay (WTP) threshold [29, 30, 40], another study observed a low ICER of RDT but admitted that whether RDT could be cost-effective would depend on how much decision-makers would be willing to pay [31], and a decision-based analysis showed that RDT was 85% certain to be cost-effective at all prevalence level below 65% [39]."
451939,4.0,"Fourteen of all fifteen studies received funding from various sources (Additional file 4). It was not clear based on current evidence whether founding sources would have an impact on whether RDT was cost-effective. Seven studies were government-sponsored, either intergovernmental organization or local government [28, 32, 34, 35, 37, 39, 41], and five of them supported the cost-effectiveness of RDT [32, 35, 37, 39, 41]. Of eight studies that did not receive funding from the government [27, 29,30,31, 33, 36, 38, 40], seven were sponsored by either non-governmental organizations or research institutions including universities and five studies reported that RDT was cost-effective [27, 29,30,31, 40]. There was only one study that had no statement of the source of funding, and its result did not support RDT s cost-effectiveness because it found that if the accuracy of microscopy could be guaranteed, there would be no additional benefits of applying RDT [36]. As most of the studies included received funding from nonprofit organizations and there was only one research that did not report its funding source, the impact of funding sources was less clear."
451939,5.0,"Studies took a wide range of study perspectives which determined the scope of costs and effects within the evaluations: five studies were conducted from the societal perspective, four adopted a perspective of the health sector, one study did not report its perspective and the rest were undertaken under narrower perspectives such as provider or patient. There was a high level of heterogeneity among the selection of outcome measures among studies with narrow perspectives while the five studies under a societal perspective adopted either the number or the proportion of appropriately treated patients as the outcome, which can be considered as the same measure of effectiveness. We thus would take  the number of appropriately treated per 1000 suspected cases  as the main outcome and recalculate the results based on the available data. The comparison of the economic value of RDT between five studies taking a societal perspective was plotted in Fig. 3. Compared with other diagnostic techniques, the incremental effects of RDT were always positive, i.e., using RDT could contribute to an increase in the number of appropriately treated patients, but its impact on additional societal costs was not clear and could largely depend on the comparator selected. The introduction of RDT to replace presumptive diagnosis resulted in an increase in costs [27, 29,30,31, 40], but that increase was relatively small in most of the studies. There were two studies that provided evidence for the comparison between RDT and microscopy from a societal perspective, they observed a cost-saving effect when RDT was introduced [27, 29]. Overall, given a small number of studies, it could be found that RDT had the potential to be cost-effective particularly compared to microscopy under a societal perspective and whether RDT could be a dominant strategy would largely depend on the threshold of policymakers. Changes to the malaria prevalence tended to have an impact on the costs and effects of diagnostic methods. Thirteen studies recognized its potential influence on the cost-effectiveness of RDT compared to other methods but only eight of them formally investigated the uncertainty brought by malaria prevalence [27, 30, 31, 33, 37, 39,40,41]. The introduction of RDT to replace microscopy was found to be a dominant strategy regardless of the prevalence levels [27, 37, 39, 41], but the ICER could be lower with an increase in prevalence [33]. The cost-effectiveness of RDT against presumptive diagnosis was consistent: all the four studies that tested the robustness of the results found that RDT could be more cost-effective in the area with lower prevalence [30, 31, 39, 40]. Among all included studies, eleven had no restriction on participants  age and four limits the population to students or children of different ages. Evidence showed that whether RDT could be cost-effective compared to other diagnostic methods was not likely to be influenced by the age of the target population. Of the four papers with a limitation on the age, half applied RDT on children under 5 years old and supported the cost-effectiveness of this diagnostic method [31, 40], while the other half focused on children as well and did not reach that conclusion, but both of them recognized the cost-saving effect of RDT compared to microscopy [28, 38]. Of eleven studies without a limitation on age, eight showed that RDT could be more cost-effective compared with other methods [27, 29, 30, 32, 35, 37, 39, 41]. The majority of economic evaluations included considered RDT as a cost-effective strategy regardless of whether the study limited the subjects  age. Further details can be seen in Additional files 2 and 3."
451939,6.0,"There are various types of RDT: some of them can detect single Plasmodium species, some can detect multiple species and some can distinguish between different species [42]. The difference in the types may bring extra costs to the economic value of RDT as they may have different prices. To compare the impact of RDT types, we categorized RDT into two categories: one is a single test which only detects single species, another is a combo test which can detect multiple Plasmodium species. The types of RDT used in included studies varied greatly. Ten studies adopted single test [27, 28, 30,31,32,33,34,35, 39, 40], while combo tests were used in seven studies [28, 29, 32, 36,37,38, 41]. Evidence suggested that single RDT could be cost-effective compared to microscopy and presumptive diagnosis. Plasmodium falciparum-specific RDTs were adopted in eight studies: four of them were decision analytical economic evaluations and suggested that the introduction of single RDT tests can largely improve the proportion of appropriate treatment for patients [27, 30, 31, 40]. In the other four studies, two of them found that RDT was likely to be more cost-effective than microscopy [35, 39], and the remaining two studies adopted single and multiple tests at the same time. In the first study conducted in Ethiopia where P. falciparum and P. vivax co-exist, both single and multiple tests were used to appraise the cost-effectiveness of RDT compared to presumptive treatment [32]. In the area with various malaria species, multiple tests were more cost-effective than either a single test or presumptive diagnosis. In a second study, a cost analysis was performed to appraise the performance of four RDT brands, including single and multiple tests, but it did not assess the effectiveness of multiple tests and only reported costs of general RDTs rather than costs by each RDT type [28]. However, the cost-effectiveness of combo tests was not clear. Four of seven studies showed positive results regarding the cost-effectiveness of combo RDT. Three studies that appraised the costs and effectiveness of RDT based on decision models observed lower costs and more clinical benefits with the use of multiple tests than microscopy [29, 37, 41]. Lemma et al. found that multiple tests performed better and cost lower than both single tests and presumptive diagnoses in the context where P. falciparum and P. vivax co-dominate [32]. However, the cost-effectiveness of multiple tests applied in the remote area of Amazon where P. falciparum and P. vivax dominate as well were uncertain as it largely depended on the accessibility to and the accuracy of microscopy [36]. Evidence identified in this review observed that RDT could also lead to the problem of over-diagnosis [28, 38]. Although RDT was the cheapest approach to detect infection in malaria school surveys compared to other strategies (i.e., microscopy or RDT corrected by alternative methods), it over-estimated the prevalence of infection [28]. Also, the study only evaluated the costs of diagnosis and thus the cost-saving effect of RDT could be maintained remainsed unclear when treatment costs were taken into account. The treatment costs were found to be higher for RDT than for microscopy when P. falciparum and pan-specific RDT was used to the management of malaria cases in Ghana [38]. The study also observed the over-diagnosis and additional costs when RDT was introduced to replace presumptive diagnosis. This may reduce RDT s advantage in terms of cost-effectiveness. In general, the impact of the types of RDT on its cost-effectiveness remained uncertain given various types of RDT, the complexity of local epidemiological characteristics and the lack of evidence reported in studies included. Further details of the types and brands of RDT can be seen in Table 1."
359124,1.0,"Sustained malaria control will depend on the global capacity to accurately detect malaria and map its distribution. The specific detection of malaria parasites is now possible even at the village level with high quality rapid diagnostic tests. Driven by the extent of over-diagnosis and misdiagnosis of malaria when syndromic approaches are used, global efforts are underway to increase the utilization of parasite-based diagnosis, and to ensure the quality of tests that are used. Elimination efforts will not only increase the need for widespread RDT use, but may drive the development of new tests with enhanced performance. Implementation of the Global Malaria Action Plan [47], proposed regional initiatives towards elimination of malaria, and the reductions in mortality from malarial and non-malarial illness necessary to achieve Millennium Development Goals will require an increased emphasis on building systems for parasite detection as an integral part of malaria case and programme management."
1012871,1.0,"During this period around 2000 under 5 year patients presented with fever at out-patient pediatric department LUH Hyderabad and it was considered low risk area for malaria..From2000 cases only 20% (400) were diagnosed as suspected clinical Malaria according to IMNCI algorithm. Distribution of sex and different age groups were shown in Table-I and Districts of positive cases and plasmodium species is shown in Table-II. From 400 cases only 40 cases (10%) have shown positive results for malaria parasite on slide microscopy and RDT. Regarding the plasmodium species 70% (28) were vivax and 30% (12) were falciparum. Except only two cases all the cases positive on slide microscopy has also shown positive results on RDT. Regarding the effectiveness, RDT has shown 95% sensitivity for the detection of plasmodium antigens in the febrile clinically suspected cases of malaria. Effectiveness of RDT with sensitivity and specificity is shown in Table-III."
2593776,1.0,"In this part of the study, 1807 subjects were tested by all 7 RDTs in field. Of which 46.1% were positive, 25.7% P. falciparum, 16.6% P. vivax, 1.0% P. malariae, 1.9% mixed infection of P. falciparum and P. vivax and 0.9% mixed infection of P. malariae with P. falciparum and/or P. vivax. FIRST RESPONSE  detected 468 out of 480 microscopically confirmed asexual sexual falciparum malaria infection (Table 1). However, other RDTs i.e. FalciVax detected 429, parascreen  425, SD BIOLINE & NecVIPARUM 416, ParaHIT  Total 373 and GENOMIX detected only 360 falciparum infections (Table 1). Among microscopically confirmed 329 P. vivax subjects, FIRST RESPONSE  detected 262, parascreen  162, SD BIOLINE 163, FalciVax 149, NecVIPARUM 141, ParaHIT  Total 112, while only 65 cases were detected by GENOMIX (Table 2). Number of invalid test (absence of control band) was recorded in 1, 7, 2, 8, 9, 15 and 4 tests respectively for FIRST RESPONSE , parascreen , ParaHIT  Total, FalciVax, SD BIOLINE, GENOMIX and NecVIPARUM. The analysis of results revealed that the sensitivity of the FIRST RESPONSE  for P. falciparum was 98% (Table 1), of parascreen  and FalciVax 89%, SD BIOLINE & NecVIPARUM 87% and ParaHIT  Total 78%, whereas the sensitivity of GENOMIX was only 76%. The specificity for P. falciparum was 92% by GENOMIX, 91% by ParaHIT  Total, 90% by FIRST RESPONSE  and NecVIPARUM, 86% by parascreen , 85% by SD BIOLINE and 84% by FalciVax. For P. vivax, the sensitivity of different tests when compared with microscopy were 80% by FIRST RESPONSE , 50% by parascreen  and SD BIOLINE, 46% by FalciVax, 43% by NecVIPARUM and 34% by ParaHIT  Total, while only 20% by GENOMIX (Table 2). Specificity of all these tests ranged between 97 99%. Analysis of sensitivity on different level of parasitaemia revealed that FIRST RESPONSE  was able to detect 100% malaria infection at >100 parasites/ l of blood for both P. falciparum and P. vivax. While parascreen , FalciVax, SD BIOLINE and NecVIPARUM were able to detect >90% P. falciparum infections when parasite densities were >500 parasites/ l. However, ParaHIT  Total and GENOMIX detects 90% P. falciparum infections when parasitaemia was >1000 parasites/ l. Regarding P. vivax infections except FIRST RESPONSE , other RDTs detect only 31 63% when parasite density is >500 parasites/ l (Figure 2)."
2593776,2.0,"RDTs kept at 35 C and 45 C for 15, 30, 60, 90 and 100 days and at 60 C for 48 hours for heat stability test in the field. Seventy five clinically suspected malaria cases were tested on 15, 30, 60 and 90 days, and 50 clinically suspected cases were tested on 100 days and at 60 C for 48 hours intervals. Results of heat stability testing was shown in Table 3 & 4. Experiments showed that sensitivity of most of the RDTs for P. falciparum was very good (>90) both at 35  and 45 C up to day 90 when compared with RDTs kept at room temperature. However, a sharp decline in sensitivity was recorded on day 100 at 35 C and 45 C by most of the RDTs. On the contrary all RDTs kept at 60 C for 48 hours showed no decline in the diagnostic performance. For P. vivax, the sensitivity of FIRST RESPONSE  was very good up to 90 days (100%) and a decline was noticed on day 100 (92%). Parascreen also performed well upto day 90 at 35 C (88%). However, a sharp decline in sensitivity was observed on day 90 at 45 C (75%). While other RDTs showed a steady decline in sensitivity from day 60 onwards (Table 4). The overall agreement and Kappa values between pairs of observers were very good for both at 35 and 45 C for P. falciparum. However, Kappa values was not good for some RDTs for P. vivax especially on days 90 and 100 (Figure 3)."
362249,1.0,"Figure 1 shows that the total costs of antimalarials and RDTs for treating all malaria patients in 2002 in the two study districts. Using clinical diagnosis, this would be $42,484 when treating them with AS+SP and $63,048 for AL. The introduction of definitive diagnosis (using RDTs) could either result in cost savings or additional costs, depending on the proportion of febrile patients confirmed to have malaria. For the scenario where 25% of febrile cases are RDT positive, use of definitive diagnosis before treating patients would result in a cost saving of up to $1,485 and $16,908, when malaria patients are treated with AS+SP and AL, respectively, provided that health workers do not give antimalarials to patients with a negative RDT. Thus the more expensive the antimalarial being used, the greater the need for restricting antimalarials to confirmed malaria cases and the higher the cost savings that will be realised through effective implementation of definitive diagnosis."
362249,2.0,"Figure 2 shows the incremental costs (or cost savings) for antimalarials and diagnosis under the different scenarios. For the relatively cheaper ACT (AS+SP), only when 29% or less of all suspected malaria cases test positive for malaria will the use of RDTs in all clinically diagnosed malaria cases result in cost savings, when compared to all patients being treated with AS+SP on the basis of clinical diagnosis. This percentage increases from 29% to 41.5% when use of RDTs is restricted to only those older than six years of age, and malaria positive patients are treated with AS+SP. For a relatively more expensive ACT (e.g. artemether-lumefantrine in 2004), as long as fewer than 52% of tested cases are found to be positive, the use of RDTs in all suspected malaria cases will result in lower treatment costs (cost savings) compared to when patients are treated on the basis of clinical diagnosis; this cut-off shifts from 52% to 74% if use of RDTs is limited to patients who are over six years of age. This strategy results in lower additional costs or higher cost savings compared to when RDTs are used in all suspected malaria cases, for both AS+SP and artemether-lumefantrine. However, in terms of cost, there are greater gains in restricting use of RDTs in patients over six years of age, when treating with a less expensive ACT (e.g. AS+SP). This is expected since the price of one RDT ($0.95) is nearly twice as high as the cost of one dose of AS+SP for a patient younger than or equal to six years ($0.49), but similar to the cost of an AL treatment course for this age group ($0.90). Hence, treating all patients younger than or equal to six years with AS+SP on a clinical basis makes more economic sense than using an expensive RDT to test this age group."
362249,3.0,"Figure 3 presents results on the incremental costs per malaria positive patient treated. Incremental costs have been calculated using total cost of RDTs and antimalarials divided by the number of malaria cases for the different scenarios. Findings reported are based on the assumption that health workers adhere to test results and do not give antimalarials to patients with a negative RDT. Results in Figure 3 again show a cost saving (of $0.19 per patient treated) if malaria is present in under 29% of patients and that even when 75% of cases are malaria positive, the incremental cost per malaria positive patient treated is less than US$ 1, when AS+SP is used for treating malaria patients. When patients are treated using artemether-lumefantrine, there are cost savings per malaria positive patient treated of up to $2.12 (in the 25% scenario) as long as 52%, or less, of the suspected cases are RDT test positive. Beyond the 52% cut-off point, additional costs are incurred with an incremental cost per malaria positive patient treated of up to $0.85 (when 95% of tested cases are found positive and treated with artemether-lumefantrine). According to the guideline provided by the Ad Hoc Committee on Health Research relating to Future Interventions Options, an intervention is considered to be highly attractive (hence 'cost-effective') in low income countries if it costs less than $25 per disability-adjusted life year (DALY) averted and any intervention that costs less than $150 per DALY averted should be considered attractive [26]. Although the health outcome used in this analysis is number of patients treated and not DALYs, this guideline could be helpful in considering whether an incremental cost per malaria positive person treated of less than $1 should be regarded as being highly cost-effective."
362249,4.0,"Findings from the one-way sensitivity analysis on variation in the age distribution show that the higher the percentage of adults among the suspected malaria cases (age breakdown 3), the lower the additional costs and the higher the costs savings (particularly with a relatively more expensive ACT like AL) associated with use of RDTs (Figure 4, quadrant 4), and vice versa. This finding is not surprising since the price of the ACTs for children is significantly lower than the price of the adult dose, and yet the price of the RDT remains constant for all age groups. Results in Figure 5 show how changes in the age distribution of patients with clinically suspected malaria have an impact on the decision on restricting their use to only those who are over six years of age. The higher the proportion of young children among those with suspected malaria, the more it makes economic sense to restrict the use of RDTs to those over the age of six years. The more expensive the unit price of the antimalarial for the one to six years age group, relative to the unit price of RDTs, the lower the cost savings associated with restricting RDTs to patients over six years of age (Figure 5).  Results of the one-way sensitivity analysis on the RDT price variable show that as expected, the lower the unit price of a rapid diagnostic test the more cost-effective it is to use definitive diagnosis (using RDTs) as the basis for ACT treatment, regardless of the price of the antimalarial being used. With a reduction in the unit price of RDTs from $0.95 to $0.50, limiting the use of RDTs in patients older than six years would result in significantly less economic gains (when patients are treated with AS+SP) and some economic losses in areas of low to moderate intensity malaria transmission (where 50% or less of fever cases are malaria positive). The same applies when patients are treated with AL (quadrant 6, Figure 6). In other words, the cheaper the RDT the less the need is to restrict to older age groups. Similarly, results of the one-way sensitivity analysis on the ACT price variable show, as expected, that the use of RDTs will become less cost-effective as the antimalarials become less expensive. This explains why, at least from an economic perspective, RDTs have not been widely used when cheaper antimalarials, such as chloroquine or sulfadoxine-pyrimethamine monotherapy, were being used in areas of moderate to high intensity malaria transmission. This may also be the in-country scenario with the implementation of a global subsidy to reduce the price of ACTs to that of chloroquine [27]. Results of the multi-way sensitivity analyses (Table 4) are presented in Figure 7. In these analyses the prices of antimalarials, prices of RDTs and age distribution were varied to assess the effect of simultaneous changes in these variables on the earlier findings on cost-effectiveness of RDTs. Figure 7 shows that, as expected, multi-way 1 (high prices of ACTs and RDTs and children younger than or equal to six years of age taking up the highest proportion) is the context in which routine use of RDTs is least cost saving (for both AS+SP and artemether-lumefantrine) (quadrant 1, Figure 7). Results of multi-way 2 sensitivity analysis show the impact of changing age distribution alone (without changing the prices of ACTs and RDTs). There is a decline in incremental cost per patient treated, from $0.82 to $0.71 and from $0.61 to $0.49 for AS+SP and artemether-lumefantrine respectively, purely as a result of increasing the proportion of adults in the population with clinically diagnosed malaria. Results of multi-way 3 sensitivity analysis (quadrant 3, Figure 7) show the impact of changing the price of RDTs and age distribution (without changing prices of ACTs). Changes in costs are mainly due to the variations in RDT prices and the proportions of adults treated. As expected, the bigger the proportion of the suspected cases that are adults, the greater the cost savings. Variation in the prices of RDTs and antimalarials shifts the cut-off points at which definitive diagnosis results in cost savings."
361337,1.0,"Out of a sample size of 2124, a total of 2123 mothers with children under five from nine districts participated in the study. Of the 2123 mothers, 70 % were in the age range of 20 and 34 years. A majority of mothers (84 %) were in marital relations. Slightly more than one third (34.7 %) of the participants had more than three children. The study population was relatively literate with only 19.4 % of respondents who had never attended school, whilst about 69.4 % had attained primary school and 11 % had secondary education. A majority (70.4 %) of respondents were farmers. About 56.2 % of respondents were Christians and 40.9 % were Muslims (Table 2). Qualitative participants composed of 21 health care professionals (18 health care providers and four paediatricians), six teachers, four religious leaders and six community health workers. Twelve more IDIs were conducted with scientists from various institutions in Dar es Salaam (Table 3). FGDs were carried on with six groups of women and six groups of men. Most of the FGD and IDI participants were of age 25 and 50. Non-professional participants were mostly farmers and petty trade dealers. Most of them had attained primary school level. The majority of the professionals, such as nurses and teachers, were of secondary school and high school levels."
361337,2.0,"Qualitative participants (mostly women) possessed a positive opinion towards vaccines. They were in the opinion that the vaccines are important for the reduction of disease severity, reduced cost of treatment and disease prevention. One female participant expressed her opinion that vaccine would reduce the severity of disease:  I know that when a child gets vaccinated he will be protected from diseases. Even if the disease comes, it will not be very much severe as compared to if the child has not completely received a vaccine  (FGD, Female_04). Another female participant was in the opinion that vaccine is important for prevention of diseases:  Just like what the experts says  it is better to prevent than to cure  then I think vaccination is important as it helps to prevent a child from diseases and reduces treatment costs because during treatment you use much cost to treat the child unlike when the child is protected (with the vaccine)  (FGD, Female_05). Similarly in the quantitative study, the majority (90.1 %) of mothers reported that there is a benefit associated with vaccination (Fig. 1). Also, about 97.6 % agreed with the statement that  I prefer my child to receive all the vaccines  (Table 4)."
361337,3.0,"Most of the opinions of the qualitative participants reflected a positive acceptance towards the anticipated malaria vaccine. The main consensus was that malaria vaccine is important since malaria is still a common disease among children under five. One of the paediatricians provided his view that malaria vaccine need to be provided since more strategies are needed to fight malaria:  I think malaria problem is still there and more weapons are needed in making sure that it is prevented, vaccine is one of the weapon, but if it s safe for the users  (IDI, Paediatrician _05). Another participant was in the opinion that malaria still affects children and hence a need to introduce malaria vaccine:  Malaria vaccine should be introduced due to the burden of malaria especially for young children  (IDI, Nurse, RCH_06). A male participant thought that malaria vaccine is needed because the mosquito nets cannot provide full protection from mosquitoes:  I think we need malaria vaccine since we are not always covered by the mosquito nets. Look at where we are now, we have stayed for almost one hour and the mosquito nets are inside our houses on the beds. Probably the mosquitoes might have already bitten the child. Therefore, we cannot totally depend on the mosquito nets   (FGD, Male_ 05). The quantitative results revealed that the majority (84.2 %) of the participants indicated a perfect acceptance of malaria vaccine, 11.9 % had partial acceptance while 3.9 % had no acceptance of the vaccine (Table 5). Occupation, tribe, religion, and regions attained a statistical significance with the perfect acceptance of the malaria vaccine (p < 0.001), with farmers, Christians, members of the tribe Hangaza and households in the Kagera region presenting higher acceptance levels."
361337,4.0,"The common expectations from the malaria vaccine by most participants comprised a view that malaria vaccine will lessen the malaria episodes, frequent visits to the hospital due to malaria, the number of deaths and that the overall burden of malaria among children will be reduced.  My expectations is that if malaria vaccine will work, it will help reduce the hassle we get of having frequent malaria, you will find a child going back to hospital even four times in a month  (FGD, Male _03).  The expectations of most people will be that the malaria vaccine will completely eradicate malaria, because the children will have protection and so malaria will finish   (FGD, Female_05).  The health care providers will feel very proud to have this additional vaccine on top of the existing ones since we hope it will succeed in reducing the mortality rate especially for children under 5 years  (Nurse, RCH_05).  Most mothers will definitely take their kids for vaccination since the costs of treatment nowadays is very high  (Teacher_02)."
360871,1.0,"The meeting feedback received from participants and observers[54], and MPAC members themselves, was very positive. Having met three times to date, the format of MPAC meetings and its feedback loops with other advisory bodies and stakeholders is beginning to settle, although it remains an evolving process. WHO-GMP and the MPAC continue to strongly welcome feedback, support and suggestions for improvement to MPAC meetings from the global malaria community."
360871,2.0,"The next meeting of the MPAC will take place from 11 to 13 September 2013 in Geneva, Switzerland. Further information, including the agenda and details on how to register, will be made available in July 2013 on the MPAC page of the WHO-GMP website, although questions are welcome at any time[5]."
995302,1.0,"A country's decision to adopt a new health technology requires more than the existence of a good product. In low and middle income settings, a wide range of organizations can support country decision making. The role of PDPs in this process is based on the PDPs' vision to see public health impact from the products they develop, and on their intimate familiarity with the products under discussion."
995302,2.0,"A PDP as a whole can cover a wide spectrum of activities ranging from basic research to implementation of interventions. At the implementation end of this spectrum, there is no single definition of where the PDP role ends, as the technical needs and available partners in endemic countries vary for each intervention. However, as more PDP-related products progress, additional experience will assist in defining the areas in which PDPs are effective and should be held accountable. Funder, partner and country participation in the development of improved means to evaluate the relative roles and impact of PDPs will also be important. Building on the insights described here, PDPs, partners and country stakeholders can continue to provide critical support for decisions on interventions that will ultimately decrease the global burden of disease."
363993,1.0,"WHO has played a major convening role in the past three decades in establishing a normative framework for critical aspects of vaccine development as antigenically-defined subunit vaccines, novel platforms and new adjuvants were introduced for human use, often for the first time in association with malaria vaccine studies. The importance of early and close involvement of scientists, developers, regulators, and public health physicians has enabled continuing close cooperation in later stages as developers evaluate vaccines in ways which will enable technical advisory bodies of WHO to have access to the data that will enable them to provide guidance for country programmes."
363993,2.0,"This review has focussed on the contributions to clinical trial design. In many cases, the discipline has moved from theory to practice, with large numbers of trials of pre-erythrocytic and asexual stage antigens with different adjuvants now completed and published, so that new protocols can benefit from practical experience added to theoretical considerations. The context has also changed with many trial sites having experienced gratifying reduction in morbidity and mortality, one consequence being the requirements for larger multi-centre studies and complications of interpretation from sites with different intensities of transmission. The reduced transmission has also caused many to focus mainly on the possible contribution of vaccines directed against any stages to reduction of transmission and possible elimination of malaria. Non-falciparum species have taken a backseat role at this stage and ongoing debate continues about the best way of reporting efficacy data. As much is now known and published on pre-erythrocytic and asexual stage vaccine trials, at least to proof of concept stage (probably better described as experimental medicine rather than product development), the review has given greater attention to what lies ahead. The focus is on design of trials for which there is little or no experience, namely trials of vaccines for P. vivax, and trials for assessment of reduction of transmission, and for which preferred product characteristics are still the subject of debate (for example with respect to efficacy against hypnozoites or go/no go criteria for transmission blocking studies)."
363993,3.0,"The review has highlighted the past and ongoing contribution made by WHO in convening groups to address key issues for investigators, vaccine developers, regulatory authorities and funders in ensuring the most efficient use of resources for developing much-needed vaccines for use in malaria endemic countries."
360654,1.0,A total of 466 household heads were involved in the survey after approaching 480 households. A majority (over 74.7%) of respondents were in the age range of 29 and 39 years (Table 2). A majority of the respondents were married; most respondents were farmers (Table 2). Respondents in the FGDs had similar demographic characteristics as those involved in the survey. Those selected for the IDIs were health professionals who had attained at least senior secondary school education or non-professionals with either no formal education or with education up to junior high school level.
360654,2.0,"Knowledge of vaccines was widespread among participants in the study. Knowledge however, seemed to be skewed towards vaccines given in the form of injections; there was some knowledge of the existence of the oral polio vaccine (OPV), which they admitted is not an injection. Finding a common local name for vaccines that is acceptable and understandable by all respondents was not difficult. Local words like  ntetee   paniebo  exist as terminologies for vaccination. Most respondents knew what vaccines are, as evidenced in the following contributions made by some respondents in both IDIs and FGDs:   Vaccines are injections given to children in their childhood so that any disease that has the possibility of attacking children become less severe if even they are attacked.  (FGD, female E)   I know that vaccines are injections given to prevent the occurrence of a disease.  (FGD, male E)  Participants differentiated vaccines from medicines given as injections in hospitals emphasizing the preventive aspect of vaccines. These observations were made:   For vaccines, they are taken to prevent the occurrence of the disease. While those injections that are taken at hospitals, the sickness occurs before one goes for the injections.  (FGD, male C)"
360654,3.0,"Over 50% of respondents spontaneously mentioned tuberculosis and poliomyelitis vaccines as childhood vaccines (Table 3). There were varied views regarding malaria prevention with vaccines. While some respondents were quite certain that malaria could be prevented through vaccination, others were rather sceptical. This is evidenced in contributions made by respondents in the IDIs and FGDs:   In science, there is a saying that you cannot say never. It can happen but I think it will be very difficult. The malaria parasite strains change so rapidly, I think that vaccination could be done but would work in the short term like every three months just like tabs for typhoid fever and the rest. Sometimes you can give it to the person but then it does not last. Its longevity is not there so they would have to come and take it again. Because the malaria strains are so varying and a whole lot of them it have lots of properties and biochemical characteristics, so to get a long-lasting vaccine, it is something we can do but we have to work harder.  (IDI, health care provider B)  A participant, expressing an opinion about a vaccine s ability to prevent malaria made the following remarks in an IDI:   Well, it looks strange but we are just hoping especially once they say the vaccine is just going through phase II and it is going to phase III. This is because malaria is endemic and any success in that direction is something that everybody is yearning for. At the OPD, the daily OPD register shows that malaria is leading, so many cases of malaria at least 50% or more. The success of this vaccine will even curtail our burden at the OPD . (IDI, health care provider A)  When the respondent was asked the reason for describing vaccination to prevent malaria as  strange , the following was the response:   The causative organism is always with us. The mosquito is always with us. Every time we get bitten by a mosquito. I do not know how long, whether the vaccine can stay in the body and produce antibodies that will not let you get malaria once you are vaccinated, just like polio which when your body is exposed to the vaccine you will not get it for your lifetime. This one looks strange because of the causative organism, but it looks impossible, but let s wait.  (IDI, health care provider A)  A chemical seller made the following remarks when asked if he believed malaria can be prevented through vaccination. He was a sceptical but made mention of a more multiple approach towards this course to fight malaria:   Well, it is possible. Chloroquine was a drug which was used to treat malaria when crystalline [ penicillin] was added but it is now phased out. It [malaria] disturbs people but they cannot complain. We do not know what the Pharmacy Council and the Food and Drugs Board saw about chloroquine and recommend that it should not be used.  (IDI, chemical seller A)   I cannot argue about that. As am saying when the polio vaccine was introduced, the incidence of polio has stopped among children after vaccination. Also with the measles vaccine, a mother who refuses to vaccinate her child is always in trouble whenever the child suffers an attack. So getting a vaccine for malaria is possible. Mosquito nets have been introduced but the incidence of malaria is still high.  (IDI, chemical seller A)  The survey showed that a large proportion of respondents think malaria can be prevented through vaccination. Over 90% of the respondents were in this category (Figure 1). Reasons were assigned for thinking that malaria can be prevented through vaccination; the statement below briefly summarizes the thoughts of participants during a discussion session:  An instance is the incident of polio which has been reduced through vaccination. I have the belief that malaria can be eradicated or reduced through vaccination. This can be seen through the research being carried out.  (IDI, head of a religious group)"
360654,4.0,"Respondents  attitudes about vaccines preventing malaria were quite positive. There was a general quest for vaccines for all types of diseases, especially malaria. Respondents in both FGDs and IDIs mentioned the types of diseases they want their children vaccinated against:   Malaria is a sickness that disturbs us a lot. So if children are protected against malaria it will help us. Because there are lots of mosquitoes that bite and cause malaria so that if we prevent the occurrence of malaria it cannot be severe even if there are mosquito bites.  (FGD, female A)   Polio, polio disturbs children a lot, it makes them very weak.  (FGD, female B)   With diarrhoea, children vomit and pass out watery stools so if we prevent it, it will be good.  (FGD, female B)"
360654,5.0,"As part of learning their attitudes towards vaccines for malaria, respondents were asked whether they preferred vaccines or drugs or both for malaria; 65.9% of respondents preferred vaccines to drugs for malaria control while 26.2% preferred drugs to vaccines. Few respondents had no preference for vaccines or drugs (Figure 2). Responses from both male and female participants on whether they will allow their children to be vaccinated against malaria, assuming a malaria vaccine is found, were very insightful:   I will agree: I have no drugs to cure my children. So if the government says a disease is about to break out so I should vaccinate my child, what can I say?  (FGD, female E)   Malaria is the number one killer diseases among children so if it is going to be prevented, then I think everyone would be happy to include his/her child.  (FGD, male A)  Diseases that respondents wanted their children vaccinated against were confirmed in the survey (Table 4). These were affirmed by some of the responses in the FGDs, thus emphasizing how generalized some of the contributions made by participants in the FGDs could be when it came to the diseases participants will or will not want their children to be vaccinated against (Table 4). Among health care providers and community religious leaders it was evident that vaccinating children against malaria will be a major breakthrough in science and accepting it will not be very challenging at the community level:  I will readily recommend that because malaria in children under five is fatal. Cerebral malaria for instance causes lots of problems. In children under-five, because of their immune system, when they get malaria it is fatal because of its added complications. Should we make a head way with this vaccine trial, I think all children, most especially, children under five should be vaccinated.  (IDI, health care provider)  Readily yes or even should I say a big yes. You see, these children are exposed to lots of filth and as you can see lots of weeds around that serve as breading grounds for mosquitoes. So getting a vaccine to prevent the effects of these mosquito bites will be a good thing. I will recommend it.  (IDI, head of a religious group)"
360654,6.0,"The success of disease control programmes to a large extent depends on the beliefs and cultural practices of the people who are directly involved in the programme and this shapes their behaviour and consequently their decision-making processes. Though beliefs and cultural practices that will prevent parents from vaccinating their children were not mentioned, some IDI sessions revealed some interesting points are quoted below:  ..somewhere in the north, when a child is born it is not brought out until after one month or so. So if we are looking at a vaccine targeting children of four weeks or less, that can possibly be a barrier to such children getting access to the vaccine. Another one is the social barrier where women cannot take decision about their children.  (IDI, health care provider)  As a Catechist who is in charge of organizing the congregation here, I always advise women who take their children to  weighing  [ child welfare clinics].  In the olden days herbs were used to treat diseases but now it is a thing of the past. We also advise against the belief that sickness is caused by gods. For now, it is only medication that is given which in the name of Jesus we also pray to support I don t know of any such beliefs. In the beginning of the trial [ RTSS malaria vaccine trial], some people from the north living here did not understand that there is the need send the child for immunization and weighing.  (IDI, religious leader)  There is nothing like that [ cultural beliefs] if you should follow these things all your children will die.  (FGD, male C) Some religious dimension was given by a participant when asked if he will recommend vaccination for malaria:  I know that God has poured his grace on a group of people who are working through the Holy Spirit. They are doctors. As the Bishop or any church member goes to the hospital when sick, if a vaccine for malaria is found I will not prevent people or any of my church members from sending their children for vaccination.  (IDI, head of a religious group) Among the Muslim participants, the situation about recommending vaccines for malaria was not very different. A participant had this to say:  Even the prophet Mohammed ( peace be on him ) implored his followers to do two important things: learning very well so that you can worship your God; learning about protecting yourself from falling sick. It will have been welcome news to be able to protect ourselves against diseases. Even God approves of that. People should actually treat themselves when they are sick. It is also mentioned in the Quoran that people should protect themselves from falling sick. It is good to  defend  yourself from sickness. This is better than allowing the disease to attack you before you treat it. Yes, the Quoran does not forbid vaccination. Quoran is totally in support of prevention. I will readily recommend, if even it means talking about it in the various mosques that are under my jurisdiction. I will even mobilize other Imams working under me, so we can educate people.  (IDI, head of a religious group)"
360628,1.0,"Implementation of an ivermectin-based strategy to reduce malaria transmission will require higher or more frequent doses that currently used for NTDs. Efficacy and safety will be the most important parameters to be evaluated by any stringent regulatory authority; both are directly related to the dose and dosing scheme selected for malaria. For a WHO policy recommendation, additional factors such as cost-effectiveness, acceptability and programmatic suitability will need to be addressed."
1449365,1.0,"396 articles were retrieved from various databases and other sources in which 72 were excluded because they were duplicate hits. The remaining 324 unique articles were screened by titles and abstracts after which 309 articles were excluded. Three articles out of the remaining 15 were excluded because one was a brief communication [17], the second was about a hypothetical malaria vaccine [18], and the third was a review study [19]. Therefore only 12 full articles qualified for the qualitative analysis [20 31] (Figure 1) ."
1449365,2.0,"Tanzania has a list of twelve priority disease conditions referred to as a national package of essential health interventions, on which to prioritize the allocation of its scarce resources for health. This list rank disease conditions according to their burden of disease and is dominated by infectious diseases   HIV/AIDS, malaria and diarrhoeal diseases are at the top. Ranking of the disease conditions is fairly consistent with the number of pharmacoeconomic studies we have identified. Nine out of the twelve pharmacoeconomic analysis studies addresses the four highest ranked disease conditions (Table1) It is disappointing to note that only one pharmacoeconomic study addresses non-communicable diseases, and none are available for acute respiratory tract infections, diabetes, cancers, and nutritional deficiencies."
359097,1.0,"Of 700 results returned by the PubMed search, 118 publications were selected for full-text review. These documents, which ranged in publication year from 1959 to 2015, included contemporary accounts of the campaign from specific countries, assessments of global programme process, and reflections on the eradication accomplishment by its participants in both journal article and book form, along with several reviews of the smallpox experience. A number of themes emerge from the literature across the seven areas of interest (Table 1)."
359097,2.0,"Henderson declared,  For a global programme against a disease to be undertaken, universal political commitment is necessary  [10]. In the case of malaria, support for fighting the disease seems strong, with malaria control activities frequently cited as one of the  best buys in global health  [11,12,13]. However, the pursuit of malaria eradication is more controversial, and whether it represents a feasible or even a worthwhile goal has been frequently debated [14,15,16,17,18,19,20,21].  Support for the smallpox eradication programme was similarly far from universal. The failures of prior eradication or regional elimination efforts including hookworm, malaria, yellow fever, and yaws increased skepticism, as did a perception that vertical eradication campaigns detracted from provision of basic health services [7]. Although the WHO was tasked with coordinating the effort from Geneva, its diverse departments and regional offices were not uniformly behind the effort, in part because  their officials competed with each other for finite financial resources and administrative influence  [22]. The Director-General of WHO reportedly had so little faith in the programme that he explained to Henderson a secondee from the United States  Centers for Disease Control and Prevention that  he wanted an American as the director so that when the programme failed, as he was sure it would, the Americans, not the WHO, would be seen as responsible  [23].  The smallpox programme survived at the WHO in part because of strong backing from both the United States and the Soviet Union [23], the major powers of the era. Henderson himself was seen as a trustworthy leader by both rival countries despite ongoing Cold War hostilities because of his strong track record as an  honest and a good scientist  whose  only objective [was] to eradicate smallpox  [23]. Still, maintaining smallpox s profile within the WHO and encouraging countries to contribute funding and resources was an ongoing challenge. Henderson used the annual meeting of the WHO assembly as an important opportunity to keep eradication on the minds of health ministers [8] and tried to maintain smallpox s public profile by widely releasing surveillance reports with summaries of progress and problems. Henderson later suggested that a mistake he made was not adding dedicated staff to his team focused on public relations and donor advocacy [10]. Malaria today appears to have a more visible profile internationally than smallpox did, in part due to similar communications efforts, such as the annual World Malaria Report which provides opportunities for visibility and public engagement [24]."
359097,3.0,"International coordination was considered important to avoid  ping-pong smallpox  [25] in which infections would be continually reintroduced from country to country. A 1960 Inter-Regional Smallpox Conference organized by the WHO reported that since  the eradication of smallpox cannot be considered on the basis of individual territories,  the Conference  therefore urges the health administrations of all countries in endemic regions to synchronize their eradication campaigns  [26]. While this declaration was sufficient to spur action in some countries [27], others, including Brazil the country with the largest burden in the Americas and many African countries [28], declined to initiate vaccination programmes, compromising the possibility of regional success [29]. Provision of dedicated smallpox funding in 1967 proved critical to allow the WHO to incentivize countries to scale up their national programmes [10], even when committed funding was small [29]. The provision of donor funding for malaria increasing from about $170 million in 2000 to $2.5 billion in 2016 [30] has likely been similarly important to convince countries to prioritize malaria programming.  Despite the international push from the WHO, the smallpox eradication effort would always remain a collection of individual national programmes, each attempting to solve their own problems through their own systems and in their own ways [28], rather than a top-down, centrally managed global undertaking. Dr. William Foege, an American epidemiologist who helped design the surveillance-driven vaccination strategy that likely enabled success in countries including Nigeria and India [31], called it  20 programmes trying different things to more quickly discover truth  [32].   The campaign to eradicate smallpox worldwide is often described in simplistic terms  The picture presented is of a unitary programme of action, where the many cogs in the wheel apparently worked in almost perfect harmony, causing orders from the top of an administrative pyramid to be unquestioningly implemented in localities across the globe  the organized drive to expunge smallpox was a much more complicated and disjointed entity  [33].  Current malaria guidance embraces an aligned belief that  adapting and tailoring interventions  to the local context will be important for elimination success [34]. While encouraging local solutions, the WHO and other international entities including the United States  Centers for Disease Control and Prevention [35] added substantial value to these independent programmes, including:  Sharing best practices across countries WHO s guidance to countries changed substantially over the course of the programme as understanding of best practices evolved. Its initial recommendation for every country to vaccinate at least 80% of the population increased to a goal of 100% vaccination [28], before being replaced with a dramatically different recommendation to invest heavily in surveillance and to focus vaccination on the places where transmission was observed. Many countries resisted this latter change despite evidence that that surveillance-driven targeting was more efficient [31], and the WHO s leadership in pushing for adoption of proven approaches was thus critical [36]. Today, regular revisions of malaria guidance (e.g., [34, 37, 38]) demonstrate that such dissemination of best practices remains an important WHO role.  Ensuring the quality of tools Smallpox programmes relied upon having a stable, reliable, effective vaccine [39]. Yet when the newly established eradication headquarters in WHO established a system for testing batches of vaccine produced in more than 40 different countries, it found?<?10% of samples were acceptable [40] due to potency and heat stability issues [41]. The WHO engaged vaccine experts to write simple manuals of production that explained best available production methods, and the WHO consultants worked with laboratories to improve their production processes [42]. Local production of vaccine was set up at government-owned facilities or associated institutes in the largest population countries including Brazil, India, and Indonesia, since donations would otherwise have been insufficient [42]. Two high quality laboratories from the Netherlands and Canada were selected to serve as vaccine reference centres [39], and they performed batch testing to evaluate improvements. As a result of these efforts, the fraction of batches meeting quality standards rose to 31% in 1967, 76% in 1972, and 96% in 1976 [36]. The WHO today provides an analogous quality control and assurance function for certain malaria commodities, prequalifying malaria drugs (https://extranet.who.int/prequal/), evaluating the accuracy of diagnostics [43], and inspecting manufacturing sites for vector control tools, though the complex landscape for malaria commodities makes it more difficult to assess the overall quality of the tools being used in endemic countries. The smallpox experience suggests that investment in the production of bed nets in high-volume countries could be considered as a possible means of reducing reliance on imported, donor-funded products [44].  Provision of technical and operational support The WHO s smallpox eradication unit provided national programmes with both field epidemiologists for technical advice and administrators to help manage logistics. Over the 12 years of the programme, 687 different individuals from 73 countries participated in the WHO-sponsored programme [45]. The expansion of WHO s role from solely providing technical advice to actively enabling operations was a learning experience for the Geneva-based programme [46]. This evolution allowed Geneva to strengthen global logistics, moving supplies from one country to another as needed, or flexibly providing necessary funds to overcome bottlenecks [10]. It was noted that the WHO was most effective when its staff, including senior leadership, spent their time working in country with programmes [47]. Henderson stated his opinion that the most effective WHO staff  were those who took an active role in field operations. Those who assumed a passive role of detached technical adviser were encouraged to leave the programme  [10]. Similar sorts of temporary field advisors have been deployed under the  Stop Transmission of Polio  programme [48] and can prove useful for building capacity in malaria programmes if deployed thoughtfully [49]. The United States President s Malaria Initiative today provides technical advisors to malaria endemic countries in this mode, as do several non-governmental organizations.  Encouraging research and innovation In Henderson s view,  The importance of problem-oriented research that was conducted throughout the course of the smallpox eradication programme cannot be too emphatically stated  [10]. Development of a heat-resistant vaccine may have been the single most impact factor in global success [7], while ongoing operational research enabled resolution of unforeseen challenges that inevitably occurred over the course of the long, complex undertaking of eradication [21]. The WHO encouraged such studies through its convening power [14], though innovation was typically decentralized.  An important lesson was that parallel activities and research, with many groups seeking better approaches, could speed up the process of improvement,  Foege wrote [50]. The jet injector, for example, a new tool for increasing the speed and efficiency of vaccine delivery [51], was first developed in the United States at the National Communicable Disease Center during the 1960s [52]. The development of a low-tech, simpler solution the bifurcated needle by a private company, Wyeth Laboratories (which waived patent costs for any manufacturer supplying them exclusively to the WHO [53]), proved both simpler [29] and ultimately more successful [54]. An examination of innovation in the smallpox programme concludes that what was important was to  insure that the problem has been defined clearly and that intervening variables and technological factors do not becloud that definition , while building organizations that scientifically evaluate evidence and seek to improve themselves according to measurement of what does and does not work [39]. This perspective suggests the importance of continued investment both in malaria s $540 to $600 million research and development pipeline [55] as well as in efforts to help countries collect, analyse, and apply data for ongoing organizational improvements within their own programmes.  In playing these roles, there was agreement that the WHO s success was strongly linked to the ability to be as flexible and non-bureaucratic as possible [21]. Sometimes, as when flying to countries with outbreaks without receiving travel approvals, this meant breaking WHO rules [41], something Henderson deemed necessary given  a sclerotic  administration that often thwarted or actively impeded what appeared to be logical initiatives  [7]. In one example, an emergency request for vaccine supply from Uganda took 5 months to be transmitted to headquarters by the regional WHO office, during which time the Geneva office had already learned about the outbreak via informal backchannels and addressed it [8]. Internal WHO disagreements also led to challenges, with Henderson noting,  Officials located within different levels and departments of the regional offices continued to hold disparate views right till global smallpox eradication was formally certified  [33]. He complained that,  The regional offices of WHO  were more a hindrance than a help,  leading him to adopt a  policy of quietly short-circuiting the regional office, when necessary  [8].  The challenge for a complex bureaucracy like WHO to nimbly respond to dynamic circumstances have been echoed in recent years by criticism surrounding its response to the 2013 2016 Ebola outbreak in West Africa [56, 57]. The success of the WHO s smallpox team may provide a model for how a Geneva-based team can flexibly facilitate malaria operations across endemic countries. However, the fact that Henderson and colleagues viewed their success as something they achieved despite WHO s structures and procedures for example, by creating a new unit within a regional office that reported directly to Henderson rather than through the normal channels [33] rather than because of them, suggests that consideration will need to be given to how to ensure a central malaria coordination team is encouraged and enabled to be agile and flexible, as is required by the rapidly evolving nature of a global eradication enterprise, while still respecting and sometimes deferring to local solutions and expertise."
359097,4.0,"Achieving malaria eradication will require each of the world s endemic countries to invest in eliminating transmission. Financial analyses typically suggest that substantial short term budget increases will be required to end endemic transmission, after which long term savings can be realized due to the lower costs of preventing its re-establishment [58, 59]. Surprisingly, in the case of smallpox, Henderson argues no such surge in funding was required, with existing domestic budgets sufficient to cover programmatic needs:   The burden of expenditure has been borne by the endemic countries themselves  But, with few exceptions, the expenditure by the countries has been little more than what they were already spending to control smallpox. In other words, WHO and its member countries, with only a very modest additional input in resources, have transformed a never ending control programme to a successful eradication programme.  [29]  The idea that smallpox could be eliminated from countries with essentially the same budget previously used to control it is remarkable, and suggests that how funds were spent proved far more critical than the total amount of those funds. As Henderson describes:   For all of us it has been a revelation in so many countries to find at the periphery such an array of unproductive health staff and facilities. It has been a revelation to discover how effectively they may be mobilized with a comparatively small input involving leadership in the field and definition of a series of activities with defined objectives and a modest element of management. Other health programmes, especially those involving immunization, but others as well, could, I believe, be similarly transformed.  [29]  The importance of using available funding better was raised both nationally and internationally. The WHO internal dynamics and disagreements between regional offices complicated the efficient expenditure of available funding. In the Americas, for example, in the early 1960s, the Pan American Health Organization (PAHO) chose to distribute available funding for mass vaccination across the entire region, even though Brazil was the only remaining endemic country [6]. As a result, Brazil s funding was insufficient and elimination programmes were prolonged unnecessarily [14]. The WHO s South-East Asia Regional Office (SEARO) chose to pass up the available funding rather than participate in the programme, which it disagreed with; Henderson then channeled the SEARO money to PAHO in hopes it would be spent in Brazil. Less than half actually was, with the remainder divided across 10 other countries [8]. When 5 years later Brazil was finally free of smallpox, PAHO refused to donate its funds back to SEARO in turn to assist India [8].  Henderson s comparison of the relatively similar costs for control versus eradication refer only to domestic contributions, and do not include the 407 million doses of vaccine that were donated over the course of the programme, primarily by the Soviet Union and the United States [29], at an average estimated value of $17 per 1000 [6] (approximately $7 million in total). Between 1967 and 1979, $67 million in cash and kind (including the donated vaccine) was donated to the WHO s special account for smallpox eradication while $33.6 million was spent from WHO s regular budget [6]. This total of approximately $7.7 million per year would translate to approximately $30 $50 million in today s dollars far less than the $2 billion per year currently contributed by international donors to malaria programmes [60].  The argument made to donors to secure these funds was that  all should be willing to contribute to carry the attack to the remaining endemic regions until there is no more smallpox  [51]. The United States, for example, was said to be domestically spending $140 million annually in 1968 to prevent re-establishment of smallpox transmission domestically, and thus its modest investment of $15 million to eliminate in West and Central Africa meant that it could help 20 countries become smallpox free for the price of 39 days of preventing its reintroduction back home [35]. A similar argument was used to successfully convince the Swedish government to make a critical contribution to the programme in India, since  every country is in danger until the last case of smallpox has been eliminated  [22].  The availability of even small amounts of funding that could be used flexibly, with minimal bureaucracy, was seen as critical to bypassing bottlenecks.  It was essential to have an allocation of funds that could be used for any necessary purpose and in any country  [10], yet nearly all available funds for smallpox eradication were earmarked for specific uses. As a result, staff were often not paid on time, insufficient fuel allowances meant vehicles were not available when needed, and funding for car repairs was lacking in multiple countries [10]. In Zaire, for example, operations would frequently grind to a halt after the government failed to release the necessary funds; the programme solved the issue by setting up an auxiliary bank account in which they deposited back-up funds whenever possible to cover expenditure during these gap periods [8]. In Bihar, India,  staff were fearful of paying too much [for vehicle maintenance] and being held accountable for extra charges  [46], so vehicles were often neglected instead. New accounts were set up to give team leads advances for these minor but essential charges so that they could avoid weeks of paperwork to receive necessary funds, instead providing receipts at subsequent meetings on a biweekly or monthly basis. This approach dramatically improved the flexibility of the elimination efforts and Henderson deemed it  one of the most important initiatives of the programme  [8].  Malaria programmes today frequently experience similar delays due to challenges with financial expenditure. Many countries have failed to spend grants from the Global Fund to Fight AIDS, Tuberculosis, and Malaria on schedule due to a wide variety of issues, including lack of human resources, delays in procurement, weak data systems, and other challenges [61]. The smallpox experience suggests that the proactive creation of a flexible fund that could be used to address bottlenecks across countries as they arise could be a valuable tool for malaria as eradication proceeds, though the challenges of ensuring those funds are well spent would be substantial, and safeguards would be needed to ensure funds are spent for their intended function. This history also emphasizes the critical importance of having strong measurement and management of programmes to ensure available funds are allocated and used as effectively as possible."
359097,5.0,"Political will has been cited as one of the most important factors in the success of smallpox eradication [14] and a necessity for eliminating malaria [34]. Not all countries viewed smallpox elimination as an urgent priority given many other public health issues [28], just as malaria elimination is often a low priority today for countries facing more visible threats [62]. Competing disease priorities, including ongoing malaria eradication efforts [29], led governments such as that of Ethiopia to have  absolutely no interest in the eradication of smallpox  [63]. Non-governmental actors such as the United Nations Children s Fund (UNICEF) also had prior commitments to malaria eradication that took precedence over contributions to smallpox [8]. Today, the need to devote substantial resources to ongoing efforts to eradicate other diseases, including guinea worm and polio, may present similar challenges for malaria.  Countries where the less virulent variola minor predominated over the far more deadly variola major, mostly in Africa, tended to downplay the importance of embarking on an elimination programme, given that this strain of the disease was  little more serious than chicken pox  [8]. Henderson cited this reticence as one of the two primary factors compromising the young programme (the other being the absence of funding) [10]. This challenge is echoed by questions of whether malaria eradication should aim to include all species of the disease or only (or initially) the more virulent Plasmodium falciparum given its outsized contribution to mortality as well as its development of resistance to artemisinin-based drugs in the Greater Mekong subregion [64, 65]. Accounts of smallpox eradication do not clarify whether an effort to only eradicate variola major could have succeeded (and thus whether a P. falciparum only attempted might be feasible), though the similarity of symptoms between the two would have complicated case finding directed only at the major variant.  Political backing also suffered with changes in government and thus the loss of advocates:  Within 4 years after the West African programme began, there were 23 changes of governments in the 18 participating countries,  causing  changing leadership and staff in the nation s smallpox programme  [47]. In India, it was noted that the Prime Minister s enthusiasm for smallpox typically increased when outbreaks were observed and thus when the electorate was most concerned about the disease and declined with smallpox incidence [22]. Pressure from powerful allies outside the government was thus seen as critical to ensure the programme remained sufficiently well supported even when smallpox was not in the headlines. An agreement to begin a vaccination programme in Ethiopia only occurred due to the intercession of a senior Austrian physician with a close relationship with the Emperor [63], while in India, the intervention of J.R.D. Tata, the well-connected head of a large corporation, played a critical role in convincing the Prime Minister to continue supporting the smallpox programme at a pivotal moment [22]. In Bhutan, where the WHO initially lacked visibility into smallpox efforts due to the secrecy of its government, an acquaintance of Henderson s with access to the royal family was eventually able to build communications with Geneva [66].  A lesson for malaria is thus the importance of getting well-connected leaders from business and high-profile institutions to act as advocates. The opinion of politicians can change based on what seems important for the next election, but smallpox programme examples show how they can be convinced by counsel from those they trust or respect. Malaria appears to already be doing a better job of identifying high-profile advocates; organizations with the explicit goal of maintaining malaria s global or regional visibility, such as Malaria No More or the African Leaders Malaria Alliance, identify champions who can contribute funding and political backing to national efforts [67], while the End Malaria Council (http://endmalariacouncil.org/) seeks to bring business leaders together with public sector leaders to keep malaria a global priority."
359097,6.0,"Community participation with the smallpox programme was considered generally strong [8], although the literature contains numerous accounts of specific anecdotes of resistance to vaccination particularly following real or perceived adverse reactions to the vaccine [28]. Some commentators note that the narrow focus on smallpox was sometimes counterproductive given the range of health issues afflicting communities. In Bangladesh, for example, vaccination occurred in the midst of a cholera epidemic, yet the vaccinators could provide no assistance with the more visible and urgent problem, resulting in community frustration [68]. As the programme proceeded, additional components were therefore added onto the responsibilities of surveillance agents to keep them engaged and motivated despite the infrequency with which smallpox was observed, including surveys investigating access to clean water, vitamin A, family planning, and rates of childhood mortality [68]. Similarly, malaria-only health workers may prove less successful than those that have been trained to treat a variety of common illnesses [69].  Gaining the support of community leaders was commonly cited as a crucial step towards community acceptance. In Nigeria, Foege believed that people participated less because they were convinced by vaccinators to do so and more because they trusted their leaders [31]. In one extraordinary case, vaccinators were reported to have awed a village chief into supporting the programme by releasing a trained bird to swoop overhead and drop pro-vaccine leaflets while vaccinators were meeting with him [29]. Despite such anecdotes, Tarantola and Foster note that little research was conducted into how the community could best be engaged [68], though attempts to do so included deployment of midwives and other village workers to engage and educate the community [39, 70] as well as provision of monetary awards for report of a smallpox case in the final stages of the programme [71]. In India, for example, a 100 rupee reward was offered for anyone reporting a previously unknown outbreak [29]. The evidence base for what drives patient participation with the health system has increased in subsequent decades, identifying factors related to cost, proximity, and confidence [72], but the relative ability of different interventions to influence those factors likely still requires additional research. Best practices for proactive engagement of community leaders and ongoing communication and collaboration with at-risk populations should be encouraged to make communities active participants in malaria elimination programmes [73].  Where efforts to improve participation failed, smallpox programmes would sometimes use compulsory vaccination, an approach that dispensed with  the need to converse with villagers at all  [74]. Compulsory vaccination was believed to be justified by the need to achieve sufficient coverage for the greater good, but it raises troubling ethical questions. Greenough quotes Stanley Music, an epidemiologist who worked in the Bangladesh programme, on the tactics sometimes employed:   In the hit-and-run excitement of such a campaign, women and children were often pulled out from under beds, from behind doors, from within latrines, etc.  Attempts were made to secure the cooperation and  blessing  of village headmen, thereby putting social pressure on the villagers to stand their ground and accept vaccination. Still, however, some form of minor chaos was the rule, as headmen s authority did not extend into individual s homes  People were chased and, when caught, vaccinated  We went from door to door and vaccinated. When they ran, we chased. When they locked their doors, we broke down their doors and vaccinated them.  [74]  While these aggressive approaches did in some cases attain the narrow goal of achieving high vaccination coverage, they seem unwise for a programme such as malaria in which long-term participation and repeated delivery cycles is needed. Ethically, they were controversial even at the time, and  the organized and sustained use of compulsion was, generally speaking, instituted with great care and only after broad administrative and political consensus had been achieved  [22].  Engagement with the private sector was reported to be generally minimal outside a few efforts to integrate private health care providers into the vaccination programme [68]. India proved one of the main exceptions, with the Tata Group playing a critical role in vaccinating the population of Bihar State, where its steel plant was located. They provided  medical and paramedical personnel, transportation, managerial support and communication facilities to implement the programme activities. The assistance in kind provided by the Company and their local knowledge of the area were so valuable that south Bihar became smallpox-free in a record period of 6 months  [75]. Malaria s recent history includes several examples of similar partnerships [76]. Given the importance of private providers and drug shops for provision of malaria treatment [77], malaria eradication will necessitate much greater engagement with the private sector than occurred during smallpox eradication."
359097,7.0,"Smallpox eradication was predicated on the idea of mass vaccination of the population. The WHO s Expert Committee initially called for countries to achieve at least 80% vaccination of the population [29]. This approach successfully led to elimination in some countries, but elsewhere it failed, likely because the vaccinated and unvaccinated fractions of the population were not homogenously mixed [36]. In Central Java, for example, a 1969 survey found greater than 95% vaccination rates had been achieved across the population of 23 million people, yet that same year over 1700 cases were recorded, nearly all amongst the 5% of the population who had been missed [78]. The WHO Expert Committee responded by telling countries they should strive for 100% vaccination rates, a target scorned as impossible [29]. Attempts to conduct greater numbers of vaccinations were undertaken, but  accessible groups, like schoolchildren, were vaccinated repeatedly so that high  scores  were achieved, but there always remained a large pool of unvaccinated persons  [47]. This language is mirrored in a recent investigation of bed net coverage across Africa by Bhatt et al., which concluded:   We found substantial over-allocation of nets to households already owning a sufficient quantity  What is certain is that over-allocation becomes a major barrier to achieving universal coverage when levels of [insecticide-treated bed net] provision are high because most new incoming nets are simply leading to surpluses in many households, while elsewhere there remains a shortfall. This may have a disproportionately high public health impact if those surplus nets are concentrated in households at lowest risk.  [79]  The critical change in smallpox programmes was a shift away from mass vaccination towards an approach called  surveillance-containment  [35] in which programmes sought out smallpox cases and then concentrated vaccination efforts in their proximity and towards those who may have come into contact with the cases. In short, the new strategy meant focusing vaccination on the places where it was most likely to matter, rather than laboring to achieve implausibly perfect coverage everywhere. In Bangladesh, for example, the programme successfully ended transmission after abandoning efforts to achieve 80% vaccination nationally and focusing efforts instead only on the northern districts where cases were reported [41].  The 1964, the WHO Expert Committee report did not even mention surveillance [8], but the new focus on finding cases, tracking down all of their contacts, and concentrating vaccination operations in the most necessary places was considered by many to be one of the keys to eradication s ultimate success [14, 80]. Identifying where smallpox was being transmitted required a network of agents who visited all health units (usually in teams of two to four per administrative unit) to ensure weekly reporting, sought out cases in the community, including by collaborating with teachers or visiting markets [78], and distributed surveillance reports so that the health staff saw how their reports were being used [81].  Undoubtedly, the greatest stimulus to reporting was the prompt visit of the surveillance team for outbreak investigations and control whenever cases were reported,  Henderson wrote.  This simple, obvious and direct indication that the routine weekly reports were actually seen and were a cause for public health action did more, I am sure, than the multitude of government directives which were issued  [81]. Case finding was intensified during the period of lowest seasonal incidence, since that low transmission season represented the weakest point in the smallpox cycle and the best opportunity to break transmission, despite the operational challenge of finding cases at that time of year [82]. Active case finding was integrated with routine reporting from public health facilities rather than conducted entirely in parallel [81]. Challenges to setting up good surveillance systems included the fact that in many countries, disease reporting fell under the purview of independent statistical units and were not thus within the control of the smallpox programme [10] (the same is true for malaria today in many countries).  The operational strategy of directing vaccine only to known transmission areas may not be directly translatable to malaria s tools. First, the approach may have worked in part because the reproductive rate for the virus was relatively low [35], estimated at approximately 3.5 to 6 [83], while estimates for malaria are variable but potentially far higher [84]. Second, case finding was far easier because the symptoms of the disease were so distinctive and recognizable even to schoolchildren [81], and smallpox unlike malaria [85] very rarely caused asymptomatic infections [6]. As a result, mathematical modeling of an analogous reactive case detection strategy for malaria suggested that such approaches may increase the probability of elimination in certain contexts, but would be  a highly resource intense, long-term intervention that is inappropriate in many settings where resources are limited  [86].  Nevertheless, the critical shift in smallpox programmes from judging success based on the volume of vaccinations to whether vaccination was achieved in the most necessary places still suggests a good model for malaria programmes, despite the extensive presence of asymptomatic carriage. Malaria programmes that seek only to distribute commodities such as nets or drugs in high volumes in an attempt to achieve  universal  coverage may be missing more inaccessible populations which may also be the highest risk for malaria [79, 87]. Shifting towards a risk-focused approach in which prevention and treatment are targeted to those who most need them has great potential for improving the efficiency and effectiveness of our efforts."
359097,8.0,"Discussion of the wisdom of eradication programmes often revolves around the relative merits of  vertical,  single disease programmes versus  horizontal  health systems efforts [14], which were increasingly coming into favour at the WHO around the time of smallpox eradication. Henderson advocated for having a specific vaccination programme distinct from, yet linked to, routine health services, worrying that fully integrated programmes would lack clear objectives, evaluation systems, and management structures.  The  horizontal programmes  I have seen best describe the sleeping postures of the workers  [80], he wrote. In contrast he considered a  targeted and time-limited special programme with funds specially allocated for it, both in the WHO budget and in most national budgets, and with full-time technical staff responsible for its supervision  [10] to be superior since it would more easily attract resources and community support and likely be more efficient and better managed given the singular focus. Such programmes were also viewed as attractive because they could be conducted even while basic health services remained weak [51]. The vertical versus horizontal health programme debate has persisted since smallpox [88] and will not be resolved here, yet a few clear lessons for malaria emerge from smallpox s successes.  First, smallpox programmes were well integrated with basic health systems, enabling routine case management and surveillance, with active case finding used as a supplement rather than a replacement. This integrated design improved upon the design of the Global Malaria Eradication Programme preceding it in the 1950s and 1960s, which largely circumvented basic health systems. The malaria eradication programme measured malaria primarily via population prevalence surveys [89] and other active means [90] and conducted insecticide spray campaigns as vertical efforts. Malaria staff were also better paid than other workers and reported to heads of state rather than ministries of health, creating unsustainable systems [7]. In contrast, smallpox programmes were still part of the health system, leveraging the same basic health services and staff to identify and report the disease [10, 33]. This integration meant that smallpox teams were not required to set up fully parallel surveillance systems, instead augmenting existing ones and leaving behind some added capacity within health programmes. Similarly, reliance upon the routine, albeit imperfect, measurement of malaria that basic health systems provide across endemic regions seems likely to greatly improve the cost-effectiveness of surveillance given that it requires minimal expenditure beyond keeping health facilities stocked with diagnostic tests, training staff in their use, and linking them to effective reporting systems. Such investment in core case management systems is a primary component of WHO s Global Technical Strategy for malaria [4].  Second, multiple authors highlight the importance to smallpox programmes of creative, problem-solving staff [32] who could figure out how to overcome any obstacle that arose, tailoring solutions to the unique challenges and contexts faced by each country [10]. Henderson described:   The essence of what has made the programme what it is is, very simply, an imaginative and dedicated field staff, both national and international, who, given scope and encouragement to work out problems according to local circumstances and support in their efforts to do so, have responded with some remarkable solutions to impossible problems.  [29]  These resourceful workers, described by former United States Surgeon General Julius Richmond as  simply too young to know it couldn t be done  [50], were supported by a similarly flexible international team at WHO, who were described as:   Essentially problem-solvers, they viewed themselves as catalysts rather than as controllers. They understood from the onset that experimental learning offered the only possibility for success. They avoided formalized programming, opting instead for innovation, flexibility, communication and experiment, by means of a number of deliberate policies and mechanisms. They recruited people with practical field experience in epidemiology (as opposed to previous work with smallpox per se). They sought people with reputations for adaptability, imagination, and hard work. They preferred younger people, assuming they would be more receptive to new approaches and ideas.  [91] quoted in [39]  Henderson contrasted the flexibility with which smallpox programmes worked with the unsuccessful prior malaria eradication effort, which he said  was conceived and executed as a military operation to be conducted in an identical manner whatever the battlefield  [92], preventing it from adapting to local contexts, structures, and systems.  Third, smallpox programmes placed great emphasis on careful measurement and verification.  Logic suggests that all disease control programmes should provide continuous measurements of disease incidence, and that these measurements should dictate changes in strategy and tactics,  wrote Henderson.  In fact, few programmes do so. Responsible authorities tend to ignore such information or dismiss efforts to obtain the data and, instead, assess progress in terms of activity, such as the numbers of vaccinations performed or patients treated  [10]. Arguably, today s malaria programmes continue to focus more on activities conducted rather than impact, in part because key performance indicators reported as proof of performance on grants such as those from the Global Fund to Fight AIDS, Tuberculosis, and Malaria tend to focus on the number of nets delivered [93], rather than whether they are delivered to those most at risk or achieve desired reductions in malaria. The smallpox experience suggests that successful elimination may require shifting focus from simply tallying how many commodities have been distributed towards assessment of whether those tools are being used as effectively as possible.  In West and Central Africa, smallpox programmes used three different types of evaluation approaches: first, evaluators would follow-up to assess whether what vaccinators claimed to have done had truly been accomplished; second, tally sheet comparisons were made to compare vaccination records against any available census data, as a quick if somewhat inaccurate estimation of whether numbers were approximately what should be expected; third, spot checks for vaccine scars were conducted at markets and other convenient gathering places to provide an independent confirmation of coverage [94]. Henderson stressed that in measurement, quality was more important than quantity:  a few indicators of overall performance, closely followed, were more useful than a broad spectrum of indicators measuring many aspects of programme execution  [10].  How to build appropriate teams and processes to conduct this measurement and verification was determined on a country by country basis. In Bolivia, one inspector was appointed for every eight to 12 vaccinators, ensuring everyone s work was reviewed at least biweekly [95]. In India, a Central Appraisal Team oversaw evaluation processes, including frequent travel to trouble spots to assess what was going wrong [8]. Ensuring accurate reporting was sometimes compromised when workers avoided reporting true cases because they thought they would be punished for allowing transmission in their region [70], underscoring the importance of clear and frequent communication between central and local levels, with regular meetings to discuss problems and progress [10]. Widespread distribution of smallpox indicators was encouraged, such as through surveillance bulletins in Brazil which were distributed on a monthly basis to a wide audience, providing updates on progress, putting pressure on non-reporters to participate, and generally helping to foster a shared sense of purpose across the diverse network of individuals participating in the campaign [8].  Fourth, the smallpox programme emphasized the importance of strong management in all aspects of the programme. Henderson suggests that,  Successful execution of the programme consists of perhaps 10% technical skill and 90% organization and leadership  [29]. He stressed the importance of leaders actually spending substantial time out in the villages where the work is being done, leading by example and helping motivate workers:  effective leadership to solve the problems faced by field workers cannot be supplied by an army of physicians and senior supervisors who never leave their desks. Regrettably, these types are all too plentiful throughout the world  [29]. These opinions were substantiated by an evaluation of unsuccessful programmes in India, Pakistan, Argentina, Iran, and Ghana, which found that:   First and most important, failure appeared to be associated with inadequate supervision and assessment. Programmes that failed normally showed the following shortcomings: (a) supervisory personnel did not check at the family level to assure that broad overage by vaccination of the population was being achieved; (b) supervisors were too burdened by other responsibilities to give more than nominal supervision; (c) inadequate provisions for travel and expenses; and (d) disinclination of supervisors to undergo the inconvenience of field work.  [22]  William Foege described how  the real problems  of  developing routines, documenting the implementation of those routines, hiring the right people, supervising, motivating, and evaluating  required  managers, administrators, and logistics experts people who knew how to solve problems and how to get things done. The programme would not fail for lack of scientists, but it could fail even with the best strategy if we didn t attract the very best managers  [32]. Strong management was required to keep up staff enthusiasm for searching for smallpox when there was nothing left to find [22]; in one case, near the very end of the programme in Ethiopia, a surveillance agent walked for 15 days to check on two reported cases which turned out to be chickenpox [29].  Programmes accordingly sought to hire non-medical, logistics-oriented staff with experience in administration in addition to those with a more conventional public health background [82]. Once brought into the programme, strong managers had to be retained: in Brazil, for example, five different directors were appointed in the 5 years between 1967 and 1971 [14] with unsurprisingly weak results. Henderson suggested that providing programme leaders with management training would have been a wise idea, though it was not done at the time [10]."
362307,1.0,"At a reference transmission setting with annual entomological inoculation rate (EIR) of 21, the simulations predict that a PEV with 52% initial efficacy could be very cost-effective when delivered via EPI alone. At a vaccine price of US$2 per dose, the cost per uncomplicated malaria episode averted would be around US$ 5, the cost per severe malaria episode averted US$ 269, the cost per DALY averted around US$ 35 and the cost per death averted US$1057 (see table S1 and S2, Additional file 1). The cost-effectiveness ratios are lower for higher effectiveness levels (Figure 1). They increase almost proportionally with vaccine price reaching US$ 160 per DALY averted and US$ 4869 per death averted for a vaccine price of US$ 10 per dose (see table S3 and S4, Additional file 1). The proportion of events averted by PEV delivered via EPI with booster doses is slightly higher, but the cost per uncomplicated episode averted is 20% higher (see table S1, Additional file 1), and cost per DALY and death averted is around 31% higher (see table S2, Additional file 1).  With EPI and mass vaccination the proportion of events averted is 5% higher for mass vaccination coverage of 50% and 8% higher for coverage of 70%[14], and the cost per uncomplicated episode averted is slightly lower. However, the costs per DALY and death averted are around 60% 66% higher (see table S1 and S2, Additional file 1). For higher efficacy levels the pattern is similar, showing that the incremental benefits of these deployment modalities, in this transmission setting, are modest (Figure 1).  In low transmission settings, while the cost per uncomplicated episode averted under EPI alone is similar to that in the reference transmission setting (see table S1 and S2, Additional file 1), the cost per DALY and death averted are lower at US$ 31 per DALY averted and US$ 925 per death averted at a vaccine price of US$ 2 per dose (see table S2 and S4, Additional file 1). Adding booster doses leads to higher cost-effectiveness ratios for efficacy levels up to around 60%, but at near 100% efficacy the cost-effectiveness ratios become similar (Figure 1). In contrast, when mass vaccination is added to EPI, the cost-effectiveness ratios decrease substantially, by around 70% for the cost per uncomplicated case averted (see table S1 and S3, Additional file 1), and by 24% to 28% for the cost per DALY and death averted (see table S2 and S4, Additional file 1).  In high transmission settings, the effectiveness of PEV is low[14] and the cost-effectiveness ratios are therefore higher than in the other transmission settings irrespective of delivery modality. For some outcomes, vaccination even leads to an increase in the number of clinical events[14], and, therefore, to negative cost-effectiveness ratios and negative case management cost savings (see table S5, Additional file 1).  Across all transmission settings, the incremental benefits of booster doses are small and the cost-effectiveness ratios are higher. Adding mass campaigns has little impact on overall effect when the primary efficacy is low. However, for high vaccine efficacy and high coverage, this strategy is predicted to lead to local elimination of the parasite in low transmission settings and substantially reduce transmission in medium transmission settings[14] at low additional costs. Under these conditions, because of the effects of the vaccine on transmission, delivery via mass campaigns plus EPI becomes a cost-effective alternative to EPI alone."
362307,2.0,"At the reference transmission intensity, BSV of moderate efficacy with a price of US$ 2 per dose applied through EPI achieves a cost per uncomplicated episode averted of about US$ 9 (see table S1, Additional file 1), which is higher than for the corresponding PEV, but the costs per DALY averted (US$ 21) and per death averted (US$ 630) are lower than for PEV (see table S2, Additional file 1). At higher efficacy levels, the cost-effectiveness ratios decrease, following the same patterns as for PEV (Figure 2). Adding booster doses increases the cost-effectiveness ratios somewhat. Mass campaigns also increase the cost-effectiveness ratios except for uncomplicated episodes, where they decrease. At low transmission intensity BSV averts a lower proportion of uncomplicated and severe cases and deaths than PEV[14] and the cost effectiveness ratios are higher for all outcomes. Adding booster doses leads to slightly higher costs per uncomplicated episode averted (see table S1 and S3, Additional file 1), and much higher costs per DALY and death averted (see table S2 and S3, Additional file 1, and Figure 2). Adding mass campaigns to EPI leads to a dramatic reduction in the cost per uncomplicated episode averted, but the costs per DALY and death averted are only slightly lower (see table S1, S2, S3, Additional file 1, and Figure 3, 4). In high transmission settings BSV is more effective than PEV especially in averting severe and mortality events[14] and it is also more efficient. Under EPI alone the cost per uncomplicated episode averted, in the highest transmission setting, is US$ 3.8, the cost per DALY averted is US$13.5 and the cost per death averted is US$401, at vaccine price US$ 2 per dose (see table S1 and S2, Additional file 1, and Figure 3). Adding boosters or mass campaigns, leads to higher incremental costs than incremental benefits (see table S1, S2, S3, Additional file 1, and Figure 2). Across all transmission settings, the incremental costs of adding booster doses to EPI are higher than the incremental benefits and this is particularly true for severe episodes, DALYs, and mortality (see table S1, S2, S3, Additional file 1, and Figure 2). In low transmission settings, campaigns improve cost-effectiveness for uncomplicated episodes averted, but do not change cost-effectiveness estimates for DALYs and deaths averted. However, in moderate to high transmission settings, the incremental costs of campaigns are higher than the incremental benefits (see table S1, S2, S3, Additional file 1, and Figure 2)."
362307,3.0,"Combining BSV with PEV (with matched efficacies) in general, improves or matches the cases averted over PEV alone for all transmission settings and vaccine delivery modalities[14]. The cost-effectiveness ratios for this combination are lower than those of PEV in all transmission settings particularly for the cost per DALY and per death averted and in moderate to high transmission settings (see table S1, S2, S3 in Additional file 1, and Figure 3, 4). Compared to BSV alone, the cost-effectiveness ratios of combining BSV with PEV are lower, though the difference is smaller than for PEV and in this case it is higher in moderate to lower transmission settings than in high transmission settings. Adding booster doses to EPI leads to higher cost-effectiveness ratios across all transmission settings for this combination   the costs per uncomplicated episode averted increases by around 19% 23% while those per DALY and death averted show even larger increases (around 30% 40%). Adding mass campaigns in low to moderate settings lead to incremental uncomplicated episodes averted that are higher than the incremental costs. However, in terms of DALYs and deaths averted the benefits exceed the costs only in the lowest transmission setting, while they are significantly lower in the reference and in high transmission settings. In high transmission settings even the additional uncomplicated episodes averted are lower than the additional costs. Combinations of MS TBV with PEV or BSV and the triple combination do not improve the effectiveness of the vaccines alone when delivered via EPI or EPI with boosters[14]. However, adding mass campaigns leads to greater effectiveness in all transmission settings (Figure 4). The additional benefits of these combination vaccines are then much higher than the additional costs compared to delivering the vaccines under EPI alone and to all delivery modalities of PEV and BSV alone. In the reference transmission setting, for instance, the cost per uncomplicated episode averted of combining BSV with MSTBV, delivered via EPI and mass campaigns, is (at a vaccine price of US$2) US$1.8 and US$2.3 for 70% and 50% coverage (see table S1, Additional file 1), while the cost per DALY averted is US$20 and US$ 22 for 70% and 50% coverage (see table S2, Additional file 1). The costs per DALY averted vary between US$ 12 and US$40 across transmission settings with the lowest value in the lowest transmission setting where the greatest improvement to effectiveness is observed. The very favourable cost-effectiveness ratios in low transmission settings are related to the case-management cost savings, which may compensate up to more than 50% of the costs of the vaccine intervention (see table S4, Additional file 1)."
362307,4.0,"Adding boosters to EPI does not improve effectiveness or cases averted over EPI alone by very much even at the very high coverage level modeled, but it does incur additional costs. This delivery modality does therefore not represent a cost-effective alternative to EPI alone in any scenario (see table S1, S2, S3, Additional file 1). Delivering all vaccines and combinations via population based campaigns improves the effectiveness at mass vaccination coverage of 50%, especially in low transmission settings[14]. Depending on the transmission setting and the vaccine type considered, the incremental costs of delivering vaccines via population based campaigns can be lower than the incremental benefits, leading to a significant reduction in the cost-effectiveness ratios (see table S1, S2, S3, Additional file 1, and Figure 4). Disseminating vaccines via population-based campaign in these cases is predicted to be a more cost-effective way of delivering malaria vaccines than EPI alone. Increasing the coverage of the mass vaccination campaigns increases the effectiveness and cases averted for all vaccine and vaccine combinations under most transmission settings[14]. However, the incremental benefits of increasing coverage are often lower than the incremental costs of achieving it (Figure 5). In some cases, the predictions suggest an optimal cost-effectiveness ratio at intermediate values for the campaign coverage. This is not a consequence of non-proportionality of vaccine delivery costs as a function of coverage (which could be realistic, but not modeled in this study), but of the indirect effects of the vaccines."
362307,5.0,"Although the simulations focus on comparative cost-effectiveness of different candidate malaria vaccines and delivery modalities, and not on the sensitivity of cost-effectiveness ratios to vaccine prices, which are hypothetical, it is evident that the cost-effectiveness results are almost directly proportional to the vaccine prices. In fact, at an assumed vaccine price of US$ 10 per dose, most cost-effectiveness ratios are between 4 and 7 times higher than those obtained at US$ 2 per dose (see table S1, S2, S3, Additional file 1). At a vaccine price of US$ 2 per dose, most vaccines and delivery modalities simulated present cost-effectiveness ratios comparable to those of other malaria interventions[9, 10, 41 43], while at a vaccine price of US$ 10 per dose in many of the simulated scenarios the cost-effectiveness ratios are higher."
