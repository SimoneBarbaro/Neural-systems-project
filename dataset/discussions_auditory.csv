,doc_id,discussion_id,text
0,232756,0,"We introduced a new comparative approach to observation learning of a discrimination task. We quantified task performance in terms of learning speed and ability to generalize, analogous to studies on observational learning of motor tasks, in which performance is quantified in terms of reaction times and generalization across motor effectors23,24."
1,232756,1," We found that zebra finches can learn to discriminatively respond to auditory stimuli by observing expert performers. Experimenter and observersí behaviors were subject to a tradeoff that depended on whether the learning cue was experienced or observed. We inferred this cue dependence thanks to our experiment design in which the stream of auditory stimuli was identical for experimenters and observers. Therefore, any differences in their abilities to learn and to generalize must have been entirely due to the learning cue, which was an aversive air-puff for experimenters and an observable action for observers. Our findings suggest that an experienced cue favors robust generalization, whereas an observed cue favors rapid learning."
2,232756,2," Part of our findings are in line with social learning theories which suggest that to learn from others is a successful strategy with high payoff under a wide range of conditions25,26. However, our findings also suggest a limitation to the ubiquitous success of social learning strategies. Namely, we find that social learning can lack robustness when environmental conditions even slightly change. As in the case of children who perform poorly in exams after neglecting their homework, insights gained through observation seem not to transfer well to new task instances."
3,232756,3," Currently, there is no reason to think that all forms of observation learning will be subject to lack of robustness. For example, it is not clear that male zebra finches would exhibit similar behaviors given the known sex differences in social learning27 also in airpuff paradigms28. Furthermore, it is not clear whether our findings will generalize to other reinforcers including reward and strong punishment (e.g. by electric shock). It is even uncertain whether to be observed played a role for experimentersí robust learning. In the light of all these possibilities, our work raises the question as to whether there exist some forms of observation learning that promote robust transfer to new task instances."
4,232756,4," Our work raises many interesting questions on the behavioral and neurobiological mechanisms used by observers to acquire stimulus-discriminative information. Behaviorally, observers could learn through social mechanisms of action imitation, of observational conditioning, and of stimulus enhancement, or a combination of these. Note that the definitions of these mechanisms are not strict enough to allow a discrete categorization of social learning in any one study29. Our findings de-emphasize some known social learning mechanisms such as perceptual learning (evidenced by PL learners) and simple stimulus enhancement (evidenced by lack of discriminative behavior during pre-testing, Supplementary Figure 3). Our experiments also de-emphasize vocal communication as a mechanism but reveal the importance of vision (-TCOM learners). Overall, the importance of a demonstrating expert suggests that experimenters signal statistical differences between puffed and unpuffed stimuli via their perching behavior such as their rates of leaving the perch. Possibly, observers focused their attention more on the diverse†actions of experimenters and their relationships with the stimuli, which is why observers apparently failed to identify the simplest environmental signal that can explain experimentersí behavior, which in our case was syllable duration."
5,232756,5," Similar speed-robustness learning tradeoffs as the one we find exist in rapidly evolving artificial systems, in which high discrimination performance tends to be associated with slow learning as an unwanted side effect30. The tradeoff we find between robustness in one learning paradigm and speed in another is most closely paralleled by regularization methods that control inference through synaptic weight subtraction. Excellent generalization of experimenters agrees with strongly regularized classifiers whereas fast learning in observers agrees with weakly regularized classifiers. Our work suggests that the benefits of regularization may be inherent to experimenting but not to observing31."
6,232756,6," It is far from clear how a brain could implement dynamic regularization. Our speculative proposal is that the balance between learning and regularizing is controlled by a neuromodulatory signal. Such signals are ubiquitous in the animal kingdom and are well suited to convey the amount of regularization, given that they respond sensitively to external reinforcements and their prediction errors32ñ36. One possibility is that air-puff reinforcers drive changes in regularization via experimentersí escape actions, which is supported by the representation of action-specific reward values in brain areas innervated by neuromodulatory neurons37. This proposal delineates a possible neural system for comparative studies of learning from experience and from observation. It has been shown that reward prediction error and reinforcement learning algorithms in general, may be utilized by humans in order to understand the social value of othersí behavior38,39, to feel vicarious rewards from their success or failure40 or from their approval41. We believe that the computational role of reward prediction error can be extended to that of regularization of learning, mediated by neuromodulator systems such as acetylcholine†or dopamine. Furthermore, subtractive weight depression through heterosynaptic competition has been observed in the amygdala31, which provides biological plausibility to L1 regularisation in the brain. We hypothesize that some form of synaptic depression is seen in zebra finches when they are experimenting, but not†when they are observing."
7,232756,7," The speculative implications of our simulations are that a prerequisite for the evolution of observation learning was a sufficiently large brain capacity that provided rich sensory representations and put few constraints on usable neural resources for sensory processing. Evolution might have chosen traits in observers that are complementary to those associated with experimenting, explaining the apparent differences in what these learning strategies extract from the sensory environment."
8,1789181,0,"In this paper, we propose a biologically plausible SOM-SNN framework for automatic sound classification. This framework integrates the auditory front-end, feature representation learning and temporal classification in a unified framework. Biological plausibility is a key consideration in the design of our framework, which distinguishes it from many other machine learning frameworks."
9,1789181,1," The SOM-SNN framework is organized in a modular manner, whereby acoustic signals are pre-processed using a biologically plausible auditory front-end, the mel-scaled filter bank, for frequency content analysis. This framework emulates the functionality of the human cochlea and the non-linearity of human perception of sound (Bear et al., 2016). Although it is still not clear how information is represented and processed in the auditory cortex, it has been shown that certain neural populations in the cochlear nuclei and primary auditory cortex are organized in a tonotopic fashion (Pantev et al., 1995; Bilecen et al., 1998). Motivated by this, the biologically plausible SOM is used for the feature extraction and representation of mel-scaled filter bank outputs. The selectivity of neurons in the SOM emerges from unsupervised training and organizes in a tonotopic fashion, whereby adjacent neurons share similar weight vectors. The SOM effectively improves pattern separation, whereby each sound frame originally represented by a 20-dimensional vector (mel-scaled filter bank output coefficients) is translated into a single output spike. The resulting BMU activation sequences are shown to have the property of low intra-class variability and high inter-class variability. Consequently, the SOM provides an effective and sparse representation of acoustic signals as observed in the auditory cortex (Hrom√°dka et al., 2008). Additionally, the feature representation of the SOM was shown to be useful inputs for RNN and LSTM classifiers in our experiments."
10,1789181,2," Although the SOM is biologically inspired by cortical maps in the human brain, it lacks certain characteristics of the biological neuron, such as spiking output and access to only local information. Other studies (Rumbell et al., 2014; Hazan et al., 2018) have shed light on the feasibility of using spiking neurons and spike-timing dependent plasticity (STDP) learning rule (Song et al., 2000) to model the SOM. We would investigate how we may integrate the spiking-SOM and the SNN classifier for classification tasks in the future."
11,1789181,3," Acoustic signals exhibit large variations not only in their frequency contents but also in temporal structures. State-of-the-art machine learning based ASC systems model the temporal transition explicitly, using the HMM, RNN or LSTM, while our work focuses on building a biologically plausible temporal classifier based on the SNN. For efficient training, we use supervised temporal learning rules, namely the membrane-potential based Maximum-Margin Tempotron and spike-timing based ReSuMe. The Maximum-Margin Tempotron (combining the Tempotron rule with the maximum-margin classifier) ensures a better separation between the positive and negative classes, improving classification accuracy in our experiments. As demonstrated in our experiments, the SOM-SNN framework achieves comparable classification results on both the RWCP and TIDIGITS datasets against other deep learning and SNN-based models."
12,1789181,4," We further discover that the SNN-based classifier has an early decision making capability: making a classification decision when only part of the input is presented. In our experiments, the SNN-based classifier achieves an accuracy of 95.1%, significantly higher than those of the RNN and LSTM (25.7% and 69.2% respectively) when only 50% of the input pattern is presented. This early decision making capability can be further exploited in noisy environments, as exemplified by the cocktail party problem (Haykin and Chen, 2005). The SNN-based classifier can potentially identify discriminative temporal features and classify accordingly from a time snippet of the acoustic signals that are less distorted, which is desirable for an environment with fluctuating noise."
13,1789181,5," Environmental noise poses a significant challenge to the robustness of any sound classification systems: the accuracy of many such systems degrade rapidly with an increasing amount of noise as shown in our experiments. Multi-condition training, whereby the model is trained with noise-corrupted sound samples, is shown to overcome this challenge effectively. In contrast to the DNN and SVM classifiers (McLoughlin et al., 2015), there is no trade-off in performance for clean sounds in the SOM-SNN framework with multi-condition training; probably because the classification decision is made based on local temporal patterns. Additionally, noise is also known to exist in the central nervous system (Schneidman, 2001; van Rossum et al., 2003) which can be simulated by spike jittering and deletion. Notably, the SOM-SNN framework is shown to be highly robust to such noises introduced to spike inputs arriving at the SNN classifier."
14,1789181,6," The SNN classifier makes a decision based on a single local discriminative feature which often only lasts for a fraction of the pattern duration, as a direct consequence of the Maximum-Margin Tempotron learning rule. We expect improved accuracy when more such local features within a single spike pattern are utilized for classification, which may be learned using the multi-spike Tempotron (G√ºtig, 2016; Yu et al., 2018). The accuracy of the SOM-SNN model trained with the ReSuMe learning rule may also be improved by using multiple spike times. However, defining these desired spike times is a challenge exacerbated by increasing intra-class variability. Although the existing single-layer SNN classifier has achieved promising results on both benchmark datasets, it is not clear how the proposed framework may scale for more challenging datasets. Recently, there is progress made in training multi-layer SNNs (Lee et al., 2016; Neftci et al., 2017; Wu et al., 2018b), which could significantly increase model capacity and classification accuracy. For future work, we would investigate how to incorporate these multi-spike and multi-layer SNN classifiers into our framework for more challenging large-vocabulary speech recognition tasks."
15,1789181,7," For real-life applications such as audio surveillance, we may add inhibitory connections between output neurons to reset all neurons once the decision has been made (i.e., a winner-takes-all mechanism). This allows output neurons to compete once again and spike upon receipt of a new local discriminative spike pattern. The firing history of all output neurons can then be analyzed so as to understand the audio scene."
16,1789181,8," The computational cost and memory bandwidth requirements of our framework would be the key concerns in a neuromorphic hardware implementation. As the proposed framework is organized in a pipelined manner, the computational cost could be analyzed independently for the auditory front-end, SOM and SNN classifier. For the auditory front-end, our implementation is similar to that of the MFCC. As evaluated in Anumula et al. (2018), the MFCC implementation is computationally more costly compared to the spike trains generated directly from the neuromorphic cochlea sensor. Our recent work (Pan et al., 2018) proposes a novel time-domain frequency filtering scheme which addresses the cost issue in MFCC implementation. We expect the SOM to be the main computational bottleneck of the proposed framework. For each sound frame, the calculation of the Euclidean distance of synaptic weights from the input vector is done for each SOM neuron. Additionally, the distances are required to be sorted so as to determine the best-matching units. However, this computational bottleneck can be addressed with the spiking-SOM implementation (Rumbell et al., 2014; Hazan et al., 2018), whereby the winner neuron spikes the earliest and inhibits all other neurons from firing (i.e., a winner-takes-all mechanism) and hence by construction, the BMU. The spiking-SOM also facilitates the implementation of the whole framework on a neuromorphic hardware. In tandem with the SNN classifier, a fully SNN-based framework when implemented would translate to significant power saving."
17,1789181,9," As for memory bandwidth requirements, the synaptic weight matrices connecting the auditory front-end with the SOM and the SOM with the SNN classifier are the two major components for memory storage and retrieval. For the synaptic connections between the auditory front-end and the SOM, the memory bandwidth increases quadratically with the product of the number of neurons in the SOM and the dimensionality of the filter banks. Since the number of output neurons is equal to the total number of classes and hence fixed, the memory bandwidth only increases linearly with the number of neurons in the SOM. Therefore, the number of neurons in the SOM should be carefully designed for a particular application considering the trade-off between classification accuracy and hardware efficiency."
18,271920,0,"In the current study, we compared bilinguals' and monolinguals' performance during a nonlinguistic learning task that involved mapping tones to symbols within a novel symbolic system that consisted of three distinctive features (timbre, pitch, and duration). Both learning and subsequent processing were examined in bilinguals vs. monolinguals. Subtle differences were evident across the two groups, particularly in the processing domain. These findings suggest that, even when bilingual advantages are not present, bilinguals may differ from monolinguals on tasks that resemble lexical mapping and involve competition resolution."
19,271920,1,"Acquisition of novel tone-to-symbol mappings in bilinguals vs. monolinguals \n  On the sound-to-symbol matching task, bilinguals did not show a learning advantage. These results are consistent with previous findings that bilingual learning advantages may be determined by how the novel information relates conceptually to the previously established language systems. For example, Kaushanskaya and Rechtzigel (2012) suggest that learning of a novel word that is tied to a concrete (vs. abstract) translation equivalent will more widely activate bilinguals' previous two languages and may thus yield a more facilitative context for learning and integration of new knowledge. In contrast to Kaushanskaya and Rechtzigel's concrete learning condition, the current study required participants to map a new symbolic system in the absence of relevant previous conceptual representations. In this sense, the current study may be likened to an extreme version of Kaushanskaya and Rechtzigel's abstract word learning condition, and is consistent with the prediction that bilinguals may only outperform monolingual learners if their previous knowledge can be directly employed to scaffold new learning. \n  Perhaps because our task does not relate to bilinguals' previous language knowledge, the current findings stand in contrast with a previous nonverbal learning task where bilinguals showed advantages in learning a Morse code system (Bartolotti et al., 2011). One possible explanation for the absence in auditory processing advantages in the present study is that the current bilinguals had no previous language-based experience with the pitch, timbre, and duration dimensions in the current study, and in fact performed equivalently to monolinguals when learning these dimensions. Indeed, previous research has suggested that bilingual experience may reconfigure attention to linguistic and extralinguistic cues in the environment based on their relevance in previous learning experiences (e.g., Deutsch et al., 2004; Bialystok et al., 2005; Brojde et al., 2012). While natural language processing relies on listeners' capacity to make distinctions between pitch, timbre (i.e., formant structure) and duration, it is possible that the nature and constellation of these dimensions was too far removed from English-Spanish processing to allow for transfer of skills. For example, it is possible that Spanish-English bilinguals have some previous training on the fine-grained duration dimension that was critical in Bartolotti et al.'s learning task, given their awareness of temporal phonetic characteristics across their two languages, such as voice onset time discrimination in English vs. Spanish (e.g., Ju and Luce, 2004). However, the challenging combination of pitch, timbre, and duration dimensions may have differed from their previous linguistic experiences and clouded potential subtle advantages (e.g., Krumanshl and Iverson, 1992). \n  It is also possible that subtle cognitive differences between bilinguals and monolinguals contributed to advantages on Bartolotti et al.'s learning task but not the current learning task. For example, bilingualism has previously been associated with advantages in auditory working memory (e.g., Adesope et al., 2010), and such advantages in working memory may in turn be linked to statistical learning success (Misyak and Christiansen, 2012). While Bartolotti et al. did not include an auditory working memory task (only a forward digit span task was included), bilinguals in the current study did not differ from their monolingual peers on an auditory backward digit span measure. Yet, auditory working memory skills may in part account for bilinguals who were not successful learners. Specifically, across all linguistic and cognitive measures, follow-up analyses did not yield significant differences between unsuccessful (<65% accuracy) and successful (>65% accuracy) bilingual learners, with only a marginal difference in numbers reversed present between the two groups (p = 0.076). While no significant correlation was present between post-training accuracy and numbers reversed in the bilingual non-learners (r = 0.33, p > 0.1), this working memory difference nevertheless may have contributed to learning outcomes. In fact, a positive correlation between overall accuracy and numbers reversed skills was present across all bilingual learners and non-learners (r = 0.4, p = 0.01). It is thus possible that reliance on working memory within the bilingual group was in part responsible for the larger proportion of weaker bilingual learners. Working memory has previously been linked to learning outcomes (e.g., Papagno and Vallar, 1995), and lower working memory in the current bilingual sample was also associated with lower PPVT scores (r = 0.4, p < 0.05, for similar findings, see Kaushanskaya et al., 2011). No such correlations were found in monolinguals (working memory and training outcomes: r = 0.04, p > 0.5; working memory and vocabulary: r = 0.17, p > 0.4). \n  Beyond auditory working memory, several factors may account for the low tone-to-symbol mapping accuracies in the bilingual non-learners. In fact, combined learning of novel auditory and visual information was challenging for most participants (see post-training accuracies). For example, the length of both the training and processing phases required sustained attention and thus motivation to perform well. It may therefore be that sustained attention skills in general differentiated learners from non-learners, a possibility that can be explored in future research. Interestingly, while Spanish skills and language immersion were not significantly related to learning outcomes in the successful bilingual learners, in the bilingual non-learners higher Spanish skills and less English exposure were related to more successful learning (TVIP: r = 0.68, p < 0.05; English exposure: r = ?0.83, p < 0.01). Of the non-learners, 9 were Spanish-English bilinguals, one was a simultaneous bilingual, and one was an early English-Spanish bilingual. Thus, in the bilinguals who struggled to learn, skill in the native language appeared to support tone-to-symbol mapping. The reason for this observed link between L1 vocabulary and learning performance in monolinguals and bilingual non-learners may be that underlying cognitive strengths facilitate both vocabulary acquisition and better task performance. It is possible that L1 vocabulary is a particularly strong indicator of underlying word learning skills while L2 vocabulary may be more context-specific and thus a reflector of experience more than word-learning skills per se. In sum, the current findings contribute to limiting the scope of bilingual learning advantages. Further they raise new questions on the nature of bilingual learning advantages, as well as pre-requisite cognitive-linguistic skills, perhaps suggesting that aspects of bilingualism may provide richer opportunities for scaffolding during specific new learning contexts, but that bilingual experience may not modulate fundamental learning mechanisms."
20,271920,2," Sound-to-symbol processing differences between bilinguals and monolinguals \n  Studying processing of newly-learned nonlinguistic information can eliminate group differences in content knowledge associated with bilingual status, thus providing an opportunity to compare competition resolution across groups in the absence of proficiency effects. Current findings across bilinguals and monolinguals that were equivalent on learning outcomes suggest subtle processing differences between the two groups. These differences emerged only when we examined the relation between sound-to-symbol retrieval and previous vocabulary knowledge and when the time course of inhibitory control was considered. \n  During the processing task, the bilinguals and monolinguals, who had attained similar skill levels with the new symbol system, also showed similar symbol retrieval efficiency. Moreover, consistent with previous explanations of bilingual retrieval disadvantages (e.g., Ivanova and Costa, 2008; Gollan et al., 2011b), participants who had attained lower learning outcomes on the novel tone-to-symbol system also showed less efficient retrieval skills. This relation between learning success and subsequent retrieval efficiency was present to an equal extent in both bilinguals and monolinguals, mimicking previous patterns from linguistic tasks (Gollan et al., 2008; Whitford and Titone, 2012), and confirming that less robust learning of content influences sound-to-content links and shapes retrieval success. \n  While retrieval efficiency could be in part explained by previous learning success in both bilinguals and monolinguals, a stronger link was identified between previous vocabulary knowledge and tone-to-symbol retrieval in the monolingual group. Specifically, in monolinguals, learners who had stronger English receptive vocabulary skills (as indexed by the PPVT) also were more efficient in retrieving sound-to-symbol mappings in the processing environment where these items had to be identified from competing alternatives. This association between receptive vocabulary knowledge and retrieval efficiency was not limited to trials with competitor items, but was found across competitor and no-competitor trials. These findings suggest that competition resolution during tone-to-symbol mapping was not modulated by previous receptive vocabulary. Rather, it appears that the ability to efficiently identify a newly-learned sound-to-symbol mapping among four alternatives was positively influenced by previous vocabulary. It is thus possible that skills that aid in the mapping of new vocabulary transferred to the novel task. Further, this effect also persisted during monolinguals' priming trials, perhaps suggesting that higher-vocabulary monolinguals used fewer cognitive resources during sound-to-symbol trials, allowing quicker responses on priming probes, or that higher-vocabulary monolinguals deployed attentional processes more efficiently in orienting toward relevant information on the displays. \n  In contrast to monolinguals, no association was found between bilinguals' English receptive vocabulary and their performance on the sound-to-symbol mapping or priming trials. When combined English/Spanish or Spanish-only receptive vocabulary skills were considered, this association was not significantly strengthened. It is possible that, in monolinguals, a more centralized and less distributed lexical system may better capture general word learning skills and related cognitive factors that might contribute to mapping a new symbolic system. It is possible that since, in bilinguals, vocabulary skills are frequently more context-specific due to language immersion tied to specific social settings, it is more challenging to index their core vocabulary knowledge through standardized measures such as the ones employed here. As a result, core knowledge that may point to underlying word learning skills was perhaps not as successfully indexed in the bilinguals. Alternatively, it is possible that bilinguals, due to word-learning experiences across linguistic contexts, may have word mapping skills that are not necessarily associated with their overall word knowledge. Interestingly, in the bilinguals who did not succeed on the learning task, a link between Spanish receptive vocabulary and sound-to-symbol mapping success was in fact evident. These findings must be treated with care given the small sample of bilingual non-learners (n = 11). Yet, they speak to a shared scaffolding mechanism for newly learned sound-to-symbol mappings in monolinguals and bilinguals. Additional research is needed to examine L1 and L2 lexical contributions to novel word learning in bilinguals. In sum, the ability to identify tone-to-symbol targets among competing options was modulated by different yet related variables in bilinguals and monolinguals, with learning success predicting retrieval efficiency in both groups, but with previous vocabulary knowledge predicting symbol retrieval efficiency more in monolinguals than bilinguals. \n  In addition to similarities in retrieval skills, monolinguals and bilinguals also showed similar competition effects within the novel symbol system. Findings of similar competition effects in monolinguals and bilinguals are consistent with previous language studies where linguistic competition resolution was examined and similar competition resolution patterns were found in the two groups (e.g., for lexical competition during word recognition, see Blumenfeld and Marian, 2011; for competition within a sentence context, see Paap and Yunyun, 2014). In the linguistic domain, comparisons of competition effects in bilinguals vs. monolinguals may be influenced by group differences in experience and proficiency, potentially obscuring bilingual advantages in competition resolution. However, the current findings suggest that, based on equivalent training and attainment, competition effects prior to target identification continue to have the same magnitude in the two groups. \n  Further, competition effects were not modulated by previous vocabulary knowledge or by learning success. These results are consistent with previous findings that language-based competition effects may not be modulated by proficiency during naming (e.g., see Marian et al., 2013, for equivalent Stroop effects across trilinguals' languages with varying proficiency levels). Similarly, Marian and Spivey (2003) found comparable lexical competition effects in L1 and L2 during auditory word identification in proficient late bilinguals. Nevertheless, other sources suggest that, in bilinguals, conflict monitoring skills may be honed to better identify ambiguities as they arise (e.g., Abutalebi et al., 2012). It is possible that novel representations must be more established before effects of previous experience on competition resolution can become visible. As might be expected in very novice learners who might show more variability in responses (e.g., Hulstijn et al., 2009), considerable variability across items and participants may have occluded subtle influences on competition effects at this early stage of learning. As such, a possible relation between competition resolution and previous vocabulary can be examined at various proficiency levels in future research. \n  While competition effects were similar in bilinguals and monolinguals, subtle group differences emerged in the nature of inhibition mechanisms that were deployed to resolve this competition. At 200 ms post-target identification, significant competitor inhibition effects were identified for bilinguals, with somewhat less robust inhibition effects in monolinguals. Interestingly, smaller Stroop inhibition effects were associated with less residual competitor inhibition at 500 ms post-target identification for bilinguals, with no such correlations in monolinguals. This correlation is suggestive of a time window where inhibition may be gradually lifted, given the absence of significant inhibition effects at this time. Together, it appears that inhibition effects lingered somewhat longer in bilinguals. These findings are consistent with Treccani et al. (2009)'s findings on a nonlinguistic priming task, and suggest that bilinguals may exert somewhat stronger inhibition effects than monolinguals to separate competitors from targets in novel symbolic processing environments. \n  While in the nonlinguistic domain findings suggest that bilinguals may maintain inhibition longer than monolinguals, a different pattern may be present in the linguistic domain. In a linguistic context that is analogous to the current study, Blumenfeld and Marian (2011) showed inhibition of linguistic competitors at 500 ms post-target identification for monolinguals but not bilinguals. Instead, a correlation was present where bilinguals with smaller Stroop effects showed less residual competitor inhibition at 500 ms post-target identification. Therefore, while the timecourse of inhibition appears identical across nonlinguistic and linguistic domains in bilinguals, monolinguals show more sustained inhibition effects in the linguistic domain. Additional research is needed to better explicate this difference across modalities. It is possible that, as bilinguals become more proficient with content knowledge (as is the case in the linguistic domain), they may show faster competition resolution, also leading to earlier release of inhibition mechanisms post-target identification (e.g., Mishra et al., 2012). Monolinguals may sustain inhibition longer in a linguistic environment to protect against intrusion from similar-sounding words, while bilinguals may release such inhibition sooner to allow for language switches. As was the case for competition resolution prior to target identification, the magnitude of residual inhibition effects post-target identification was not modulated by experiential factors. These findings suggest that, at least for newly-learned symbolic information, the magnitude of inhibition may not be related to linguistic knowledge per se but may relate to participants' domain-general cognitive skills."
21,271920,3," Together, findings from the linguistic and nonlinguistic processing domains suggest that, while bilinguals and monolinguals are very similar in their efficiency of competition resolution (as indexed by response efficiency on tone-symbol mapping trials with vs. without competitors), they show subtle differences in the time course along which they maintain inhibition after word identification. In turn, as in Blumenfeld and Marian (2011), bilinguals and monolinguals showed equivalent magnitudes of target facilitation during the time immediately following target identification. It is likely that target facilitation acts as a competition resolution mechanism that complements inhibition of irrelevant information (e.g., Paradis, 2004), and previous work suggests that it outlasts inhibition effects across time (Tanaka and Shimojo, 2000). The current findings where residual activation was probed at three times post-target identification, confirm these patterns."
22,2617564,0,"The present results replicate and extend reports by Stilp et al. [22] of rapid efficient coding of redundancy among acoustic dimensions in novel complex sounds. Three manipulations, each of which attenuates correlation among attributes, were tested separately to examine the perceptual significance of each. Overall, simple strength of the primary correlation (principal component) is inadequate to predict listener performance. Initial superiority of discrimination for statistically consistent sound pairs was relatively insensitive to truncation of evidence supporting the correlation (Experiment 2) and to increases in the frequency of Orthogonal test trials (Experiments 4, 5). However, increased evidence of an orthogonal dimension provided by greater acoustic/psychoacoustic range (Experiment 3) proved highly salient, resulting in equivalent discrimination performance throughout the experiment."
23,2617564,1," Patterns of performance cannot be explained by independent weighting of acoustic dimensions (AD, SS), as changes in discriminability can only be attributed to the correlation or covariance orthogonal to it. This perceptual adherence to derived statistical structure, and not physical acoustic dimensions per se, is not without precedent. There is good evidence that auditory cortical representations decreasingly correspond to physical stimulus dimensions [37]ñ[39]. Wang [39] refers to this as ìnon-isomorphicî transformations of the input. Examples of non-isomorphic stimulus representations in auditory cortex include encoding spectral shape across varying absolute frequencies [38], gross representation of rapid change in click trains with short inter-click intervals versus phase-locking to trains with slower inter-click intervals [40], [41], and encoding pitch versus individual frequency components [42], [43]. Such non-isomorphic transformations may be similar to the loss of acoustic dimensions (AD, SS) seen here, as more efficient dimensions better capture perceptual performance. Results are in agreement with Stilp and Kluender [44], who report efficient coding of redundant acoustic dimensions in the face of unrelated variability in a third acoustic feature."
24,2617564,2," Optimal combination and weighting of individual stimulus dimensions has received considerable attention in vision research. Models of Bayesian inference and ideal perceptual performance have been shown to effectively capture aspects of perception of objects [45], [46], edges [47], movement [48], and slant or orientation [49]ñ[52]. These ideal observer models have been extended to perceptual combination of sensory cues from different modalities, such as integrating visual and auditory cues to location [53], visual and motor cues to performing certain actions [54]ñ[57], and visual and haptic cues to height [58], shape [59], and even thoroughly trained arbitrary associations such as one between luminance and stiffness [19]."
25,2617564,3," Three important points distinguish these earlier studies from the present findings in auditory perception. First, such studies often must address inherent weights or biases ascribed to each cue. For example, visual information is habitually weighted more heavily than auditory or haptic information. Here, acoustic dimensions AD and SS were adjusted through extensive control studies to be equally available perceptually, so a priori perceptual weights are equated. Second, many cue weighting studies examine performance as a function of relative noisiness (relative ?) of respective cues. Sensibly, when multiple cues are available but one is or becomes more noisy (larger ?), perceptual weights are greater for less noisy cues that better inform behavior. Optimal cue combination occurs when one cue (typically the one weighted more heavily absent experimental manipulation) is made noisier and perceptual weights shift toward a less noisy source of information (e.g., making the visual signal noisier and observing increased weight attributed to haptic information [58]). Cues AD and SS share equal psychoacoustic variability as measured by JNDs. Third and most importantly, these examples from vision or multimodal research demonstrate optimal weighting of individual physical stimulus dimensions. The present findings indicate optimal weighting of derived dimensions that capture statistical relationships between attributes. This likely suggests a more sophisticated level of processing than that observed for reports of combination or integration of individual physical stimulus cues."
26,2617564,4," Behavioral results were consistently predicted by the PCA network model [26]. Perceptual processes first capture the principal component of variation in the two-dimensional stimulus space at the expense of the orthogonal component [22]. From listener performance and models, it appears that both principal and second components become weighted proportional to the amount of variance accounted for by each. In the stimulus sets tested here, this entailed relatively modest weights on the second component, corresponding to initially reduced discriminability. Following further exposure to the stimulus set, variance not explained by the principal correlation is detected and exploited, improving discrimination of Orthogonal sound pairs back to baseline levels. Only when evidence for the orthogonal dimension was increased through greater covariance not shared with the principal component (Experiment 3) was sufficient weight attributed to the second component, extinguishing early differences in discriminability. Otherwise, given that correlations tested here were attenuated in different manners, simulations primarily varied in how the initial decrease in Euclidean distance between Orthogonal stimuli gets smaller and/or recovery to baseline distances occurs sooner."
27,2617564,5," One shortcoming of Sanger's [26] network model is that it assumes the correlation matrix of the inputs. PCA can operate over either a correlation or covariance matrix, and there are reasons to prefer a covariance matrix for psychoacoustically-normed experimental materials employed here. The predictive power of the PCA model [26] was improved when modified to operate on the covariance matrix of the input rather than the correlation matrix. The modified model provided predictions that better fit listener performance. Further, Eigenvalues from covariance- but not correlation-based PCA analyses closely reflect listener performance (Table 1). Greater Eigenvalues on the second component (orthogonal to the main correlation) predicted better discrimination of orthogonal variation. At least for these stimuli, covariance among acoustic attributes appears to be a better estimate of perceptual performance than correlation, but given markedly different ways to manipulate covariance captured by a particular component in PCA (stimulus addition/deletion, over/undersampling, etc.), further studies are required to better understand this relationship."
28,2617564,6," The particular PCA model investigated here [26] is certainly oversimplified and is unlikely to precisely reflect neural learning mechanisms. Dimensions of AD and SS are almost certainly encoded across a large number of neurons and not the localist representation tested here. A more serious challenge is to identify neurally plausible mechanisms for instantiating PCA-like performance. Conceivably, circuitry of auditory cortical and association areas may provide the required connectivities. Precortical processes might also be implicated, given that PCA has proven practical for depicting correlations across neurons in the vibrissal sensory area of rat thalamus [60]. Lower subcortical auditory nuclei are also candidates given that, relative to the visual system, much more processing (more synapses and hence greater neural recoding) occurs within the brainstem before cortex [37]. Identification of neural substrates supporting perceptual changes demonstrated here and by Stilp and colleagues [22] would facilitate development of more authentic computational models."
29,2617564,7," The present experiments have investigated how listeners adapt to strong covariance structure coupled with varying types of orthogonal variation. This form of structure is particularly amenable to decomposition via PCA, but other models are better suited for a broader array of cases such as those presented by statistical distributions for some speech sounds (e.g. distributions of vowels in formant (F1-F2-F3) space are not orthogonal). For extraction of independent dimensions that are not necessarily orthogonal, techniques such as linear independent component analysis (ICA), which efficiently encodes structure into latent components that minimize mutual information (redundancy) between outputs (e.g., [61]), may provide a better statistical analog to perceptual organization."
30,2617564,8," The present results could provide insights into models of perceptual organization for complex sounds such as speech. While the novel sounds tested here only varied along two complex dimensions, patterns of covariance naturally scale to high-dimensional feature spaces. In complex natural stimuli such as speech, multiple forms of stimulus attribute redundancy exist concurrently and successively [20], [21], [62]ñ[65]. To the extent that patterns of covariance among acoustic attributes in natural sounds are efficiently coded, the present results may inform how the auditory system exploits different patterns of redundancy to learn and distinguish different speech sounds."
31,2617564,9," While some have suggested the importance of correlations among stimulus attributes are central to perceptual organization for speech [22], [63], [66]ñ[68], it has been more common to emphasize 1st-order statistics (e.g., probability density) as a means to characterize distributions of speech sounds [69]ñ[73] or cues [74]ñ[77]. In experiments that oversampled the Orthogonal sound pair (Experiments 4 and 5), manipulations of probability density had little to no effect on patterns of performance. At least in this particular paradigm, higher-order redundancy (covariance) was more perceptually salient than lower-order redundancy (probability density). Future research that explores relative influences of these different types of statistical structure will inform models of perceptual organization and categorization of speech."
32,2617564,10," Covariance among complex acoustic attributes in novel stimuli is exploited quickly and automatically in the present experiments. Perception only later comes to encode residual variability in ways that reflect optimal statistical weighting of covariance not accounted for by the principal component of the stimuli. Results illuminate stimulus characteristics that support coding of stimulus redundancy that is rapid, unsupervised, efficient, and statistically optimal."
33,1911559,0,"The current study used a novel category?learning task to examine the effects of unisensory and multisensory cues on incidental category learning across middle childhood. As expected, the results indicate a significant improvement in incidental learning from 6 to 10†years of age. In addition, as early as 6†years of age in this study, children demonstrated greater performance on an incidental categorization task following exposure to multisensory (audiovisual) cues compared to unisensory information (visual or auditory alone)."
34,1911559,1," Multisensory information has previously been shown to improve encoding (Bahrick & Lickliter, 2012) and better facilitate subsequent learning compared to unisensory stimulation in children as young as 3 to 4†years of age (Jordan & Baker, 2011). Similarly, on speeded RT tasks, children as young as 4†years of age were able to integrate audiovisual information to improve performance to a greater extent than with the presentation of unimodal stimuli, but were less efficient than older children and adults (Nardini et†al., 2015). Other developmental studies that have examined multisensory integration on tasks that did not require speeded responses also report the pooling of bimodal signals to be sub?optimal until even later in childhood, around 8 to 12†years of age (Gori et†al., 2008; Gori et†al., 2012; Nardini et†al., 2010; Nardini et†al., 2008; Petrini et†al., 2014). In sum, such findings suggest that although multisensory information may be pooled to a certain extent at this young age, mature integration of bimodal signals undergoes a more protracted developmental course."
35,1911559,2," The emphasis in the current study was on incidental category learning during a sustained attention task. This differed from the aforementioned previous studies and their focus on developmental changes in the pooling of redundant cues on explicit learning or perceptual tasks. Incidental acquisition of information occurs across multiple learning tasks in educational environments (Postman, 1964), and is therefore an important area of focus for research examining the role of multisensory stimuli on learning. In the current study, the simultaneous presentation of complementary visual and auditory information, in which both features were informative to family membership, resulted in enhanced performance on the incidental learning of categories across all age groups."
36,1911559,3," Although no significant interaction between age and learning condition was found, others have found that the pooling of multisensory cues may become more advanced with age (Barutchu et†al., 2009; Gori et†al., 2008; Gori et†al., 2012). The emphasis on learning in the current study may therefore underlie the differences in findings from studies examining the development of pooling bimodal cues. That said, despite a lack of reliable difference in the pattern of performance with age in the current study, some age?related changes in the benefits of multisensory cues were identified. For instance, performance on the category identification task following audiovisual learning positively correlated with age, and with a trend for a positive relationship between age and auditory?only learning. In contrast, performance following visual?only learning did not correlate with age. These results are therefore somewhat in line with previous findings that argue for a refining of the ability to use multisensory information across this age span (e.g., Nardini et†al., 2015). This would afford the conclusion that the use of multisensory cues for learning may still undergo some development during the primary school years. Of note, however, is that there was also a trend for improved performance with age in the auditory?only condition, suggesting that these findings may reflect age?related changes in the use of auditory information to support learning. This is particularly supported by our findings that 6?year?olds performed at chance following learning with auditory?only cues, but above chance with visual and audiovisual cues. Others have also reported age?related improvements in auditory processing throughout childhood and into adolescence that may affect responses to perceptual training (Huyck & Wright, 2013). Similarly, differences in the processing of visual and auditory stimuli with age have been seen on multisensory tasks, with children and adolescents, compared to adults, showing reduced processing of auditory distractors compared to visual and bimodal (Downing, Barutchu, & Crewther, 2014)."
37,1911559,4," In this study, therefore, although younger children used visual information (both in the visual?only and multisensory conditions) to the same level as older children, changes with age were seen in the extent to which auditory cues were considered useful for learning. Initially, this could be considered a matter of cue saliency, with the auditory stimuli not having been as salient as the visual information. However, this explanation is contested by our seemingly contradictory findings that children at this age were less able to discriminate between visual targets than between auditory exemplars, but with an equal level of discriminability between the different modality exemplars above 8†years of age. Furthermore, no differences in categorical learning were found between unisensory visual and auditory cues in any group in this study, including 6?year?olds, suggesting that visual and auditory stimuli were equally salient and usable."
38,1911559,5," As an alternative explanation, the findings may allude to a visual processing bias in younger children. This is in contrast to findings of an auditory processing dominance in young children, with a change to visual dominance in older children and adults (Napolitano & Sloutsky, 2004; Sloutsky & Napolitano, 2003). By 4†years of age there is some flexibility observed in terms of modality dominance that is dependent on the task demands, wherein stimuli are only processed in the preferred modality when different sensory cues are of equal salience (Robinson & Sloutsky, 2004). Therefore, children aged 6†years may already demonstrate visual dominance on tasks such as the one presented here. Given that no age and condition interactions were identified, however, such conclusions can only be met tentatively. Indeed, it is also worth noting that neither of the oldest two groups demonstrated this visual processing dominance, despite robust findings of visual modality dominance in older children and adults on other tasks (Koppen & Spence, 2007; Sinnett, Soto?Faraco, & Spence, 2008; Spence, 2009)."
39,1911559,6," As well as an analysis of group differences on an incidental category?learning task, we also reported the findings from the attention trials on the main MALT task. Here, no differences were found across the different MALT learning conditions, suggesting that effects of condition in incidental learning were not related to the attentional aspects of the original task. Although differences were seen between age groups, all groups demonstrated a comparable pattern of performance."
40,1911559,7," Furthermore, although 6?year?olds required more trials to criterion, all participants included in the analyses experienced a total of 50 target exemplars travelling to the two habitats before the category task was presented. Analyses of these learning task parameters therefore only highlight age group differences rather than differences across learning conditions. This is in line with what would be expected on measures of sustained attention in these age groups. As such, age?related differences on this aspect of the task likely reflect improvements in speed of processing visual and auditory information, developmental changes in levels of inhibition (Levy, 1980), as indicated in a reduction in commission errors, and improved attention, as measured by decreasing omission errors, from the youngest to oldest age groups."
41,1911559,8," As well as a measure of incidental category learning, the current study examined explicit categorical knowledge across groups. A difference was found in the pattern of performance in the incidental learning compared to the explicit knowledge tests, with no effect of condition observed in the latter, and the youngest children (6?year?olds) demonstrating particular difficulty in expressing correct categorical information. While no feedback was given on the incidental categorization task, this finding may be related to the participants being made aware of categorical differences both in the incidental task and being posed a question of this nature in the subsequent explicit knowledge task. This may have cued participants to devise a plausible explanation for categorical differences. Thus, being asked to verbally express categorical information before the presentation of the incidental category identification task may have resulted in a levelling of performance across the two different tests. Alternatively, this finding may be reflective of different processing systems for explicit and incidental learning (Gabay et†al., 2015; Tricomi et†al., 2006)."
42,1911559,9," Our results raise the question as to whether similar findings would also be observed not only on other novel categorical learning tasks, but also other learning tasks such as associative learning, and in different domains such as language and numerical learning. Jordan and Baker (2011) found that in young children aged 3 to 5†years, learning to match numerosities was facilitated when given multisensory rather than unisensory information about the number. A key difference in these studies is in the nature of incidental learning in the current task as opposed to explicit mathematical concept learning in the above?mentioned study. A further difference is that our analyses were not concerned with speed of responses, but rather the accuracy of categorical selection. In addition, in the study by Jordan and Baker (2011), audiovisual trials provided a greater total amount of stimulation in comparison to unimodal trials. That is, only on audiovisual trials were participants exposed to both visual and auditory information. This may have resulted in enhanced arousal to stimulus properties and subsequent representations. In the current study, all learning trials (regardless of learning condition) included both auditory and visual events, with learning conditions differing only on the basis of the informative nature of the cues (i.e., the features that could be used for categorical judgements). Findings from the current study therefore refute the assumption that better performance in a multisensory learning condition compared to unisensory is a result of enhanced stimulation from multisensory trials. In conclusion, even in light of the differences in tasks used across studies, the comparable results of improved learning following exposure to multisensory cues compared to unisensory, even in children as young as 6†years, is a robust finding."
43,1911559,10," As mentioned previously, on some tasks, multisensory integration is not as efficient in young children as it is in older children and adults (Burr & Gori, 2012; Gori et†al., 2008; Nardini et†al., 2010; Nardini et†al., 2008), a finding somewhat reflected in the current study. Conclusions from earlier studies imply that combining audio and visual stimuli either at the level of attention or at a neural level of stimuli integration may be more difficult for younger children and therefore not facilitate learning to the same extent as in older children. However, there are likely to be numerous cortical and subcortical mechanisms involved in multisensory integration that may develop at different rates (e.g., Molholm et†al., 2002; Noesselt et†al., 2007; Stekelenburg & Vroomen, 2007). This may underlie the disparity in the reported ages at which mature levels of multisensory facilitation are observed, particularly given that performance on different multisensory tasks may be associated with distinct neural substrates. The examination of multisensory cues on incidental category learning in children younger than 6†years of age would be an important avenue for future research in order to elucidate this further."
44,1911559,11," In the current study, it was only the nature of cues for categorical learning that differed across learning conditions. It is not clear therefore whether multisensory stimulation in some learning contexts would have a distracting effect on performance or would lead to increased focus of attention; particularly when multimodal stimuli are not task?related, as would typically be encountered within a learning environment. For instance, difficulties in encoding unisensory cues have been found when multisensory properties compete for attention (Lickliter & Bahrick, 2004). Given known developmental changes in attention, there may also be differing patterns of response to multisensory distraction across development. Further research should therefore examine the use of unimodal and bimodal noise (distractors), or an increased working memory load within and between modalities on a similar learning task."
45,1911559,12," This study provides important insight into the use of multisensory information in an educational environment on incidental category learning. The intersensory redundancy hypothesis (IRH; Bahrick & Lickliter, 2012) posits that the pooling of multisensory cues presented in synchrony leads to enhanced perception. Given the nature of the current task, theoretical assumptions of the IRH can only go some way to explaining the current results of enhanced category learning following multisensory cue exposure compared to unisensory. Essentially, the current study included complementary but not redundant amodal stimuli in order to better emulate sensory information typically found in learning environments. Even in light of this difference, the results suggest a reliable facilitatory effect of multisensory stimuli presentation between 6 and 10†years of age. Moreover, our results are in accord with findings that multisensory integration (particularly with the integration of auditory and visual information) may undergo a protracted developmental course through the early primary school years. This has particular implications for the deployment of multisensory learning tasks within primary education. In particular, multisensory information may not be as beneficial to younger children when information from a single sense is dominant. For instance, the results are indicative of a relative difficulty in the use of auditory information to support category learning in 6?year?olds, unless combined with complementary visual information. This has implications for the use of auditory information on categorical learning tasks in children below 8†years of age. Where the simultaneous presentation of auditory information with visual cues may better support a representation and subsequent learning, this may be particularly relevant for younger children who demonstrate poorer performance than older children on unimodal auditory tasks."
46,271124,0,"Summary of results \n This study examined the role of tone vs. non-tone language experience, monolingualism vs. bilingualism, and auditory-only vs. auditory-visual training of foreign lexical tone contrasts. The results are summarized under four headings below, followed by discussion of the results."
47,271124,1,"Trainingóeffects of age and language factors \n  Training was effective: there was a general improvement in performance from pre- to post-training. Training was most effective for 8-year-olds; 6-year-olds showed only limited effects of training. Training was more effective if children had tone language experience, an advantage evident in the 8- but not the 6-year-olds. These effects of age and tone language on training were most clearly indexed by the ao rather than the av pre- and post-training tests."
48,271124,2," Language background and training mode \n  There was a differential effect for the type of training: Monolingual children improved markedly with AV training but not at all with AO training, whereas Bilingual children improved markedly with AO training and to a lesser extent with AV training. However, these effects were only apparent when indexed by ao tests."
49,271124,3," Correlation with language measures \n  For children with English as their only, or as one of their, language(s), proficiency on a phoneme deletion task was positively related to Mandarin tone identification in auditory-visual pre-training test trials. As this was before training began, it shows that those children good at manipulating phonemes in (one of) their native language(s) were also good at perceiving what were completely novel phonological elements for the Mono-Eng, the Bi-Eng/Arabic and the Bi-Eng/Thai groups. This advantage did not extend to training, there was no advantage for good phoneme deleters in learning about foreign tones, just in their initial perception of foreign tones. \n  The results bear on a number of issues which are discussed below ahead of a discussion of limitations and suggestions for future research."
50,271124,4," age \n  There are two possible reasons why training was more effective with the older 8-year-olds than the younger 6-year-olds: task difficulty, and reduced sensitivity to foreign sounds. First it may be that the task employed here was demanding in terms of the degree of sustained attention required. For example, while in the procedure used here the pre- and post-training trials were the same, the training trials incorporated variation of both speakers and words. Wang et al. (1999) trained adults on a variety of monosyllabic Mandarin words spoken by a variety of speakers and found especially resilient learning. In an adaptation for children Wang and Kuhl (2003) also found a high degree of learning. However, over their six training sessions they graded the difficulty of the tasks (2 weeks ABX, 2 weeks 2AFC identification, then 2AFC with speaker variation) and within each pair of sessions they trained easier tone pairs first. While the Wang and Kuhl (2003) study and the study reported here shared the variability of speakers and words, here the task would have been more difficult because (i) tasks were not graded and (ii) a single presentation 4AFC identification task was used. It remains for future studies to adapt the procedures here and those in the Wang studies (Wang et al., 1999; Wang and Kuhl, 2003) to derive optimal, L2 training regimes especially for younger, e.g., 6-year-old children. \n  Secondly, irrespective of task difficulty, 6-year-old children may have reduced sensitivity to foreign sounds. Burnham and colleagues (Burnham et al., 1991; Burnham, 2003) investigating what has been called a second period of perceptual attunement, have shown that 6-year-olds, compared with both 8-year-olds and also 4-year-olds, have reduced sensitivity to L2 sounds and suggest that this is an adaptive device which facilitates attention to the difficult task of phoneme-to-grapheme mapping involved in reading. Burnham contends that at 4 years this process has not begun, and by 8 years the process has become relatively automated, whereas at 6 years this attentional filtering is most useful. Whether this explains the results here cannot be fully ascertained without a 4-year-old comparison group, and it remains for future research to investigate this issue further."
51,271124,5," Test trials and generalization of training \n  In this experiment children were given both ao- and av-test trials pre- and then post-training. The training was either with AO stimuli in one group and AV stimuli in another group. In addition, the stimulus words and speakers were different in the pre- and post-training test phase on the one hand and in the Training trials on the other. Therefore, generalization of training can be indexed in two ways. First, any improvement after training, can be considered generalization because the training and test stimuli differed (although there could be an across-the-board improvement because the pre- and post-training stimuli were from the same pool). In this sense then, any performance gain from pre- to post-training, such as those gains found in this study, can be considered as both learning, and generalization of learning. Second, generalization can be indexed by any performance gain across both the ao- and the av-tests, irrespective of whether the training used AO or AV materials. A confounding factor in the interpretation of the results with respect to this type of generalization is that ao-tests proved to be more sensitive indices of performance gain than were av-tests. Nevertheless, it can be concluded that, in general, generalization of training was best for 8-year-olds, and especially for 8-year-olds with tone language experience whether that be monolingual (Mono-Thai) or bilingual experience (Bi-Eng/Thai)."
52,271124,6," Tone language experience \n  Participants with tone-language experience (the Bi-Eng/Thai and Mono-Thai groups) benefitted more from training than those with no tone language experience (Bi-Eng/Arabic and Mono-Eng), irrespective of whether the children were monolingual or bilingual. In addition, those with tone language experience (especially the 8-year-olds) also showed better generalization of training across test typeóao and av. This supports previous findings that tone language experience facilitates adult lexical tone perception (e.g., Burnham et al., 2014) and extends these findings to children. Moreover, these data provide information about two aspects of language learning. First, the data tell us that there is some perceptual or conceptual information about lexical tones that is general across tone languages (or at least for the two tone languages here, Mandarin (the target language) and Thai (the language experience language). Second, the data tell us that any metalinguistic advantage or extra skills learned as a product of learning more than one language is independent of the skills required for learning to perceive lexical tone in a tone language. Each of these is discussed in further detail below."
53,271124,7," Task difficulty and differences between tone languages \n  Mandarin and Thai tone inventories differ on a number dimensions: Mandarin has 4 tones and Thai 5; Thai has 2 level tones and 3 contour tones, Mandarin has 1 level and 3 contour tones; all 5 Thai tones are of similar duration, whereas Mandarin tones differ markedly in duration. Thus Mandarin and Thai are quite distinct with respect to their tones and this has two interesting implications with respect to the results obtained here. Firstly, given these differences, it is reassuring that there was an effect of (Thai) tone language background on the learning of the target tones in Mandarin, i.e., that there was transfer of learning from Thai tones to learning Mandarin tones. Second, the differences between Thai and Mandarin may have played a part in the relatively small performance gains in tone perception here. Further studies in which the background language and target tone language are more similar with respect to their tones, e.g., Thai and Cantonese (6 tones: 3 level and 3 contour, all tones of similar duration), may result in more performance gains. More generally, the relative salience of differences between tones within a particular language and the relative difficulty of discriminating tones in one tone system vs. that in another system is largely unknown (but see Burnham et al., 2017). Recent studies have shown that tone perception develops for a specific tone system (Yeung, et al., 2013) and that non-native tone language speakers have difficulty with tones that are similar or overlap with their native tone systems (Hao, 2012). Much more research is required on what particular parameters make particular tones or tone systems easier or more difficult to learn."
54,271124,8," Monolingual and bilingual children \n  While monolingual vs. bilingual status of the children did not in itself facilitate tone learning in children, it did contribute to the mode of training that was most effective, as measured by the performance gain between pre- and post-training ao-test trials. The Auditory-Visual (AV) mode of training was the most effective for monolingual children, whereas for bilingual children Auditory-Only (AO) training, and, to a lesser extent, AV training resulted in performance gains. The source of this difference is not clear. One possibility is that exposure to a greater range of linguistic differences and devices, as would be the case for bilingual children, allowed them to (i) learn from a range of parameters, including auditory information alone or auditory and visual information combined, and (ii) learn that, even though there is visual information for tone (Burnham et al., 2001a,b, 2014; Smith and Burnham, 2012) the auditory information is by far the most salient. This is speculative and requires more definitive evidence."
55,271124,9," Phonological awareness \n  English phoneme deletion ability (in the Mono-Eng, Bi-Eng/Arabic, and Bi-Eng/Thai groups) was positively related to pre-training auditory-visual test trial performance. Although there was no relationship here between reading and tone perception, the results are reminiscent of those of Burnham et al. (2011) who found a significant relationship between Thai children's reading ability and their phonological and tonological awareness, and between Australian English children's reading and their phonological awareness. Thus here, the ability to manipulate phonemes is related to the ability to perceive foreign speech sounds and in Burnham et al. (2011) reading ability is related to the ability to manipulate (foreign) phonemes and tonemes. Further research is required to investigate the nature of any three-way relationship between reading, phonological awareness, and foreign speech sound (and of especial interest here, lexical tones), the findings of which could be relevant to children's propensity to learn a second language, especially a tone language."
56,271124,10, Limitations and future directions \n A number of limitations can be noted.
57,271124,11,"Training and test \n  The post-training test implicitly tested for generalization across speakers and words, and, in addition, these trials provided implicit tests of generalization from training mode (be it AO or AV) to test mode, as both ao and av tests were given irrespective of training. The downside of this is that tests between trained and untrained stimuli and voices could not be conducted. It is possible that children, even the younger 6-year-olds, may have performed better on trained than untrained stimuli and voices. This should be remedied in future studies. The upside is that any improvement as a result of training indicated generalization of training. So the performance gains obtained here, while modest, are robust. \n  A related point concerns variability. As discussed above, variability improves the robustness of learned distinctions (Wang et al., 1999), but variability should be optimized for the age and maybe the language background of the children. Here it was not. \n  A final point on this theme is that for both clusters of resultsóthe age and tone language experience cluster, and the training mode and monolingual/bilingual language experience clusteróthe ao-tests were more sensitive measures of improvement than were the av-tests. And, even though auditory and auditory-visual modes differentially affected training outcomes in monolingual and bilingual children, the indexation of such training was still generally better on ao-tests. The reason for this is unclear. In future studies it would seem that ao-tests should be preferred."
58,271124,12," Phonological awareness \n We included English language tests of phonological awareness here and found a positive relationship between phoneme deletion and pre-training auditory-visual test performance. Future studies should investigate this further by including reading tests across languages, phonological awareness tests across languages, and also tests of morphological awareness (McBride-Chang et al., 2003) and even executive function, in order to determine predictors of good lexical tone learning."
59,271124,13,"Instructions \n No specific instructions were given. Children were simply told to pay attention to both the auditory and visual aspects of the speakers as we wished to determine whether children naturally pick up relevant lexical tone cues in an experimental setting. In real-life L2 learning situations such experimentally objective procedures may not be desired; indeed any relevant cue could and should be made available. In this regard, Chen and Massaro (2008) tested Mandarin perceivers' Visual-Only (VO) identification of the four Mandarin tones. (Remember that Mandarin language adults are worse than English language adults in VO tone perceptionóSmith and Burnham, 2012; Burnham et al., 2014). Initially the Chen and Massaro adults performed only just above chance and were better for the 55 and 214 tones than the 35 or the 51 tones. In a follow-up test adults were told about visible movements in tone perception and instructed to pay attention to movements of the neck, head, and mouth. Visual-Only tone perception improved significantly. Further work on perceivable visible cues for tone perception is required to facilitate L2 tone learning regimes."
60,271124,14,"Tone difficulty \n The Chen and Massaro (2008) results also raise the issue of the relative difficulty of identification of individual tones and discrimination of tone pairs. Although the results of this study reported here were based on perception across all Mandarin tones, the data also showed some differences of how the participants of different ages and language backgrounds learned the Mandarin tones in this study. Details of performance on the different tones for each language background group and each age are shown in Table C (Supplementary Material) and some comments on these are provided here. Generally, high Static tone (T55) was the easiest tone to learn for monolingual non-tonal group while the Dynamic tones (either T241 or T51) were the most difficult. The results for the monolingual tonal group were exactly the opposite: the Static (T55) the most difficult to learn while the dynamic tones (T214 and T55) were the easiest. The data is a little less definite for the bilingual language background groups. Nevertheless, it appears that 6 year-olds in both bilingual groups found the Static tone (T55) the easiest to learn while the other Dynamic tones (T35, T241, and T51) were similarly difficult; whereas the 8 year-old bilingual groups found that the Dynamic (T214) was the easiest to learn. The fact that the participants WITH A TONAL BACKGROUND found the generally difficult DYNAMIC tones T35 and T214 (Chang, 2011) in Mandarin relatively easy to learn in this study is quite interesting. However, as the task used in this study was tone identification, some distinctive contours, rising and dipping, of these two rising tones might help in identifying them. The results might well be different if participants were asked to discriminate between these two rising tones; the task might be much more difficult. Future work must take into account such differences, but at the moment there are no objective criteria for determining difficulty of tone perception within and between languages. We (Burnham et al., 2017) are currently collecting data on the perception of tone pairs from three different tone languages by adults from five different language backgrounds in order to leach out some such criteria."
61,1303382,0,"In this study, we compared frequency discrimination in the same groups of participants for two tasks designed to address different problems with the standard 2-interval psychoacoustic task designs. Our results suggest the 3I_2AFC design is less susceptible to non-auditory specific differences among participants than the 2I_6A_X design. These findings were surprising given that this latter design is often cited as minimising problems with sensory memory trace formation [12], auditory attention [24] and formation of perceptual anchors [34]. In the following, as part of addressing the issue of task susceptibility to task external effects like musical training, we consider why different results were obtained to those reported by France et al. [12]. We conclude by addressing the question of whether or how frequency discrimination may support language development."
62,1303382,1," 3.1. Performance Variability on the 2I_6A_X Task \n  An appealing aspect of the 2I_6A_X task design was that it did not appear to be susceptible to non-auditory specific differences among individuals [12] suggesting it could be reliably employed in studies involving heterogeneous populations. We did not, however, replicate this observation. A number of possible explanations come to mind to explain our different findings.  \n  Firstly, in the earlier study [12] a two-step process of threshold estimation was applied. Rough estimates were obtained of discrimination threshold and then a final threshold was estimated using an initial ?F close to the expected final threshold together with a more refined (i.e., smaller step size) adaptive staircase procedure. The small initial ?F for the second estimation would have also limited the range in which variation could be observed and all participants would have had considerable experience on the task at the point of final threshold estimation, minimising training effects. This approach to threshold estimation, better approximates standard psychophysical procedures and it is likely that had we adopted a similar strategy, we would have observed lower thresholds and reduced individual variation across the groups. However, we were primarily interested in task designs that could be reliably applied to address clinical or developmental questions, where one rarely has the luxury of applying such techniques.  \n  Secondly, although France et al. [12] provide little information about their participants, it is clear they were high functioning. The mean IQs for both the reading disabled and normal readers were more than 1 standard deviation above the population mean. The majority of the participants were therefore likely to have been students, who, as our own data demonstrate, tend to perform better than the general population on psychophysical tasks. Moreover, they tend to be more homogeneous in terms of education and socio-economic status which will also limit the impact of such individual differences on thresholds observed.  \n  Thirdly, and related to the preceding point, there is an interesting literature suggesting 2I tasks stress cognitive abilities [22] more than other tasks designs [21,24,25]. We did not expect the 2I_6A_X design to be similarly demanding since the inclusion of a stream of six repeated standard tones should have minimised cognitive demands, first by enhancing sensory memory for the standard relative to the target tone and second by cueing the presentation of the target tone to enhance temporal focus of attention [24]. However, in an analogous analysis to that used by Bishop et al. [21] to compare backward-masking in child populations using 2I or 3I tasks, we observed how the participants who performed worst on the 2I_6A_X task demonstrated the greatest improvements on the 3I task. Moreover, despite designing our protocol to maximise experience on the 2I_6A_X task prior to testing, some participants had final thresholds that were greater than the initial starting point of ?F = 160 Hz (Figure 1) though they got sufficient numbers of catch trials at this level correct. Together these observations suggest the poor performance on the 2I task was less about perceptual limitations, than about task-specific cognitive demands. This raises a question regarding why this design should be so cognitively demanding. In response to this, we can only provide the anecdotal evidence of our participants. Many commented that they found it more difficult than the 3I_2AFC task. Some noted how they had to concentrate harder when doing the task, while others commented that the target tone was always different, because it was longer as well as higher than the preceding six tones. Target and standard tones can have a variable perceptual quality particularly around threshold which contributes to the difficulty of correctly identifying the target tone. The comments of our participants suggest the presentation format for the 2I_6A_X task may have complicated the auditory decision-making process by promoting confusions in auditory percept.  \n  Finally, although we have focused entirely on issues to do with task design, it is also possible that differences in the stimuli may have also contributed to the variations in individual differences apparent between the two tasks. Roving of the standard frequency in a frequency discrimination task, as we did in the 2I_6A_X task, makes it cognitively more demanding, resulting in greater individual differences in performance [35]. Differences in stimulus duration may also have contributed since the tones in the 2I_6A_X task were longer than those used in the 3I_2AFC task. Our design does not allow us to assess these stimulus-specific effects, though work by Banai and colleagues suggest they may be outweighed by effects specific to the task [22]."
63,1303382,2," 3.2. Contributions to Task Performance of Different Environmental Factors \n  Environmental effects such as socioeconomic status (SES) and more particularly, active musical training, but not passive music listening, had a significant effect on threshold estimates for both the 2I_6A_X and 3I_2AFC tasks. Musical training may support frequency discrimination by developing a more sophisticated sense of how different sounds relate to each other. The SES measure used here incorporated among other things differences in education which may impact of an individualís ability to develop different strategies to cope with varying task demands. The 2I_6A_X task was particularly sensitive to these factors with the relative impact on task performance increasing with increasing ISI. This supports our earlier conclusion, that it is a cognitively demanding task and further suggests that it became more cognitively demanding as the time interval between standard and target increased meaning listeners became increasingly reliant on other (non-auditory) skills to support processes involved in their decision-making. The increasing contribution of musical training to performance on the longer ISI conditions in the 2I task further suggests that musical training may enhance skills associated with auditory imaging [36] which in turn would support sensory memory for the standard tone. This idea is reminiscent of rehearsal mechanisms which support information storage in the Baddeley and Hitch [37] model of verbal short-term memory. \n  We are not the first to note how musical training makes a significant contribution to frequency discrimination abilities. Micheyl et al. [20] have demonstrated excellent frequency discrimination abilities in professional musicians. However, our data suggest, very little musical training is required to enhance frequency discrimination abilities, since none of the participants in this study were professionally trained.  \n  Bishop [15] has previously noted how exposure to music in the home was an important environmental factor for predicting performance on a test of rapid temporal processing in a study investigating auditory and cognitive abilities in twins. We did not replicate this finding; nonetheless, both our study and that of Bishop [15] demonstrate the sensitivity of the auditory system to environmental factors like musical training or listening."
64,1303382,3," 3.3. Relationships between Frequency Discrimination and Nonword Repetition \n  Auditory sensory memory is hypothesised to support verbal short term memory and we were ultimately interested in assessing the suitability of the 2I_6A_X task for further studying this component of verbal short-term memory especially since France et al. [12] had reported a relationship between frequency discrimination thresholds for the 2I_6A_X task and digit spanóa measure of short-term and working memory. We therefore predicted that we would also observe a relationship (particularly for the long (1000 ms) ISI condition) with the nonword repetition task (another measure of short-term memory). However, no evidence of a relationship with nonword repetition was observed for any ISI condition in the 2I_6A_X task. By contrast, a small but significant association was observed between nonword repetition and JNDs estimated using the 3I_2AFC task. These observations add to a body of literature reporting similar such associations between frequency discrimination and performance on a range of tasks including, reading and phonological decoding skills [4,38], nonword same/different discrimination [22], as well as nonword repetition [39]. Such associations suggest frequency discrimination may impact on speech perception and hence on ability to develop language and literacy. However, we do not think the relationship is quite so direct. Gathercole and Baddeley [40] found no association with speech perception and repetition of short nonwords. In a similar vein, Rosen and Manganari [41] were unable to demonstrate a clear link between deficits in auditory processing and speech perception skills in a group of children with dyslexia. Finally, Halliday and Bishop [39] showed how, despite having deficits in frequency discrimination, children with mild to moderate hearing losses did not obligatorily demonstrate difficulties in reading or nonword repetition."
65,1303382,4," Overall, while we did observe a link between the frequency discrimination and nonword repetition using a task that was relatively robust to the individual differences assessed in this study, our study does not rule out the involvement of a third higher cognitive capacity which is separately relevant to both nonword repetition and frequency discrimination. Similar arguments have also been put forward by Halliday and Bishop [39] and Banai and Ahissar [22]. Halliday and Bishop proposed auditory attention as a possible candidate for this third cognitive capacity, while Banai and colleagues have argued that whatever the capacity, it may not be specifically auditory in nature, and is likely to be mediated by higher level processes involving the engagement of the pre-frontal cortex which associates both with attention and with memory."
66,2521573,0,"There is considerable controversy regarding what exactly the nonword repetition task is tapping into that makes it such a good predictor of language learning. In this study, we employed stimuli that were designed to explore the functioning of a hypothesized phonological storage system. We exploited the electrophysiologically-measured mismatch response to test for sensitivity to change at different syllable positions in good and poor nonword-repeaters. We predicted that if nonword repetition ability was determined by factors ancillary to the phonological loop, then depending on which factor was primary, we would see either:"
67,2521573,1, (a) Significantly reduced MMN responses for poor nonword-repeaters to the deviants at all four syllable positions which would point to deficits in early auditory discrimination; or
68,2521573,2," (b) No group or syllable-position effect if differences in nonword repetition derive from factors extrinsic to the phonological loop, such as differences in motor ability or in vocabulary knowledge."
69,2521573,3," Alternatively, if a syllable-specific group difference emerged, this would suggest that factors associated with a capacity-limited storage system were impacting on the efficiency of information processing and change detection."
70,2521573,4," In the context of our three predictions, two findings are particularly noteworthy. First, the two groups of nonword-repeaters had similar early consonant change discrimination abilities as indicated by the MMN response i.e., accuracy of early encoding of incoming auditory information was similar between the groups. In the context of children with SLI, Gathercole and Baddeley [13] first argued that deficits in nonword repetition ability could not be wholly attributed to differences in speech discrimination ability. Our findings with adults with poor nonword repetition skills are consistent with that view. Second, in the poor nonword-repeaters, the LDN response was abolished for the consonant change occurring at the third syllable of the CV-string, resulting in a significant Group √ó Deviant interaction. As noted above, this pattern of results is not consistent with the idea that the group difference on behavioral tests of nonword repetition is explicable solely in terms of factors such as pre-existing vocabulary knowledge or differences in articulation skills."
71,2521573,5," Rather different conclusions were reached by ?eponien? et al. [23], who compared responses to deviant changes using a similar paradigm to ours to investigate the discrimination of just noticeable differences in two nonsense syllables ëba-kaí versus ëba-gaí in young good and poor nonword-repeaters. Contrary to our own conclusions with adult participants, their data suggest a role for discrimination deficits in young poor nonword-repeaters. However, their stimuli, unlike ours, were difficult to discriminate by design and shorter in length. Moreover their participants were younger. It is likely that the different conclusions arrived at by ?eponien? et al. reflect a range of factors including the subtlety of the acoustic differences to be discriminated and maturational differences between the participants in the two studies."
72,2521573,6, Gathercole and Baddeley [13] suggested three possible candidates directly associated with the phonological loop as impacting on its function: quality of initial encoding into the loop; storage capacity; and the rate of fading of the memory trace once encoded there.
73,2521573,7," At first glance, poor encoding seems inadequate to explain the results, because of the intact MMN responses seen in poor nonword-repeaters at all syllable positions, indicating adequacy of the early stages of speech discrimination. A simple storage account is also hard to reconcile with the results. If, for instance, poor nonword-repeaters could retain few syllables in memory, we might expect to see more pronounced deficits in their discriminative responses for both the third and fourth syllables, whereas the LDN attenuation was found for the third syllable only."
74,2521573,8," The notion of a rapidly fading memory trace has been proposed to explain deficits in verbal working memory [22], [37], but seems implausible to account for our results for two reasons. First, in an earlier task, using pure tone stimuli with variable inter-stimulus intervals, Barry, Hardiman, Line, White, Yasin, and Bishop [38] showed that, although parents of children with SLI have less durable sensory memory traces than parents of typically-developing children, these differences did not associate with differences in nonword repetition ability. Second, in this paradigm, the temporal gap (and hence opportunity for decay) was held constant between each standard syllable and its deviant analogue. If it was only rate of memory trace decay that distinguished the two groups of participants, one would not predict the observed syllable-specific position effect that was observed here."
75,2521573,9," It seems then that whatever differentiates good from poor nonword-repeaters is associated with information-processing under conditions of high input load. The position-specific group differences were not reflected in the early MMN response. They only became apparent in the LDN response. This, together with a lack of correlation between the two mismatch response types, suggests that the LDN provides different information about the processing of the auditory input. In the light of previous research, we suggest that the LDN is an index of formation of a phonological representation. This corresponds to a process of encoding into short-term memory, giving a more robust representation that can persist long enough to allow comparison between deviant and standard nonwords."
76,2521573,10," Why should this encoding process be selectively impaired for the third syllable of a four syllable nonword? One interpretation is in terms of the demands the task places on rapid processing of sequential information. The notion of differences in rate of processing of incoming auditory information derives from the SLI literature, where it has been hypothesized that ability to rapidly process incoming auditory stimuli is deficient in people affected by a language or literacy disorder [39]. The results from both behavioral and electrophysiological studies probing the validity of this hypothesis have been fairly mixed, but in a meta-analysis of studies investigating mismatch responses to syllables in children with language or literacy problems, Bishop [40] concluded that deficits in auditory processing were more likely to be observed when stimuli were presented in rapid succession."
77,2521573,11," Previous MMN studies in populations with language impairments have mostly focused on single syllables, but it may be that deficits in rate of processing only become apparent when processing multiple syllables. This hypothesis was tested by Kujala, Halmetoja, N√§√§t√§nen, Alku, Lyytinen, et al. [41] who assessed the ability of participants with dyslexia to discriminate changes in vowel durations embedded in three syllable CV-strings (e.g., ëta-ta-taí versus ëta-taa-taí). They observed no deficits pre-attentively to the change in vowel duration. However, when the participants were required to attend to the stimuli, they were less accurate at locating the change in syllable duration and they showed a significantly reduced N2b component in response to duration changes in the final syllable of the CV-string. These findings are somewhat reminiscent of our own findings. As such they are of interest given the overlap between dyslexia and SLI and given the fact that deficits in nonword repetition have been reported for both disorders [42]."
78,2521573,12," Within the context of the behavioral literature on SLI, Gathercole [43] observed that nonword repetition by language-impaired children was more accurate when nonsense syllables were presented singly with short intervals between them, than when they were presented in a string. Again this supports the notion that ability to rapidly process incoming sequences of stimuli embedded within other complex stimuli plays an important role in nonword repetition and hence in language learning."
79,2521573,13," One problem for this account of findings is that one might expect to see effects on peak latencies of MMN and/or LDN, reflecting the slower rate of syllable-processing in the poor nonword-repeaters. This was not observed. Nevertheless, in other regards, the hypothesis makes sense of the specific pattern of results obtained here. A slower rate of processing of incoming speech would have a cumulative effect across the CV-string up to the final syllable where, because there is no subsequent syllable, perceptual analysis could be completed with a consequent recovery in LDN amplitude. In effect, this is an explanation in terms of deficits in encoding. It maintains that despite adequate early discrimination processes, poor nonword-repeaters fail to generate a robust phonological representation memory. These problems however, only become evident at rapid rates of stimulus presentation."
80,2521573,14," A radically different type of encoding account is suggested by the literature on perceptual grouping. Horv√°th, Czigler, Sussman, & Winkler [44] demonstrated that mismatch responses can be elicited by both global and local features of stimuli. In our design, we treated the global stimulus ëba-bi-bu-beí as the standard to be compared with deviants differing on one syllable. However, this stimulus contains within it a local repeated phoneme, /b/, which potentially acts as a standard. Thus on hearing ëba-bi-du-beí the response to the third syllable might be influenced both by the deviance from the standard, but also by the deviant /d/ after a train of preceding /b/ consonants, both within the same syllable and from the preceding nonwords. Limited ability to segment individual phonemes has been mooted as a possible cause of poor nonword repetition [21], raising the possibility that poor nonword-repeaters fail to engage in local processing and so are influenced solely by global mismatch. Although this explanation fits well with prior theoretical speculations about nonword repetition, it does not readily account for the pattern of results obtained here, because when progressing through the four syllables of the nonword, one would expect to see a steadily increasing impact of local mismatch, as the number of prior standards increases. We cannot rule out the possibility that such a process contributes to the profile of results obtained here, but it would need further testing with materials designed to evaluate this explanation. If local processing is involved in mismatch generation only in good nonword-repeaters, then a clear prediction is that mismatch responses will be reduced (and resemble those seen in poor nonword-repeaters) if a different consonant were used for each syllable of the standard."
81,2521573,15," Overall, the results from this study suggest a link between two different theoretical accounts of factors affecting language learning. The auditory temporal processing account of Tallal [45] has a long history, but evidence has been mixed [46]. Most empirical studies have considered discrimination of pairs of tones or speech sounds, whereas the current study would suggest that, as the impact of slow processing is cumulative so that longer sequences of sounds are needed to reveal a deficit. The notion that phonological short-term memory is important for language-learning also has a long history. Within the context of these this theory, but the focus has been on explaining poor nonword repetition in terms of storage limitations or of rapid decay of representations. Encoding explanations have tended to be dismissed on the grounds that such problems should be apparent in short nonwords with one- or two-syllables. We suggest that this view is mistaken, because encoding is affected by the presence of adjacent syllables, and so will become apparent only in the later syllables of longer nonwords. The problem of poor nonword-repeaters seems to reflect an inability of encoding mechanisms to keep pace with incoming input. This would explain why nonword repetition is a more sensitive index of language difficulties than more conventional verbal memory span tasks, which typically adopt a slower rate of presentation."
82,2521573,16," Though the focus of this study has been on factors affecting nonword repetition, our participants were heterogeneous with respect to the language learning status of their child. The poor nonword-repeater group included a sizable minority of parents of typically-developing children, just as the good nonword-repeater group included many parents of children with SLI. However, as a further analysis of the data showed (Figure 3), the effects reported here are specific to nonword repetition ability and not necessarily associated with having a language impairment child per se. One must therefore ask, given the composition of our participant groups, what implications do our findings have for current understanding of the etiology of developmental disorders such as dyslexia and SLI?"
83,2521573,17," Much of the research published to date has focused on finding a single underlying cause for a developmental language disorder, but it is becoming increasingly clear that a deficit in any one single underlying cognitive skill is unlikely to explain the broad range of phenotypes captured under simple umbrella terms such as SLI or dyslexia. Instead as Bishop [47] has argued, these disorders are more likely to develop out of a confluence of risk and protective factors, some of which are heritable. In the context of this study, deficits in the ability to process rapidly presented incoming auditory input seem to represent one such risk factor."
84,2521573,18," In sum, previous suggestions for language specialization in the human brain have focused mainly on categorical speech perception, speech production, processing of serial order, and syntactic processing [1]. Our data suggest that human language learning capacity is boosted by being able to process sequentially-presented verbal material rapidly enough to permit the accurate recognition of syllables occurring at the rate of 5 per second, without earlier syllables interfering with the processing of later ones. We conclude that without this ability, it is hard to learn polysyllabic words or to discriminate the non-redundant information contained within a rapidly changing speech stream."
85,2562735,0,"The current study provides the first evidence in a direct comparison that distributional training of speech sounds is less effective in adulthood, when new languages must be mastered, than in the first months of life, when infants start acquiring native speech sounds. Specifically, an earlier study [4] showed that Dutch 2-to-3-month-old infants who are exposed to a bimodal distribution encompassing the Southern British English vowel contrast /√¶/?/?/, have a larger MMR amplitude, and thus supposedly discriminate the two test vowels [√¶] and [?] better, than infants exposed to a unimodal distribution. The current study demonstrates that this bimodal advantage is smaller (if at all present) in Dutch adults than in Dutch infants."
86,2562735,1," The presence of a bimodal advantage in Dutch adults is uncertain, because the difference in test vowel perception between bimodally and unimodally trained adults was not significant. It may be hypothesized that this non-significance was due to a ceiling effect (i.e., top discrimination) in both groups. After all, in the Netherlands English is a compulsory subject of study in middle school and high school, and it is also a language that can be listened to easily on television and other media. However, such a ceiling effect is unlikely. The MMR amplitudes in both groups were rather small (with 95% confidence intervals close to zero), suggesting relatively poor discrimination (cf., the amplitudes in adults listed in Table 1). Moreover, it has been shown that despite their experience with English, Dutch adults have trouble distinguishing the English vowels that were used in the current study [6]ñ[9]. Similar results have also been obtained with other languages: for instance, adult native speakers of Spanish have considerable trouble in discriminating tokens of Dutch /?/- and /a/, irrespective of the length of exposure to the Dutch language [56]."
87,2562735,2," Notwithstanding our efforts to make a sound comparison of the effect of distributional training in infants and adults, it is clear that future research is needed to replicate our results and to confirm the feasibility of our approach. For confirming this feasibility, it will be particularly important to ascertain that infant MMRs truly reflect behavioral discrimination just as adult MMRs do (section 1 below). Relatedly, future research should aim to get a much more detailed understanding of the neural processes underlying infant and adult MMRs, so that differences between them can be explained better (section 2 below presents a tentative rough explanation for the current results)."
88,2562735,3," 1. Measuring learning in adults and infants \n  The comparison of the effect of distributional training in adults versus infants was based on the MMR amplitudes. Our approach featured a minimization of methodological differences between testing infants and testing adults, and a normalization of the MMR amplitudes prior to statistical analysis in order to filter out possible residual differences between adult and infant MMRs. We presented a range of feasible normalization factors to account for the scarcity of information available for estimating such a factor in the literature, and to accommodate different possibilities of calculating such a factor. \n  Still, an important concern in our approach remains, which, notably, also applies to other outcome measures (such as looking times) in other paradigms. This concern is that the MMR may not reflect the same processes in adults as in infants. In particular, it is important to ascertain in future research whether the infant MMR indeed reflects behavioral discrimination. This has been assumed widely on the basis of evidence in adults (for a review see [23]), but has never been verified experimentally. In this context it is noteworthy that a discrepancy between behavioral and neurophysiological measures also exists in the literature on auditory thresholds. These thresholds appear to be much higher in infants than in adults in the behavioral literature [57], but less so in research where auditory brainstem responses have been measured [58]. It has been suggested that this discrepancy occurs due to the co-existence of a mature auditory system and an immature system necessary for making efficient use of this auditory system; the discrepancy can then arise when behavioral measures tap the immature system, while neurophysiological measures tap the mature system [58], [59]. To examine whether the infant MMR truly reflects behavioral discrimination, it seems therefore important to relate behavioral measures (such as high-amplitude sucking measures for the youngest infants, and eye-tracking measures for older infants) with MMR recordings."
89,2562735,4," 2. Top-down influence on bottom-up learning \n  It is not certain whether the observed smaller effect of distributional training in adults than in infants is due to a weakened distributional learning mechanism, which is generally considered to represent a purely stimulus-driven, and thus bottom-up learning mechanism [1], [2], or rather to strengthened top-down processing, or perhaps to both of these factors. Top-down processing refers to the modulation of stimulus-driven neural activity in lower-level areas (e.g., the primary auditory cortex) by higher-level linguistic representations (e.g., phonological word forms). In 2-to-3-month olds such top-down influence is lacking, because they do not have such higher-level representations yet [60]ñ[64]. \n  The first scenario (i.e., a weakened bottom-up learning mechanism) matches the decline of neural plasticity in the course of childhood, which has been related to an increase in the difficulty of ìlearningî with age [65], and which has been included in successful computer simulations of distributional learning [1], [2]. The second scenario (i.e., strengthened top-down processing) is in accordance with the observation that distributional learning of human speech sounds can be measured in adult rats [66], thus suggesting that it is a low-level mechanism that remains in place after neural plasticity has reduced to adult levels. In this scenario, distributional learning can be observed in the rats, because, similarly to the 2-to-3-month olds, they do not have linguistic representations that could modulate lower-level neural activity. \n  A top-down influence of higher- on lower-level representations may already emerge after 4 to 5 months of life, as implied by research on the histological structure and development of the human auditory cortex [67]ñ[69]. This research shows that the six cortical layers that children and adults have, are not present from birth but develop in the first year of life and become visible in post-mortem tissue around 4 to 5 months. Crucially, the division into multiple layers seems to be a prerequisite for top-down influence from higher- to lower-level cortical areas [70]. A look at the functional organization of the layers may clarify this. Roughly, layer IV receives input from the thalamus and projects primarily to layers II and III (ìsupragranular layersî), which in turn target other parts of the cortex; layers V and VI (ìinfragranular layersî) receive input from the supragranular layers and project to the thalamus and other subcortical structures [71]. This functional division suggests that in order to make top-down influence from higher- to lower-level representations possible, the infant cortex must first develop supragranular layers, so that incoming signals can reach higher-level areas, where higher-level representations can be formed, and it must develop infragranular layers that receive top-down influence from these higher-level representations. At 4 to 5 months, rudimentary layering becomes visible in the tissue [68]. Although it is possible that some top-down influence from higher-level to lower-level cortical areas occurs before this time via layer I, which is the only layer that is clearly visible in post-mortem tissue at birth [67]ñ[69], the infrastructure for canonical top-down cortical influence thus emerges just before infants begin to perceive speech sounds in a language-specific way, which is from 6 months of life ([72], [3]; review in [4]). This opens up the possibility that this language-specific speech perception relies on top-down influence of higher-level speech sound representations. At the same time, neural plasticity is still high at 6 months (e.g., [73]), so that the possibility remains that the onset of language-specific speech perception (also) relies on bottom-up learning. \n  If in adults the distributional learning mechanism tends to be ìsuppressedî by top-down influence of higher-level native linguistic representations, the previous significant effects of adult distributional training might have been obtained because the experimental setting (entailing the absence of a natural language context) reduced the influence of these representations on perception. Alternatively, the way the training stimuli were presented may have attracted participantsí attention to the differences between the speech sounds in the tested contrast. If this is true, the observed effects of distributional training would be due to ìattentionî, which can be related to top-down processes in the brain (e.g., [74], [75]) rather than to distributional training, which is a strictly bottom-up mechanism. \n  In this respect it is noteworthy that for the adult Spanish learners of the Dutch vowel contrast /?/~/a:/ in [20]ñ[22], enhanced bimodal training in particular seemed effective. Here the acoustic difference between the minimum and the maximum value along the presented continuum of the training distribution was made larger. From previous research in the second-language literature where other training paradigms than distributional training were used, it is known that widening the acoustic distance between presented stimuli in the training phase can draw participantsí attention to the differences between these stimuli and improve subsequent discrimination and categorization performance [76]ñ[78]. Thus, it is possible that the previous observations of ìdistributional learningî in adults were related to attention instead."
90,2562735,5," All in all, distributional learning as a mechanism for learning speech sounds seems to be weaker later in life than in infancy. The reduced prominence in adulthood may be due to fainter bottom-up learning as well as to the presence (versus the virtual absence in newborns) of higher-level linguistic representations and of a cortical infrastructure that enables top-down influence of these representations on bottom-up learning."
91,1695972,0,"General discussion \n In the present work, we used a test-training-retest procedure in two groups of participants who performed one hour of phonetic discrimination training, or were passively exposed to the same stimulus material, with the aim to (1) infer putative changes in the brainstem and auditory cortex as a function of short-term training, (2) estimate whether these short-term changes are reflected in neural facilitation or adaptation, (3) and to describe mutual interdependences between auditory cortex and brainstem. Results demonstrated that the brainstem but not the auditory cortex distinctively altered its response properties after short-term training. Most notably, this functional change was manifested in terms of neural adaptation and restricted to the frequency range (i.e., f1) corresponding to the trained stimulus attribute (i.e., F1). Since this frequency-specific neural adaptation was negatively correlated with the behavioral improvement of the participants during training, results point to a close relationship (~36% explained variance) between behavior and the underlying brainstem physiology."
92,1695972,1," Brainstem responses \n  Nowadays, it is generally acknowledged that the human brainstem constitutes a highly plastic entity13 that can alter its response properties as a function of both long-8 and short-term training34. For example, Carcagno and Plack44 evaluated the FFR before and after ten hours of pitch discrimination training consisting of differentiating complex tones with a static-, raising-, or falling pitch contour, and found a more robust phase locking of the FFR to the static and dynamic f0 after training. Furthermore, neural activity in the brainstem has previously been shown to be specifically modulated as a function of long-term language experience as reflected by increased f0 magnitudes in Chinese compared to English speakers in response to iterated rippled noise with Mandarin pitch contours45 or high rising Mandarin lexical tones46. However, until now, only two EEG studies specifically addressed causal changes in the brainstem induced by speech discrimination training11, 12. In a first study, Russo and co-workers11 reported that after long-term training (i.e., 35ñ40 sessions of one hour each) children suffering from learning disabilities exhibited brainstem responses that were more resistant to the detrimental effect of background noise than before treatment. Similarly, Song and colleagues12 demonstrated that native English-speaking participants who learned to incorporate foreign lexical pitch patterns varying in f0 (i.e., 8 sessions √† 30?minutes, accomplished in 14 consecutive days) were characterized by a more faithful representation of f0 stimulus contour. \n  In the present work, we provide evidence for short-term changes in the human brainstem after only one hour of phonetic discrimination training. However, contrary to previous studies that used professional musicians as a model for long-term training8, 47, results revealed functional changes that were manifested in terms of neural adaptation and not facilitation. Interestingly, a similar neural adaptation at the processing level of the brainstem has previously been reported by Slabu and colleagues48 in the context of a passive oddball paradigm. Thereby, the authors revealed a reduction of FFRs to deviant stimuli compared to standard ones, leading to suggest that the brainstem is able to encode statistical regularities34 by suppressing responses to rare stimulus events. Even though in the present study the ìdeviantî stimulus (i.e.,/go/) presented during brainstem measurements occurred with a low probability during the training session, the experimental manipulation we used precludes that results were driven by stimulus statistics34 or even by repetition suppression28. In fact, the PG was passively exposed to the same stimulus material as the TG, however, without showing a modulation of brainstem responses in pre-post comparisons. In addition, since brainstem changes were restricted to the solely discriminative physical attribute enabling to distinguish the trained stimuli, namely F1, results clearly point to feature-specific changes possibly reflecting increased neural efficiency28. This perspective is further supported by the negative correlation we revealed within the TG between percent f1 signal change and behavioral improvement during the training session. \n  Neural adaptation constitutes an intrinsic organizational property of the auditory system across the entire hierarchical tree, ranging from the periphery to the auditory cortex (for a review consider49). In this context, it is noteworthy to mention a previous EEG study targeting at evaluating the encoding of statistical regularities while participants learned to segment complex tone patterns embedded in concatenated sound sequences. Interestingly, the authors revealed decreased brainstem responses to the patterned compared- to a pseudo-random condition after only fifteen minutes of task34. However, by looking at brain responses of the single participants, Skoe and colleagues34 noticed that neural adaptation and facilitation can go hand in hand with remarkable inter-individual differences. Furthermore, the authors revealed a positive relationship between brainstem physiology and behavior, such that better performance was related to greater neural enhancement. Notably, our results are comparable with those of Skoe and colleagues34 in that the TG demonstrated decreased f1 magnitudes after short-term learning compared to the PG. Otherwise, in contrast to Skoe and co-workers, we revealed a negative instead of a positive relationship between the magnitude of brainstem responses and behavioral improvement. From a physiological perspective, the adaptation we revealed at the processing level of the brainstem can be explained at least by three different phenomena. The first possibility is that short-term training may have altered the response properties of brainstem neurons by uncoupling neural entities that were not relevant for discriminating task-specific acoustic features, resulting in activation of fewer neurons, and consequently neural adaptation28. A second possibility is that the observed brainstem changes may have been indirectly mediated by performance feedback. In fact, since in the present study only the TG received such a feedback, it is thoroughly possible that reward and motivation may have modulated brainstem activity. This perspective is supported by previous work showing that the human reward system is responsive to high-order rewards (i.e., intellectual, artistic, or altruistic pleasures)31 and that feedback confirming reward expectation can modulate activity in auditory-related brain regions32, 33. Finally, since active learning requires a stronger engagement of attention functions compared to passive listening, we cannot rule out that this variable may have played a role in mediating neural adaptation29, 30. Such an influence of attention could, for example, have been mediated by the cortex through corticofugal projections. In fact, such a contribution of the cortex to auditory learning mechanisms via the corticofugal system has previously been demonstrated in animals by using both ablation and pharmacological interventions49, 50. \n  A disadvantage of the EEG technique is that it does not enable to exactly determine the specific origin of the brainstem signal measured. However, currently there is evidence showing that neurons situated in the inferior colliculi are highly frequency-selective51, 52 as well as sensitive to the direction of frequency modulation53, 54. Since the TG was specifically trained to recognize subtle F1 signal changes only in one direction (i.e., always from/gu/to/go/, in the range between 364ñ480?Hz), we may speculate whether this specific experimental manipulation may have altered the response properties of neurons being selective to the direction of frequency modulation or rather frequency-selective neurons per se. In addition, since we did not reveal group differences in stimulus-response cross-correlations (i.e., lag and signal tracking), results suggest that during short-term training the brainstem is more likely prone to change its response properties to the spectrum of the trained stimulus attribute than to the waveform periodicity. This result is somehow in opposition with those previously reported by Russo and colleagues11 who revealed an increased temporal alignment of FFRs after training, as reflected by increased quiet-to-noise inter-response correlations. However, in this previous work the authors measured children with learning disabilities that were trained for a much longer period of time (namely 35ñ40?hours) compared to the present work. The same is true for the work of Anderson and colleagues55 where the authors evaluated the impact of an 8 weeks computer-based auditory training program in elderly subjects, and reported earlier brainstem peak latencies in both quiet and noise conditions after treatment. Taken together, these previous results substantiate the suspicion that brainstem changes in timing parameters may necessitate longer training periods."
93,1695972,2," MMN responses \n  A further goal of this study was to evaluate the functional malleability of the auditory cortex as indexed by altered MMN responses. In addition, based on previous studies indicating that neuronal entities which are sensitive to temporal and spectral acoustic attributes lie side by side in the auditory cortex56, we evaluated putative transfer effects57 from phonetic discrimination training to temporal aspects of speech processing. Reconstructed sources revealed MMN maxima originating from posterior superior temporal areas across groups (i.e., TG and PG), conditions (i.e., spectral and temporal manipulation), and time points (i.e., T0 and T1). This finding is in line with previous literature58 and points to a main contribution of the auditory cortex to MMN responses. In the present work, we did not reveal group differences in the modulation of MMN responses (i.e., MMN area and latency) as a function of treatment, leading to suggest that the auditory cortex was not specifically modulated by training. Interestingly, previous training studies consistently revealed increased MMN responses that were accompanied by an improved behavioral performance, however, especially after multiple training sessions lasting several days or weeks22, 59, 60. In particular, Ylinen et al.60 measured native Finnish (i.e., quantitative language) and English speakers before and after 10 training session of 25?minutes each consisting of learning to discriminate spectral and temporal cues of English vowels. As a main result the authors reported that after training the Finnish speakers were better able to discriminate spectral vowel cues, as reflected by increased MMN responses. In a further EEG study, Tamminen and colleagues59 applied a three-day phonetic-listen- and repeat training in a sample of Finnish speakers who learned voicing contrasts in fricative sounds (i.e., fricatives are not differentiated by voicing in Finnish) and revealed significantly increased MMN responses after the second but not the first training day. Taken together, these previous results lead to suggest that functional changes in the auditory cortex can most reliably be induced by multiple training sessions. Therefore, we may speculate whether a consolidation period is necessarily required for inducing detectable plastic changes in the auditory cortex61, 62. \n  An alternative explanation that may account for the apparent insensitivity of MMN responses to training is that the constant serial order of the cortical and subcortical EEG measurements (i.e., FFRs were always collected first) may possibly have blurred neural facilitation through a superimposed signal adaptation. However, since between the two measurement points (i.e., T0 and T1) the two groups were additionally exposed to acoustic stimulation for one hour, we should have observed such an effect in pre-post comparisons (i.e., a significant percent MMN change against zero), irrespective of group affiliation. Finally, based on the fact that phonetic discrimination learning is an active perceptual process that operates under the influence of attentive functions, future training studies should evaluate short-term changes in the auditory cortex by combining active and passive oddball paradigms."
94,1695972,3," Cortical-subcortical coupling mechanisms \n  To the best of our knowledge, until now only four studies conjointly recorded FFRs and AEPs while participants were exposed to CV syllables36, 37 or vowels15, 35. In particular, Musacchia and colleagues36 measured musicians and non-musicians while participants were repeatedly exposed to the syllable/da/, and reported a positive relationship between subcortical f0 amplitude and cortical P1-to-N1 slope. Otherwise, Bidelman and colleagues35 measured young and older adults while the participants categorized vowels that spanned a perceptual continuum from/u/to/a/and revealed that older adults were characterized by slower and more variable speech classification performance than younger listeners. This differential behavioral performance was reflected by reduced brainstem amplitudes, increased cortical AEPs, as well as by a negative relationship between f1 and cortical N1/P2 amplitudes. In a second study of the same group15, the authors recorded cortical and subcortical brain responses in older adults with and without music training while the participants categorized vowels along a continuum. Even though the authors did not find between-group differences in terms of cortical (i.e., P1-N1-P2 complex) or subcortical (i.e., f0 amplitude) brain responses, musicians showed a closer relationship between neural activity and behavioral performance. Finally, Parbery-Clark et al.37 investigated the effect of background noise on both brainstem and auditory cortex activity, and reported a relationship between subcortical response fidelity and cortical N1 magnitude that was predictive of speech-in-noise perception. In the present work, we did not find evidence for a relationship between auditory cortex and brainstem changes as a function of training. However, this may rather be a byproduct of unmodulated MMN responses as a function of training rather than an evidence for the inexistence of cortical-subcortical coupling mechanisms. In this context, it is also important to mention that our experimental design profoundly differed from the previous studies mentioned above. In fact, Musacchia and colleagues36 as well as Bidelman et al.15 measured musicians, a specific group of subjects that has previously repeatedly been shown to constitute a suitable model for evaluating the influence of long-term training on auditory processing16, 63, 64. Otherwise, the group of Parbery-Clark37 evaluated cortical-subcortical coupling mechanisms in normal hearing young adults while performing a speech-in-noise perception task, an experimental condition which is well known to place stronger demands on cognitive control mechanisms that have a modulatory influence on brainstem activity through the corticofugal system34."
