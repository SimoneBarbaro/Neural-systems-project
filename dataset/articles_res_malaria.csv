Id|Res_id|Paragraph
||
1904820|1|Microscopic examination was performed for diagnosis in all of the malaria cases. A total of 153 cases of malaria were observed between January 2004 and June 2013, 113 of which were found among Japanese travellers. Of the latter, there were 78 cases of P. falciparum malaria (including 1 case of co-infection with P. malariae malaria and 1 case of co-infection with P. vivax malaria confirmed by PCR), 22 cases of P. vivax malaria (including 1 case of co-infected with P. falciparum malaria confirmed by PCR), 11 cases of P. ovale malaria, 3 cases of P. malariae malaria, and 1 case of P. knowlesi malaria. RDTs were performed in 67, 21, 10, 2, 1 and 2 cases among the mono-infection cases of P. falciparum malaria, P. vivax malaria, P. ovale malaria, P. malariae malaria, P. knowlesi malaria and co-infection cases, respectively. The cases confirmed by PCR were 11, 19, 10, 3 and 1 cases in P. falciparum malaria, P. vivax malaria, P. ovale malaria, P. malariae malaria and P. knowlesi malaria, respectively (Table ?(Table11).
1904820|2|We focused on a comparison of P. ovale malaria mono-infection cases and P. vivax malaria mono-infection cases. There were 10 cases of P. ovale malaria (mean age, 27.8 years; male-to-female ratio, 2.3:1) and 18 cases of P. vivax (mean age, 29.8 years; male-to-female ratio, 2.6:1). These patients constituted the final study population. The results of RDTs were evaluated for 9 patients with P. ovale malaria and 17 patients with P. vivax malaria (excluding 1 co-infected case). Among the 18 cases of P. vivax malaria, 13 (72.2%) had been infected in Asia, 4 (22.2%) in South America, and 1 (5.6%) in Africa (Republic of Rwanda) (Table ?(Table2).2). All of the 10 cases of P. ovale malaria had been infected in Africa (Table ?(Table3).3). The average parasitemia in the cases of P. ovale malaria was significantly lower than that in P. vivax malaria (P = 0.002). The sensitivity of RDTs for P. ovale malaria was also significantly lower than that for P. vivax malaria (P < 0.001). The sensitivity of SDMA for P. vivax malaria and P. ovale malaria was 100% (7/7) and 50% (2/4), respectively. The sensitivity of BN for P. vivax malaria was 90.0% (9/10), but it was ineffective in detecting the cases of P. ovale malaria (0/5; Table ?Table4).4). There were only 3 cases of P. malariae malaria, one of which showed co-infection with P. falciparum. The other 2 cases of P. malariae malaria were mono-infection of P. malariae. In the mono-infection cases, one case of P. malariae malaria showed a positive line detecting pLDH of SDMA while the other case showed a positive line detecting aldolase of BN.
359836|1|Figure 2 shows the incidence of clinical malaria over the 18-month follow-up period observed in the control arm of the Phase III trial and estimated by the model, for each age group and each transmission level. The modelled results matched the trial results closely, although some differences appeared mainly in the infant age group for the low transmission category and in the older age group for moderate and high transmission. The model mostly underestimates the malaria incidence observed in the trial for the 5 to 17-month group. Table 4 shows the number of clinical malaria cases and the percentage of severe malaria cases observed in the control and vaccine arms of the Phase III trial and predicted by the model. The modelled results matched well with the data (error in acceptable 10 % area) in the age group vaccinated at age 6 12 weeks although in the vaccine arm the model provided more severe cases than the trial (+23 %). In the age group vaccinated at 5 17 months the data were more difficult to reproduce because of the lower number of cases estimated in moderate and high transmission settings. The model tended to underestimate the burden of malaria compared with the observed data from the trial in the 5 17 months as pointed out in Table 4. The age distribution of malaria cases predicted by the model matched well with the age distribution published by Carneiro et al. [14] for clinical cases (Fig. 3a) and severe cases (Fig. 3b).
359836|2|Table 5 shows the estimated impact of adding RTS,S vaccination with doses administered at age 6, 10 and 14 weeks or 6, 7-and-a-half and 9 months in 42 African countries and eight specific countries (see Additional file 3: Table S1 for results in each country). The estimates were based on vaccinating the birth cohort in 2017 and following them for 10 years, assuming no change in malaria transmission. Vaccination at age 6, 10 and 14 weeks would be expected to avert almost five million cases of clinical malaria, 119,000 severe malaria cases, 98,600 malaria hospitalizations and 31,000 malaria deaths. Vaccination at age 6, 7-and-a-half and 9 months would be expected to avert almost 12.5 million cases of clinical malaria, 250,400 severe malaria cases, 208,000 malaria hospitalizations and 65,400 malaria deaths. Therefore the higher efficacy obtained in five to 17-months age group would overcome the lower coverage with vaccination starting at 6 months (75 % of DTP3). Table 6 shows these estimated impact data expressed per 100,000 vaccinees. Countries with high malaria transmission, such as Nigeria and Burkina Faso, generally had higher values than countries with lower malaria transmission, such as Kenya. In Kenya more than 75 % of the population is not exposed or exposed to low levels of malaria transmission (i.e., with parasite prevalence below 5 % in children of 2 10 years old) while 7 % would experience high malaria transmission (i.e., with parasite prevalence above 40 % in children of 2 10 years old). Exposure levels are also variable in Tanzania with about 45 % of the population in low transmission areas versus 12 % experiencing high levels of transmission. This suggests that the projected impact of vaccination increases with transmission even if the relative percentage of events averted is predicted to decrease with transmission. Vaccination at age 6, 7-and-a-half and 9 months generally resulted in higher values than vaccination at age 6, 10 and 14 weeks, reflecting the higher vaccine efficacy in the older age group. Over the 42 African countries it is estimated that 2019 (?3652; 6341) cases of neurological sequelae would be averted with vaccination at the age of 6, 10 and 14 weeks and 4258 (?7; 8191) cases of neurological sequelae with vaccination at the age of 6, 7-and-a-half and 9 months.
359836|3|Figure 4 shows the estimated percentage of clinical malaria cases averted when adding RTS,S vaccination at age 6, 10 and 14 weeks and at age 6, 7-and-a-half and 9 months in low, moderate and high transmission categories. Addition of RTS,S would be expected to reduce the incidence of clinical malaria in a higher proportion for low transmission than higher transmission settings. The benefit would be expected to occur in the first 1 4 years, and the model predicted a small increase in later years in high transmission areas, reflecting delayed development of natural immunity. This appears in the reduction of proportion of events averted in children less than 10 years of age compared with children under 5 years of age.
2052982|1|A total of 1099 children were included in the study. During the analysis it became apparent that information on one malaria RDT result and two malaria slide readings were missing and these were considered as missing data for the analysis. Malaria was the most frequently infection diagnosed by nurses by malaria RDT in 72.68% (798/1098) of febrile children, but only 53.69% (589/1097) of febrile children could be confirmed by expert microscopy. The second commonest cause of fever diagnosed by heath facilities nurses were respiratory tract infections (RTI) [bronchiolitis 9.2%(101/1099), pneumonia 14.47% (159/1099), other RTI 14.10% (155/1099)]. The characteristics of study population are presented in Table 1. A small percentage of the febrile children who received antimalarial prescription got first an injectable antimalarial (artesunate or artemether) followed by artemisinin-based combination therapy (artemether lumefantrine or artesunate amodiaquine) for subsequent home treatment 2.11% (17/805). The majority of malaria treatment 97.88% (788/805) was artemisinin-based combination therapy as previously mentioned. For the antibiotic prescriptions, 14.58% (125/857) and 1.17% (10/857) have received respectively 2 and 3 antibiotic prescriptions, and 84.24% (722/857) received a single prescription. All antiparasitics were single prescriptions (Table 2).
2052982|2|Table 3 presents the risk of antimicrobial prescriptions according to malaria RDT results during the study period. It is evident that rural health facilities as well as the referral hospital were likely to prescribe an antimalarial in case of a positive malaria RDT, as recommended by WHO, compared to negative tested cases. Antibiotics were likely to be prescribed to negative malaria RDT. The adherence rate of the health care workers to the result of the malaria RDT-PfHRP2 was 92.89% (1020/1098: 762 malaria RDT positive patients received an antimalarial treatment and 258 malaria RDT negative cases did not receive an antimalarial treatment). However, if malaria expert microscopy is considered as gold standard, the risk for febrile children tested with RDT-PfHRP2 to have their initial antimalarial prescription affected (modified) was statistically significant (RR?=?7.74, p?=?0.00001). Moreover, the likelihood of antibiotic prescription in case of a negative malaria RDTs was 3 times higher compared to positive malaria RDTs and statistically significant (RR?=?3.57, p?<?0.0001). It is apparent from Table 4 that the health care workers at the rural health facilities were more likely to prescribe antimicrobials to children who tested positive for malaria by RDT (antimalarial?=?96.11%; antibiotics?=?75.20%; antiparasitics?=?18.63%) than at the level of the referral hospital (antimalarial?=?93.37%; antibiotics?=?62.98%; antiparasitics?=?1.65%). Furthermore, the nurses in the rural health facilities were more likely to prescribe antibiotics (97.86%) and antiparasitics (26.73%) to children who tested negative by malaria RDT than attending health staff at the referral hospital (antimalarial?=?84.07%; antiparasitics?=?2.65%), except for malaria treatments (rural health facilities?=?7.48%; referral hospital?=?24.77%). As an overall trend it was found that the risk of prescribing antimalarial as well as antibiotic and antiparasitic to children with a positive malaria RDT compared to children with negative malaria RDT was higher in health facility compared to referral hospital. The risk of prescribing antimalarial in positive tested patients compared to negative malaria RDTs was 8.01 (95% CI 5.51 11.66, p?=?0.00001) and 6.93 (95% CI 4.07 11.81, p?=?0.00001) for the rural health facility and referral hospital, respectively. The risk of prescribing antibiotic in case of negative malaria RDT compared to RDT positive was 11.10 (95% CI 4.18 29.43, p?=?0.00001) in health facility and 2.14 (95% CI 1.38 3.32, p?=?0.00001) in referral hospital.
2052982|3|By cross-checking the laboratory findings (actual cause of disease) with the antimicrobials prescribed by health care workers based on the routine practice (based on the national guideline for the treatment of childhood diseases), it is evident that a large part of the febrile children who received an antibiotic prescription did actually not need such a treatment. It was that at the rural health facilities all children with a positive bacterial bloodstream infection (bBSI) (25/25) or urinary tract infection (UTI) (8/8) and 80.39% (41/51) with bacterial gastro-intestinal infection (bGII) based to laboratory results did actually receive antibiotic prescriptions. But also 93.98% of the febrile children without any infection (confirmed by laboratory testing) in the present study too actually received antibiotic prescriptions. In contrast, at the referral hospital only 75% (30/40) of children with positive bBSI, 64.28% (9/14) with bGII and 100% (3/3) with UTI did actually receive antibiotic prescription. Moreover, 86.04% (74/86) of febrile children without (laboratory confirmed) infection did also got antibiotic prescriptions (Table 5).
1904879|1|The baseline characteristics of the study population are shown in Table 1. A total of 491 children aged between 6?months and 14?years participated in the study. There were more females (55.6%) than males (44.6%), and most of the participants were less than 5?years (43.6%) old. A greater proportion of parents/caregivers of the children had a primary level of education (51.8%) followed by those with secondary school education (31.6%). The proportion of children who slept under a long-lasting mosquito net the previous night before the survey was 62.3%. On microscopic examination, P. falciparum infection was present in 27.7% of the children, while using RDT, malaria was diagnosed in 39.7% of participants. Fever and anaemia were observed in 3.7% and 72.7% of the children, respectively. The prevalence of falciparum malaria among the 491 children varied with sex as shown in Table 2. By microscopy, malaria parasite prevalence was higher in females (31.9%) than males (22.5%) and the difference was significant at P?=?0.021, whereas by RDT, the difference in prevalence of malaria parasite between males (35.8%) and females (42.9%) was not statistically significant (P?=?0.111). Conversely, the geometric mean parasite density (GMPD) was significantly higher (P?=?0.025) in males (218 parasites/?L of blood) than females (172 parasites/?L of blood). A significant difference in P. falciparum infection by microscopy (P?=?0.002) and RDT (P?=?0.001) was observed with age, with the ??4?years age group having the highest malaria prevalence (31.9% by microscopy and 47.4% by RDT), followed by the 5 8?years age group (29.9% by microscopy and 38.1% by RDT) and least by the ??9?years age group (11.9% by microscopy and 23.8% by RDT). In addition, children ??4?years of age had the highest GMPD (224/?L of blood), followed by the 5 8?years age group (159/?L of blood) and lastly the 9?years age group (141/?L of blood). In both microscopy and by RDT, the prevalence of P. falciparum infection was highest in children whose parents had no formal level of education (63.2% by microscopy and 57.4% by RDT), while children whose parents had tertiary level of education had the least prevalence (9.0% by microscopy and 14.1% by RDT), and the difference was significant at P?<?0.001 and P?<?0.001 respectively (Table 2). Children who used mosquito bed net had a significantly lower P. falciparum infection prevalence (15.4% by microscopy and 35.6% by RDT) when compared with children who did not use a bed net (48.4% by microscopy and 46.7% by RDT). P. falciparum infection prevalence was significantly higher by microscopy (P?=?0.039) and RDT (P?<?0.001) in children with anaemia (30.3% by microscopy and 44.5% by RDT) than those non-anaemic (20.9% by microscopy and 26.9% by RDT) as shown in Table 2.
1904879|2|The CareStart  Malaria HRP2 pf Ag RDT had a sensitivity of 82.4% (95% CI:74.9 88.4%) and specificity of 76.6% (95% CI 71.9 80.9%). The PPV, NPV and Acc were 57.4% (95% CI 52.4 62.3%), 91.9% (95% CI 88.7 94.2%) and 78.2% (95% CI 74.3 81.8), respectively. False positive results were observed in 42.6% (83) of children with microscopy negative results for P. falciparum, while the false negative rate was 8.1% (24) among the children as shown in Table 3. The measure of agreement kappa (?) between microscopy and CareStart  Malaria HRP2 pf Ag RDT (G0141) was 0.52. There was a statistically significant dependence of the positivity of the RDT on clinical malaria parasitaemia (P?<?0.001), fever (P?<?0.004) and parasite density (P?<?0.001). The positivity of the RDT was 100% for clinical malaria parasitaemia (presence of Plasmodium, with an axillary temperature of ??37.5? C) and 72.2% among febrile children (temperature of ??37.5? C, regardless of the presence of Plasmodium). The RDT demonstrated a sensitivity of 96.1% for parasite densities above 200 parasites/?L of blood (Table 4). A multivariate analysis demonstrated that children who were febrile (P?<?0.001), less than 5 years old (P?<?0.02), those who had fever within a month (P?<?0.001), and those anaemic were more likely to have a positive RDT result. Febrile children were 6.8 times more likely to have a positive RDT for P. falciparum than non-febrile children while those under 5 years of age were 2 times at odds of having a positive RDT than their contemporaries. In addition, children with a history of fever within a month at the time of the survey were 4.57 times more likely to be positive for P. falciparum infection by RDT when compared with children without fever. Moreover, those with anaemia were 2 times at higher odds of having a positive outcome with RDT than non-anaemic children as shown in Table 5. The accuracy of malaria parasitaemia as assessed by the area under the ROC curve to predict malaria by RDT was 75.4% (95% CI, 70.6 80.1). The optimal cutoff for the diagnosis of malaria by RDT was 77 parasites/?L of blood.
544861|1|Seventy-four facilities correctly filled out and returned their questionnaires given a response rate of 90.2%. More than half 50 (67.6%) of the functional facilities were in the urban area. As shown in table 1, among the doctors and nurses, a majority 22 (95.6%) and 10 (83.3%) respectively were in the urban area, while among the community health extension workers (CHEWs)/community health officers (CHO), a majority 20 (90.9%) were in the rural areas. Respondents were asked to state the various methods they used in diagnosing malaria. If they used more than one method, they were asked to say so. As shown in table 2, the most common method for diagnosing malaria in the study area by health workers was syndromic approach, followed by microscopy and then RDT examination. Doctors and laboratory technicians were significantly more likely to use RDTs than CHEWs/CHOs and nurses while the laboratory technicians and nurses were more likely to use microscopy than doctors and CHEWs/CHOs. Also, nurses, CHEW/CHO and doctors were significantly more likely to use syndromic approach than laboratory technicians. Within the groups, all the other health workers were significantly more likely to use syndromic approach except for the laboratory technicians who used microscopy more. As shown in table 3, majority of the respondents 45/74 (61.1%) knew about RDTs and most of them learnt it through their co-workers 18 (40%) and conferences 13 (28.9%). Awareness was higher among doctors 18/23 (78.3%) and laboratory technicians 14/17 (82.4%). There was statistically significant differences in awareness among the different cadres of health workers. Also, the proportion of workers aware was higher in the urban area (34/50, 68.0%) than in the rural area (11/24, 45.8%). Health workers in the public facilities were more aware than those in the private facilities and this was statistically significant.
544861|2|As shown in table 3, majority of the respondents 45/74 (61.1%) knew about RDTs and most of them learnt it through their co-workers 18 (40%) and conferences 13 (28.9%). Awareness was higher among doctors 18/23 (78.3%) and laboratory technicians 14/17 (82.4%). There was statistically significant differences in awareness among the different cadres of health workers. Also, the proportion of workers aware was higher in the urban area (34/50, 68.0%) than in the rural area (11/24, 45.8%). Health workers in the public facilities were more aware than those in the private facilities and this was statistically significant. As shown in table 4, a total of 24 (32.4%) had RDT kits in their health facilities of work at the time of the survey. In the urban area, 13/50 (26.0%) of them and 11/24 (45.8%) of the rural facilities had RDTs, but there was no statistical significant difference (p > 0.05). Among the public health facilities, 14/36 (38.9%) of them and 10/38 (26.3%) of the private facilities had RDTs, but the difference was not significant (p > 0.05). Most of these RDTs were either bought from a pharmacy store 10 (41.7%) or were donated to them by nongovernmental organizations 10 (41.7%). Only 3 (12.5%) of the facilities got their RDTs from the government. However 26 (35.1%) of the respondents knew where to purchase or get RDTs.
544861|3|Table 5 shows that of the 45 that were aware of RDTs, only 23 (51.1%) facilities had actually used it. Most of the users were in urban area 16/34 (47.1%) and were mostly from the public facilities 16/26 (61.5%). Doctors 11/18 (61.1%), laboratory technologists 7/14 (50.0%) and CHEWs/CHOs 5/10 (50.0%) were the main users with no nurse using them. Out of the 23 facilities that had used RDTs only 10 (43.5%) were still using it at the time of the survey. The non users were mainly from the private clinics 8/19 (42.1%) and the reasons given for non use included: unreliability of RDTs, supply issues, cost of the RDTs and preference for other methods of diagnosis. Table 6 shows that out of the 23 respondents that had used RDTs, most of them 17 (74%) said RDTs saved time and was better than other diagnostic methods 11 (47.8%), while 4 (17.4%) and 2 (8.7%) of them said RDTs were the same with other diagnostics and were worse than other diagnostic methods respectively. However, 6 (26.1%) were not sure. From the table, supply issues, charge to patients, and ignorance, were the most important limitations of the use of RDTs being 20 (86.9%), 15 (65.2%) and 6 (26.1%) respectively. More than 90% of the respondents rated RDTs to be either good, very good or excellent. A majority of them 16 (69.6%) were satisfied with the benefits of RDT while a few 3 (13%) and 4 (17.4%) were not and indifferent respectively. As shown in table 7, of the 23 respondents that had used RDT, 10/16 (62.5%) in public facilities and 6/7 (85.7%) in private facilities said they knew RDT could be affected by temperature. While 6/16 (37.5%) and 2/7 (28.6%) of public and private facilities respondents respectively preserved their RDTs in cold boxes, 4/16 (25.0%) and 2/7 (28.6%) of them in public and private facilities respectively had no special arrangement. There was no statistical significant differences between the private and public facilities in all the variables.
544861|4|Table 8 shows that more of the public health facilities (32, 88.8%) and fewer (13, 34.2%) of the private health facilities reported using ACTs for the treatment of malaria. Private health facilities reported using SP, chloroquine and Artemisinin Monotherapy more than the public health facilities, being SP (12, 31.6%), chloroquine (10, 26.3%) and Artemisinin Monotherapy (3, 7.9%) for private health facilities and SP (2, 5.%6),and chloroquine (2, 5.6%) for public health facilities respectively.. ACTs were available in 32 (88.8%) and 17 (44.7%) of the public and private facilities respectively at the time of this survey (p < 0.05). Most of the public facilities 30 (83.3%) and 14 (36.8%) of the private facilities had Artemether-Lumefantrine (AL). However, Artesunate+Amodiaquine (AA) were found in 13 (36.1%) of the public and 5 (13.2%) of the private health facilities respectively, while Dihydroartemisinin-Piperaquine (DP) were found in 16 (44.4%) of the public and 8 (21.1%) of the private facilities respectively. 
361983|1|A total of 78,454 patients with a clinical diagnosis of malaria were tested using RDTs over a period of approximately four years at four study health centres; 25,473 (32.5%) tested positive for P. falciparum malaria. Bufundi and Kilibwoni, both located at relatively high altitude, had lower RDT positivity rates compared to Kebisoni and Sengera (Table 1). Positivity rate increased with decreasing altitude. Sites located at high altitudes showed similar positivity rates among all age groups (Figure 1) except for increased rates in males aged 15 years and above at Bufundi, which probably reflects high levels of mobility in this group due to seasonal labour in neighbouring (and more endemic) districts. Some variations in morbidity levels between age groups were observed in Sengera and Kebisoni, areas located at lower altitudes. Sengera, which is a non-governmental health centre, showed an age pattern compatible with moderately high endemicity in which relatively few adults are affected compared with younger age groups. RDT positivity rates varied by season and year at each site, indicating temporal changes in accuracy of clinical diagnosis of malaria (Figure 2). The absolute number of suspected cases of malaria who tested positive varied between sites depending on altitude and type of health facility. As an example, Sengera, the non-governmental facility, charged fees for consultation and drugs whereas the other government facilities provided free treatment, resulting in relatively low observed attendance at the facility. RDT positivity rates increased as the number of RDT-positive cases increased, especially in sites located at lower altitudes. There was a strong correlation between monthly RDT positivity rates and number testing positive with RDTs in all sites, with correlation coefficients varying between 0.64 (Kebisoni) and 0.87 (Sengera). At Kebisoni, both clinical malaria cases and RDT-positive cases increased during the study period, but there was no similar trend in the RDT positivity rate (Figure 2).
361983|2|At the hypoendemic site (Kilibwoni), only 10/1,000 (1.0%) of cases examined microscopically were positive for P. falciparum by RDT, whereas at the mesoendemic site (Kebisoni), 609/1,237 (49.2%) were positive. The sensitivity, specificity, PPV and NPV of the RDTs at Kilibwoni were 90.0%, 99.9%, 90.0% and 99.9%, respectively, whereas the corresponding figures at Kebisoni were 91.0%, 65.0%, 71.6% and 88.1%, respectively. A significantly higher specificity was observed at Kilibwoni compared to that of the more endemic Kebisoni (p < 0.0001) (Figure 3). This resulted in a significantly higher NPV for RDTs in the former (p < 0.0001), but there was no significant difference between the two sites in terms of PPV (p = 0.198). At Kebisoni, 220/628 patients (35%) who tested negative by microscopy tested positive by RDT. At Kilibwoni, only one of the 990 patients who tested negative by microscopy tested positive by RDT. Fifty-five of the 609 patients (9%) confirmed to be positive with microscopy at Kebisoni were declared negative with RDTs. Most of these patients had low mean parasite densities (below 1,000/?l in 34/55). However, six of the 55 false negative patients at Kebisoni (11%) had parasite densities exceeding 8,000/?l. At Kilibwoni, one patient was false negative by RDT out of a total of 10 who were confirmed positive by microscopy. At Kebisoni, true parasite rates (as determined by microscopy) declined during the four months (December 2005   March 2006) of concurrent collection of blood samples for comparison of RDTs with microscopy. During this period, the specificity of RDTs increased steadily from 56% in December 2005 to 79% in March 2006 (Figure 4a). There was no substantial change in the sensitivity of RDTs. During the same period, the NPV of RDTs increased from 67% to 92% whereas there was little change in PPV (76% in December 2005 and 77% in March 2006). The true parasite rate varied between age groups. The peak parasite rate was observed in children 2 4 years of age and the rate decreased in the older age groups (Figure 4b). Specificity of RDTs increased as parasite rates decreased, but sensitivity was more or less uniform among the various age groups. Sensitivity of RDTs was significantly higher in patients with fever (body temperature of 37.5 C and above) on presentation compared to non-febrile patients (97% versus 89%, p = 0.006) but specificity was significantly lower in febrile patients (33% versus 69%, p < 0.0001). No significant differences were detected between the two groups in terms of PPV and NPV (p = 0.827 and p = 0.742, respectively). At Kebisoni, microscopically confirmed P. falciparum patients with high parasite densities were significantly more likely to be true positive with RDTs than patients with a low parasite density (Figure 5). The mean parasite densities of false negatives and true positives were 898/?l and 5,215/?l and this difference was statistically highly significant (p < 0.0001). A logistic regression model showed that age, presence of fever, area and month of presentation were significantly and independently associated with probability of a negative RDT test result being a true negative (Table 2). False positive error rates declined in older age groups. Patients with fever at the time of presentation were more likely to test false positive with RDTs compared to those without. The site at higher altitude and with low malaria transmission intensity was associated with higher specificity. Specificity increased towards the end of the transmission season. Previous intake of antimalarials, revisit in the previous two weeks, travel outside the district in the previous two weeks and sex were not significantly associated with the probability of a negative RDT test result being true negative.
451939|1|One thousand seven hundred forty studies were identified from electronic databases. After screening the titles, abstracts, and keywords, 1595 studies were removed based on inclusion and exclusion criteria, 85 studies were removed due to the duplicates and 60 full-text potentially eligible articles were retrieved for the consideration. Finally, 15 studies were included in the analysis [27,28,29,30,31,32,33,34,35,36,37,38,39,40,41]. The flow diagram of our study selection is shown in Fig. 1. We included fifteen studies that compared the economic value of RDT with other malaria diagnostic methods. Fourteen studies were full health economic evaluations that made a comparison in terms of costs and effectiveness between RDT and its comparators. All of them were cost-effectiveness analyses, nine of which used decision tree models. Besides, one study, although did not say that it was a cost-effectiveness analysis, assessed both the costs and the specificity of RDT, thus we also considered it as full economic evaluations and included it [28] (Table 1). Most of the studies were conducted in Africa, except three: one in Afghanistan [29], and two in Brazil [36, 37]. The Africa-based studies were all performed in Sub-Saharan Africa (Ethiopia [32], Congo [35], Ghana [38, 40], Kenya [28], Nigeria [41], Senegal [34], Tanzania [33], Uganda [27, 30, 31]). One study targeted at all endemic countries in Sub-Saharan Africa using a simulated cohort with fever in the rural areas [39]. Eleven studies focused on suspected malaria and fever patients. Among the other four studies, two targeted at children [38, 40], one focused on the application of RDT in school students [28], and one assessed the effectiveness of RDT among healthy pregnant women [35]. According to the CHEERS checklist, huge gaps existed in the quality of evidence reported. Scores ranged from 7 to 23. Two studies provided a high quality of evidence with the highest score of 23 [29, 40], five had evidence of moderate quality [27, 30, 35, 36, 38], and eight had low quality with the lowest score of 7 [28, 31,32,33,34, 37, 39, 41]. The overall quality of all studies included could be seen in Fig. 2 and Additional file 1.
451939|2|The economic value of RDT was assessed in the fifteen economic evaluations and summarized in Table 2. Three malaria diagnostic techniques were reported and compared in all papers: RDT, microscopy, and presumptive diagnosis, and the majority took microscopy and/or presumptive diagnosis method as the comparison for RDT.
451939|3|Microscopy is a conventional diagnostic method to detect malaria infection. Six out of fifteen studies found that introducing RDT to substitute microscopy was likely to be cost-effective [27, 29, 35, 37, 39, 41]. Four of them made that conclusion as RDT could lead to either lower costs and improved outcomes, or a cost-saving when compared to microscopy [29, 35, 37, 41]. A cost-effectiveness analysis based on decision tree compared RDT and microscopy to presumptive diagnosis simultaneously [27]. It found that overall, RDT had lower positive ICER than microscopy and was most cost-effective in both high and low transmission settings. A decision-analytical study presented evidence of the cost-effectiveness of RDT compared to both microscopy and presumptive diagnosis [39]. With a threshold of USD 150 for the incremental cost per addition averted disability-adjusted life years (DALYs), RDT was highly likely to be cost-effective. The cost-effectiveness of RDT in comparison to the presumptive diagnostic method was reported in ten studies, and all of them used presumptive diagnosis as a base case with RDT as the intervention to compare [27, 29,30,31,32, 34, 38,39,40,41]. Eight studies provided supportive evidence that RDT was highly likely to be cost-effective: three studies observed that the use of RDT could be less costly while more effective [27, 32, 41], three studies found that RDT could result in an increase in both costs and effectiveness but it had the potential to be cost-effective at a low willingness to pay (WTP) threshold [29, 30, 40], another study observed a low ICER of RDT but admitted that whether RDT could be cost-effective would depend on how much decision-makers would be willing to pay [31], and a decision-based analysis showed that RDT was 85% certain to be cost-effective at all prevalence level below 65% [39].
451939|4|Fourteen of all fifteen studies received funding from various sources (Additional file 4). It was not clear based on current evidence whether founding sources would have an impact on whether RDT was cost-effective. Seven studies were government-sponsored, either intergovernmental organization or local government [28, 32, 34, 35, 37, 39, 41], and five of them supported the cost-effectiveness of RDT [32, 35, 37, 39, 41]. Of eight studies that did not receive funding from the government [27, 29,30,31, 33, 36, 38, 40], seven were sponsored by either non-governmental organizations or research institutions including universities and five studies reported that RDT was cost-effective [27, 29,30,31, 40]. There was only one study that had no statement of the source of funding, and its result did not support RDT s cost-effectiveness because it found that if the accuracy of microscopy could be guaranteed, there would be no additional benefits of applying RDT [36]. As most of the studies included received funding from nonprofit organizations and there was only one research that did not report its funding source, the impact of funding sources was less clear.
451939|5|Studies took a wide range of study perspectives which determined the scope of costs and effects within the evaluations: five studies were conducted from the societal perspective, four adopted a perspective of the health sector, one study did not report its perspective and the rest were undertaken under narrower perspectives such as provider or patient. There was a high level of heterogeneity among the selection of outcome measures among studies with narrow perspectives while the five studies under a societal perspective adopted either the number or the proportion of appropriately treated patients as the outcome, which can be considered as the same measure of effectiveness. We thus would take  the number of appropriately treated per 1000 suspected cases  as the main outcome and recalculate the results based on the available data. The comparison of the economic value of RDT between five studies taking a societal perspective was plotted in Fig. 3. Compared with other diagnostic techniques, the incremental effects of RDT were always positive, i.e., using RDT could contribute to an increase in the number of appropriately treated patients, but its impact on additional societal costs was not clear and could largely depend on the comparator selected. The introduction of RDT to replace presumptive diagnosis resulted in an increase in costs [27, 29,30,31, 40], but that increase was relatively small in most of the studies. There were two studies that provided evidence for the comparison between RDT and microscopy from a societal perspective, they observed a cost-saving effect when RDT was introduced [27, 29]. Overall, given a small number of studies, it could be found that RDT had the potential to be cost-effective particularly compared to microscopy under a societal perspective and whether RDT could be a dominant strategy would largely depend on the threshold of policymakers. Changes to the malaria prevalence tended to have an impact on the costs and effects of diagnostic methods. Thirteen studies recognized its potential influence on the cost-effectiveness of RDT compared to other methods but only eight of them formally investigated the uncertainty brought by malaria prevalence [27, 30, 31, 33, 37, 39,40,41]. The introduction of RDT to replace microscopy was found to be a dominant strategy regardless of the prevalence levels [27, 37, 39, 41], but the ICER could be lower with an increase in prevalence [33]. The cost-effectiveness of RDT against presumptive diagnosis was consistent: all the four studies that tested the robustness of the results found that RDT could be more cost-effective in the area with lower prevalence [30, 31, 39, 40]. Among all included studies, eleven had no restriction on participants  age and four limits the population to students or children of different ages. Evidence showed that whether RDT could be cost-effective compared to other diagnostic methods was not likely to be influenced by the age of the target population. Of the four papers with a limitation on the age, half applied RDT on children under 5 years old and supported the cost-effectiveness of this diagnostic method [31, 40], while the other half focused on children as well and did not reach that conclusion, but both of them recognized the cost-saving effect of RDT compared to microscopy [28, 38]. Of eleven studies without a limitation on age, eight showed that RDT could be more cost-effective compared with other methods [27, 29, 30, 32, 35, 37, 39, 41]. The majority of economic evaluations included considered RDT as a cost-effective strategy regardless of whether the study limited the subjects  age. Further details can be seen in Additional files 2 and 3.
451939|6|There are various types of RDT: some of them can detect single Plasmodium species, some can detect multiple species and some can distinguish between different species [42]. The difference in the types may bring extra costs to the economic value of RDT as they may have different prices. To compare the impact of RDT types, we categorized RDT into two categories: one is a single test which only detects single species, another is a combo test which can detect multiple Plasmodium species. The types of RDT used in included studies varied greatly. Ten studies adopted single test [27, 28, 30,31,32,33,34,35, 39, 40], while combo tests were used in seven studies [28, 29, 32, 36,37,38, 41]. Evidence suggested that single RDT could be cost-effective compared to microscopy and presumptive diagnosis. Plasmodium falciparum-specific RDTs were adopted in eight studies: four of them were decision analytical economic evaluations and suggested that the introduction of single RDT tests can largely improve the proportion of appropriate treatment for patients [27, 30, 31, 40]. In the other four studies, two of them found that RDT was likely to be more cost-effective than microscopy [35, 39], and the remaining two studies adopted single and multiple tests at the same time. In the first study conducted in Ethiopia where P. falciparum and P. vivax co-exist, both single and multiple tests were used to appraise the cost-effectiveness of RDT compared to presumptive treatment [32]. In the area with various malaria species, multiple tests were more cost-effective than either a single test or presumptive diagnosis. In a second study, a cost analysis was performed to appraise the performance of four RDT brands, including single and multiple tests, but it did not assess the effectiveness of multiple tests and only reported costs of general RDTs rather than costs by each RDT type [28]. However, the cost-effectiveness of combo tests was not clear. Four of seven studies showed positive results regarding the cost-effectiveness of combo RDT. Three studies that appraised the costs and effectiveness of RDT based on decision models observed lower costs and more clinical benefits with the use of multiple tests than microscopy [29, 37, 41]. Lemma et al. found that multiple tests performed better and cost lower than both single tests and presumptive diagnoses in the context where P. falciparum and P. vivax co-dominate [32]. However, the cost-effectiveness of multiple tests applied in the remote area of Amazon where P. falciparum and P. vivax dominate as well were uncertain as it largely depended on the accessibility to and the accuracy of microscopy [36]. Evidence identified in this review observed that RDT could also lead to the problem of over-diagnosis [28, 38]. Although RDT was the cheapest approach to detect infection in malaria school surveys compared to other strategies (i.e., microscopy or RDT corrected by alternative methods), it over-estimated the prevalence of infection [28]. Also, the study only evaluated the costs of diagnosis and thus the cost-saving effect of RDT could be maintained remainsed unclear when treatment costs were taken into account. The treatment costs were found to be higher for RDT than for microscopy when P. falciparum and pan-specific RDT was used to the management of malaria cases in Ghana [38]. The study also observed the over-diagnosis and additional costs when RDT was introduced to replace presumptive diagnosis. This may reduce RDT s advantage in terms of cost-effectiveness. In general, the impact of the types of RDT on its cost-effectiveness remained uncertain given various types of RDT, the complexity of local epidemiological characteristics and the lack of evidence reported in studies included. Further details of the types and brands of RDT can be seen in Table 1.
359124|1|Sustained malaria control will depend on the global capacity to accurately detect malaria and map its distribution. The specific detection of malaria parasites is now possible even at the village level with high quality rapid diagnostic tests. Driven by the extent of over-diagnosis and misdiagnosis of malaria when syndromic approaches are used, global efforts are underway to increase the utilization of parasite-based diagnosis, and to ensure the quality of tests that are used. Elimination efforts will not only increase the need for widespread RDT use, but may drive the development of new tests with enhanced performance. Implementation of the Global Malaria Action Plan [47], proposed regional initiatives towards elimination of malaria, and the reductions in mortality from malarial and non-malarial illness necessary to achieve Millennium Development Goals will require an increased emphasis on building systems for parasite detection as an integral part of malaria case and programme management.
1012871|1|During this period around 2000 under 5 year patients presented with fever at out-patient pediatric department LUH Hyderabad and it was considered low risk area for malaria..From2000 cases only 20% (400) were diagnosed as suspected clinical Malaria according to IMNCI algorithm. Distribution of sex and different age groups were shown in Table-I and Districts of positive cases and plasmodium species is shown in Table-II. From 400 cases only 40 cases (10%) have shown positive results for malaria parasite on slide microscopy and RDT. Regarding the plasmodium species 70% (28) were vivax and 30% (12) were falciparum. Except only two cases all the cases positive on slide microscopy has also shown positive results on RDT. Regarding the effectiveness, RDT has shown 95% sensitivity for the detection of plasmodium antigens in the febrile clinically suspected cases of malaria. Effectiveness of RDT with sensitivity and specificity is shown in Table-III.
2593776|1|In this part of the study, 1807 subjects were tested by all 7 RDTs in field. Of which 46.1% were positive, 25.7% P. falciparum, 16.6% P. vivax, 1.0% P. malariae, 1.9% mixed infection of P. falciparum and P. vivax and 0.9% mixed infection of P. malariae with P. falciparum and/or P. vivax. FIRST RESPONSE  detected 468 out of 480 microscopically confirmed asexual sexual falciparum malaria infection (Table 1). However, other RDTs i.e. FalciVax detected 429, parascreen  425, SD BIOLINE & NecVIPARUM 416, ParaHIT  Total 373 and GENOMIX detected only 360 falciparum infections (Table 1). Among microscopically confirmed 329 P. vivax subjects, FIRST RESPONSE  detected 262, parascreen  162, SD BIOLINE 163, FalciVax 149, NecVIPARUM 141, ParaHIT  Total 112, while only 65 cases were detected by GENOMIX (Table 2). Number of invalid test (absence of control band) was recorded in 1, 7, 2, 8, 9, 15 and 4 tests respectively for FIRST RESPONSE , parascreen , ParaHIT  Total, FalciVax, SD BIOLINE, GENOMIX and NecVIPARUM. The analysis of results revealed that the sensitivity of the FIRST RESPONSE  for P. falciparum was 98% (Table 1), of parascreen  and FalciVax 89%, SD BIOLINE & NecVIPARUM 87% and ParaHIT  Total 78%, whereas the sensitivity of GENOMIX was only 76%. The specificity for P. falciparum was 92% by GENOMIX, 91% by ParaHIT  Total, 90% by FIRST RESPONSE  and NecVIPARUM, 86% by parascreen , 85% by SD BIOLINE and 84% by FalciVax. For P. vivax, the sensitivity of different tests when compared with microscopy were 80% by FIRST RESPONSE , 50% by parascreen  and SD BIOLINE, 46% by FalciVax, 43% by NecVIPARUM and 34% by ParaHIT  Total, while only 20% by GENOMIX (Table 2). Specificity of all these tests ranged between 97 99%. Analysis of sensitivity on different level of parasitaemia revealed that FIRST RESPONSE  was able to detect 100% malaria infection at >100 parasites/ l of blood for both P. falciparum and P. vivax. While parascreen , FalciVax, SD BIOLINE and NecVIPARUM were able to detect >90% P. falciparum infections when parasite densities were >500 parasites/ l. However, ParaHIT  Total and GENOMIX detects 90% P. falciparum infections when parasitaemia was >1000 parasites/ l. Regarding P. vivax infections except FIRST RESPONSE , other RDTs detect only 31 63% when parasite density is >500 parasites/ l (Figure 2).
2593776|2|RDTs kept at 35 C and 45 C for 15, 30, 60, 90 and 100 days and at 60 C for 48 hours for heat stability test in the field. Seventy five clinically suspected malaria cases were tested on 15, 30, 60 and 90 days, and 50 clinically suspected cases were tested on 100 days and at 60 C for 48 hours intervals. Results of heat stability testing was shown in Table 3 & 4. Experiments showed that sensitivity of most of the RDTs for P. falciparum was very good (>90) both at 35  and 45 C up to day 90 when compared with RDTs kept at room temperature. However, a sharp decline in sensitivity was recorded on day 100 at 35 C and 45 C by most of the RDTs. On the contrary all RDTs kept at 60 C for 48 hours showed no decline in the diagnostic performance. For P. vivax, the sensitivity of FIRST RESPONSE  was very good up to 90 days (100%) and a decline was noticed on day 100 (92%). Parascreen also performed well upto day 90 at 35 C (88%). However, a sharp decline in sensitivity was observed on day 90 at 45 C (75%). While other RDTs showed a steady decline in sensitivity from day 60 onwards (Table 4). The overall agreement and Kappa values between pairs of observers were very good for both at 35 and 45 C for P. falciparum. However, Kappa values was not good for some RDTs for P. vivax especially on days 90 and 100 (Figure 3).
362249|1|Figure 1 shows that the total costs of antimalarials and RDTs for treating all malaria patients in 2002 in the two study districts. Using clinical diagnosis, this would be $42,484 when treating them with AS+SP and $63,048 for AL. The introduction of definitive diagnosis (using RDTs) could either result in cost savings or additional costs, depending on the proportion of febrile patients confirmed to have malaria. For the scenario where 25% of febrile cases are RDT positive, use of definitive diagnosis before treating patients would result in a cost saving of up to $1,485 and $16,908, when malaria patients are treated with AS+SP and AL, respectively, provided that health workers do not give antimalarials to patients with a negative RDT. Thus the more expensive the antimalarial being used, the greater the need for restricting antimalarials to confirmed malaria cases and the higher the cost savings that will be realised through effective implementation of definitive diagnosis.
362249|2|Figure 2 shows the incremental costs (or cost savings) for antimalarials and diagnosis under the different scenarios. For the relatively cheaper ACT (AS+SP), only when 29% or less of all suspected malaria cases test positive for malaria will the use of RDTs in all clinically diagnosed malaria cases result in cost savings, when compared to all patients being treated with AS+SP on the basis of clinical diagnosis. This percentage increases from 29% to 41.5% when use of RDTs is restricted to only those older than six years of age, and malaria positive patients are treated with AS+SP. For a relatively more expensive ACT (e.g. artemether-lumefantrine in 2004), as long as fewer than 52% of tested cases are found to be positive, the use of RDTs in all suspected malaria cases will result in lower treatment costs (cost savings) compared to when patients are treated on the basis of clinical diagnosis; this cut-off shifts from 52% to 74% if use of RDTs is limited to patients who are over six years of age. This strategy results in lower additional costs or higher cost savings compared to when RDTs are used in all suspected malaria cases, for both AS+SP and artemether-lumefantrine. However, in terms of cost, there are greater gains in restricting use of RDTs in patients over six years of age, when treating with a less expensive ACT (e.g. AS+SP). This is expected since the price of one RDT ($0.95) is nearly twice as high as the cost of one dose of AS+SP for a patient younger than or equal to six years ($0.49), but similar to the cost of an AL treatment course for this age group ($0.90). Hence, treating all patients younger than or equal to six years with AS+SP on a clinical basis makes more economic sense than using an expensive RDT to test this age group.
362249|3|Figure 3 presents results on the incremental costs per malaria positive patient treated. Incremental costs have been calculated using total cost of RDTs and antimalarials divided by the number of malaria cases for the different scenarios. Findings reported are based on the assumption that health workers adhere to test results and do not give antimalarials to patients with a negative RDT. Results in Figure 3 again show a cost saving (of $0.19 per patient treated) if malaria is present in under 29% of patients and that even when 75% of cases are malaria positive, the incremental cost per malaria positive patient treated is less than US$ 1, when AS+SP is used for treating malaria patients. When patients are treated using artemether-lumefantrine, there are cost savings per malaria positive patient treated of up to $2.12 (in the 25% scenario) as long as 52%, or less, of the suspected cases are RDT test positive. Beyond the 52% cut-off point, additional costs are incurred with an incremental cost per malaria positive patient treated of up to $0.85 (when 95% of tested cases are found positive and treated with artemether-lumefantrine). According to the guideline provided by the Ad Hoc Committee on Health Research relating to Future Interventions Options, an intervention is considered to be highly attractive (hence 'cost-effective') in low income countries if it costs less than $25 per disability-adjusted life year (DALY) averted and any intervention that costs less than $150 per DALY averted should be considered attractive [26]. Although the health outcome used in this analysis is number of patients treated and not DALYs, this guideline could be helpful in considering whether an incremental cost per malaria positive person treated of less than $1 should be regarded as being highly cost-effective.
362249|4|Findings from the one-way sensitivity analysis on variation in the age distribution show that the higher the percentage of adults among the suspected malaria cases (age breakdown 3), the lower the additional costs and the higher the costs savings (particularly with a relatively more expensive ACT like AL) associated with use of RDTs (Figure 4, quadrant 4), and vice versa. This finding is not surprising since the price of the ACTs for children is significantly lower than the price of the adult dose, and yet the price of the RDT remains constant for all age groups. Results in Figure 5 show how changes in the age distribution of patients with clinically suspected malaria have an impact on the decision on restricting their use to only those who are over six years of age. The higher the proportion of young children among those with suspected malaria, the more it makes economic sense to restrict the use of RDTs to those over the age of six years. The more expensive the unit price of the antimalarial for the one to six years age group, relative to the unit price of RDTs, the lower the cost savings associated with restricting RDTs to patients over six years of age (Figure 5).  Results of the one-way sensitivity analysis on the RDT price variable show that as expected, the lower the unit price of a rapid diagnostic test the more cost-effective it is to use definitive diagnosis (using RDTs) as the basis for ACT treatment, regardless of the price of the antimalarial being used. With a reduction in the unit price of RDTs from $0.95 to $0.50, limiting the use of RDTs in patients older than six years would result in significantly less economic gains (when patients are treated with AS+SP) and some economic losses in areas of low to moderate intensity malaria transmission (where 50% or less of fever cases are malaria positive). The same applies when patients are treated with AL (quadrant 6, Figure 6). In other words, the cheaper the RDT the less the need is to restrict to older age groups. Similarly, results of the one-way sensitivity analysis on the ACT price variable show, as expected, that the use of RDTs will become less cost-effective as the antimalarials become less expensive. This explains why, at least from an economic perspective, RDTs have not been widely used when cheaper antimalarials, such as chloroquine or sulfadoxine-pyrimethamine monotherapy, were being used in areas of moderate to high intensity malaria transmission. This may also be the in-country scenario with the implementation of a global subsidy to reduce the price of ACTs to that of chloroquine [27]. Results of the multi-way sensitivity analyses (Table 4) are presented in Figure 7. In these analyses the prices of antimalarials, prices of RDTs and age distribution were varied to assess the effect of simultaneous changes in these variables on the earlier findings on cost-effectiveness of RDTs. Figure 7 shows that, as expected, multi-way 1 (high prices of ACTs and RDTs and children younger than or equal to six years of age taking up the highest proportion) is the context in which routine use of RDTs is least cost saving (for both AS+SP and artemether-lumefantrine) (quadrant 1, Figure 7). Results of multi-way 2 sensitivity analysis show the impact of changing age distribution alone (without changing the prices of ACTs and RDTs). There is a decline in incremental cost per patient treated, from $0.82 to $0.71 and from $0.61 to $0.49 for AS+SP and artemether-lumefantrine respectively, purely as a result of increasing the proportion of adults in the population with clinically diagnosed malaria. Results of multi-way 3 sensitivity analysis (quadrant 3, Figure 7) show the impact of changing the price of RDTs and age distribution (without changing prices of ACTs). Changes in costs are mainly due to the variations in RDT prices and the proportions of adults treated. As expected, the bigger the proportion of the suspected cases that are adults, the greater the cost savings. Variation in the prices of RDTs and antimalarials shifts the cut-off points at which definitive diagnosis results in cost savings.
361337|1|Out of a sample size of 2124, a total of 2123 mothers with children under five from nine districts participated in the study. Of the 2123 mothers, 70 % were in the age range of 20 and 34 years. A majority of mothers (84 %) were in marital relations. Slightly more than one third (34.7 %) of the participants had more than three children. The study population was relatively literate with only 19.4 % of respondents who had never attended school, whilst about 69.4 % had attained primary school and 11 % had secondary education. A majority (70.4 %) of respondents were farmers. About 56.2 % of respondents were Christians and 40.9 % were Muslims (Table 2). Qualitative participants composed of 21 health care professionals (18 health care providers and four paediatricians), six teachers, four religious leaders and six community health workers. Twelve more IDIs were conducted with scientists from various institutions in Dar es Salaam (Table 3). FGDs were carried on with six groups of women and six groups of men. Most of the FGD and IDI participants were of age 25 and 50. Non-professional participants were mostly farmers and petty trade dealers. Most of them had attained primary school level. The majority of the professionals, such as nurses and teachers, were of secondary school and high school levels.
361337|2|Qualitative participants (mostly women) possessed a positive opinion towards vaccines. They were in the opinion that the vaccines are important for the reduction of disease severity, reduced cost of treatment and disease prevention. One female participant expressed her opinion that vaccine would reduce the severity of disease:  I know that when a child gets vaccinated he will be protected from diseases. Even if the disease comes, it will not be very much severe as compared to if the child has not completely received a vaccine  (FGD, Female_04). Another female participant was in the opinion that vaccine is important for prevention of diseases:  Just like what the experts says  it is better to prevent than to cure  then I think vaccination is important as it helps to prevent a child from diseases and reduces treatment costs because during treatment you use much cost to treat the child unlike when the child is protected (with the vaccine)  (FGD, Female_05). Similarly in the quantitative study, the majority (90.1 %) of mothers reported that there is a benefit associated with vaccination (Fig. 1). Also, about 97.6 % agreed with the statement that  I prefer my child to receive all the vaccines  (Table 4).
361337|3|Most of the opinions of the qualitative participants reflected a positive acceptance towards the anticipated malaria vaccine. The main consensus was that malaria vaccine is important since malaria is still a common disease among children under five. One of the paediatricians provided his view that malaria vaccine need to be provided since more strategies are needed to fight malaria:  I think malaria problem is still there and more weapons are needed in making sure that it is prevented, vaccine is one of the weapon, but if it s safe for the users  (IDI, Paediatrician _05). Another participant was in the opinion that malaria still affects children and hence a need to introduce malaria vaccine:  Malaria vaccine should be introduced due to the burden of malaria especially for young children  (IDI, Nurse, RCH_06). A male participant thought that malaria vaccine is needed because the mosquito nets cannot provide full protection from mosquitoes:  I think we need malaria vaccine since we are not always covered by the mosquito nets. Look at where we are now, we have stayed for almost one hour and the mosquito nets are inside our houses on the beds. Probably the mosquitoes might have already bitten the child. Therefore, we cannot totally depend on the mosquito nets   (FGD, Male_ 05). The quantitative results revealed that the majority (84.2 %) of the participants indicated a perfect acceptance of malaria vaccine, 11.9 % had partial acceptance while 3.9 % had no acceptance of the vaccine (Table 5). Occupation, tribe, religion, and regions attained a statistical significance with the perfect acceptance of the malaria vaccine (p < 0.001), with farmers, Christians, members of the tribe Hangaza and households in the Kagera region presenting higher acceptance levels.
361337|4|The common expectations from the malaria vaccine by most participants comprised a view that malaria vaccine will lessen the malaria episodes, frequent visits to the hospital due to malaria, the number of deaths and that the overall burden of malaria among children will be reduced.  My expectations is that if malaria vaccine will work, it will help reduce the hassle we get of having frequent malaria, you will find a child going back to hospital even four times in a month  (FGD, Male _03).  The expectations of most people will be that the malaria vaccine will completely eradicate malaria, because the children will have protection and so malaria will finish   (FGD, Female_05).  The health care providers will feel very proud to have this additional vaccine on top of the existing ones since we hope it will succeed in reducing the mortality rate especially for children under 5 years  (Nurse, RCH_05).  Most mothers will definitely take their kids for vaccination since the costs of treatment nowadays is very high  (Teacher_02).
360871|1|The meeting feedback received from participants and observers[54], and MPAC members themselves, was very positive. Having met three times to date, the format of MPAC meetings and its feedback loops with other advisory bodies and stakeholders is beginning to settle, although it remains an evolving process. WHO-GMP and the MPAC continue to strongly welcome feedback, support and suggestions for improvement to MPAC meetings from the global malaria community.
360871|2|The next meeting of the MPAC will take place from 11 to 13 September 2013 in Geneva, Switzerland. Further information, including the agenda and details on how to register, will be made available in July 2013 on the MPAC page of the WHO-GMP website, although questions are welcome at any time[5].
995302|1|A country's decision to adopt a new health technology requires more than the existence of a good product. In low and middle income settings, a wide range of organizations can support country decision making. The role of PDPs in this process is based on the PDPs' vision to see public health impact from the products they develop, and on their intimate familiarity with the products under discussion.
995302|2|A PDP as a whole can cover a wide spectrum of activities ranging from basic research to implementation of interventions. At the implementation end of this spectrum, there is no single definition of where the PDP role ends, as the technical needs and available partners in endemic countries vary for each intervention. However, as more PDP-related products progress, additional experience will assist in defining the areas in which PDPs are effective and should be held accountable. Funder, partner and country participation in the development of improved means to evaluate the relative roles and impact of PDPs will also be important. Building on the insights described here, PDPs, partners and country stakeholders can continue to provide critical support for decisions on interventions that will ultimately decrease the global burden of disease.
363993|1|WHO has played a major convening role in the past three decades in establishing a normative framework for critical aspects of vaccine development as antigenically-defined subunit vaccines, novel platforms and new adjuvants were introduced for human use, often for the first time in association with malaria vaccine studies. The importance of early and close involvement of scientists, developers, regulators, and public health physicians has enabled continuing close cooperation in later stages as developers evaluate vaccines in ways which will enable technical advisory bodies of WHO to have access to the data that will enable them to provide guidance for country programmes.
363993|2|This review has focussed on the contributions to clinical trial design. In many cases, the discipline has moved from theory to practice, with large numbers of trials of pre-erythrocytic and asexual stage antigens with different adjuvants now completed and published, so that new protocols can benefit from practical experience added to theoretical considerations. The context has also changed with many trial sites having experienced gratifying reduction in morbidity and mortality, one consequence being the requirements for larger multi-centre studies and complications of interpretation from sites with different intensities of transmission. The reduced transmission has also caused many to focus mainly on the possible contribution of vaccines directed against any stages to reduction of transmission and possible elimination of malaria. Non-falciparum species have taken a backseat role at this stage and ongoing debate continues about the best way of reporting efficacy data. As much is now known and published on pre-erythrocytic and asexual stage vaccine trials, at least to proof of concept stage (probably better described as experimental medicine rather than product development), the review has given greater attention to what lies ahead. The focus is on design of trials for which there is little or no experience, namely trials of vaccines for P. vivax, and trials for assessment of reduction of transmission, and for which preferred product characteristics are still the subject of debate (for example with respect to efficacy against hypnozoites or go/no go criteria for transmission blocking studies).
363993|3|The review has highlighted the past and ongoing contribution made by WHO in convening groups to address key issues for investigators, vaccine developers, regulatory authorities and funders in ensuring the most efficient use of resources for developing much-needed vaccines for use in malaria endemic countries.
360654|1|A total of 466 household heads were involved in the survey after approaching 480 households. A majority (over 74.7%) of respondents were in the age range of 29 and 39 years (Table 2). A majority of the respondents were married; most respondents were farmers (Table 2). Respondents in the FGDs had similar demographic characteristics as those involved in the survey. Those selected for the IDIs were health professionals who had attained at least senior secondary school education or non-professionals with either no formal education or with education up to junior high school level.
360654|2|Knowledge of vaccines was widespread among participants in the study. Knowledge however, seemed to be skewed towards vaccines given in the form of injections; there was some knowledge of the existence of the oral polio vaccine (OPV), which they admitted is not an injection. Finding a common local name for vaccines that is acceptable and understandable by all respondents was not difficult. Local words like  ntetee   paniebo  exist as terminologies for vaccination. Most respondents knew what vaccines are, as evidenced in the following contributions made by some respondents in both IDIs and FGDs:   Vaccines are injections given to children in their childhood so that any disease that has the possibility of attacking children become less severe if even they are attacked.  (FGD, female E)   I know that vaccines are injections given to prevent the occurrence of a disease.  (FGD, male E)  Participants differentiated vaccines from medicines given as injections in hospitals emphasizing the preventive aspect of vaccines. These observations were made:   For vaccines, they are taken to prevent the occurrence of the disease. While those injections that are taken at hospitals, the sickness occurs before one goes for the injections.  (FGD, male C)
360654|3|Over 50% of respondents spontaneously mentioned tuberculosis and poliomyelitis vaccines as childhood vaccines (Table 3). There were varied views regarding malaria prevention with vaccines. While some respondents were quite certain that malaria could be prevented through vaccination, others were rather sceptical. This is evidenced in contributions made by respondents in the IDIs and FGDs:   In science, there is a saying that you cannot say never. It can happen but I think it will be very difficult. The malaria parasite strains change so rapidly, I think that vaccination could be done but would work in the short term like every three months just like tabs for typhoid fever and the rest. Sometimes you can give it to the person but then it does not last. Its longevity is not there so they would have to come and take it again. Because the malaria strains are so varying and a whole lot of them it have lots of properties and biochemical characteristics, so to get a long-lasting vaccine, it is something we can do but we have to work harder.  (IDI, health care provider B)  A participant, expressing an opinion about a vaccine s ability to prevent malaria made the following remarks in an IDI:   Well, it looks strange but we are just hoping especially once they say the vaccine is just going through phase II and it is going to phase III. This is because malaria is endemic and any success in that direction is something that everybody is yearning for. At the OPD, the daily OPD register shows that malaria is leading, so many cases of malaria at least 50% or more. The success of this vaccine will even curtail our burden at the OPD . (IDI, health care provider A)  When the respondent was asked the reason for describing vaccination to prevent malaria as  strange , the following was the response:   The causative organism is always with us. The mosquito is always with us. Every time we get bitten by a mosquito. I do not know how long, whether the vaccine can stay in the body and produce antibodies that will not let you get malaria once you are vaccinated, just like polio which when your body is exposed to the vaccine you will not get it for your lifetime. This one looks strange because of the causative organism, but it looks impossible, but let s wait.  (IDI, health care provider A)  A chemical seller made the following remarks when asked if he believed malaria can be prevented through vaccination. He was a sceptical but made mention of a more multiple approach towards this course to fight malaria:   Well, it is possible. Chloroquine was a drug which was used to treat malaria when crystalline [ penicillin] was added but it is now phased out. It [malaria] disturbs people but they cannot complain. We do not know what the Pharmacy Council and the Food and Drugs Board saw about chloroquine and recommend that it should not be used.  (IDI, chemical seller A)   I cannot argue about that. As am saying when the polio vaccine was introduced, the incidence of polio has stopped among children after vaccination. Also with the measles vaccine, a mother who refuses to vaccinate her child is always in trouble whenever the child suffers an attack. So getting a vaccine for malaria is possible. Mosquito nets have been introduced but the incidence of malaria is still high.  (IDI, chemical seller A)  The survey showed that a large proportion of respondents think malaria can be prevented through vaccination. Over 90% of the respondents were in this category (Figure 1). Reasons were assigned for thinking that malaria can be prevented through vaccination; the statement below briefly summarizes the thoughts of participants during a discussion session:  An instance is the incident of polio which has been reduced through vaccination. I have the belief that malaria can be eradicated or reduced through vaccination. This can be seen through the research being carried out.  (IDI, head of a religious group)
360654|4|Respondents  attitudes about vaccines preventing malaria were quite positive. There was a general quest for vaccines for all types of diseases, especially malaria. Respondents in both FGDs and IDIs mentioned the types of diseases they want their children vaccinated against:   Malaria is a sickness that disturbs us a lot. So if children are protected against malaria it will help us. Because there are lots of mosquitoes that bite and cause malaria so that if we prevent the occurrence of malaria it cannot be severe even if there are mosquito bites.  (FGD, female A)   Polio, polio disturbs children a lot, it makes them very weak.  (FGD, female B)   With diarrhoea, children vomit and pass out watery stools so if we prevent it, it will be good.  (FGD, female B)
360654|5|As part of learning their attitudes towards vaccines for malaria, respondents were asked whether they preferred vaccines or drugs or both for malaria; 65.9% of respondents preferred vaccines to drugs for malaria control while 26.2% preferred drugs to vaccines. Few respondents had no preference for vaccines or drugs (Figure 2). Responses from both male and female participants on whether they will allow their children to be vaccinated against malaria, assuming a malaria vaccine is found, were very insightful:   I will agree: I have no drugs to cure my children. So if the government says a disease is about to break out so I should vaccinate my child, what can I say?  (FGD, female E)   Malaria is the number one killer diseases among children so if it is going to be prevented, then I think everyone would be happy to include his/her child.  (FGD, male A)  Diseases that respondents wanted their children vaccinated against were confirmed in the survey (Table 4). These were affirmed by some of the responses in the FGDs, thus emphasizing how generalized some of the contributions made by participants in the FGDs could be when it came to the diseases participants will or will not want their children to be vaccinated against (Table 4). Among health care providers and community religious leaders it was evident that vaccinating children against malaria will be a major breakthrough in science and accepting it will not be very challenging at the community level:  I will readily recommend that because malaria in children under five is fatal. Cerebral malaria for instance causes lots of problems. In children under-five, because of their immune system, when they get malaria it is fatal because of its added complications. Should we make a head way with this vaccine trial, I think all children, most especially, children under five should be vaccinated.  (IDI, health care provider)  Readily yes or even should I say a big yes. You see, these children are exposed to lots of filth and as you can see lots of weeds around that serve as breading grounds for mosquitoes. So getting a vaccine to prevent the effects of these mosquito bites will be a good thing. I will recommend it.  (IDI, head of a religious group)
360654|6|The success of disease control programmes to a large extent depends on the beliefs and cultural practices of the people who are directly involved in the programme and this shapes their behaviour and consequently their decision-making processes. Though beliefs and cultural practices that will prevent parents from vaccinating their children were not mentioned, some IDI sessions revealed some interesting points are quoted below:  ..somewhere in the north, when a child is born it is not brought out until after one month or so. So if we are looking at a vaccine targeting children of four weeks or less, that can possibly be a barrier to such children getting access to the vaccine. Another one is the social barrier where women cannot take decision about their children.  (IDI, health care provider)  As a Catechist who is in charge of organizing the congregation here, I always advise women who take their children to  weighing  [ child welfare clinics].  In the olden days herbs were used to treat diseases but now it is a thing of the past. We also advise against the belief that sickness is caused by gods. For now, it is only medication that is given which in the name of Jesus we also pray to support I don t know of any such beliefs. In the beginning of the trial [ RTSS malaria vaccine trial], some people from the north living here did not understand that there is the need send the child for immunization and weighing.  (IDI, religious leader)  There is nothing like that [ cultural beliefs] if you should follow these things all your children will die.  (FGD, male C) Some religious dimension was given by a participant when asked if he will recommend vaccination for malaria:  I know that God has poured his grace on a group of people who are working through the Holy Spirit. They are doctors. As the Bishop or any church member goes to the hospital when sick, if a vaccine for malaria is found I will not prevent people or any of my church members from sending their children for vaccination.  (IDI, head of a religious group) Among the Muslim participants, the situation about recommending vaccines for malaria was not very different. A participant had this to say:  Even the prophet Mohammed ( peace be on him ) implored his followers to do two important things: learning very well so that you can worship your God; learning about protecting yourself from falling sick. It will have been welcome news to be able to protect ourselves against diseases. Even God approves of that. People should actually treat themselves when they are sick. It is also mentioned in the Quoran that people should protect themselves from falling sick. It is good to  defend  yourself from sickness. This is better than allowing the disease to attack you before you treat it. Yes, the Quoran does not forbid vaccination. Quoran is totally in support of prevention. I will readily recommend, if even it means talking about it in the various mosques that are under my jurisdiction. I will even mobilize other Imams working under me, so we can educate people.  (IDI, head of a religious group)
360628|1|Implementation of an ivermectin-based strategy to reduce malaria transmission will require higher or more frequent doses that currently used for NTDs. Efficacy and safety will be the most important parameters to be evaluated by any stringent regulatory authority; both are directly related to the dose and dosing scheme selected for malaria. For a WHO policy recommendation, additional factors such as cost-effectiveness, acceptability and programmatic suitability will need to be addressed.
1449365|1|396 articles were retrieved from various databases and other sources in which 72 were excluded because they were duplicate hits. The remaining 324 unique articles were screened by titles and abstracts after which 309 articles were excluded. Three articles out of the remaining 15 were excluded because one was a brief communication [17], the second was about a hypothetical malaria vaccine [18], and the third was a review study [19]. Therefore only 12 full articles qualified for the qualitative analysis [20 31] (Figure 1) .
1449365|2|Tanzania has a list of twelve priority disease conditions referred to as a national package of essential health interventions, on which to prioritize the allocation of its scarce resources for health. This list rank disease conditions according to their burden of disease and is dominated by infectious diseases   HIV/AIDS, malaria and diarrhoeal diseases are at the top. Ranking of the disease conditions is fairly consistent with the number of pharmacoeconomic studies we have identified. Nine out of the twelve pharmacoeconomic analysis studies addresses the four highest ranked disease conditions (Table1) It is disappointing to note that only one pharmacoeconomic study addresses non-communicable diseases, and none are available for acute respiratory tract infections, diabetes, cancers, and nutritional deficiencies.
359097|1|Of 700 results returned by the PubMed search, 118 publications were selected for full-text review. These documents, which ranged in publication year from 1959 to 2015, included contemporary accounts of the campaign from specific countries, assessments of global programme process, and reflections on the eradication accomplishment by its participants in both journal article and book form, along with several reviews of the smallpox experience. A number of themes emerge from the literature across the seven areas of interest (Table 1).
359097|2|Henderson declared,  For a global programme against a disease to be undertaken, universal political commitment is necessary  [10]. In the case of malaria, support for fighting the disease seems strong, with malaria control activities frequently cited as one of the  best buys in global health  [11,12,13]. However, the pursuit of malaria eradication is more controversial, and whether it represents a feasible or even a worthwhile goal has been frequently debated [14,15,16,17,18,19,20,21].  Support for the smallpox eradication programme was similarly far from universal. The failures of prior eradication or regional elimination efforts including hookworm, malaria, yellow fever, and yaws increased skepticism, as did a perception that vertical eradication campaigns detracted from provision of basic health services [7]. Although the WHO was tasked with coordinating the effort from Geneva, its diverse departments and regional offices were not uniformly behind the effort, in part because  their officials competed with each other for finite financial resources and administrative influence  [22]. The Director-General of WHO reportedly had so little faith in the programme that he explained to Henderson a secondee from the United States  Centers for Disease Control and Prevention that  he wanted an American as the director so that when the programme failed, as he was sure it would, the Americans, not the WHO, would be seen as responsible  [23].  The smallpox programme survived at the WHO in part because of strong backing from both the United States and the Soviet Union [23], the major powers of the era. Henderson himself was seen as a trustworthy leader by both rival countries despite ongoing Cold War hostilities because of his strong track record as an  honest and a good scientist  whose  only objective [was] to eradicate smallpox  [23]. Still, maintaining smallpox s profile within the WHO and encouraging countries to contribute funding and resources was an ongoing challenge. Henderson used the annual meeting of the WHO assembly as an important opportunity to keep eradication on the minds of health ministers [8] and tried to maintain smallpox s public profile by widely releasing surveillance reports with summaries of progress and problems. Henderson later suggested that a mistake he made was not adding dedicated staff to his team focused on public relations and donor advocacy [10]. Malaria today appears to have a more visible profile internationally than smallpox did, in part due to similar communications efforts, such as the annual World Malaria Report which provides opportunities for visibility and public engagement [24].
359097|3|International coordination was considered important to avoid  ping-pong smallpox  [25] in which infections would be continually reintroduced from country to country. A 1960 Inter-Regional Smallpox Conference organized by the WHO reported that since  the eradication of smallpox cannot be considered on the basis of individual territories,  the Conference  therefore urges the health administrations of all countries in endemic regions to synchronize their eradication campaigns  [26]. While this declaration was sufficient to spur action in some countries [27], others, including Brazil the country with the largest burden in the Americas and many African countries [28], declined to initiate vaccination programmes, compromising the possibility of regional success [29]. Provision of dedicated smallpox funding in 1967 proved critical to allow the WHO to incentivize countries to scale up their national programmes [10], even when committed funding was small [29]. The provision of donor funding for malaria increasing from about $170 million in 2000 to $2.5 billion in 2016 [30] has likely been similarly important to convince countries to prioritize malaria programming.  Despite the international push from the WHO, the smallpox eradication effort would always remain a collection of individual national programmes, each attempting to solve their own problems through their own systems and in their own ways [28], rather than a top-down, centrally managed global undertaking. Dr. William Foege, an American epidemiologist who helped design the surveillance-driven vaccination strategy that likely enabled success in countries including Nigeria and India [31], called it  20 programmes trying different things to more quickly discover truth  [32].   The campaign to eradicate smallpox worldwide is often described in simplistic terms  The picture presented is of a unitary programme of action, where the many cogs in the wheel apparently worked in almost perfect harmony, causing orders from the top of an administrative pyramid to be unquestioningly implemented in localities across the globe  the organized drive to expunge smallpox was a much more complicated and disjointed entity  [33].  Current malaria guidance embraces an aligned belief that  adapting and tailoring interventions  to the local context will be important for elimination success [34]. While encouraging local solutions, the WHO and other international entities including the United States  Centers for Disease Control and Prevention [35] added substantial value to these independent programmes, including:  Sharing best practices across countries WHO s guidance to countries changed substantially over the course of the programme as understanding of best practices evolved. Its initial recommendation for every country to vaccinate at least 80% of the population increased to a goal of 100% vaccination [28], before being replaced with a dramatically different recommendation to invest heavily in surveillance and to focus vaccination on the places where transmission was observed. Many countries resisted this latter change despite evidence that that surveillance-driven targeting was more efficient [31], and the WHO s leadership in pushing for adoption of proven approaches was thus critical [36]. Today, regular revisions of malaria guidance (e.g., [34, 37, 38]) demonstrate that such dissemination of best practices remains an important WHO role.  Ensuring the quality of tools Smallpox programmes relied upon having a stable, reliable, effective vaccine [39]. Yet when the newly established eradication headquarters in WHO established a system for testing batches of vaccine produced in more than 40 different countries, it found?<?10% of samples were acceptable [40] due to potency and heat stability issues [41]. The WHO engaged vaccine experts to write simple manuals of production that explained best available production methods, and the WHO consultants worked with laboratories to improve their production processes [42]. Local production of vaccine was set up at government-owned facilities or associated institutes in the largest population countries including Brazil, India, and Indonesia, since donations would otherwise have been insufficient [42]. Two high quality laboratories from the Netherlands and Canada were selected to serve as vaccine reference centres [39], and they performed batch testing to evaluate improvements. As a result of these efforts, the fraction of batches meeting quality standards rose to 31% in 1967, 76% in 1972, and 96% in 1976 [36]. The WHO today provides an analogous quality control and assurance function for certain malaria commodities, prequalifying malaria drugs (https://extranet.who.int/prequal/), evaluating the accuracy of diagnostics [43], and inspecting manufacturing sites for vector control tools, though the complex landscape for malaria commodities makes it more difficult to assess the overall quality of the tools being used in endemic countries. The smallpox experience suggests that investment in the production of bed nets in high-volume countries could be considered as a possible means of reducing reliance on imported, donor-funded products [44].  Provision of technical and operational support The WHO s smallpox eradication unit provided national programmes with both field epidemiologists for technical advice and administrators to help manage logistics. Over the 12 years of the programme, 687 different individuals from 73 countries participated in the WHO-sponsored programme [45]. The expansion of WHO s role from solely providing technical advice to actively enabling operations was a learning experience for the Geneva-based programme [46]. This evolution allowed Geneva to strengthen global logistics, moving supplies from one country to another as needed, or flexibly providing necessary funds to overcome bottlenecks [10]. It was noted that the WHO was most effective when its staff, including senior leadership, spent their time working in country with programmes [47]. Henderson stated his opinion that the most effective WHO staff  were those who took an active role in field operations. Those who assumed a passive role of detached technical adviser were encouraged to leave the programme  [10]. Similar sorts of temporary field advisors have been deployed under the  Stop Transmission of Polio  programme [48] and can prove useful for building capacity in malaria programmes if deployed thoughtfully [49]. The United States President s Malaria Initiative today provides technical advisors to malaria endemic countries in this mode, as do several non-governmental organizations.  Encouraging research and innovation In Henderson s view,  The importance of problem-oriented research that was conducted throughout the course of the smallpox eradication programme cannot be too emphatically stated  [10]. Development of a heat-resistant vaccine may have been the single most impact factor in global success [7], while ongoing operational research enabled resolution of unforeseen challenges that inevitably occurred over the course of the long, complex undertaking of eradication [21]. The WHO encouraged such studies through its convening power [14], though innovation was typically decentralized.  An important lesson was that parallel activities and research, with many groups seeking better approaches, could speed up the process of improvement,  Foege wrote [50]. The jet injector, for example, a new tool for increasing the speed and efficiency of vaccine delivery [51], was first developed in the United States at the National Communicable Disease Center during the 1960s [52]. The development of a low-tech, simpler solution the bifurcated needle by a private company, Wyeth Laboratories (which waived patent costs for any manufacturer supplying them exclusively to the WHO [53]), proved both simpler [29] and ultimately more successful [54]. An examination of innovation in the smallpox programme concludes that what was important was to  insure that the problem has been defined clearly and that intervening variables and technological factors do not becloud that definition , while building organizations that scientifically evaluate evidence and seek to improve themselves according to measurement of what does and does not work [39]. This perspective suggests the importance of continued investment both in malaria s $540 to $600 million research and development pipeline [55] as well as in efforts to help countries collect, analyse, and apply data for ongoing organizational improvements within their own programmes.  In playing these roles, there was agreement that the WHO s success was strongly linked to the ability to be as flexible and non-bureaucratic as possible [21]. Sometimes, as when flying to countries with outbreaks without receiving travel approvals, this meant breaking WHO rules [41], something Henderson deemed necessary given  a sclerotic  administration that often thwarted or actively impeded what appeared to be logical initiatives  [7]. In one example, an emergency request for vaccine supply from Uganda took 5 months to be transmitted to headquarters by the regional WHO office, during which time the Geneva office had already learned about the outbreak via informal backchannels and addressed it [8]. Internal WHO disagreements also led to challenges, with Henderson noting,  Officials located within different levels and departments of the regional offices continued to hold disparate views right till global smallpox eradication was formally certified  [33]. He complained that,  The regional offices of WHO  were more a hindrance than a help,  leading him to adopt a  policy of quietly short-circuiting the regional office, when necessary  [8].  The challenge for a complex bureaucracy like WHO to nimbly respond to dynamic circumstances have been echoed in recent years by criticism surrounding its response to the 2013 2016 Ebola outbreak in West Africa [56, 57]. The success of the WHO s smallpox team may provide a model for how a Geneva-based team can flexibly facilitate malaria operations across endemic countries. However, the fact that Henderson and colleagues viewed their success as something they achieved despite WHO s structures and procedures for example, by creating a new unit within a regional office that reported directly to Henderson rather than through the normal channels [33] rather than because of them, suggests that consideration will need to be given to how to ensure a central malaria coordination team is encouraged and enabled to be agile and flexible, as is required by the rapidly evolving nature of a global eradication enterprise, while still respecting and sometimes deferring to local solutions and expertise.
359097|4|Achieving malaria eradication will require each of the world s endemic countries to invest in eliminating transmission. Financial analyses typically suggest that substantial short term budget increases will be required to end endemic transmission, after which long term savings can be realized due to the lower costs of preventing its re-establishment [58, 59]. Surprisingly, in the case of smallpox, Henderson argues no such surge in funding was required, with existing domestic budgets sufficient to cover programmatic needs:   The burden of expenditure has been borne by the endemic countries themselves  But, with few exceptions, the expenditure by the countries has been little more than what they were already spending to control smallpox. In other words, WHO and its member countries, with only a very modest additional input in resources, have transformed a never ending control programme to a successful eradication programme.  [29]  The idea that smallpox could be eliminated from countries with essentially the same budget previously used to control it is remarkable, and suggests that how funds were spent proved far more critical than the total amount of those funds. As Henderson describes:   For all of us it has been a revelation in so many countries to find at the periphery such an array of unproductive health staff and facilities. It has been a revelation to discover how effectively they may be mobilized with a comparatively small input involving leadership in the field and definition of a series of activities with defined objectives and a modest element of management. Other health programmes, especially those involving immunization, but others as well, could, I believe, be similarly transformed.  [29]  The importance of using available funding better was raised both nationally and internationally. The WHO internal dynamics and disagreements between regional offices complicated the efficient expenditure of available funding. In the Americas, for example, in the early 1960s, the Pan American Health Organization (PAHO) chose to distribute available funding for mass vaccination across the entire region, even though Brazil was the only remaining endemic country [6]. As a result, Brazil s funding was insufficient and elimination programmes were prolonged unnecessarily [14]. The WHO s South-East Asia Regional Office (SEARO) chose to pass up the available funding rather than participate in the programme, which it disagreed with; Henderson then channeled the SEARO money to PAHO in hopes it would be spent in Brazil. Less than half actually was, with the remainder divided across 10 other countries [8]. When 5 years later Brazil was finally free of smallpox, PAHO refused to donate its funds back to SEARO in turn to assist India [8].  Henderson s comparison of the relatively similar costs for control versus eradication refer only to domestic contributions, and do not include the 407 million doses of vaccine that were donated over the course of the programme, primarily by the Soviet Union and the United States [29], at an average estimated value of $17 per 1000 [6] (approximately $7 million in total). Between 1967 and 1979, $67 million in cash and kind (including the donated vaccine) was donated to the WHO s special account for smallpox eradication while $33.6 million was spent from WHO s regular budget [6]. This total of approximately $7.7 million per year would translate to approximately $30 $50 million in today s dollars far less than the $2 billion per year currently contributed by international donors to malaria programmes [60].  The argument made to donors to secure these funds was that  all should be willing to contribute to carry the attack to the remaining endemic regions until there is no more smallpox  [51]. The United States, for example, was said to be domestically spending $140 million annually in 1968 to prevent re-establishment of smallpox transmission domestically, and thus its modest investment of $15 million to eliminate in West and Central Africa meant that it could help 20 countries become smallpox free for the price of 39 days of preventing its reintroduction back home [35]. A similar argument was used to successfully convince the Swedish government to make a critical contribution to the programme in India, since  every country is in danger until the last case of smallpox has been eliminated  [22].  The availability of even small amounts of funding that could be used flexibly, with minimal bureaucracy, was seen as critical to bypassing bottlenecks.  It was essential to have an allocation of funds that could be used for any necessary purpose and in any country  [10], yet nearly all available funds for smallpox eradication were earmarked for specific uses. As a result, staff were often not paid on time, insufficient fuel allowances meant vehicles were not available when needed, and funding for car repairs was lacking in multiple countries [10]. In Zaire, for example, operations would frequently grind to a halt after the government failed to release the necessary funds; the programme solved the issue by setting up an auxiliary bank account in which they deposited back-up funds whenever possible to cover expenditure during these gap periods [8]. In Bihar, India,  staff were fearful of paying too much [for vehicle maintenance] and being held accountable for extra charges  [46], so vehicles were often neglected instead. New accounts were set up to give team leads advances for these minor but essential charges so that they could avoid weeks of paperwork to receive necessary funds, instead providing receipts at subsequent meetings on a biweekly or monthly basis. This approach dramatically improved the flexibility of the elimination efforts and Henderson deemed it  one of the most important initiatives of the programme  [8].  Malaria programmes today frequently experience similar delays due to challenges with financial expenditure. Many countries have failed to spend grants from the Global Fund to Fight AIDS, Tuberculosis, and Malaria on schedule due to a wide variety of issues, including lack of human resources, delays in procurement, weak data systems, and other challenges [61]. The smallpox experience suggests that the proactive creation of a flexible fund that could be used to address bottlenecks across countries as they arise could be a valuable tool for malaria as eradication proceeds, though the challenges of ensuring those funds are well spent would be substantial, and safeguards would be needed to ensure funds are spent for their intended function. This history also emphasizes the critical importance of having strong measurement and management of programmes to ensure available funds are allocated and used as effectively as possible.
359097|5|Political will has been cited as one of the most important factors in the success of smallpox eradication [14] and a necessity for eliminating malaria [34]. Not all countries viewed smallpox elimination as an urgent priority given many other public health issues [28], just as malaria elimination is often a low priority today for countries facing more visible threats [62]. Competing disease priorities, including ongoing malaria eradication efforts [29], led governments such as that of Ethiopia to have  absolutely no interest in the eradication of smallpox  [63]. Non-governmental actors such as the United Nations Children s Fund (UNICEF) also had prior commitments to malaria eradication that took precedence over contributions to smallpox [8]. Today, the need to devote substantial resources to ongoing efforts to eradicate other diseases, including guinea worm and polio, may present similar challenges for malaria.  Countries where the less virulent variola minor predominated over the far more deadly variola major, mostly in Africa, tended to downplay the importance of embarking on an elimination programme, given that this strain of the disease was  little more serious than chicken pox  [8]. Henderson cited this reticence as one of the two primary factors compromising the young programme (the other being the absence of funding) [10]. This challenge is echoed by questions of whether malaria eradication should aim to include all species of the disease or only (or initially) the more virulent Plasmodium falciparum given its outsized contribution to mortality as well as its development of resistance to artemisinin-based drugs in the Greater Mekong subregion [64, 65]. Accounts of smallpox eradication do not clarify whether an effort to only eradicate variola major could have succeeded (and thus whether a P. falciparum only attempted might be feasible), though the similarity of symptoms between the two would have complicated case finding directed only at the major variant.  Political backing also suffered with changes in government and thus the loss of advocates:  Within 4 years after the West African programme began, there were 23 changes of governments in the 18 participating countries,  causing  changing leadership and staff in the nation s smallpox programme  [47]. In India, it was noted that the Prime Minister s enthusiasm for smallpox typically increased when outbreaks were observed and thus when the electorate was most concerned about the disease and declined with smallpox incidence [22]. Pressure from powerful allies outside the government was thus seen as critical to ensure the programme remained sufficiently well supported even when smallpox was not in the headlines. An agreement to begin a vaccination programme in Ethiopia only occurred due to the intercession of a senior Austrian physician with a close relationship with the Emperor [63], while in India, the intervention of J.R.D. Tata, the well-connected head of a large corporation, played a critical role in convincing the Prime Minister to continue supporting the smallpox programme at a pivotal moment [22]. In Bhutan, where the WHO initially lacked visibility into smallpox efforts due to the secrecy of its government, an acquaintance of Henderson s with access to the royal family was eventually able to build communications with Geneva [66].  A lesson for malaria is thus the importance of getting well-connected leaders from business and high-profile institutions to act as advocates. The opinion of politicians can change based on what seems important for the next election, but smallpox programme examples show how they can be convinced by counsel from those they trust or respect. Malaria appears to already be doing a better job of identifying high-profile advocates; organizations with the explicit goal of maintaining malaria s global or regional visibility, such as Malaria No More or the African Leaders Malaria Alliance, identify champions who can contribute funding and political backing to national efforts [67], while the End Malaria Council (http://endmalariacouncil.org/) seeks to bring business leaders together with public sector leaders to keep malaria a global priority.
359097|6|Community participation with the smallpox programme was considered generally strong [8], although the literature contains numerous accounts of specific anecdotes of resistance to vaccination particularly following real or perceived adverse reactions to the vaccine [28]. Some commentators note that the narrow focus on smallpox was sometimes counterproductive given the range of health issues afflicting communities. In Bangladesh, for example, vaccination occurred in the midst of a cholera epidemic, yet the vaccinators could provide no assistance with the more visible and urgent problem, resulting in community frustration [68]. As the programme proceeded, additional components were therefore added onto the responsibilities of surveillance agents to keep them engaged and motivated despite the infrequency with which smallpox was observed, including surveys investigating access to clean water, vitamin A, family planning, and rates of childhood mortality [68]. Similarly, malaria-only health workers may prove less successful than those that have been trained to treat a variety of common illnesses [69].  Gaining the support of community leaders was commonly cited as a crucial step towards community acceptance. In Nigeria, Foege believed that people participated less because they were convinced by vaccinators to do so and more because they trusted their leaders [31]. In one extraordinary case, vaccinators were reported to have awed a village chief into supporting the programme by releasing a trained bird to swoop overhead and drop pro-vaccine leaflets while vaccinators were meeting with him [29]. Despite such anecdotes, Tarantola and Foster note that little research was conducted into how the community could best be engaged [68], though attempts to do so included deployment of midwives and other village workers to engage and educate the community [39, 70] as well as provision of monetary awards for report of a smallpox case in the final stages of the programme [71]. In India, for example, a 100 rupee reward was offered for anyone reporting a previously unknown outbreak [29]. The evidence base for what drives patient participation with the health system has increased in subsequent decades, identifying factors related to cost, proximity, and confidence [72], but the relative ability of different interventions to influence those factors likely still requires additional research. Best practices for proactive engagement of community leaders and ongoing communication and collaboration with at-risk populations should be encouraged to make communities active participants in malaria elimination programmes [73].  Where efforts to improve participation failed, smallpox programmes would sometimes use compulsory vaccination, an approach that dispensed with  the need to converse with villagers at all  [74]. Compulsory vaccination was believed to be justified by the need to achieve sufficient coverage for the greater good, but it raises troubling ethical questions. Greenough quotes Stanley Music, an epidemiologist who worked in the Bangladesh programme, on the tactics sometimes employed:   In the hit-and-run excitement of such a campaign, women and children were often pulled out from under beds, from behind doors, from within latrines, etc.  Attempts were made to secure the cooperation and  blessing  of village headmen, thereby putting social pressure on the villagers to stand their ground and accept vaccination. Still, however, some form of minor chaos was the rule, as headmen s authority did not extend into individual s homes  People were chased and, when caught, vaccinated  We went from door to door and vaccinated. When they ran, we chased. When they locked their doors, we broke down their doors and vaccinated them.  [74]  While these aggressive approaches did in some cases attain the narrow goal of achieving high vaccination coverage, they seem unwise for a programme such as malaria in which long-term participation and repeated delivery cycles is needed. Ethically, they were controversial even at the time, and  the organized and sustained use of compulsion was, generally speaking, instituted with great care and only after broad administrative and political consensus had been achieved  [22].  Engagement with the private sector was reported to be generally minimal outside a few efforts to integrate private health care providers into the vaccination programme [68]. India proved one of the main exceptions, with the Tata Group playing a critical role in vaccinating the population of Bihar State, where its steel plant was located. They provided  medical and paramedical personnel, transportation, managerial support and communication facilities to implement the programme activities. The assistance in kind provided by the Company and their local knowledge of the area were so valuable that south Bihar became smallpox-free in a record period of 6 months  [75]. Malaria s recent history includes several examples of similar partnerships [76]. Given the importance of private providers and drug shops for provision of malaria treatment [77], malaria eradication will necessitate much greater engagement with the private sector than occurred during smallpox eradication.
359097|7|Smallpox eradication was predicated on the idea of mass vaccination of the population. The WHO s Expert Committee initially called for countries to achieve at least 80% vaccination of the population [29]. This approach successfully led to elimination in some countries, but elsewhere it failed, likely because the vaccinated and unvaccinated fractions of the population were not homogenously mixed [36]. In Central Java, for example, a 1969 survey found greater than 95% vaccination rates had been achieved across the population of 23 million people, yet that same year over 1700 cases were recorded, nearly all amongst the 5% of the population who had been missed [78]. The WHO Expert Committee responded by telling countries they should strive for 100% vaccination rates, a target scorned as impossible [29]. Attempts to conduct greater numbers of vaccinations were undertaken, but  accessible groups, like schoolchildren, were vaccinated repeatedly so that high  scores  were achieved, but there always remained a large pool of unvaccinated persons  [47]. This language is mirrored in a recent investigation of bed net coverage across Africa by Bhatt et al., which concluded:   We found substantial over-allocation of nets to households already owning a sufficient quantity  What is certain is that over-allocation becomes a major barrier to achieving universal coverage when levels of [insecticide-treated bed net] provision are high because most new incoming nets are simply leading to surpluses in many households, while elsewhere there remains a shortfall. This may have a disproportionately high public health impact if those surplus nets are concentrated in households at lowest risk.  [79]  The critical change in smallpox programmes was a shift away from mass vaccination towards an approach called  surveillance-containment  [35] in which programmes sought out smallpox cases and then concentrated vaccination efforts in their proximity and towards those who may have come into contact with the cases. In short, the new strategy meant focusing vaccination on the places where it was most likely to matter, rather than laboring to achieve implausibly perfect coverage everywhere. In Bangladesh, for example, the programme successfully ended transmission after abandoning efforts to achieve 80% vaccination nationally and focusing efforts instead only on the northern districts where cases were reported [41].  The 1964, the WHO Expert Committee report did not even mention surveillance [8], but the new focus on finding cases, tracking down all of their contacts, and concentrating vaccination operations in the most necessary places was considered by many to be one of the keys to eradication s ultimate success [14, 80]. Identifying where smallpox was being transmitted required a network of agents who visited all health units (usually in teams of two to four per administrative unit) to ensure weekly reporting, sought out cases in the community, including by collaborating with teachers or visiting markets [78], and distributed surveillance reports so that the health staff saw how their reports were being used [81].  Undoubtedly, the greatest stimulus to reporting was the prompt visit of the surveillance team for outbreak investigations and control whenever cases were reported,  Henderson wrote.  This simple, obvious and direct indication that the routine weekly reports were actually seen and were a cause for public health action did more, I am sure, than the multitude of government directives which were issued  [81]. Case finding was intensified during the period of lowest seasonal incidence, since that low transmission season represented the weakest point in the smallpox cycle and the best opportunity to break transmission, despite the operational challenge of finding cases at that time of year [82]. Active case finding was integrated with routine reporting from public health facilities rather than conducted entirely in parallel [81]. Challenges to setting up good surveillance systems included the fact that in many countries, disease reporting fell under the purview of independent statistical units and were not thus within the control of the smallpox programme [10] (the same is true for malaria today in many countries).  The operational strategy of directing vaccine only to known transmission areas may not be directly translatable to malaria s tools. First, the approach may have worked in part because the reproductive rate for the virus was relatively low [35], estimated at approximately 3.5 to 6 [83], while estimates for malaria are variable but potentially far higher [84]. Second, case finding was far easier because the symptoms of the disease were so distinctive and recognizable even to schoolchildren [81], and smallpox unlike malaria [85] very rarely caused asymptomatic infections [6]. As a result, mathematical modeling of an analogous reactive case detection strategy for malaria suggested that such approaches may increase the probability of elimination in certain contexts, but would be  a highly resource intense, long-term intervention that is inappropriate in many settings where resources are limited  [86].  Nevertheless, the critical shift in smallpox programmes from judging success based on the volume of vaccinations to whether vaccination was achieved in the most necessary places still suggests a good model for malaria programmes, despite the extensive presence of asymptomatic carriage. Malaria programmes that seek only to distribute commodities such as nets or drugs in high volumes in an attempt to achieve  universal  coverage may be missing more inaccessible populations which may also be the highest risk for malaria [79, 87]. Shifting towards a risk-focused approach in which prevention and treatment are targeted to those who most need them has great potential for improving the efficiency and effectiveness of our efforts.
359097|8|Discussion of the wisdom of eradication programmes often revolves around the relative merits of  vertical,  single disease programmes versus  horizontal  health systems efforts [14], which were increasingly coming into favour at the WHO around the time of smallpox eradication. Henderson advocated for having a specific vaccination programme distinct from, yet linked to, routine health services, worrying that fully integrated programmes would lack clear objectives, evaluation systems, and management structures.  The  horizontal programmes  I have seen best describe the sleeping postures of the workers  [80], he wrote. In contrast he considered a  targeted and time-limited special programme with funds specially allocated for it, both in the WHO budget and in most national budgets, and with full-time technical staff responsible for its supervision  [10] to be superior since it would more easily attract resources and community support and likely be more efficient and better managed given the singular focus. Such programmes were also viewed as attractive because they could be conducted even while basic health services remained weak [51]. The vertical versus horizontal health programme debate has persisted since smallpox [88] and will not be resolved here, yet a few clear lessons for malaria emerge from smallpox s successes.  First, smallpox programmes were well integrated with basic health systems, enabling routine case management and surveillance, with active case finding used as a supplement rather than a replacement. This integrated design improved upon the design of the Global Malaria Eradication Programme preceding it in the 1950s and 1960s, which largely circumvented basic health systems. The malaria eradication programme measured malaria primarily via population prevalence surveys [89] and other active means [90] and conducted insecticide spray campaigns as vertical efforts. Malaria staff were also better paid than other workers and reported to heads of state rather than ministries of health, creating unsustainable systems [7]. In contrast, smallpox programmes were still part of the health system, leveraging the same basic health services and staff to identify and report the disease [10, 33]. This integration meant that smallpox teams were not required to set up fully parallel surveillance systems, instead augmenting existing ones and leaving behind some added capacity within health programmes. Similarly, reliance upon the routine, albeit imperfect, measurement of malaria that basic health systems provide across endemic regions seems likely to greatly improve the cost-effectiveness of surveillance given that it requires minimal expenditure beyond keeping health facilities stocked with diagnostic tests, training staff in their use, and linking them to effective reporting systems. Such investment in core case management systems is a primary component of WHO s Global Technical Strategy for malaria [4].  Second, multiple authors highlight the importance to smallpox programmes of creative, problem-solving staff [32] who could figure out how to overcome any obstacle that arose, tailoring solutions to the unique challenges and contexts faced by each country [10]. Henderson described:   The essence of what has made the programme what it is is, very simply, an imaginative and dedicated field staff, both national and international, who, given scope and encouragement to work out problems according to local circumstances and support in their efforts to do so, have responded with some remarkable solutions to impossible problems.  [29]  These resourceful workers, described by former United States Surgeon General Julius Richmond as  simply too young to know it couldn t be done  [50], were supported by a similarly flexible international team at WHO, who were described as:   Essentially problem-solvers, they viewed themselves as catalysts rather than as controllers. They understood from the onset that experimental learning offered the only possibility for success. They avoided formalized programming, opting instead for innovation, flexibility, communication and experiment, by means of a number of deliberate policies and mechanisms. They recruited people with practical field experience in epidemiology (as opposed to previous work with smallpox per se). They sought people with reputations for adaptability, imagination, and hard work. They preferred younger people, assuming they would be more receptive to new approaches and ideas.  [91] quoted in [39]  Henderson contrasted the flexibility with which smallpox programmes worked with the unsuccessful prior malaria eradication effort, which he said  was conceived and executed as a military operation to be conducted in an identical manner whatever the battlefield  [92], preventing it from adapting to local contexts, structures, and systems.  Third, smallpox programmes placed great emphasis on careful measurement and verification.  Logic suggests that all disease control programmes should provide continuous measurements of disease incidence, and that these measurements should dictate changes in strategy and tactics,  wrote Henderson.  In fact, few programmes do so. Responsible authorities tend to ignore such information or dismiss efforts to obtain the data and, instead, assess progress in terms of activity, such as the numbers of vaccinations performed or patients treated  [10]. Arguably, today s malaria programmes continue to focus more on activities conducted rather than impact, in part because key performance indicators reported as proof of performance on grants such as those from the Global Fund to Fight AIDS, Tuberculosis, and Malaria tend to focus on the number of nets delivered [93], rather than whether they are delivered to those most at risk or achieve desired reductions in malaria. The smallpox experience suggests that successful elimination may require shifting focus from simply tallying how many commodities have been distributed towards assessment of whether those tools are being used as effectively as possible.  In West and Central Africa, smallpox programmes used three different types of evaluation approaches: first, evaluators would follow-up to assess whether what vaccinators claimed to have done had truly been accomplished; second, tally sheet comparisons were made to compare vaccination records against any available census data, as a quick if somewhat inaccurate estimation of whether numbers were approximately what should be expected; third, spot checks for vaccine scars were conducted at markets and other convenient gathering places to provide an independent confirmation of coverage [94]. Henderson stressed that in measurement, quality was more important than quantity:  a few indicators of overall performance, closely followed, were more useful than a broad spectrum of indicators measuring many aspects of programme execution  [10].  How to build appropriate teams and processes to conduct this measurement and verification was determined on a country by country basis. In Bolivia, one inspector was appointed for every eight to 12 vaccinators, ensuring everyone s work was reviewed at least biweekly [95]. In India, a Central Appraisal Team oversaw evaluation processes, including frequent travel to trouble spots to assess what was going wrong [8]. Ensuring accurate reporting was sometimes compromised when workers avoided reporting true cases because they thought they would be punished for allowing transmission in their region [70], underscoring the importance of clear and frequent communication between central and local levels, with regular meetings to discuss problems and progress [10]. Widespread distribution of smallpox indicators was encouraged, such as through surveillance bulletins in Brazil which were distributed on a monthly basis to a wide audience, providing updates on progress, putting pressure on non-reporters to participate, and generally helping to foster a shared sense of purpose across the diverse network of individuals participating in the campaign [8].  Fourth, the smallpox programme emphasized the importance of strong management in all aspects of the programme. Henderson suggests that,  Successful execution of the programme consists of perhaps 10% technical skill and 90% organization and leadership  [29]. He stressed the importance of leaders actually spending substantial time out in the villages where the work is being done, leading by example and helping motivate workers:  effective leadership to solve the problems faced by field workers cannot be supplied by an army of physicians and senior supervisors who never leave their desks. Regrettably, these types are all too plentiful throughout the world  [29]. These opinions were substantiated by an evaluation of unsuccessful programmes in India, Pakistan, Argentina, Iran, and Ghana, which found that:   First and most important, failure appeared to be associated with inadequate supervision and assessment. Programmes that failed normally showed the following shortcomings: (a) supervisory personnel did not check at the family level to assure that broad overage by vaccination of the population was being achieved; (b) supervisors were too burdened by other responsibilities to give more than nominal supervision; (c) inadequate provisions for travel and expenses; and (d) disinclination of supervisors to undergo the inconvenience of field work.  [22]  William Foege described how  the real problems  of  developing routines, documenting the implementation of those routines, hiring the right people, supervising, motivating, and evaluating  required  managers, administrators, and logistics experts people who knew how to solve problems and how to get things done. The programme would not fail for lack of scientists, but it could fail even with the best strategy if we didn t attract the very best managers  [32]. Strong management was required to keep up staff enthusiasm for searching for smallpox when there was nothing left to find [22]; in one case, near the very end of the programme in Ethiopia, a surveillance agent walked for 15 days to check on two reported cases which turned out to be chickenpox [29].  Programmes accordingly sought to hire non-medical, logistics-oriented staff with experience in administration in addition to those with a more conventional public health background [82]. Once brought into the programme, strong managers had to be retained: in Brazil, for example, five different directors were appointed in the 5 years between 1967 and 1971 [14] with unsurprisingly weak results. Henderson suggested that providing programme leaders with management training would have been a wise idea, though it was not done at the time [10].
362307|1|At a reference transmission setting with annual entomological inoculation rate (EIR) of 21, the simulations predict that a PEV with 52% initial efficacy could be very cost-effective when delivered via EPI alone. At a vaccine price of US$2 per dose, the cost per uncomplicated malaria episode averted would be around US$ 5, the cost per severe malaria episode averted US$ 269, the cost per DALY averted around US$ 35 and the cost per death averted US$1057 (see table S1 and S2, Additional file 1). The cost-effectiveness ratios are lower for higher effectiveness levels (Figure 1). They increase almost proportionally with vaccine price reaching US$ 160 per DALY averted and US$ 4869 per death averted for a vaccine price of US$ 10 per dose (see table S3 and S4, Additional file 1). The proportion of events averted by PEV delivered via EPI with booster doses is slightly higher, but the cost per uncomplicated episode averted is 20% higher (see table S1, Additional file 1), and cost per DALY and death averted is around 31% higher (see table S2, Additional file 1).  With EPI and mass vaccination the proportion of events averted is 5% higher for mass vaccination coverage of 50% and 8% higher for coverage of 70%[14], and the cost per uncomplicated episode averted is slightly lower. However, the costs per DALY and death averted are around 60% 66% higher (see table S1 and S2, Additional file 1). For higher efficacy levels the pattern is similar, showing that the incremental benefits of these deployment modalities, in this transmission setting, are modest (Figure 1).  In low transmission settings, while the cost per uncomplicated episode averted under EPI alone is similar to that in the reference transmission setting (see table S1 and S2, Additional file 1), the cost per DALY and death averted are lower at US$ 31 per DALY averted and US$ 925 per death averted at a vaccine price of US$ 2 per dose (see table S2 and S4, Additional file 1). Adding booster doses leads to higher cost-effectiveness ratios for efficacy levels up to around 60%, but at near 100% efficacy the cost-effectiveness ratios become similar (Figure 1). In contrast, when mass vaccination is added to EPI, the cost-effectiveness ratios decrease substantially, by around 70% for the cost per uncomplicated case averted (see table S1 and S3, Additional file 1), and by 24% to 28% for the cost per DALY and death averted (see table S2 and S4, Additional file 1).  In high transmission settings, the effectiveness of PEV is low[14] and the cost-effectiveness ratios are therefore higher than in the other transmission settings irrespective of delivery modality. For some outcomes, vaccination even leads to an increase in the number of clinical events[14], and, therefore, to negative cost-effectiveness ratios and negative case management cost savings (see table S5, Additional file 1).  Across all transmission settings, the incremental benefits of booster doses are small and the cost-effectiveness ratios are higher. Adding mass campaigns has little impact on overall effect when the primary efficacy is low. However, for high vaccine efficacy and high coverage, this strategy is predicted to lead to local elimination of the parasite in low transmission settings and substantially reduce transmission in medium transmission settings[14] at low additional costs. Under these conditions, because of the effects of the vaccine on transmission, delivery via mass campaigns plus EPI becomes a cost-effective alternative to EPI alone.
362307|2|At the reference transmission intensity, BSV of moderate efficacy with a price of US$ 2 per dose applied through EPI achieves a cost per uncomplicated episode averted of about US$ 9 (see table S1, Additional file 1), which is higher than for the corresponding PEV, but the costs per DALY averted (US$ 21) and per death averted (US$ 630) are lower than for PEV (see table S2, Additional file 1). At higher efficacy levels, the cost-effectiveness ratios decrease, following the same patterns as for PEV (Figure 2). Adding booster doses increases the cost-effectiveness ratios somewhat. Mass campaigns also increase the cost-effectiveness ratios except for uncomplicated episodes, where they decrease. At low transmission intensity BSV averts a lower proportion of uncomplicated and severe cases and deaths than PEV[14] and the cost effectiveness ratios are higher for all outcomes. Adding booster doses leads to slightly higher costs per uncomplicated episode averted (see table S1 and S3, Additional file 1), and much higher costs per DALY and death averted (see table S2 and S3, Additional file 1, and Figure 2). Adding mass campaigns to EPI leads to a dramatic reduction in the cost per uncomplicated episode averted, but the costs per DALY and death averted are only slightly lower (see table S1, S2, S3, Additional file 1, and Figure 3, 4). In high transmission settings BSV is more effective than PEV especially in averting severe and mortality events[14] and it is also more efficient. Under EPI alone the cost per uncomplicated episode averted, in the highest transmission setting, is US$ 3.8, the cost per DALY averted is US$13.5 and the cost per death averted is US$401, at vaccine price US$ 2 per dose (see table S1 and S2, Additional file 1, and Figure 3). Adding boosters or mass campaigns, leads to higher incremental costs than incremental benefits (see table S1, S2, S3, Additional file 1, and Figure 2). Across all transmission settings, the incremental costs of adding booster doses to EPI are higher than the incremental benefits and this is particularly true for severe episodes, DALYs, and mortality (see table S1, S2, S3, Additional file 1, and Figure 2). In low transmission settings, campaigns improve cost-effectiveness for uncomplicated episodes averted, but do not change cost-effectiveness estimates for DALYs and deaths averted. However, in moderate to high transmission settings, the incremental costs of campaigns are higher than the incremental benefits (see table S1, S2, S3, Additional file 1, and Figure 2).
362307|3|Combining BSV with PEV (with matched efficacies) in general, improves or matches the cases averted over PEV alone for all transmission settings and vaccine delivery modalities[14]. The cost-effectiveness ratios for this combination are lower than those of PEV in all transmission settings particularly for the cost per DALY and per death averted and in moderate to high transmission settings (see table S1, S2, S3 in Additional file 1, and Figure 3, 4). Compared to BSV alone, the cost-effectiveness ratios of combining BSV with PEV are lower, though the difference is smaller than for PEV and in this case it is higher in moderate to lower transmission settings than in high transmission settings. Adding booster doses to EPI leads to higher cost-effectiveness ratios across all transmission settings for this combination   the costs per uncomplicated episode averted increases by around 19% 23% while those per DALY and death averted show even larger increases (around 30% 40%). Adding mass campaigns in low to moderate settings lead to incremental uncomplicated episodes averted that are higher than the incremental costs. However, in terms of DALYs and deaths averted the benefits exceed the costs only in the lowest transmission setting, while they are significantly lower in the reference and in high transmission settings. In high transmission settings even the additional uncomplicated episodes averted are lower than the additional costs. Combinations of MS TBV with PEV or BSV and the triple combination do not improve the effectiveness of the vaccines alone when delivered via EPI or EPI with boosters[14]. However, adding mass campaigns leads to greater effectiveness in all transmission settings (Figure 4). The additional benefits of these combination vaccines are then much higher than the additional costs compared to delivering the vaccines under EPI alone and to all delivery modalities of PEV and BSV alone. In the reference transmission setting, for instance, the cost per uncomplicated episode averted of combining BSV with MSTBV, delivered via EPI and mass campaigns, is (at a vaccine price of US$2) US$1.8 and US$2.3 for 70% and 50% coverage (see table S1, Additional file 1), while the cost per DALY averted is US$20 and US$ 22 for 70% and 50% coverage (see table S2, Additional file 1). The costs per DALY averted vary between US$ 12 and US$40 across transmission settings with the lowest value in the lowest transmission setting where the greatest improvement to effectiveness is observed. The very favourable cost-effectiveness ratios in low transmission settings are related to the case-management cost savings, which may compensate up to more than 50% of the costs of the vaccine intervention (see table S4, Additional file 1).
362307|4|Adding boosters to EPI does not improve effectiveness or cases averted over EPI alone by very much even at the very high coverage level modeled, but it does incur additional costs. This delivery modality does therefore not represent a cost-effective alternative to EPI alone in any scenario (see table S1, S2, S3, Additional file 1). Delivering all vaccines and combinations via population based campaigns improves the effectiveness at mass vaccination coverage of 50%, especially in low transmission settings[14]. Depending on the transmission setting and the vaccine type considered, the incremental costs of delivering vaccines via population based campaigns can be lower than the incremental benefits, leading to a significant reduction in the cost-effectiveness ratios (see table S1, S2, S3, Additional file 1, and Figure 4). Disseminating vaccines via population-based campaign in these cases is predicted to be a more cost-effective way of delivering malaria vaccines than EPI alone. Increasing the coverage of the mass vaccination campaigns increases the effectiveness and cases averted for all vaccine and vaccine combinations under most transmission settings[14]. However, the incremental benefits of increasing coverage are often lower than the incremental costs of achieving it (Figure 5). In some cases, the predictions suggest an optimal cost-effectiveness ratio at intermediate values for the campaign coverage. This is not a consequence of non-proportionality of vaccine delivery costs as a function of coverage (which could be realistic, but not modeled in this study), but of the indirect effects of the vaccines.
362307|5|Although the simulations focus on comparative cost-effectiveness of different candidate malaria vaccines and delivery modalities, and not on the sensitivity of cost-effectiveness ratios to vaccine prices, which are hypothetical, it is evident that the cost-effectiveness results are almost directly proportional to the vaccine prices. In fact, at an assumed vaccine price of US$ 10 per dose, most cost-effectiveness ratios are between 4 and 7 times higher than those obtained at US$ 2 per dose (see table S1, S2, S3, Additional file 1). At a vaccine price of US$ 2 per dose, most vaccines and delivery modalities simulated present cost-effectiveness ratios comparable to those of other malaria interventions[9, 10, 41 43], while at a vaccine price of US$ 10 per dose in many of the simulated scenarios the cost-effectiveness ratios are higher.
